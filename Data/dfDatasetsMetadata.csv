"ID","Package","Item","Title","RowsCount","ColumnsCount","BinaryColumnsCount","CharacterColumnsCount","FactorColumnsCount","LogicalColumnsCount","NumericColumnsCount","CSVURL","DocURL","Description"
"AER-Affairs","AER","Affairs","Fair's Extramarital Affairs Data",601,9,2,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Affairs.html","Affairs R Documentation   Fair's Extramarital Affairs Data   Description  
Infidelity data, known as Fair's Affairs. Cross-section data from a survey conducted by Psychology Today in 1969.    Usage   data(""Affairs"")   Format  
A data frame containing 601 observations on 9 variables.    affairs
numeric. How often engaged in extramarital sexual intercourse during the past year? 0 = none, 1 = once, 2 = twice,  3 = 3 times, 7 = 4–10 times, 12 = monthly,  12 = weekly, 12 = daily.   gender
factor indicating gender.   age
numeric variable coding age in years: 17.5 = under 20, 22 = 20–24,  27 = 25–29, 32 = 30–34, 37 = 35–39, 42 = 40–44,  47 = 45–49, 52 = 50–54, 57 = 55 or over.   yearsmarried
numeric variable coding number of years married: 0.125 = 3 months or less,  0.417 = 4–6 months, 0.75 = 6 months–1 year, 1.5 = 1–2 years,  4 = 3–5 years, 7 = 6–8 years, 10 = 9–11 years, 15 = 12 or more years.   children
factor. Are there children in the marriage?   religiousness
numeric variable coding religiousness: 1 = anti, 2 = not at all,  3 = slightly, 4 = somewhat, 5 = very.   education
numeric variable coding level of education: 9 = grade school,  12 = high school graduate, 14 = some college, 16 = college graduate,  17 = some graduate work, 18 = master's degree, 20 = Ph.D., M.D., or other advanced degree.   occupation
numeric variable coding occupation according to Hollingshead classification (reverse numbering).   rating
numeric variable coding self rating of marriage: 1 = very unhappy,  2 = somewhat unhappy, 3 = average, 4 = happier than average, 5 = very happy.     Source  
Online complements to Greene (2003). Table F22.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Fair, R.C. (1978). A Theory of Extramarital Affairs. Journal of Political Economy ,  86 , 45–61.    See Also  
Greene2003   Examples    data(""Affairs"") ## Greene (2003) ## Tab. 22.3 and 22.4 fm_ols <- lm(affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs) fm_probit <- glm(I(affairs > 0) ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs, family = binomial(link = ""probit"")) fm_tobit <- tobit(affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs) fm_tobit2 <- tobit(affairs ~ age + yearsmarried + religiousness + occupation + rating, right = 4, data = Affairs) fm_pois <- glm(affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs, family = poisson) library(""MASS"") fm_nb <- glm.nb(affairs ~ age + yearsmarried + religiousness + occupation + rating, data = Affairs) ## Tab. 22.6 library(""pscl"") fm_zip <- zeroinfl(affairs ~ age + yearsmarried + religiousness + occupation + rating | age + yearsmarried + religiousness + occupation + rating, data = Affairs)"
"AER-ArgentinaCPI","AER","ArgentinaCPI","Consumer Price Index in Argentina",80,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ArgentinaCPI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ArgentinaCPI.html","ArgentinaCPI R Documentation   Consumer Price Index in Argentina   Description  
Time series of consumer price index (CPI) in Argentina (index with 1969(4) = 1).    Usage   data(""ArgentinaCPI"")   Format  
A quarterly univariate time series from 1970(1) to 1989(4).    Source  
Online complements to Franses (1998).    References  
De Ruyter van Steveninck, M.A. (1996). The Impact of Capital Imports; Argentina 1970–1989 . Amsterdam: Thesis Publishers.   
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""ArgentinaCPI"") plot(ArgentinaCPI) plot(log(ArgentinaCPI)) library(""dynlm"") ## estimation sample 1970.3-1988.4 means acpi <- window(ArgentinaCPI, start = c(1970,1), end = c(1988,4)) ## eq. (3.90), p.54 acpi_ols <- dynlm(d(log(acpi)) ~ L(d(log(acpi)))) summary(acpi_ols) ## alternatively ar(diff(log(acpi)), order.max = 1, method = ""ols"")"
"AER-BankWages","AER","BankWages","Bank Wages",474,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/BankWages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/BankWages.html","BankWages R Documentation   Bank Wages   Description  
Wages of employees of a US bank.    Usage   data(""BankWages"")   Format  
A data frame containing 474 observations on 4 variables.    job
Ordered factor indicating job category, with levels ""custodial"" ,  ""admin"" and ""manage"" .   education
Education in years.   gender
Factor indicating gender.   minority
Factor. Is the employee member of a minority?     Source  
Online complements to Heij, de Boer, Franses, Kloek, and van Dijk (2004).  
http://www.oup.com/uk/booksites/content/0199268010/datasets/ch6/xr614bwa.asc     References  
Heij, C., de Boer, P.M.C., Franses, P.H., Kloek, T. and van Dijk, H.K. (2004). Econometric Methods with Applications in Business and Economics . Oxford: Oxford University Press.    Examples    data(""BankWages"") ## exploratory analysis of job ~ education ## (tables and spine plots, some education levels merged) xtabs(~ education + job, data = BankWages) edcat <- factor(BankWages$education) levels(edcat)[3:10] <- rep(c(""14-15"", ""16-18"", ""19-21""), c(2, 3, 3)) tab <- xtabs(~ edcat + job, data = BankWages) prop.table(tab, 1) spineplot(tab, off = 0) plot(job ~ edcat, data = BankWages, off = 0) ## fit multinomial model for male employees library(""nnet"") fm_mnl <- multinom(job ~ education + minority, data = BankWages, subset = gender == ""male"", trace = FALSE) summary(fm_mnl) confint(fm_mnl) ## same with mlogit package if(require(""mlogit"")) { fm_mlogit <- mlogit(job ~ 1 | education + minority, data = BankWages, subset = gender == ""male"", shape = ""wide"", reflevel = ""custodial"") summary(fm_mlogit) }"
"AER-BenderlyZwick","AER","BenderlyZwick","Benderly and Zwick Data: Inflation, Growth and Stock Returns",31,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/BenderlyZwick.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/BenderlyZwick.html","BenderlyZwick R Documentation   Benderly and Zwick Data: Inflation, Growth and Stock Returns   Description  
Time series data, 1952–1982.   Usage   data(""BenderlyZwick"")   Format  
An annual multiple time series from 1952 to 1982 with 5 variables.    returns
real annual returns on stocks, measured using the Ibbotson-Sinquefeld data base.   growth
annual growth rate of output, measured by real GNP (from the given year to the next year).   inflation
inflation rate, measured as growth of price rate (from December of the previous year to December of the present year).   growth2
annual growth rate of real GNP as given by Baltagi.   inflation2
inflation rate as given by Baltagi     Source  
The first three columns of the data are from Table 1 in Benderly and Zwick (1985). The remaining columns are taken from the online complements of Baltagi (2002). The first column is identical in both sources, the other two variables differ in their numeric values and additionally the growth series seems to be lagged differently. Baltagi (2002) states Lott and Ray (1992) as the source for his version of the data set.    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Benderly, J., and Zwick, B. (1985). Inflation, Real Balances, Output and Real Stock Returns. American Economic Review , 75 , 1115–1123.   
Lott, W.F., and Ray, S.C. (1992). Applied Econometrics: Problems with Data Sets . New York: The Dryden Press.   
Zaman, A., Rousseeuw, P.J., and Orhan, M. (2001). Econometric Applications of High-Breakdown Robust Regression Techniques. Economics Letters , 71 , 1–8.    See Also  
Baltagi2002   Examples    data(""BenderlyZwick"") plot(BenderlyZwick) ## Benderly and Zwick (1985), p. 1116 library(""dynlm"") bz_ols <- dynlm(returns ~ growth + inflation, data = BenderlyZwick/100, start = 1956, end = 1981) summary(bz_ols) ## Zaman, Rousseeuw and Orhan (2001) ## use larger period, without scaling bz_ols2 <- dynlm(returns ~ growth + inflation, data = BenderlyZwick, start = 1954, end = 1981) summary(bz_ols2)"
"AER-BondYield","AER","BondYield","Bond Yield Data",60,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/BondYield.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/BondYield.html","BondYield R Documentation   Bond Yield Data   Description  
Monthly averages of the yield on a Moody's Aaa rated corporate bond (in percent/year).   Usage   data(""BondYield"")   Format  
A monthly univariate time series from 1990(1) to 1994(12).    Source  
Online complements to Greene (2003), Table F20.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""BondYield"") plot(BondYield)"
"AER-CartelStability","AER","CartelStability","CartelStability",328,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CartelStability.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CartelStability.html","CartelStability R Documentation   CartelStability   Description  
Weekly observations on prices and other factors from 1880–1886, for a total of 326 weeks.    Usage   data(""CartelStability"")   Format  
A data frame containing 328 observations on 5 variables.    price
weekly index of price of shipping a ton of grain by rail.   cartel
factor. Is a railroad cartel operative?   quantity
total tonnage of grain shipped in the week.   season
factor indicating season of year. To match the weekly data, the calendar has been divided into 13 periods, each approximately 4 weeks long.   ice
factor. Are the Great Lakes innavigable because of ice?     Source  
Online complements to Stock and Watson (2007).   References  
Porter, R. H. (1983). A Study of Cartel Stability: The Joint Executive Committee, 1880–1886. The Bell Journal of Economics , 14 , 301–314.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""CartelStability"") summary(CartelStability)"
"AER-CASchools","AER","CASchools","California Test Score Data",420,14,1,2,2,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CASchools.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CASchools.html","CASchools R Documentation   California Test Score Data   Description  
The dataset contains data on test performance, school characteristics and student demographic backgrounds for school districts in California.   Usage   data(""CASchools"")   Format  
A data frame containing 420 observations on 14 variables.    district
character. District code.   school
character. School name.   county
factor indicating county.   grades
factor indicating grade span of district.   students
Total enrollment.   teachers
Number of teachers.   calworks
Percent qualifying for CalWorks (income assistance).   lunch
Percent qualifying for reduced-price lunch.   computer
Number of computers.   expenditure
Expenditure per student.   income
District average income (in USD 1,000).   english
Percent of English learners.   read
Average reading score.   math
Average math score.     Details  
The data used here are from all 420 K-6 and K-8 districts in California with data available for 1998 and 1999. Test scores are on the Stanford 9 standardized test administered to 5th grade students. School characteristics (averaged across the district) include enrollment, number of teachers (measured as “full-time equivalents”, number of computers per classroom, and expenditures per student. Demographic variables for the students are averaged across the district. The demographic variables include the percentage of students in the public assistance program CalWorks (formerly AFDC), the percentage of students that qualify for a reduced price lunch, and the percentage of students that are English learners (that is, students for whom English is a second language).   Source  
Online complements to Stock and Watson (2007).   References  
Stock, J. H. and Watson, M. W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , MASchools   Examples    ## data and transformations data(""CASchools"") CASchools$stratio <- with(CASchools, students/teachers) CASchools$score <- with(CASchools, (math + read)/2) ## Stock and Watson (2007) ## p. 152 fm1 <- lm(score ~ stratio, data = CASchools) coeftest(fm1, vcov = sandwich) ## p. 159 fm2 <- lm(score ~ I(stratio < 20), data = CASchools) ## p. 199 fm3 <- lm(score ~ stratio + english, data = CASchools) ## p. 224 fm4 <- lm(score ~ stratio + expenditure + english, data = CASchools) ## Table 7.1, p. 242 (numbers refer to columns) fmc3 <- lm(score ~ stratio + english + lunch, data = CASchools) fmc4 <- lm(score ~ stratio + english + calworks, data = CASchools) fmc5 <- lm(score ~ stratio + english + lunch + calworks, data = CASchools) ## More examples can be found in: ## help(""StockWatson2007"")"
"AER-ChinaIncome","AER","ChinaIncome","Chinese Real National Income Data",37,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ChinaIncome.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ChinaIncome.html","ChinaIncome R Documentation   Chinese Real National Income Data   Description  
Time series of real national income in China per section (index with 1952 = 100).    Usage   data(""ChinaIncome"")   Format  
An annual multiple time series from 1952 to 1988 with 5 variables.    agriculture
Real national income in agriculture sector.   industry
Real national income in industry sector.   construction
Real national income in construction sector.   transport
Real national income in transport sector.   commerce
Real national income in commerce sector.     Source  
Online complements to Franses (1998).    References  
Chow, G.C. (1993). Capital Formation and Economic Growth in China.  Quarterly Journal of Economics , 103 , 809–842.   
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""ChinaIncome"") plot(ChinaIncome)"
"AER-CigarettesB","AER","CigarettesB","Cigarette Consumption Data",46,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CigarettesB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CigarettesB.html","CigarettesB R Documentation   Cigarette Consumption Data   Description  
Cross-section data on cigarette consumption for 46 US States, for the year 1992.    Usage   data(""CigarettesB"")   Format  
A data frame containing 46 observations on 3 variables.   packs
Logarithm of cigarette consumption (in packs) per person of smoking age (> 16 years).   price
Logarithm of real price of cigarette in each state.   income
Logarithm of real disposable income (per capita) in each state.     Source  
The data are from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Baltagi, B.H. and Levin, D. (1992). Cigarette Taxation: Raising Revenues and Reducing Consumption. Structural Change and Economic Dynamics , 3 , 321–335.    See Also  
Baltagi2002 , CigarettesSW   Examples    data(""CigarettesB"") ## Baltagi (2002) ## Table 3.3 cig_lm <- lm(packs ~ price, data = CigarettesB) summary(cig_lm) ## Chapter 5: diagnostic tests (p. 111-115) cig_lm2 <- lm(packs ~ price + income, data = CigarettesB) summary(cig_lm2) ## Glejser tests (p. 112) ares <- abs(residuals(cig_lm2)) summary(lm(ares ~ income, data = CigarettesB)) summary(lm(ares ~ I(1/income), data = CigarettesB)) summary(lm(ares ~ I(1/sqrt(income)), data = CigarettesB)) summary(lm(ares ~ sqrt(income), data = CigarettesB)) ## Goldfeld-Quandt test (p. 112) gqtest(cig_lm2, order.by = ~ income, data = CigarettesB, fraction = 12, alternative = ""less"") ## NOTE: Baltagi computes the test statistic as mss1/mss2, ## i.e., tries to find decreasing variances. gqtest() always uses ## mss2/mss1 and has an ""alternative"" argument. ## Spearman rank correlation test (p. 113) cor.test(~ ares + income, data = CigarettesB, method = ""spearman"") ## Breusch-Pagan test (p. 113) bptest(cig_lm2, varformula = ~ income, data = CigarettesB, student = FALSE) ## White test (Table 5.1, p. 113) bptest(cig_lm2, ~ income * price + I(income^2) + I(price^2), data = CigarettesB) ## White HC standard errors (Table 5.2, p. 114) coeftest(cig_lm2, vcov = vcovHC(cig_lm2, type = ""HC1"")) ## Jarque-Bera test (Figure 5.2, p. 115) hist(residuals(cig_lm2), breaks = 16, ylim = c(0, 10), col = ""lightgray"") library(""tseries"") jarque.bera.test(residuals(cig_lm2)) ## Tables 8.1 and 8.2 influence.measures(cig_lm2) ## More examples can be found in: ## help(""Baltagi2002"")"
"AER-CigarettesSW","AER","CigarettesSW","Cigarette Consumption Panel Data",96,9,2,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CigarettesSW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CigarettesSW.html","CigarettesSW R Documentation   Cigarette Consumption Panel Data   Description  
Panel data on cigarette consumption for the 48 continental US States from 1985–1995.    Usage   data(""CigarettesSW"")   Format  
A data frame containing 48 observations on 7 variables for 2 periods.   state
Factor indicating state.   year
Factor indicating year.   cpi
Consumer price index.   population
State population.   packs
Number of packs per capita.   income
State personal income (total, nominal).   tax
Average state, federal and average local excise taxes for fiscal year.   price
Average price during fiscal year, including sales tax.   taxs
Average excise taxes for fiscal year, including sales tax.     Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CigarettesB   Examples    ## Stock and Watson (2007) ## data and transformations data(""CigarettesSW"") CigarettesSW$rprice <- with(CigarettesSW, price/cpi) CigarettesSW$rincome <- with(CigarettesSW, income/population/cpi) CigarettesSW$rtax <- with(CigarettesSW, tax/cpi) CigarettesSW$rtdiff <- with(CigarettesSW, (taxs - tax)/cpi) c1985 <- subset(CigarettesSW, year == ""1985"") c1995 <- subset(CigarettesSW, year == ""1995"") ## convenience function: HC1 covariances hc1 <- function(x) vcovHC(x, type = ""HC1"") ## Equations 12.9--12.11 fm_s1 <- lm(log(rprice) ~ rtdiff, data = c1995) coeftest(fm_s1, vcov = hc1) fm_s2 <- lm(log(packs) ~ fitted(fm_s1), data = c1995) fm_ivreg <- ivreg(log(packs) ~ log(rprice) | rtdiff, data = c1995) coeftest(fm_ivreg, vcov = hc1) ## Equation 12.15 fm_ivreg2 <- ivreg(log(packs) ~ log(rprice) + log(rincome) | log(rincome) + rtdiff, data = c1995) coeftest(fm_ivreg2, vcov = hc1) ## Equation 12.16 fm_ivreg3 <- ivreg(log(packs) ~ log(rprice) + log(rincome) | log(rincome) + rtdiff + rtax, data = c1995) coeftest(fm_ivreg3, vcov = hc1) ## More examples can be found in: ## help(""StockWatson2007"")"
"AER-CollegeDistance","AER","CollegeDistance","College Distance Data",4739,14,7,0,8,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CollegeDistance.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CollegeDistance.html","CollegeDistance R Documentation   College Distance Data   Description  
Cross-section data from the High School and Beyond survey conducted by the Department of Education in 1980, with a follow-up in 1986. The survey included students from approximately 1,100 high schools.    Usage   data(""CollegeDistance"")   Format  
A data frame containing 4,739 observations on 14 variables.    gender
factor indicating gender.   ethnicity
factor indicating ethnicity (African-American, Hispanic or other).   score
base year composite test score. These are achievement tests given to high school seniors in the sample.   fcollege
factor. Is the father a college graduate?   mcollege
factor. Is the mother a college graduate?   home
factor. Does the family own their home?   urban
factor. Is the school in an urban area?   unemp
county unemployment rate in 1980.   wage
state hourly wage in manufacturing in 1980.   distance
distance from 4-year college (in 10 miles).   tuition
average state 4-year college tuition (in 1000 USD).   education
number of years of education.   income
factor. Is the family income above USD 25,000 per year?   region
factor indicating region (West or other).     Details  
Rouse (1995) computed years of education by assigning 12 years to all members of the senior class. Each additional year of secondary education counted as a one year. Students with vocational degrees were assigned 13 years, AA degrees were assigned 14 years, BA degrees were assigned 16 years, those with some graduate education were assigned 17 years, and those with a graduate degree were assigned 18 years.   
Stock and Watson (2007) provide separate data files for the students from Western states and the remaining students. CollegeDistance includes both data sets, subsets are easily obtained (see also examples).    Source  
Online complements to Stock and Watson (2007).   References  
Rouse, C.E. (1995). Democratization or Diversion? The Effect of Community Colleges on Educational Attainment. Journal of Business \& Economic Statistics ,  12 , 217–224.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## exclude students from Western states data(""CollegeDistance"") cd <- subset(CollegeDistance, region != ""west"") summary(cd)"
"AER-ConsumerGood","AER","ConsumerGood","Properties of a Fast-Moving Consumer Good",108,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ConsumerGood.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ConsumerGood.html","ConsumerGood R Documentation   Properties of a Fast-Moving Consumer Good   Description  
Time series of distribution, market share and price of a fast-moving consumer good.    Usage   data(""ConsumerGood"")   Format  
A weekly multiple time series from 1989(11) to 1991(9) with 3 variables.    distribution
Distribution.   share
Market share.   price
Price.     Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""ConsumerGood"") plot(ConsumerGood)"
"AER-CPS1985","AER","CPS1985","Determinants of Wages Data (CPS 1985)",534,11,4,0,7,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPS1985.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPS1985.html","CPS1985 R Documentation   Determinants of Wages Data (CPS 1985)   Description  
Cross-section data originating from the May 1985 Current Population Survey by the US Census Bureau (random sample drawn for Berndt 1991).    Usage   data(""CPS1985"")   Format  
A data frame containing 534 observations on 11 variables.    wage
Wage (in dollars per hour).   education
Number of years of education.   experience
Number of years of potential work experience ( age - education - 6 ).   age
Age in years.   ethnicity
Factor with levels ""cauc"" , ""hispanic"" ,  ""other"" .   region
Factor. Does the individual live in the South?   gender
Factor indicating gender.   occupation
Factor with levels ""worker"" (tradesperson or assembly line worker),  ""technical"" (technical or professional worker), ""services"" (service worker), ""office"" (office and clerical worker), ""sales"" (sales worker),  ""management"" (management and administration).   sector
Factor with levels ""manufacturing"" (manufacturing or mining),  ""construction"" , ""other"" .   union
Factor. Does the individual work on a union job?   married
Factor. Is the individual married?     Source  
StatLib.  
http://lib.stat.cmu.edu/datasets/CPS_85_Wages     References  
Berndt, E.R. (1991). The Practice of Econometrics . New York: Addison-Wesley.    See Also  
CPS1988 , CPSSW   Examples    data(""CPS1985"") ## Berndt (1991) ## Exercise 2, p. 196 cps_2b <- lm(log(wage) ~ union + education, data = CPS1985) cps_2c <- lm(log(wage) ~ -1 + union + education, data = CPS1985) ## Exercise 3, p. 198/199 cps_3a <- lm(log(wage) ~ education + experience + I(experience^2), data = CPS1985) cps_3b <- lm(log(wage) ~ gender + education + experience + I(experience^2), data = CPS1985) cps_3c <- lm(log(wage) ~ gender + married + education + experience + I(experience^2), data = CPS1985) cps_3e <- lm(log(wage) ~ gender*married + education + experience + I(experience^2), data = CPS1985) ## Exercise 4, p. 199/200 cps_4a <- lm(log(wage) ~ gender + union + ethnicity + education + experience + I(experience^2), data = CPS1985) cps_4c <- lm(log(wage) ~ gender + union + ethnicity + education * experience + I(experience^2), data = CPS1985) ## Exercise 6, p. 203 cps_6a <- lm(log(wage) ~ gender + union + ethnicity + education + experience + I(experience^2), data = CPS1985) cps_6a_noeth <- lm(log(wage) ~ gender + union + education + experience + I(experience^2), data = CPS1985) anova(cps_6a_noeth, cps_6a) ## Exercise 8, p. 208 cps_8a <- lm(log(wage) ~ gender + union + ethnicity + education + experience + I(experience^2), data = CPS1985) summary(cps_8a) coeftest(cps_8a, vcov = vcovHC(cps_8a, type = ""HC0""))"
"AER-CPS1988","AER","CPS1988","Determinants of Wages Data (CPS 1988)",28155,7,3,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPS1988.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPS1988.html","CPS1988 R Documentation   Determinants of Wages Data (CPS 1988)   Description  
Cross-section data originating from the March 1988 Current Population Survey by the US Census Bureau.    Usage   data(""CPS1988"")   Format  
A data frame containing 28,155 observations on 7 variables.    wage
Wage (in dollars per week).   education
Number of years of education.   experience
Number of years of potential work experience.   ethnicity
Factor with levels ""cauc"" and ""afam"" (African-American).   smsa
Factor. Does the individual reside in a Standard Metropolitan Statistical Area (SMSA)?   region
Factor with levels ""northeast"" , ""midwest"" , ""south"" , ""west"" .   parttime
Factor. Does the individual work part-time?     Details  
A sample of men aged 18 to 70 with positive annual income greater than USD 50 in 1992, who are not self-employed nor working without pay. Wages are deflated by the deflator of Personal Consumption Expenditure for 1992.   
A problem with CPS data is that it does not provide actual work experience. It is therefore customary to compute experience as age - education - 6 (as was done by Bierens and Ginther, 2001), this may be considered potential experience. As a result, some respondents have negative experience.    Source  
http://www.personal.psu.edu/hxb11/MEDIAN.HTM     References  
Bierens, H.J., and Ginther, D. (2001). Integrated Conditional Moment Testing of Quantile Regression Models. Empirical Economics , 26 , 307–324.   
Buchinsky, M. (1998). Recent Advances in Quantile Regression Models: A Practical Guide for Empirical Research. Journal of Human Resources , 33 , 88–126.    See Also  
CPS1985 , CPSSW   Examples    ## data and packages library(""quantreg"") data(""CPS1988"") CPS1988$region <- relevel(CPS1988$region, ref = ""south"") ## Model equations: Mincer-type, quartic, Buchinsky-type mincer <- log(wage) ~ ethnicity + education + experience + I(experience^2) quart <- log(wage) ~ ethnicity + education + experience + I(experience^2) + I(experience^3) + I(experience^4) buchinsky <- log(wage) ~ ethnicity * (education + experience + parttime) + region*smsa + I(experience^2) + I(education^2) + I(education*experience) ## OLS and LAD fits (for LAD see Bierens and Ginter, Tables 1-3.A.) mincer_ols <- lm(mincer, data = CPS1988) mincer_lad <- rq(mincer, data = CPS1988) quart_ols <- lm(quart, data = CPS1988) quart_lad <- rq(quart, data = CPS1988) buchinsky_ols <- lm(buchinsky, data = CPS1988) buchinsky_lad <- rq(buchinsky, data = CPS1988)"
"AER-CPSSW04","AER","CPSSW04","Stock and Watson CPS Data Sets",7986,4,2,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSW04.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSW04.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CPSSW3","AER","CPSSW3","Stock and Watson CPS Data Sets",20999,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSW3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSW3.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CPSSW8","AER","CPSSW8","Stock and Watson CPS Data Sets",61395,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSW8.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSW8.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CPSSW9204","AER","CPSSW9204","Stock and Watson CPS Data Sets",15588,5,3,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSW9204.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSW9204.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CPSSW9298","AER","CPSSW9298","Stock and Watson CPS Data Sets",13501,5,3,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSW9298.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSW9298.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CPSSWEducation","AER","CPSSWEducation","Stock and Watson CPS Data Sets",2950,4,2,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CPSSWEducation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CPSSWEducation.html","CPSSW R Documentation   Stock and Watson CPS Data Sets   Description  
Stock and Watson (2007) provide several subsets created from March Current Population Surveys (CPS) with data on the relationship of earnings and education over several year.    Usage    data(""CPSSW9204"") data(""CPSSW9298"") data(""CPSSW04"") data(""CPSSW3"") data(""CPSSW8"") data(""CPSSWEducation"")    Format  
CPSSW9298 : A data frame containing 13,501 observations on 5 variables.  CPSSW9204 : A data frame containing 15,588 observations on 5 variables.  CPSSW04 : A data frame containing 7,986 observations on 4 variables.  CPSSW3 : A data frame containing 20,999 observations on 3 variables.  CPSSW8 : A data frame containing 61,395 observations on 5 variables.  CPSSWEducation : A data frame containing 2,950 observations on 4 variables.    year
factor indicating year.   earnings
average hourly earnings (sum of annual pretax wages, salaries, tips, and bonuses, divided by the number of hours worked annually).   education
number of years of education.   degree
factor indicating highest educational degree ( ""bachelor""  or ""highschool"" ).   gender
factor indicating gender.   age
age in years.   region
factor indicating region of residence ( ""Northeast"" , ""Midwest"" , ""South"" , ""West"" ).     Details  
Each month the Bureau of Labor Statistics in the US Department of Labor conducts the Current Population Survey (CPS), which provides data on labor force characteristics of the population, including the level of employment, unemployment, and earnings. Approximately 65,000 randomly selected US households are surveyed each month. The sample is chosen by randomly selecting addresses from a database. Details can be found in the Handbook of Labor Statistics and is described on the Bureau of Labor Statistics website ( http://www.bls.gov/ ).   
The survey conducted each March is more detailed than in other months and asks questions about earnings during the previous year. The data sets contain data for 2004 (from the March 2005 survey), and some also for earlier years (up to 1992).  
If education is given, it is for full-time workers, defined as workers employed more than 35 hours per week for at least 48 weeks in the previous year. Data are provided for workers whose highest educational achievement is a high school diploma and a bachelor's degree.   
Earnings for years earlier than 2004 were adjusted for inflation by putting them in 2004 USD using the Consumer Price Index (CPI). From 1992 to 2004, the price of the CPI market basket rose by 34.6%. To make earnings in 1992 and 2004 comparable, 1992 earnings are inflated by the amount of overall CPI price inflation, by multiplying 1992 earnings by 1.346 to put them into 2004 dollars.   
CPSSW9204 provides the distribution of earnings in the US in 1992 and 2004 for college-educated full-time workers aged 25–34.  CPSSW04 is a subset of CPSSW9204 and provides the distribution of earnings in the US in 2004 for college-educated full-time workers aged 25–34.  CPSSWEducation is similar (but not a true subset) and contains the distribution of earnings in the US in 2004 for college-educated full-time workers aged 29–30.  CPSSW8 contains a larger sample with workers aged 21–64, additionally providing information about the region of residence.  CPSSW9298 is similar to CPSSW9204 providing data from 1992 and 1998 (with the 1992 subsets not being exactly identical).  CPSSW3 provides trends (from 1992 to 2004) in hourly earnings in the US of working college graduates aged 25–34 (in 2004 USD).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CPS1985 , CPS1988   Examples    data(""CPSSW3"") with(CPSSW3, interaction.plot(year, gender, earnings)) ## Stock and Watson, p. 165 data(""CPSSWEducation"") plot(earnings ~ education, data = CPSSWEducation) fm <- lm(earnings ~ education, data = CPSSWEducation) coeftest(fm, vcov = sandwich) abline(fm)"
"AER-CreditCard","AER","CreditCard","Expenditure and Default Data",1319,12,4,0,3,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/CreditCard.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/CreditCard.html","CreditCard R Documentation   Expenditure and Default Data   Description  
Cross-section data on the credit history for a sample of applicants for a type of credit card.    Usage   data(""CreditCard"")   Format  
A data frame containing 1,319 observations on 12 variables.    card
Factor. Was the application for a credit card accepted?   reports
Number of major derogatory reports.   age
Age in years plus twelfths of a year.   income
Yearly income (in USD 10,000).   share
Ratio of monthly credit card expenditure to yearly income.   expenditure
Average monthly credit card expenditure.   owner
Factor. Does the individual own their home?   selfemp
Factor. Is the individual self-employed?   dependents
Number of dependents.   months
Months living at current address.   majorcards
Number of major credit cards held.   active
Number of active credit accounts.     Details  
According to Greene (2003, p. 952) dependents equals 1 + number of dependents , our calculations suggest that it equals number of dependents .   
Greene (2003) provides this data set twice in Table F21.4 and F9.1, respectively. Table F9.1 has just the observations, rounded to two digits. Here, we give the F21.4 version, see the examples for the F9.1 version. Note that age has some suspiciously low values (below one year) for some applicants. One of these differs between the F9.1 and F21.4 version.    Source  
Online complements to Greene (2003). Table F21.4.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""CreditCard"") ## Greene (2003) ## extract data set F9.1 ccard <- CreditCard[1:100,] ccard$income <- round(ccard$income, digits = 2) ccard$expenditure <- round(ccard$expenditure, digits = 2) ccard$age <- round(ccard$age + .01) ## suspicious: CreditCard$age[CreditCard$age < 1] ## the first of these is also in TableF9.1 with 36 instead of 0.5: ccard$age[79] <- 36 ## Example 11.1 ccard <- ccard[order(ccard$income),] ccard0 <- subset(ccard, expenditure > 0) cc_ols <- lm(expenditure ~ age + owner + income + I(income^2), data = ccard0) ## Figure 11.1 plot(residuals(cc_ols) ~ income, data = ccard0, pch = 19) ## Table 11.1 mean(ccard$age) prop.table(table(ccard$owner)) mean(ccard$income) summary(cc_ols) sqrt(diag(vcovHC(cc_ols, type = ""HC0""))) sqrt(diag(vcovHC(cc_ols, type = ""HC2""))) sqrt(diag(vcovHC(cc_ols, type = ""HC1""))) bptest(cc_ols, ~ (age + income + I(income^2) + owner)^2 + I(age^2) + I(income^4), data = ccard0) gqtest(cc_ols) bptest(cc_ols, ~ income + I(income^2), data = ccard0, studentize = FALSE) bptest(cc_ols, ~ income + I(income^2), data = ccard0) ## More examples can be found in: ## help(""Greene2003"")"
"AER-DJFranses","AER","DJFranses","Dow Jones Index Data (Franses)",770,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DJFranses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/DJFranses.html","DJFranses R Documentation   Dow Jones Index Data (Franses)   Description  
Dow Jones index time series computed at the end of the week where week is assumed to run from Thursday to Wednesday.    Usage   data(""DJFranses"")   Format  
A weekly univariate time series from 1980(1) to 1994(42).    Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""DJFranses"") plot(DJFranses)"
"AER-DJIA8012","AER","DJIA8012","Dow Jones Industrial Average (DJIA) index",8610,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DJIA8012.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/DJIA8012.html","DJIA8012 R Documentation   Dow Jones Industrial Average (DJIA) index   Description  
Time series of the Dow Jones Industrial Average (DJIA) index.    Usage   data(""DJIA8012"")   Format  
A daily univariate time series from 1980-01-01 to 2012-12-31 (of class ""zoo"" with ""Date"" index).    Source  
Online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    Examples    data(""DJIA8012"") plot(DJIA8012) # p.26, Figure 2.18 dldjia <- diff(log(DJIA8012)) plot(dldjia) # p.141, Figure 6.4 plot(window(dldjia, start = ""1987-09-01"", end = ""1987-12-31"")) # p.167, Figure 7.1 dldjia9005 <- window(dldjia, start = ""1990-01-01"", end = ""2005-12-31"") qqnorm(dldjia9005) qqline(dldjia9005, lty = 2) # p.170, Figure 7.4 acf(dldjia9005, na.action = na.exclude, lag.max = 250, ylim = c(-0.1, 0.25)) acf(dldjia9005^2, na.action = na.exclude, lag.max = 250, ylim = c(-0.1, 0.25)) acf(abs(dldjia9005), na.action = na.exclude, lag.max = 250, ylim = c(-0.1, 0.25))"
"AER-DoctorVisits","AER","DoctorVisits","Australian Health Service Utilization Data",5190,12,6,0,6,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DoctorVisits.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/DoctorVisits.html","DoctorVisits R Documentation   Australian Health Service Utilization Data   Description  
Cross-section data originating from the 1977–1978 Australian Health Survey.   Usage   data(""DoctorVisits"")   Format  
A data frame containing 5,190 observations on 12 variables.    visits
Number of doctor visits in past 2 weeks.   gender
Factor indicating gender.   age
Age in years divided by 100.   income
Annual income in tens of thousands of dollars.   illness
Number of illnesses in past 2 weeks.   reduced
Number of days of reduced activity in past 2 weeks due to illness or injury.   health
General health questionnaire score using Goldberg's method.   private
Factor. Does the individual have private health insurance?   freepoor
Factor. Does the individual have free government health insurance due to low income?   freerepat
Factor. Does the individual have free government health insurance due to old age, disability or veteran status?   nchronic
Factor. Is there a chronic condition not limiting activity?   lchronic
Factor. Is there a chronic condition limiting activity?     Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1997-v12.3/mullahy/     References  
Cameron, A.C. and Trivedi, P.K. (1986). Econometric Models Based on Count Data: Comparisons and Applications of Some Estimators and Tests.  Journal of Applied Econometrics ,  1 , 29–53.   
Cameron, A.C. and Trivedi, P.K. (1998). Regression Analysis of Count Data . Cambridge: Cambridge University Press.   
Mullahy, J. (1997). Heterogeneity, Excess Zeros, and the Structure of Count Data Models. Journal of Applied Econometrics ,  12 , 337–350.    See Also  
CameronTrivedi1998   Examples    data(""DoctorVisits"", package = ""AER"") library(""MASS"") ## Cameron and Trivedi (1986), Table III, col. (1) dv_lm <- lm(visits ~ . + I(age^2), data = DoctorVisits) summary(dv_lm) ## Cameron and Trivedi (1998), Table 3.3 dv_pois <- glm(visits ~ . + I(age^2), data = DoctorVisits, family = poisson) summary(dv_pois) ## MLH standard errors coeftest(dv_pois, vcov = vcovOPG) ## MLOP standard errors logLik(dv_pois) ## standard errors denoted RS (""unspecified omega robust sandwich estimate"") coeftest(dv_pois, vcov = sandwich) ## Cameron and Trivedi (1986), Table III, col. (4) dv_nb <- glm.nb(visits ~ . + I(age^2), data = DoctorVisits) summary(dv_nb) logLik(dv_nb)"
"AER-DutchAdvert","AER","DutchAdvert","TV and Radio Advertising Expenditures Data",221,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DutchAdvert.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/DutchAdvert.html","DutchAdvert R Documentation   TV and Radio Advertising Expenditures Data   Description  
Time series of television and radio advertising expenditures (in real terms) in The Netherlands.    Usage   data(""DutchAdvert"")   Format  
A four-weekly multiple time series from 1978(1) to 1994(13) with 2 variables.    tv
Television advertising expenditures.   radio
Radio advertising expenditures.     Source  
Originally available as an online supplement to Franses (1998). Now available via online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.   
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""DutchAdvert"") plot(DutchAdvert) ## EACF tables (Franses 1998, Sec. 5.1, p. 99) ctrafo <- function(x) residuals(lm(x ~ factor(cycle(x)))) ddiff <- function(x) diff(diff(x, frequency(x)), 1) eacf <- function(y, lag = 12) { stopifnot(all(lag > 0)) if(length(lag) < 2) lag <- 1:lag rval <- sapply( list(y = y, dy = diff(y), cdy = ctrafo(diff(y)), Dy = diff(y, frequency(y)), dDy = ddiff(y)), function(x) acf(x, plot = FALSE, lag.max = max(lag))$acf[lag + 1]) rownames(rval) <- lag return(rval) } ## Franses (1998, p. 103), Table 5.4 round(eacf(log(DutchAdvert[,""tv""]), lag = c(1:19, 26, 39)), digits = 3)"
"AER-DutchSales","AER","DutchSales","Dutch Retail Sales Index Data",425,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/DutchSales.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/DutchSales.html","DutchSales R Documentation   Dutch Retail Sales Index Data   Description  
Time series of retail sales index in The Netherlands.    Usage   data(""DutchSales"")   Format  
A monthly univariate time series from 1960(5) to 1995(9).    Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""DutchSales"") plot(DutchSales) ## EACF tables (Franses 1998, p. 99) ctrafo <- function(x) residuals(lm(x ~ factor(cycle(x)))) ddiff <- function(x) diff(diff(x, frequency(x)), 1) eacf <- function(y, lag = 12) { stopifnot(all(lag > 0)) if(length(lag) < 2) lag <- 1:lag rval <- sapply( list(y = y, dy = diff(y), cdy = ctrafo(diff(y)), Dy = diff(y, frequency(y)), dDy = ddiff(y)), function(x) acf(x, plot = FALSE, lag.max = max(lag))$acf[lag + 1]) rownames(rval) <- lag return(rval) } ## Franses (1998), Table 5.3 round(eacf(log(DutchSales), lag = c(1:18, 24, 36)), digits = 3)"
"AER-Electricity1955","AER","Electricity1955","Cost Function of Electricity Producers (1955, Nerlove Data)",159,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Electricity1955.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Electricity1955.html","Electricity1955 R Documentation   Cost Function of Electricity Producers (1955, Nerlove Data)   Description  
Cost function data for 145 (+14) US electricity producers in 1955.    Usage   data(""Electricity1955"")   Format  
A data frame containing 159 observations on 8 variables.    cost
total cost.   output
total output.   labor
wage rate.   laborshare
cost share for labor.   capital
capital price index.   capitalshare
cost share for capital.   fuel
fuel price.   fuelshare
cost share for fuel.     Details  
The data contains several extra observations that are aggregates of commonly owned firms. Only the first 145 observations should be used for analysis.    Source  
Online complements to Greene (2003). Table F14.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Nerlove, M. (1963) “Returns to Scale in Electricity Supply.” In C. Christ (ed.), Measurement in Economics: Studies in Mathematical Economics and Econometrics in Memory of Yehuda Grunfeld . Stanford University Press, 1963.    See Also  
Greene2003 , Electricity1970   Examples    data(""Electricity1955"") Electricity <- Electricity1955[1:145,] ## Greene (2003) ## Example 7.3 ## Cobb-Douglas cost function fm_all <- lm(log(cost/fuel) ~ log(output) + log(labor/fuel) + log(capital/fuel), data = Electricity) summary(fm_all) ## hypothesis of constant returns to scale linearHypothesis(fm_all, ""log(output) = 1"") ## Table 7.4 ## log quadratic cost function fm_all2 <- lm(log(cost/fuel) ~ log(output) + I(log(output)^2) + log(labor/fuel) + log(capital/fuel), data = Electricity) summary(fm_all2) ## More examples can be found in: ## help(""Greene2003"")"
"AER-Electricity1970","AER","Electricity1970","Cost Function of Electricity Producers 1970",158,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Electricity1970.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Electricity1970.html","Electricity1970 R Documentation   Cost Function of Electricity Producers 1970   Description  
Cross-section data, at the firm level, on electric power generation.   Usage   data(""Electricity1970"")   Format  
A data frame containing 158 cross-section observations on 9 variables.    cost
total cost.   output
total output.   labor
wage rate.   laborshare
cost share for labor.   capital
capital price index.   capitalshare
cost share for capital.   fuel
fuel price.   fuelshare
cost share for fuel.     Details  
The data are from Christensen and Greene (1976) and pertain to the year 1970. However, the file contains some extra observations, the holding companies. Only the first 123 observations are needed to replicate Christensen and Greene (1976).    Source  
Online complements to Greene (2003), Table F5.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Christensen, L. and Greene, W.H. (1976). Economies of Scale in U.S. Electric Power Generation.  Journal of Political Economy , 84 , 655–676.   
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , Electricity1955   Examples    data(""Electricity1970"") ## Greene (2003), Ex. 5.6: a generalized Cobb-Douglas cost function fm <- lm(log(cost/fuel) ~ log(output) + I(log(output)^2/2) + log(capital/fuel) + log(labor/fuel), data=Electricity1970[1:123,])"
"AER-EquationCitations","AER","EquationCitations","Number of Equations and Citations for Evolutionary Biology Publications",649,13,0,1,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/EquationCitations.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/EquationCitations.html","EquationCitations R Documentation   Number of Equations and Citations for Evolutionary Biology Publications   Description  
Analysis of citations of evolutionary biology papers published in 1998 in the top three journals (as judged by their 5-year impact factors in the Thomson Reuters Journal Citation Reports 2010).    Usage   data(""EquationCitations"")   Format  
A data frame containing 649 observations on 13 variables.    journal
Factor. Journal in which the paper was published (The American Naturalist, Evolution, Proceedings of the Royal Society of London B: Biological Sciences).   authors
Character. Names of authors.   volume
Volume in which the paper was published.   startpage
Starting page of publication.   pages
Number of pages.   equations
Number of equations in total.   mainequations
Number of equations in main text.   appequations
Number of equations in appendix.   cites
Number of citations in total.   selfcites
Number of citations by the authors themselves.   othercites
Number of citations by other authors.   theocites
Number of citations by theoretical papers.   nontheocites
Number of citations by nontheoretical papers.     Details  
Fawcett and Higginson (2012) investigate the relationship between the number of citations evolutionary biology papers receive, depending on the number of equations per page in the cited paper. Overall it can be shown that papers with many mathematical equations significantly lower the number of citations they receive, in particular from nontheoretical papers.    Source  
Online supplements to Fawcett and Higginson (2012).   
http://www.pnas.org/lookup/suppl/doi:10.1073/pnas.1205259109/-/DCSupplemental     References  
Fawcett, T.W. and Higginson, A.D. (2012). Heavy Use of Equations Impedes Communication among Biologists.  PNAS – Proceedings of the National Academy of Sciences of the United States of America ,  109 , 11735–11739. http://dx.doi.org/10.1073/pnas.1205259109     See Also  
PhDPublications   Examples    ## load data and MASS package data(""EquationCitations"", package = ""AER"") library(""MASS"") ## convenience function for summarizing NB models nbtable <- function(obj, digits = 3) round(cbind( ""OR"" = exp(coef(obj)), ""CI"" = exp(confint.default(obj)), ""Wald z"" = coeftest(obj)[,3], ""p"" = coeftest(obj)[, 4]), digits = digits) ################# ## Replication ## ################# ## Table 1 m1a <- glm.nb(othercites ~ I(equations/pages) * pages + journal, data = EquationCitations) m1b <- update(m1a, nontheocites ~ .) m1c <- update(m1a, theocites ~ .) nbtable(m1a) nbtable(m1b) nbtable(m1c) ## Table 2 m2a <- glm.nb( othercites ~ (I(mainequations/pages) + I(appequations/pages)) * pages + journal, data = EquationCitations) m2b <- update(m2a, nontheocites ~ .) m2c <- update(m2a, theocites ~ .) nbtable(m2a) nbtable(m2b) nbtable(m2c) ############### ## Extension ## ############### ## nonlinear page effect: use log(pages) instead of pages+interaction m3a <- glm.nb(othercites ~ I(equations/pages) + log(pages) + journal, data = EquationCitations) m3b <- update(m3a, nontheocites ~ .) m3c <- update(m3a, theocites ~ .) ## nested models: allow different equation effects over journals m4a <- glm.nb(othercites ~ journal / I(equations/pages) + log(pages), data = EquationCitations) m4b <- update(m4a, nontheocites ~ .) m4c <- update(m4a, theocites ~ .) ## nested model best (wrt AIC) for all responses AIC(m1a, m2a, m3a, m4a) nbtable(m4a) AIC(m1b, m2b, m3b, m4b) nbtable(m4b) AIC(m1c, m2c, m3c, m4c) nbtable(m4c) ## equation effect by journal/response ## comb nontheo theo ## AmNat =/- - + ## Evolution =/+ = + ## ProcB - - =/+"
"AER-Equipment","AER","Equipment","Transportation Equipment Manufacturing Data",25,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Equipment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Equipment.html","Equipment R Documentation   Transportation Equipment Manufacturing Data   Description  
Statewide data on transportation equipment manufacturing for 25 US states.   Usage   data(""Equipment"")   Format  
A data frame containing 25 observations on 4 variables.    valueadded
Aggregate output, in millions of 1957 dollars.   capital
Capital input, in millions of 1957 dollars.   labor
Aggregate labor input, in millions of man hours.   firms
Number of firms.     Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1998-v13.2/zellner-ryu/    
Online complements to Greene (2003), Table F9.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Zellner, A. and Revankar, N. (1969). Generalized Production Functions. Review of Economic Studies , 36 , 241–250.   
Zellner, A. and Ryu, H. (1998). Alternative Functional Forms for Production, Cost and Returns to Scale Functions. Journal of Applied Econometrics , 13 , 101–127.    See Also  
Greene2003   Examples    ## Greene (2003), Example 17.5 data(""Equipment"") ## Cobb-Douglas fm_cd <- lm(log(valueadded/firms) ~ log(capital/firms) + log(labor/firms), data = Equipment) ## generalized Cobb-Douglas with Zellner-Revankar trafo GCobbDouglas <- function(theta) lm(I(log(valueadded/firms) + theta * valueadded/firms) ~ log(capital/firms) + log(labor/firms), data = Equipment) ## yields classical Cobb-Douglas for theta = 0 fm_cd0 <- GCobbDouglas(0) ## ML estimation of generalized model ## choose starting values from classical model par0 <- as.vector(c(coef(fm_cd0), 0, mean(residuals(fm_cd0)^2))) ## set up likelihood function nlogL <- function(par) { beta <- par[1:3] theta <- par[4] sigma2 <- par[5] Y <- with(Equipment, valueadded/firms) K <- with(Equipment, capital/firms) L <- with(Equipment, labor/firms) rhs <- beta[1] + beta[2] * log(K) + beta[3] * log(L) lhs <- log(Y) + theta * Y rval <- sum(log(1 + theta * Y) - log(Y) + dnorm(lhs, mean = rhs, sd = sqrt(sigma2), log = TRUE)) return(-rval) } ## optimization opt <- optim(par0, nlogL, hessian = TRUE) ## Table 17.2 opt$par sqrt(diag(solve(opt$hessian)))[1:4] -opt$value ## re-fit ML model fm_ml <- GCobbDouglas(opt$par[4]) deviance(fm_ml) sqrt(diag(vcov(fm_ml))) ## fit NLS model rss <- function(theta) deviance(GCobbDouglas(theta)) optim(0, rss) opt2 <- optimize(rss, c(-1, 1)) fm_nls <- GCobbDouglas(opt2$minimum) -nlogL(c(coef(fm_nls), opt2$minimum, mean(residuals(fm_nls)^2)))"
"AER-EuroEnergy","AER","EuroEnergy","European Energy Consumption Data",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/EuroEnergy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/EuroEnergy.html","EuroEnergy R Documentation   European Energy Consumption Data   Description  
Cross-section data on energy consumption for 20 European countries, for the year 1980.   Usage   data(""EuroEnergy"")   Format  
A data frame containing 20 observations on 2 variables.   gdp
Real gross domestic product for the year 1980 (in million 1975 US dollars).   energy
Aggregate energy consumption (in million kilograms coal equivalence).     Source  
The data are from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002   Examples    data(""EuroEnergy"") energy_lm <- lm(log(energy) ~ log(gdp), data = EuroEnergy) influence.measures(energy_lm)"
"AER-Fatalities","AER","Fatalities","US Traffic Fatalities",336,34,3,0,5,0,29,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fatalities.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Fatalities.html","Fatalities R Documentation   US Traffic Fatalities   Description  
US traffic fatalities panel data for the “lower 48” US states (i.e., excluding Alaska and Hawaii), annually for 1982 through 1988.   Usage   data(""Fatalities"")   Format  
A data frame containing 336 observations on 34 variables.    state
factor indicating state.   year
factor indicating year.   spirits
numeric. Spirits consumption.   unemp
numeric. Unemployment rate.   income
numeric. Per capita personal income in 1987 dollars.   emppop
numeric. Employment/population ratio.   beertax
numeric. Tax on case of beer.   baptist
numeric. Percent of southern baptist.   mormon
numeric. Percent of mormon.   drinkage
numeric. Minimum legal drinking age.   dry
numeric. Percent residing in “dry” countries.   youngdrivers
numeric. Percent of drivers aged 15–24.   miles
numeric. Average miles per driver.   breath
factor. Preliminary breath test law?   jail
factor. Mandatory jail sentence?   service
factor. Mandatory community service?   fatal
numeric. Number of vehicle fatalities.   nfatal
numeric. Number of night-time vehicle fatalities.   sfatal
numeric. Number of single vehicle fatalities.   fatal1517
numeric. Number of vehicle fatalities, 15–17 year olds.   nfatal1517
numeric. Number of night-time vehicle fatalities, 15–17 year olds.   fatal1820
numeric. Number of vehicle fatalities, 18–20 year olds.   nfatal1820
numeric. Number of night-time vehicle fatalities, 18–20 year olds.   fatal2124
numeric. Number of vehicle fatalities, 21–24 year olds.   nfatal2124
numeric. Number of night-time vehicle fatalities, 21–24 year olds.   afatal
numeric. Number of alcohol-involved vehicle fatalities.   pop
numeric. Population.   pop1517
numeric. Population, 15–17 year olds.   pop1820
numeric. Population, 18–20 year olds.   pop2124
numeric. Population, 21–24 year olds.   milestot
numeric. Total vehicle miles (millions).   unempus
numeric. US unemployment rate.   emppopus
numeric. US employment/population ratio.   gsp
numeric. GSP rate of change.     Details  
Traffic fatalities are from the US Department of Transportation Fatal Accident Reporting System. The beer tax is the tax on a case of beer, which is an available measure of state alcohol taxes more generally. The drinking age variable is a factor indicating whether the legal drinking age is 18, 19, or 20. The two binary punishment variables describe the state's minimum sentencing requirements for an initial drunk driving conviction.  
Total vehicle miles traveled annually by state was obtained from the Department of Transportation. Personal income was obtained from the US Bureau of Economic Analysis, and the unemployment rate was obtained from the US Bureau of Labor Statistics.    Source  
Online complements to Stock and Watson (2007).   References  
Ruhm, C. J. (1996). Alcohol Policies and Highway Vehicle Fatalities. Journal of Health Economics , 15 , 435–454.   
Stock, J. H. and Watson, M. W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## data from Stock and Watson (2007) data(""Fatalities"", package = ""AER"") ## add fatality rate (number of traffic deaths ## per 10,000 people living in that state in that year) Fatalities$frate <- with(Fatalities, fatal/pop * 10000) ## add discretized version of minimum legal drinking age Fatalities$drinkagec <- cut(Fatalities$drinkage, breaks = 18:22, include.lowest = TRUE, right = FALSE) Fatalities$drinkagec <- relevel(Fatalities$drinkagec, ref = 4) ## any punishment? Fatalities$punish <- with(Fatalities, factor(jail == ""yes"" | service == ""yes"", labels = c(""no"", ""yes""))) ## plm package library(""plm"") ## for comparability with Stata we use HC1 below ## p. 351, Eq. (10.2) f1982 <- subset(Fatalities, year == ""1982"") fm_1982 <- lm(frate ~ beertax, data = f1982) coeftest(fm_1982, vcov = vcovHC(fm_1982, type = ""HC1"")) ## p. 353, Eq. (10.3) f1988 <- subset(Fatalities, year == ""1988"") fm_1988 <- lm(frate ~ beertax, data = f1988) coeftest(fm_1988, vcov = vcovHC(fm_1988, type = ""HC1"")) ## pp. 355, Eq. (10.8) fm_diff <- lm(I(f1988$frate - f1982$frate) ~ I(f1988$beertax - f1982$beertax)) coeftest(fm_diff, vcov = vcovHC(fm_diff, type = ""HC1"")) ## pp. 360, Eq. (10.15) ## (1) via formula fm_sfe <- lm(frate ~ beertax + state - 1, data = Fatalities) ## (2) by hand fat <- with(Fatalities, data.frame(frates = frate - ave(frate, state), beertaxs = beertax - ave(beertax, state))) fm_sfe2 <- lm(frates ~ beertaxs - 1, data = fat) ## (3) via plm() fm_sfe3 <- plm(frate ~ beertax, data = Fatalities, index = c(""state"", ""year""), model = ""within"") coeftest(fm_sfe, vcov = vcovHC(fm_sfe, type = ""HC1""))[1,] ## uses different df in sd and p-value coeftest(fm_sfe2, vcov = vcovHC(fm_sfe2, type = ""HC1""))[1,] ## uses different df in p-value coeftest(fm_sfe3, vcov = vcovHC(fm_sfe3, type = ""HC1"", method = ""white1""))[1,] ## pp. 363, Eq. (10.21) ## via lm() fm_stfe <- lm(frate ~ beertax + state + year - 1, data = Fatalities) coeftest(fm_stfe, vcov = vcovHC(fm_stfe, type = ""HC1""))[1,] ## via plm() fm_stfe2 <- plm(frate ~ beertax, data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") coeftest(fm_stfe2, vcov = vcovHC) ## different ## p. 368, Table 10.1, numbers refer to cols. fm1 <- plm(frate ~ beertax, data = Fatalities, index = c(""state"", ""year""), model = ""pooling"") fm2 <- plm(frate ~ beertax, data = Fatalities, index = c(""state"", ""year""), model = ""within"") fm3 <- plm(frate ~ beertax, data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") fm4 <- plm(frate ~ beertax + drinkagec + jail + service + miles + unemp + log(income), data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") fm5 <- plm(frate ~ beertax + drinkagec + jail + service + miles, data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") fm6 <- plm(frate ~ beertax + drinkage + punish + miles + unemp + log(income), data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") fm7 <- plm(frate ~ beertax + drinkagec + jail + service + miles + unemp + log(income), data = Fatalities, index = c(""state"", ""year""), model = ""within"", effect = ""twoways"") ## summaries not too close, s.e.s generally too small coeftest(fm1, vcov = vcovHC) coeftest(fm2, vcov = vcovHC) coeftest(fm3, vcov = vcovHC) coeftest(fm4, vcov = vcovHC) coeftest(fm5, vcov = vcovHC) coeftest(fm6, vcov = vcovHC) coeftest(fm7, vcov = vcovHC) ## TODO: Testing exclusion restrictions"
"AER-Fertility","AER","Fertility","Fertility and Women's Labor Supply",254654,8,6,0,6,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Fertility.html","Fertility R Documentation   Fertility and Women's Labor Supply   Description  
Cross-section data from the 1980 US Census on married women aged 21–35 with two or more children.    Usage    data(""Fertility"") data(""Fertility2"")    Format  
A data frame containing 254,654 (and 30,000, respectively) observations on 8 variables.    morekids
factor. Does the mother have more than 2 children?   gender1
factor indicating gender of first child.   gender2
factor indicating gender of second child.   age
age of mother at census.   afam
factor. Is the mother African-American?   hispanic
factor. Is the mother Hispanic?   other
factor. Is the mother's ethnicity neither African-American nor Hispanic, nor Caucasian? (see below)   work
number of weeks in which the mother worked in 1979.     Details  
Fertility2 is a random subset of Fertility with 30,000 observations.   
There are conflicts in the ethnicity coding (see also examples). Hence, it was not possible to create a single factor and the original three indicator variables have been retained.   
Not all variables from Angrist and Evans (1998) have been included.    Source  
Online complements to Stock and Watson (2007).   References  
Angrist, J.D., and Evans, W.N. (1998). Children and Their Parents' Labor Supply: Evidence from Exogenous Variation in Family Size  American Economic Review , 88 , 450–477.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""Fertility2"") ## conflicts in ethnicity coding ftable(xtabs(~ afam + hispanic + other, data = Fertility2)) ## create convenience variables Fertility2$mkids <- with(Fertility2, as.numeric(morekids) - 1) Fertility2$samegender <- with(Fertility2, factor(gender1 == gender2)) Fertility2$twoboys <- with(Fertility2, factor(gender1 == ""male"" & gender2 == ""male"")) Fertility2$twogirls <- with(Fertility2, factor(gender1 == ""female"" & gender2 == ""female"")) ## similar to Angrist and Evans, p. 462 fm1 <- lm(mkids ~ samegender, data = Fertility2) summary(fm1) fm2 <- lm(mkids ~ gender1 + gender2 + samegender + age + afam + hispanic + other, data = Fertility2) summary(fm2) fm3 <- lm(mkids ~ gender1 + twoboys + twogirls + age + afam + hispanic + other, data = Fertility2) summary(fm3)"
"AER-Fertility2","AER","Fertility2","Fertility and Women's Labor Supply",30000,8,6,0,6,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Fertility2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Fertility2.html","Fertility R Documentation   Fertility and Women's Labor Supply   Description  
Cross-section data from the 1980 US Census on married women aged 21–35 with two or more children.    Usage    data(""Fertility"") data(""Fertility2"")    Format  
A data frame containing 254,654 (and 30,000, respectively) observations on 8 variables.    morekids
factor. Does the mother have more than 2 children?   gender1
factor indicating gender of first child.   gender2
factor indicating gender of second child.   age
age of mother at census.   afam
factor. Is the mother African-American?   hispanic
factor. Is the mother Hispanic?   other
factor. Is the mother's ethnicity neither African-American nor Hispanic, nor Caucasian? (see below)   work
number of weeks in which the mother worked in 1979.     Details  
Fertility2 is a random subset of Fertility with 30,000 observations.   
There are conflicts in the ethnicity coding (see also examples). Hence, it was not possible to create a single factor and the original three indicator variables have been retained.   
Not all variables from Angrist and Evans (1998) have been included.    Source  
Online complements to Stock and Watson (2007).   References  
Angrist, J.D., and Evans, W.N. (1998). Children and Their Parents' Labor Supply: Evidence from Exogenous Variation in Family Size  American Economic Review , 88 , 450–477.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""Fertility2"") ## conflicts in ethnicity coding ftable(xtabs(~ afam + hispanic + other, data = Fertility2)) ## create convenience variables Fertility2$mkids <- with(Fertility2, as.numeric(morekids) - 1) Fertility2$samegender <- with(Fertility2, factor(gender1 == gender2)) Fertility2$twoboys <- with(Fertility2, factor(gender1 == ""male"" & gender2 == ""male"")) Fertility2$twogirls <- with(Fertility2, factor(gender1 == ""female"" & gender2 == ""female"")) ## similar to Angrist and Evans, p. 462 fm1 <- lm(mkids ~ samegender, data = Fertility2) summary(fm1) fm2 <- lm(mkids ~ gender1 + gender2 + samegender + age + afam + hispanic + other, data = Fertility2) summary(fm2) fm3 <- lm(mkids ~ gender1 + twoboys + twogirls + age + afam + hispanic + other, data = Fertility2) summary(fm3)"
"AER-FrozenJuice","AER","FrozenJuice","Price of Frozen Orange Juice",612,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/FrozenJuice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/FrozenJuice.html","FrozenJuice R Documentation   Price of Frozen Orange Juice   Description  
Monthly data on the price of frozen orange juice concentrate and temperature in the orange-growing region of Florida.    Usage   data(""FrozenJuice"")   Format  
A monthly multiple time series from 1950(1) to 2000(12) with 3 variables.    price
Average producer price for frozen orange juice.   ppi
Producer price index for finished goods. Used to deflate the overall producer price index for finished goods to eliminate the effects of overall price inflation.   fdd
Number of freezing degree days at the Orlando, Florida, airport. Calculated as the sum of the number of degrees Fahrenheit that the minimum temperature falls below freezing (32 degrees Fahrenheit = about 0 degrees Celsius) in a given day over all days in the month: fdd = sum(max(0, 32 - minimum daily temperature)), e.g. for February fdd is the number of freezing degree days from January 11 to February 10.     Details  
The orange juice price data are the frozen orange juice component of processed foods and feeds group of the Producer Price Index (PPI), collected by the US Bureau of Labor Statistics (BLS series wpu02420301). The orange juice price series was divided by the overall PPI for finished goods to adjust for general price inflation. The freezing degree days series was constructed from daily minimum temperatures recorded at Orlando area airports, obtained from the National Oceanic and Atmospheric Administration (NOAA) of the US Department of Commerce.    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## load data data(""FrozenJuice"") ## Stock and Watson, p. 594 library(""dynlm"") fm_dyn <- dynlm(d(100 * log(price/ppi)) ~ fdd, data = FrozenJuice) coeftest(fm_dyn, vcov = vcovHC(fm_dyn, type = ""HC1"")) ## equivalently, returns can be computed 'by hand' ## (reducing the complexity of the formula notation) fj <- ts.union(fdd = FrozenJuice[, ""fdd""], ret = 100 * diff(log(FrozenJuice[,""price""]/FrozenJuice[,""ppi""]))) fm_dyn <- dynlm(ret ~ fdd, data = fj) ## Stock and Watson, p. 595 fm_dl <- dynlm(ret ~ L(fdd, 0:6), data = fj) coeftest(fm_dl, vcov = vcovHC(fm_dl, type = ""HC1"")) ## Stock and Watson, Table 15.1, p. 620, numbers refer to columns ## (1) Dynamic Multipliers fm1 <- dynlm(ret ~ L(fdd, 0:18), data = fj) coeftest(fm1, vcov = NeweyWest(fm1, lag = 7, prewhite = FALSE)) ## (2) Cumulative Multipliers fm2 <- dynlm(ret ~ L(d(fdd), 0:17) + L(fdd, 18), data = fj) coeftest(fm2, vcov = NeweyWest(fm2, lag = 7, prewhite = FALSE)) ## (3) Cumulative Multipliers, more lags in NW coeftest(fm2, vcov = NeweyWest(fm2, lag = 14, prewhite = FALSE)) ## (4) Cumulative Multipliers with monthly indicators fm4 <- dynlm(ret ~ L(d(fdd), 0:17) + L(fdd, 18) + season(fdd), data = fj) coeftest(fm4, vcov = NeweyWest(fm4, lag = 7, prewhite = FALSE)) ## monthly indicators needed? fm4r <- update(fm4, . ~ . - season(fdd)) waldtest(fm4, fm4r, vcov= NeweyWest(fm4, lag = 7, prewhite = FALSE)) ## close ..."
"AER-GermanUnemployment","AER","GermanUnemployment","Unemployment in Germany Data",120,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GermanUnemployment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GermanUnemployment.html","GermanUnemployment R Documentation   Unemployment in Germany Data   Description  
Time series of unemployment rate (in percent) in Germany.    Usage   data(""GermanUnemployment"")   Format  
A quarterly multiple time series from 1962(1) to 1991(4) with 2 variables.    unadjusted
Raw unemployment rate,   adjusted
Seasonally adjusted rate.     Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""GermanUnemployment"") plot(GermanUnemployment, plot.type = ""single"", col = 1:2)"
"AER-GoldSilver","AER","GoldSilver","Gold and Silver Prices",9132,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GoldSilver.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GoldSilver.html","GoldSilver R Documentation   Gold and Silver Prices   Description  
Time series of gold and silver prices.    Usage   data(""GoldSilver"")   Format  
A daily multiple time series from 1977-12-30 to 2012-12-31 (of class ""zoo"" with ""Date"" index).    gold
spot price for gold,   silver
spot price for silver.     Source  
Online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    Examples    data(""GoldSilver"", package = ""AER"") ## p.31, daily returns lgs <- log(GoldSilver) plot(lgs[, c(""silver"", ""gold"")]) dlgs <- 100 * diff(lgs) plot(dlgs[, c(""silver"", ""gold"")]) ## p.31, monthly log prices lgs7812 <- window(lgs, start = as.Date(""1978-01-01"")) lgs7812m <- aggregate(lgs7812, as.Date(as.yearmon(time(lgs7812))), mean) plot(lgs7812m, plot.type = ""single"", lty = 1:2, lwd = 2) ## p.93, empirical ACF of absolute daily gold returns, 1978-01-01 - 2012-12-31 absgret <- abs(100 * diff(lgs7812[, ""gold""])) sacf <- acf(absgret, lag.max = 200, na.action = na.exclude, plot = FALSE) plot(1:201, sacf$acf, ylim = c(0.04, 0.28), type = ""l"", xaxs = ""i"", yaxs = ""i"", las = 1) ## ARFIMA(0,1,1) model, eq. (4.44) library(""longmemo"") WhittleEst(absgret, model = ""fARIMA"", p = 0, q = 1, start = list(H = 0.3, MA = .25)) library(""forecast"") arfima(as.vector(absgret), max.p = 0, max.q = 1) ## p.254: VAR(2), monthly data for 1986.1 - 2012.12 library(""vars"") lgs8612 <- window(lgs, start = as.Date(""1986-01-01"")) dim(lgs8612) lgs8612m <- aggregate(lgs8612, as.Date(as.yearmon(time(lgs8612))), mean) plot(lgs8612m) dim(lgs8612m) VARselect(lgs8612m, 5) gs2 <- VAR(lgs8612m, 2) summary(gs2) summary(gs2)$covres ## ACF of residuals, p.256 acf(resid(gs2), 2, plot = FALSE) ## Figure 9.1, p.260 (somewhat different) plot(irf(gs2, impulse = ""gold"", n.ahead = 50), ylim = c(-0.02, 0.1)) plot(irf(gs2, impulse = ""silver"", n.ahead = 50), ylim = c(-0.02, 0.1)) ## Table 9.2, p.261 fevd(gs2) ## p.266 ls <- lgs8612[, ""silver""] lg <- lgs8612[, ""gold""] gsreg <- lm(lg ~ ls) summary(gsreg) sgreg <- lm(ls ~ lg) summary(sgreg) library(""tseries"") adf.test(resid(gsreg), k = 0) adf.test(resid(sgreg), k = 0)"
"AER-GrowthDJ","AER","GrowthDJ","Determinants of Economic Growth",121,10,3,0,3,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GrowthDJ.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GrowthDJ.html","GrowthDJ R Documentation   Determinants of Economic Growth   Description  
Growth regression data as provided by Durlauf & Johnson (1995).   Usage   data(""GrowthDJ"")   Format  
A data frame containing 121 observations on 10 variables.    oil
factor. Is the country an oil-producing country?   inter
factor. Does the country have better quality data?   oecd
factor. Is the country a member of the OECD?   gdp60
Per capita GDP in 1960.   gdp85
Per capita GDP in 1985.   gdpgrowth
Average growth rate of per capita GDP from 1960 to 1985 (in percent).   popgrowth
Average growth rate of working-age population 1960 to 1985 (in percent).   invest
Average ratio of investment (including Government Investment) to GDP from 1960 to 1985 (in percent).   school
Average fraction of working-age population enrolled in secondary school from 1960 to 1985 (in percent).   literacy60
Fraction of the population over 15 years old that is able to read and write in 1960 (in percent).     Details  
The data are derived from the Penn World Table 4.0 and are given in Mankiw, Romer and Weil (1992), except literacy60 that is from the World Bank's World Development Report.    Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1995-v10.4/durlauf-johnson/     References  
Durlauf, S.N., and Johnson, P.A. (1995). Multiple Regimes and Cross-Country Growth Behavior. Journal of Applied Econometrics , 10 , 365–384.  
Koenker, R., and Zeileis, A. (2009). On Reproducible Econometric Research.  Journal of Applied Econometrics , 24 (5), 833–847.   
Mankiw, N.G, Romer, D., and Weil, D.N. (1992). A Contribution to the Empirics of Economic Growth. Quarterly Journal of Economics , 107 , 407–437.  
Masanjala, W.H., and Papageorgiou, C. (2004). The Solow Model with CES Technology: Nonlinearities and Parameter Heterogeneity. Journal of Applied Econometrics , 19 , 171–201.    See Also  
OECDGrowth , GrowthSW   Examples    ## data for non-oil-producing countries data(""GrowthDJ"") dj <- subset(GrowthDJ, oil == ""no"") ## Different scalings have been used by different authors, ## different types of standard errors, etc., ## see Koenker & Zeileis (2009) for an overview ## Durlauf & Johnson (1995), Table II mrw_model <- I(log(gdp85) - log(gdp60)) ~ log(gdp60) + log(invest/100) + log(popgrowth/100 + 0.05) + log(school/100) dj_mrw <- lm(mrw_model, data = dj) coeftest(dj_mrw) dj_model <- I(log(gdp85) - log(gdp60)) ~ log(gdp60) + log(invest) + log(popgrowth/100 + 0.05) + log(school) dj_sub1 <- lm(dj_model, data = dj, subset = gdp60 < 1800 & literacy60 < 50) coeftest(dj_sub1, vcov = sandwich) dj_sub2 <- lm(dj_model, data = dj, subset = gdp60 >= 1800 & literacy60 >= 50) coeftest(dj_sub2, vcov = sandwich)"
"AER-GrowthSW","AER","GrowthSW","Determinants of Economic Growth",65,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GrowthSW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GrowthSW.html","GrowthSW R Documentation   Determinants of Economic Growth   Description  
Data on average growth rates over 1960–1995 for 65 countries, along with variables that are potentially related to growth.    Usage   data(""GrowthSW"")   Format  
A data frame containing 65 observations on 6 variables.    growth
average annual percentage growth of real GDP from 1960 to 1995.   rgdp60
value of GDP per capita in 1960, converted to 1960 US dollars.   tradeshare
average share of trade in the economy from 1960 to 1995, measured as the sum of exports (X) plus imports (M), divided by GDP; that is, the average value of (X + M)/GDP from 1960 to 1995.   education
average number of years of schooling of adult residents in that country in 1960.   revolutions
average annual number of revolutions, insurrections (successful or not) and coup d'etats in that country from 1960 to 1995.   assassinations
average annual number of political assassinations in that country from 1960 to 1995 (in per million population).     Source  
Online complements to Stock and Watson (2007).   References  
Beck, T., Levine, R., and Loayza, N. (2000). Finance and the Sources of Growth.  Journal of Financial Economics , 58 , 261–300.   
Stock, J. H. and Watson, M. W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , GrowthDJ , OECDGrowth   Examples    data(""GrowthSW"") summary(GrowthSW)"
"AER-Grunfeld","AER","Grunfeld","Grunfeld's Investment Data",220,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Grunfeld.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Grunfeld.html","Grunfeld R Documentation   Grunfeld's Investment Data   Description  
Panel data on 11 large US manufacturing firms over 20 years, for the years 1935–1954.    Usage   data(""Grunfeld"")   Format  
A data frame containing 20 annual observations on 3 variables for 11 firms.   invest
Gross investment, defined as additions to plant and equipment plus maintenance and repairs in millions of dollars deflated by the implicit price deflator of producers' durable equipment (base 1947).   value
Market value of the firm, defined as the price of common shares at December 31 (or, for WH, IBM and CH, the average price of December 31 and January 31 of the following year) times the number of common shares outstanding plus price of preferred shares at December 31 (or average price of December 31 and January 31 of the following year) times number of preferred shares plus total book value of debt at December 31 in millions of dollars deflated by the implicit GNP price deflator (base 1947).   capital
Stock of plant and equipment, defined as the accumulated sum of net additions to plant and equipment deflated by the implicit price deflator for producers' durable equipment (base 1947) minus depreciation allowance deflated by depreciation expense deflator (10 years moving average of wholesale price index of metals and metal products, base 1947).   firm
factor with 11 levels: ""General Motors"" , ""US Steel"" ,  ""General Electric"" , ""Chrysler"" , ""Atlantic Refining"" , ""IBM"" ,  ""Union Oil"" , ""Westinghouse"" , ""Goodyear"" , ""Diamond Match"" ,  ""American Steel"" .   year
Year.     Details  
This is a popular data set for teaching purposes. Unfortunately, there exist several different versions (see Kleiber and Zeileis, 2010, for a detailed discussion). In particular, the version provided by Greene (2003) has a couple of errors for ""US Steel"" (firm 2): investment in 1940 is 261.6 (instead of the correct 361.6), investment in 1952 is 645.2 (instead of the correct 645.5), capital in 1946 is 132.6 (instead of the correct 232.6).   
Here, we provide the original data from Grunfeld (1958). The data for the first 10 firms are identical to those of Baltagi (2002) or Baltagi (2005), now also used by Greene (2008).    Source  
The data are taken from Grunfeld (1958, Appendix, Tables 2–9 and 11–13).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed., Berlin: Springer-Verlag.  
Baltagi, B.H. (2005). Econometric Analysis of Panel Data , 3rd ed. Chichester, UK: John Wiley.   
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Greene, W.H. (2008). Econometric Analysis , 6th edition. Upper Saddle River, NJ: Prentice Hall.   
Grunfeld, Y. (1958). The Determinants of Corporate Investment . Unpublished Ph.D. Dissertation, University of Chicago.   
Kleiber, C., and Zeileis, A. (2010). “The Grunfeld Data at 50.”  German Economic Review , 11 (4), 404–417.  http://dx.doi.org/10.1111/j.1468-0475.2010.00513.x     See Also  
Baltagi2002 , Greene2003   Examples    data(""Grunfeld"", package = ""AER"") ## Greene (2003) ## subset of data with mistakes ggr <- subset(Grunfeld, firm %in% c(""General Motors"", ""US Steel"", ""General Electric"", ""Chrysler"", ""Westinghouse"")) ggr[c(26, 38), 1] <- c(261.6, 645.2) ggr[32, 3] <- 232.6 ## Tab. 14.2, col. ""GM"" fm_gm <- lm(invest ~ value + capital, data = ggr, subset = firm == ""General Motors"") mean(residuals(fm_gm)^2) ## Greene uses MLE ## Tab. 14.2, col. ""Pooled"" fm_pool <- lm(invest ~ value + capital, data = ggr) ## equivalently library(""plm"") pggr <- pdata.frame(ggr, c(""firm"", ""year"")) library(""systemfit"") fm_ols <- systemfit(invest ~ value + capital, data = pggr, method = ""OLS"") fm_pols <- systemfit(invest ~ value + capital, data = pggr, method = ""OLS"", pooled = TRUE) ## Tab. 14.1 fm_sur <- systemfit(invest ~ value + capital, data = pggr, method = ""SUR"", methodResidCov = ""noDfCor"") fm_psur <- systemfit(invest ~ value + capital, data = pggr, method = ""SUR"", pooled = TRUE, methodResidCov = ""noDfCor"", residCovWeighted = TRUE) ## Further examples: ## help(""Greene2003"") ## Panel models library(""plm"") pg <- pdata.frame(subset(Grunfeld, firm != ""American Steel""), c(""firm"", ""year"")) fm_fe <- plm(invest ~ value + capital, model = ""within"", data = pg) summary(fm_fe) coeftest(fm_fe, vcov = vcovHC) fm_reswar <- plm(invest ~ value + capital, data = pg, model = ""random"", random.method = ""swar"") summary(fm_reswar) ## testing for random effects fm_ols <- plm(invest ~ value + capital, data = pg, model = ""pooling"") plmtest(fm_ols, type = ""bp"") plmtest(fm_ols, type = ""honda"") ## Random effects models fm_ream <- plm(invest ~ value + capital, data = pg, model = ""random"", random.method = ""amemiya"") fm_rewh <- plm(invest ~ value + capital, data = pg, model = ""random"", random.method = ""walhus"") fm_rener <- plm(invest ~ value + capital, data = pg, model = ""random"", random.method = ""nerlove"") ## Baltagi (2005), Tab. 2.1 rbind( ""OLS(pooled)"" = coef(fm_ols), ""FE"" = c(NA, coef(fm_fe)), ""RE-SwAr"" = coef(fm_reswar), ""RE-Amemiya"" = coef(fm_ream), ""RE-WalHus"" = coef(fm_rewh), ""RE-Nerlove"" = coef(fm_rener)) ## Hausman test phtest(fm_fe, fm_reswar) ## Further examples: ## help(""Baltagi2002"") ## help(""Greene2003"")"
"AER-GSOEP9402","AER","GSOEP9402","German Socio-Economic Panel 1994-2002",675,12,1,0,5,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GSOEP9402.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GSOEP9402.html","GSOEP9402 R Documentation   German Socio-Economic Panel 1994–2002   Description  
Cross-section data for 675 14-year old children born between 1980 and 1988. The sample is taken from the German Socio-Economic Panel (GSOEP) for the years 1994 to 2002 to investigate the determinants of secondary school choice.    Usage   data(""GSOEP9402"")   Format  
A data frame containing 675 observations on 12 variables.   school
factor. Child's secondary school level.   birthyear
Year of child's birth.   gender
factor indicating child's gender.   kids
Total number of kids living in household.   parity
Birth order.   income
Household income.   size
Household size   state
factor indicating German federal state.   marital
factor indicating mother's marital status.   meducation
Mother's educational level in years.   memployment
factor indicating mother's employment level: full-time, part-time, or not working.   year
Year of GSOEP wave.     Details  
This sample from the German Socio-Economic Panel (GSOEP) for the years between 1994 and 2002 has been selected by Winkelmann and Boes (2009) to investigate the determinants of secondary school choice.   
In the German schooling system, students are separated relatively early into different school types, depending on their ability as perceived by the teachers after four years of primary school. After that, around the age of ten, students are placed into one of three types of secondary school: ""Hauptschule""  (lower secondary school), ""Realschule"" (middle secondary school), or  ""Gymnasium"" (upper secondary school). Only a degree from the latter type of school (called Abitur) provides direct access to universities.   
A frequent criticism of this system is that the tracking takes place too early, and that it cements inequalities in education across generations. Although the secondary school choice is based on the teachers' recommendations, it is typically also influenced by the parents; both indirectly through their own educational level and directly through influence on the teachers.    Source  
Online complements to Winkelmann and Boes (2009).    References  
Winkelmann, R., and Boes, S. (2009). Analysis of Microdata , 2nd ed. Berlin and Heidelberg: Springer-Verlag.    See Also  
WinkelmannBoes2009   Examples    ## data data(""GSOEP9402"", package = ""AER"") ## some convenience data transformations gsoep <- GSOEP9402 gsoep$year2 <- factor(gsoep$year) ## visualization plot(school ~ meducation, data = gsoep, breaks = c(7, 9, 10.5, 11.5, 12.5, 15, 18)) ## Chapter 5, Table 5.1 library(""nnet"") gsoep_mnl <- multinom( school ~ meducation + memployment + log(income) + log(size) + parity + year2, data = gsoep) coeftest(gsoep_mnl)[c(1:6, 1:6 + 14),] ## alternatively if(require(""mlogit"")) { gsoep_mnl2 <- mlogit( school ~ 0 | meducation + memployment + log(income) + log(size) + parity + year2, data = gsoep, shape = ""wide"", reflevel = ""Hauptschule"") coeftest(gsoep_mnl2)[1:12,] } ## Table 5.2 library(""effects"") gsoep_eff <- effect(""meducation"", gsoep_mnl, xlevels = list(meducation = sort(unique(gsoep$meducation)))) gsoep_eff$prob plot(gsoep_eff, confint = FALSE) ## omit year gsoep_mnl1 <- multinom( school ~ meducation + memployment + log(income) + log(size) + parity, data = gsoep) lrtest(gsoep_mnl, gsoep_mnl1) ## Chapter 6 ## Table 6.1 library(""MASS"") gsoep_pop <- polr( school ~ meducation + I(memployment != ""none"") + log(income) + log(size) + parity + year2, data = gsoep, method = ""probit"", Hess = TRUE) gsoep_pol <- polr( school ~ meducation + I(memployment != ""none"") + log(income) + log(size) + parity + year2, data = gsoep, Hess = TRUE) ## compare polr and multinom via AIC gsoep_pol1 <- polr( school ~ meducation + memployment + log(income) + log(size) + parity, data = gsoep, Hess = TRUE) AIC(gsoep_pol1, gsoep_mnl) ## effects eff_pol1 <- allEffects(gsoep_pol1) plot(eff_pol1, ask = FALSE, confint = FALSE) ## More examples can be found in: ## help(""WinkelmannBoes2009"")"
"AER-GSS7402","AER","GSS7402","US General Social Survey 1974-2002",9120,10,4,0,4,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/GSS7402.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/GSS7402.html","GSS7402 R Documentation   US General Social Survey 1974–2002   Description  
Cross-section data for 9120 women taken from every fourth year of the US General Social Survey between 1974 and 2002 to investigate the determinants of fertility.    Usage   data(""GSS7402"")   Format  
A data frame containing 9120 observations on 10 variables.   kids
Number of children. This is coded as a numerical variable but note that the value 8 actually encompasses 8 or more children.   age
Age of respondent.   education
Highest year of school completed.   year
GSS year for respondent.   siblings
Number of brothers and sisters.   agefirstbirth
Woman's age at birth of first child.   ethnicity
factor indicating ethnicity. Is the individual Caucasian ( ""cauc"" ) or not ( ""other"" )?   city16
factor. Did the respondent live in a city (with population > 50,000) at age 16?   lowincome16
factor. Was the income below average at age 16?   immigrant
factor. Was the respondent (or both parents) born abroad?     Details  
This subset of the US General Social Survey (GSS) for every fourth year between 1974 and 2002 has been selected by Winkelmann and Boes (2009) to investigate the determinants of fertility. To do so they typically restrict their empirical analysis to the women for which the completed fertility is (assumed to be) known, employing the common cutoff of 40 years. Both, the average number of children borne to a woman and the probability of being childless, are of interest.    Source  
Online complements to Winkelmann and Boes (2009).    References  
Winkelmann, R., and Boes, S. (2009). Analysis of Microdata , 2nd ed. Berlin and Heidelberg: Springer-Verlag.    See Also  
WinkelmannBoes2009   Examples    ## completed fertility subset data(""GSS7402"", package = ""AER"") gss40 <- subset(GSS7402, age >= 40) ## Chapter 1 ## exploratory statistics gss_kids <- prop.table(table(gss40$kids)) names(gss_kids)[9] <- ""8+"" gss_zoo <- as.matrix(with(gss40, cbind( tapply(kids, year, mean), tapply(kids, year, function(x) mean(x <= 0)), tapply(education, year, mean)))) colnames(gss_zoo) <- c(""Number of children"", ""Proportion childless"", ""Years of schooling"") gss_zoo <- zoo(gss_zoo, sort(unique(gss40$year))) ## visualizations instead of tables barplot(gss_kids, xlab = ""Number of children ever borne to women (age 40+)"", ylab = ""Relative frequencies"") library(""lattice"") trellis.par.set(theme = canonical.theme(color = FALSE)) print(xyplot(gss_zoo[,3:1], type = ""b"", xlab = ""Year"")) ## Chapter 3, Example 3.14 ## Table 3.1 gss40$nokids <- factor(gss40$kids <= 0, levels = c(FALSE, TRUE), labels = c(""no"", ""yes"")) gss40$trend <- gss40$year - 1974 nokids_p1 <- glm(nokids ~ 1, data = gss40, family = binomial(link = ""probit"")) nokids_p2 <- glm(nokids ~ trend, data = gss40, family = binomial(link = ""probit"")) nokids_p3 <- glm(nokids ~ trend + education + ethnicity + siblings, data = gss40, family = binomial(link = ""probit"")) lrtest(nokids_p1, nokids_p2, nokids_p3) ## Chapter 4, Figure 4.4 library(""effects"") nokids_p3_ef <- effect(""education"", nokids_p3, xlevels = list(education = 0:20)) plot(nokids_p3_ef, rescale.axis = FALSE, ylim = c(0, 0.3)) ## Chapter 8, Example 8.11 kids_pois <- glm(kids ~ education + trend + ethnicity + immigrant + lowincome16 + city16, data = gss40, family = poisson) library(""MASS"") kids_nb <- glm.nb(kids ~ education + trend + ethnicity + immigrant + lowincome16 + city16, data = gss40) lrtest(kids_pois, kids_nb) ## More examples can be found in: ## help(""WinkelmannBoes2009"")"
"AER-Guns","AER","Guns","More Guns, Less Crime?",1173,13,1,0,3,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Guns.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Guns.html","Guns R Documentation   More Guns, Less Crime?   Description  
Guns is a balanced panel of data on 50 US states, plus the District of Columbia (for a total of 51 states), by year for 1977–1999.    Usage   data(""Guns"")   Format  
A data frame containing 1,173 observations on 13 variables.    state
factor indicating state.   year
factor indicating year.   violent
violent crime rate (incidents per 100,000 members of the population).   murder
murder rate (incidents per 100,000).   robbery
robbery rate (incidents per 100,000).   prisoners
incarceration rate in the state in the previous year (sentenced prisoners per 100,000 residents; value for the previous year).   afam
percent of state population that is African-American, ages 10 to 64.   cauc
percent of state population that is Caucasian, ages 10 to 64.   male
percent of state population that is male, ages 10 to 29.   population
state population, in millions of people.   income
real per capita personal income in the state (US dollars).   density
population per square mile of land area, divided by 1,000.   law
factor. Does the state have a shall carry law in effect in that year?     Details  
Each observation is a given state in a given year. There are a total of 51 states times 23 years = 1,173 observations.    Source  
Online complements to Stock and Watson (2007).   References  
Ayres, I., and Donohue, J.J. (2003). Shooting Down the ‘More Guns Less Crime’ Hypothesis.  Stanford Law Review , 55 , 1193–1312.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## data data(""Guns"") ## visualization library(""lattice"") xyplot(log(violent) ~ as.numeric(as.character(year)) | state, data = Guns, type = ""l"") ## Stock & Watson (2007), Empirical Exercise 10.1, pp. 376--377 fm1 <- lm(log(violent) ~ law, data = Guns) coeftest(fm1, vcov = sandwich) fm2 <- lm(log(violent) ~ law + prisoners + density + income + population + afam + cauc + male, data = Guns) coeftest(fm2, vcov = sandwich) fm3 <- lm(log(violent) ~ law + prisoners + density + income + population + afam + cauc + male + state, data = Guns) printCoefmat(coeftest(fm3, vcov = sandwich)[1:9,]) fm4 <- lm(log(violent) ~ law + prisoners + density + income + population + afam + cauc + male + state + year, data = Guns) printCoefmat(coeftest(fm4, vcov = sandwich)[1:9,])"
"AER-HealthInsurance","AER","HealthInsurance","Medical Expenditure Panel Survey Data",8802,11,6,0,9,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/HealthInsurance.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/HealthInsurance.html","HealthInsurance R Documentation   Medical Expenditure Panel Survey Data   Description  
Cross-section data originating from the Medical Expenditure Panel Survey survey conducted in 1996.    Usage   data(""HealthInsurance"")   Format  
A data frame containing 8,802 observations on 11 variables.    health
factor. Is the self-reported health status “healthy”?.   age
age in years.   limit
factor. Is there any limitation?   gender
factor indicating gender.   insurance
factor. Does the individual have a health insurance?   married
factor. Is the individual married?   selfemp
factor. Is the individual self-employed?   family
family size.   region
factor indicating region.   ethnicity
factor indicating ethnicity: African-American, Caucasian, other.   education
factor indicating highest degree attained: no degree, GED (high school equivalent), high school, bachelor, master, PhD, other.     Details  
This is a subset of the data used in Perry and Rosen (2004).    Source  
Online complements to Stock and Watson (2007).   References  
Perry, C. and Rosen, H.S. (2004). “The Self-Employed are Less Likely than Wage-Earners to Have Health Insurance. So What?” in Holtz-Eakin, D. and Rosen, H.S. (eds.), Entrepeneurship and Public Policy , MIT Press.  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""HealthInsurance"") summary(HealthInsurance) prop.table(xtabs(~ selfemp + insurance, data = HealthInsurance), 1)"
"AER-HMDA","AER","HMDA","Home Mortgage Disclosure Act Data",2380,14,8,0,10,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/HMDA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/HMDA.html","HMDA R Documentation   Home Mortgage Disclosure Act Data   Description  
Cross-section data on the Home Mortgage Disclosure Act (HMDA).   Usage   data(""HMDA"")   Format  
A data frame containing 2,380 observations on 14 variables.    deny
Factor. Was the mortgage denied?   pirat
Payments to income ratio.   hirat
Housing expense to income ratio.   lvrat
Loan to value ratio.   chist
Factor. Credit history: consumer payments.   mhist
Factor. Credit history: mortgage payments.   phist
Factor. Public bad credit record?   unemp
1989 Massachusetts unemployment rate in applicant's industry.   selfemp
Factor. Is the individual self-employed?   insurance
Factor. Was the individual denied mortgage insurance?   condomin
Factor. Is the unit a condominium?   afam
Factor. Is the individual African-American?   single
Factor. Is the individual single?   hschool
Factor. Does the individual have a high-school diploma?     Details  
Only includes variables used by Stock and Watson (2007), some of which had to be generated from the raw data.    Source  
Online complements to Stock and Watson (2007).   References  
Munnell, A. H., Tootell, G. M. B., Browne, L. E. and McEneaney, J. (1996). Mortgage Lending in Boston: Interpreting HMDA Data. American Economic Review , 86 , 25–53.   
Stock, J. H. and Watson, M. W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""HMDA"") ## Stock and Watson (2007) ## Equations 11.1, 11.3, 11.7, 11.8 and 11.10, pp. 387--395 fm1 <- lm(I(as.numeric(deny) - 1) ~ pirat, data = HMDA) fm2 <- lm(I(as.numeric(deny) - 1) ~ pirat + afam, data = HMDA) fm3 <- glm(deny ~ pirat, family = binomial(link = ""probit""), data = HMDA) fm4 <- glm(deny ~ pirat + afam, family = binomial(link = ""probit""), data = HMDA) fm5 <- glm(deny ~ pirat + afam, family = binomial(link = ""logit""), data = HMDA) ## More examples can be found in: ## help(""StockWatson2007"")"
"AER-HousePrices","AER","HousePrices","House Prices in the City of Windsor, Canada",546,12,6,0,6,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/HousePrices.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/HousePrices.html","HousePrices R Documentation   House Prices in the City of Windsor, Canada   Description  
Sales prices of houses sold in the city of Windsor, Canada, during July, August and September, 1987.    Usage   data(""HousePrices"")   Format  
A data frame containing 546 observations on 12 variables.    price
Sale price of a house.   lotsize
Lot size of a property in square feet.   bedrooms
Number of bedrooms.   bathrooms
Number of full bathrooms.   stories
Number of stories excluding basement.   driveway
Factor. Does the house have a driveway?   recreation
Factor. Does the house have a recreational room?   fullbase
Factor. Does the house have a full finished basement?   gasheat
Factor. Does the house use gas for hot water heating?   aircon
Factor. Is there central air conditioning?   garage
Number of garage places.   prefer
Factor. Is the house located in the preferred neighborhood of the city?     Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1996-v11.6/anglin-gencay/     References  
Anglin, P., and Gencay, R. (1996). Semiparametric Estimation of a Hedonic Price Function. Journal of Applied Econometrics , 11 , 633–648.   
Verbeek, M. (2004). A Guide to Modern Econometrics , 2nd ed. Chichester, UK: John Wiley.    Examples    data(""HousePrices"") ### Anglin + Gencay (1996), Table II fm_ag <- lm(log(price) ~ driveway + recreation + fullbase + gasheat + aircon + garage + prefer + log(lotsize) + log(bedrooms) + log(bathrooms) + log(stories), data = HousePrices) ### Anglin + Gencay (1996), Table III fm_ag2 <- lm(log(price) ~ driveway + recreation + fullbase + gasheat + aircon + garage + prefer + log(lotsize) + bedrooms + bathrooms + stories, data = HousePrices) ### Verbeek (2004), Table 3.1 fm <- lm(log(price) ~ log(lotsize) + bedrooms + bathrooms + aircon, data = HousePrices) summary(fm) ### Verbeek (2004), Table 3.2 fm_ext <- lm(log(price) ~ . - lotsize + log(lotsize), data = HousePrices) summary(fm_ext) ### Verbeek (2004), Table 3.3 fm_lin <- lm(price ~ . , data = HousePrices) summary(fm_lin)"
"AER-Journals","AER","Journals","Economics Journal Subscription Data",180,10,1,1,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Journals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Journals.html","Journals R Documentation   Economics Journal Subscription Data   Description  
Subscriptions to economics journals at US libraries, for the year 2000.    Usage   data(""Journals"")   Format  
A data frame containing 180 observations on 10 variables.    title
Journal title.   publisher
factor with publisher name.   society
factor. Is the journal published by a scholarly society?   price
Library subscription price.   pages
Number of pages.   charpp
Characters per page.   citations
Total number of citations.   foundingyear
Year journal was founded.   subs
Number of library subscriptions.   field
factor with field description.     Details  
Data on 180 economic journals, collected in particular for analyzing journal pricing. See also http://www.econ.ucsb.edu/~tedb/Journals/jpricing.html  for general information on this topic as well as a more up-to-date version of the data set. This version is taken from Stock and Watson (2007).   
The data as obtained from the online complements for Stock and Watson (2007) contained two journals with title “World Development”. One of these (observation 80) seemed to be an error and was changed to “The World Economy”.    Source  
Online complements to Stock and Watson (2007).   References  
Bergstrom, T. (2001). Free Labor for Costly Journals? Journal of Economic Perspectives , 15, 183–198.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## data and transformed variables data(""Journals"") journals <- Journals[, c(""subs"", ""price"")] journals$citeprice <- Journals$price/Journals$citations journals$age <- 2000 - Journals$foundingyear journals$chars <- Journals$charpp*Journals$pages/10^6 ## Stock and Watson (2007) ## Figure 8.9 (a) and (b) plot(subs ~ citeprice, data = journals, pch = 19) plot(log(subs) ~ log(citeprice), data = journals, pch = 19) fm1 <- lm(log(subs) ~ log(citeprice), data = journals) abline(fm1) ## Table 8.2, use HC1 for comparability with Stata fm2 <- lm(subs ~ citeprice + age + chars, data = log(journals)) fm3 <- lm(subs ~ citeprice + I(citeprice^2) + I(citeprice^3) + age + I(age * citeprice) + chars, data = log(journals)) fm4 <- lm(subs ~ citeprice + age + I(age * citeprice) + chars, data = log(journals)) coeftest(fm1, vcov = vcovHC(fm1, type = ""HC1"")) coeftest(fm2, vcov = vcovHC(fm2, type = ""HC1"")) coeftest(fm3, vcov = vcovHC(fm3, type = ""HC1"")) coeftest(fm4, vcov = vcovHC(fm4, type = ""HC1"")) waldtest(fm3, fm4, vcov = vcovHC(fm3, type = ""HC1"")) ## changes with respect to age library(""strucchange"") ## Nyblom-Hansen test scus <- gefp(subs ~ citeprice, data = log(journals), fit = lm, order.by = ~ age) plot(scus, functional = meanL2BB) ## estimate breakpoint(s) journals <- journals[order(journals$age),] bp <- breakpoints(subs ~ citeprice, data = log(journals), h = 20) plot(bp) bp.age <- journals$age[bp$breakpoints] ## visualization plot(subs ~ citeprice, data = log(journals), pch = 19, col = (age > log(bp.age)) + 1) abline(coef(bp)[1,], col = 1) abline(coef(bp)[2,], col = 2) legend(""bottomleft"", legend = c(""age > 18"", ""age < 18""), lty = 1, col = 2:1, bty = ""n"")"
"AER-KleinI","AER","KleinI","Klein Model I",22,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/KleinI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/KleinI.html","KleinI R Documentation   Klein Model I   Description  
Klein's Model I for the US economy.    Usage   data(""KleinI"")   Format  
An annual multiple time series from 1920 to 1941 with 9 variables.    consumption
Consumption.   cprofits
Corporate profits.   pwage
Private wage bill.   invest
Investment.   capital
Previous year's capital stock.   gnp
Gross national product.   gwage
Government wage bill.   gexpenditure
Government spending.   taxes
Taxes.     Source  
Online complements to Greene (2003). Table F15.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Klein, L. (1950). Economic Fluctuations in the United States, 1921–1941 . New York: John Wiley.   
Maddala, G.S. (1977). Econometrics . New York: McGraw-Hill.    See Also  
Greene2003   Examples    data(""KleinI"", package = ""AER"") plot(KleinI) ## Greene (2003), Tab. 15.3, OLS library(""dynlm"") fm_cons <- dynlm(consumption ~ cprofits + L(cprofits) + I(pwage + gwage), data = KleinI) fm_inv <- dynlm(invest ~ cprofits + L(cprofits) + capital, data = KleinI) fm_pwage <- dynlm(pwage ~ gnp + L(gnp) + I(time(gnp) - 1931), data = KleinI) summary(fm_cons) summary(fm_inv) summary(fm_pwage) ## More examples can be found in: ## help(""Greene2003"")"
"AER-Longley","AER","Longley","Longley's Regression Data",16,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Longley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Longley.html","Longley R Documentation   Longley's Regression Data   Description  
US macroeconomic time series, 1947–1962.    Usage   data(""Longley"")   Format  
An annual multiple time series from 1947 to 1962 with 4 variables.    employment
Number of people employed (in 1000s).   price
GNP deflator.   gnp
Gross national product.   armedforces
Number of people in the armed forces.     Details  
An extended version of this data set, formatted as a ""data.frame""  is available as longley in base R.    Source  
Online complements to Greene (2003). Table F4.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Longley, J.W. (1967). An Appraisal of Least-Squares Programs from the Point of View of the User.  Journal of the American Statistical Association , 62 , 819–841.    See Also  
longley , Greene2003   Examples    data(""Longley"") library(""dynlm"") ## Example 4.6 in Greene (2003) fm1 <- dynlm(employment ~ time(employment) + price + gnp + armedforces, data = Longley) fm2 <- update(fm1, end = 1961) cbind(coef(fm2), coef(fm1)) ## Figure 4.3 in Greene (2003) plot(rstandard(fm2), type = ""b"", ylim = c(-3, 3)) abline(h = c(-2, 2), lty = 2)"
"AER-ManufactCosts","AER","ManufactCosts","Manufacturing Costs Data",25,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ManufactCosts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ManufactCosts.html","ManufactCosts R Documentation   Manufacturing Costs Data   Description  
US time series data on prices and cost shares in manufacturing, 1947–1971.    Usage   data(""ManufactCosts"")   Format  
An annual multiple time series from 1947 to 1971 with 9 variables.    cost
Cost index.   capitalcost
Capital cost share.   laborcost
Labor cost share.   energycost
Energy cost share.   materialscost
Materials cost share.   capitalprice
Capital price.   laborprice
Labor price.   energyprice
Energy price.   materialsprice
Materials price.     Source  
Online complements to Greene (2003).   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Berndt, E. and Wood, D. (1975). Technology, Prices, and the Derived Demand for Energy.  Review of Economics and Statistics , 57 , 376–384.   
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""ManufactCosts"") plot(ManufactCosts)"
"AER-MarkDollar","AER","MarkDollar","DEM/USD Exchange Rate Returns",518,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MarkDollar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MarkDollar.html","MarkDollar R Documentation   DEM/USD Exchange Rate Returns   Description  
A time series of intra-day percentage returns of Deutsche mark/US dollar (DEM/USD) exchange rates, consisting of two observations per day from 1992-10-01 through 1993-09-29.    Usage   data(""MarkDollar"")   Format  
A univariate time series of 518 returns (exact dates unknown) for the DEM/USD exchange rate.    Source  
Journal of Business \& Economic Statistics Data Archive.  
http://www.amstat.org/publications/jbes/upload/index.cfm?fuseaction=ViewArticles&pub=JBES&issue=96-2-APR     References  
Bollerslev, T., and Ghysels, E. (1996). Periodic Autoregressive Conditional Heteroskedasticity. Journal of Business \& Economic Statistics ,  14 , 139–151.    See Also  
MarkPound   Examples    library(""tseries"") data(""MarkDollar"") ## GARCH(1,1) fm <- garch(MarkDollar, grad = ""numerical"") summary(fm) logLik(fm)"
"AER-MarkPound","AER","MarkPound","DEM/GBP Exchange Rate Returns",1974,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MarkPound.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MarkPound.html","MarkPound R Documentation   DEM/GBP Exchange Rate Returns   Description  
A daily time series of percentage returns of Deutsche mark/British pound (DEM/GBP) exchange rates from 1984-01-03 through 1991-12-31.    Usage   data(""MarkPound"")   Format  
A univariate time series of 1974 returns (exact dates unknown) for the DEM/GBP exchange rate.    Details  
Greene (2003, Table F11.1) rounded the series to six digits while eight digits are given in Bollerslev and Ghysels (1996). Here, we provide the original data. Using round  a series can be produced that is virtually identical to that of Greene (2003) (except for eight observations where a slightly different rounding arithmetic was used).    Source  
Journal of Business \& Economic Statistics Data Archive.  
http://www.amstat.org/publications/jbes/upload/index.cfm?fuseaction=ViewArticles&pub=JBES&issue=96-2-APR     References  
Bollerslev, T., and Ghysels, E. (1996). Periodic Autoregressive Conditional Heteroskedasticity. Journal of Business \& Economic Statistics ,  14 , 139–151.   
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , MarkDollar   Examples    ## data as given by Greene (2003) data(""MarkPound"") mp <- round(MarkPound, digits = 6) ## Figure 11.3 in Greene (2003) plot(mp) ## Example 11.8 in Greene (2003), Table 11.5 library(""tseries"") mp_garch <- garch(mp, grad = ""numerical"") summary(mp_garch) logLik(mp_garch) ## Greene (2003) also includes a constant and uses different ## standard errors (presumably computed from Hessian), here ## OPG standard errors are used. garchFit() in ""fGarch"" ## implements the approach used by Greene (2003). ## compare Errata to Greene (2003) library(""dynlm"") res <- residuals(dynlm(mp ~ 1))^2 mp_ols <- dynlm(res ~ L(res, 1:10)) summary(mp_ols) logLik(mp_ols) summary(mp_ols)$r.squared * length(residuals(mp_ols))"
"AER-MASchools","AER","MASchools","Massachusetts Test Score Data",220,16,0,2,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MASchools.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MASchools.html","MASchools R Documentation   Massachusetts Test Score Data   Description  
The dataset contains data on test performance, school characteristics and student demographic backgrounds for school districts in Massachusetts.    Usage   data(""MASchools"")   Format  
A data frame containing 220 observations on 16 variables.    district
character. District code.   municipality
character. Municipality name.   expreg
Expenditures per pupil, regular.   expspecial
Expenditures per pupil, special needs.   expbil
Expenditures per pupil, bilingual.   expocc
Expenditures per pupil, occupational.   exptot
Expenditures per pupil, total.   scratio
Students per computer.   special
Special education students (per cent).   lunch
Percent qualifying for reduced-price lunch.   stratio
Student-teacher ratio.   income
Per capita income.   score4
4th grade score (math + English + science).   score8
8th grade score (math + English + science).   salary
Average teacher salary.   english
Percent of English learners.     Details  
The Massachusetts data are district-wide averages for public elementary school districts in 1998. The test score is taken from the Massachusetts Comprehensive Assessment System (MCAS) test, administered to all fourth graders in Massachusetts public schools in the spring of 1998. The test is sponsored by the Massachusetts Department of Education and is mandatory for all public schools. The data analyzed here are the overall total score, which is the sum of the scores on the English, Math, and Science portions of the test. Data on the student-teacher ratio, the percent of students receiving a subsidized lunch and on the percent of students still learning english are averages for each elementary school district for the 1997–1998 school year and were obtained from the Massachusetts department of education. Data on average district income are from the 1990 US Census.    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J. H. and Watson, M. W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , CASchools   Examples    ## Massachusetts data(""MASchools"") ## compare with California data(""CASchools"") CASchools$stratio <- with(CASchools, students/teachers) CASchools$score4 <- with(CASchools, (math + read)/2) ## Stock and Watson, parts of Table 9.1, p. 330 vars <- c(""score4"", ""stratio"", ""english"", ""lunch"", ""income"") cbind( CA_mean = sapply(CASchools[, vars], mean), CA_sd = sapply(CASchools[, vars], sd), MA_mean = sapply(MASchools[, vars], mean), MA_sd = sapply(MASchools[, vars], sd)) ## Stock and Watson, Table 9.2, p. 332, col. (1) fm1 <- lm(score4 ~ stratio, data = MASchools) coeftest(fm1, vcov = vcovHC(fm1, type = ""HC1"")) ## More examples, notably the entire Table 9.2, can be found in: ## help(""StockWatson2007"")"
"AER-Medicaid1986","AER","Medicaid1986","Medicaid Utilization Data",996,14,5,0,5,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Medicaid1986.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Medicaid1986.html","Medicaid1986 R Documentation   Medicaid Utilization Data   Description  
Cross-section data originating from the 1986 Medicaid Consumer Survey. The data comprise two groups of Medicaid eligibles at two sites in California (Santa Barbara and Ventura counties): a group enrolled in a managed care demonstration program and a fee-for-service comparison group of non-enrollees.    Usage   data(""Medicaid1986"")   Format  
A data frame containing 996 observations on 14 variables.    visits
Number of doctor visits.   exposure
Length of observation period for ambulatory care (days).   children
Total number of children in the household.   age
Age of the respondent.   income
Annual household income (average of income range in million USD).   health1
The first principal component (divided by 1000) of three health-status variables: functional limitations, acute conditions, and chronic conditions.   health2
The second principal component (divided by 1000) of three health-status variables: functional limitations, acute conditions, and chronic conditions.   access
Availability of health services (0 = low access, 1 = high access).   married
Factor. Is the individual married?   gender
Factor indicating gender.   ethnicity
Factor indicating ethnicity ( ""cauc"" or ""other"" ).   school
Number of years completed in school.   enroll
Factor. Is the individual enrolled in a demonstration program?   program
Factor indicating the managed care demonstration program: Aid to Families with Dependent Children ( ""afdc"" ) or non-institutionalized Supplementary Security Income ( ""ssi"" ).     Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1997-v12.3/gurmu/     References  
Gurmu, S. (1997). Semi-Parametric Estimation of Hurdle Regression Models with an Application to Medicaid Utilization. Journal of Applied Econometrics ,  12 , 225–242.    Examples    ## data and packages data(""Medicaid1986"") library(""MASS"") library(""pscl"") ## scale regressors Medicaid1986$age2 <- Medicaid1986$age^2 / 100 Medicaid1986$school <- Medicaid1986$school / 10 Medicaid1986$income <- Medicaid1986$income / 10 ## subsets afdc <- subset(Medicaid1986, program == ""afdc"")[, c(1, 3:4, 15, 5:9, 11:13)] ssi <- subset(Medicaid1986, program == ""ssi"")[, c(1, 3:4, 15, 5:13)] ## Gurmu (1997): ## Table VI., Poisson and negbin models afdc_pois <- glm(visits ~ ., data = afdc, family = poisson) summary(afdc_pois) coeftest(afdc_pois, vcov = sandwich) afdc_nb <- glm.nb(visits ~ ., data = afdc) ssi_pois <- glm(visits ~ ., data = ssi, family = poisson) ssi_nb <- glm.nb(visits ~ ., data = ssi) ## Table VII., Hurdle models (without semi-parametric effects) afdc_hurdle <- hurdle(visits ~ . | . - access, data = afdc, dist = ""negbin"") ssi_hurdle <- hurdle(visits ~ . | . - access, data = ssi, dist = ""negbin"") ## Table VIII., Observed and expected frequencies round(cbind( Observed = table(afdc$visits)[1:8], Poisson = sapply(0:7, function(x) sum(dpois(x, fitted(afdc_pois)))), Negbin = sapply(0:7, function(x) sum(dnbinom(x, mu = fitted(afdc_nb), size = afdc_nb$theta))), Hurdle = colSums(predict(afdc_hurdle, type = ""prob"")[,1:8]) )/nrow(afdc), digits = 3) * 100 round(cbind( Observed = table(ssi$visits)[1:8], Poisson = sapply(0:7, function(x) sum(dpois(x, fitted(ssi_pois)))), Negbin = sapply(0:7, function(x) sum(dnbinom(x, mu = fitted(ssi_nb), size = ssi_nb$theta))), Hurdle = colSums(predict(ssi_hurdle, type = ""prob"")[,1:8]) )/nrow(ssi), digits = 3) * 100"
"AER-Mortgage","AER","Mortgage","Fixed versus Adjustable Mortgages",78,16,5,0,5,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Mortgage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Mortgage.html","Mortgage R Documentation   Fixed versus Adjustable Mortgages   Description  
Cross-section data about fixed versus adjustable mortgages for 78 households.   Usage   data(""Mortgage"")   Format  
A data frame containing 78 observations on 16 variables.    rate
Factor with levels ""fixed"" and ""adjustable"" .   age
Age of the borrower.   school
Years of schooling for the borrower.   networth
Net worth of the borrower.   interest
Fixed interest rate.   points
Ratio of points paid on adjustable to fixed rate mortgages.   maturities
Ratio of maturities on adjustable to fixed rate mortgages.   years
Years at the present address.   married
Factor. Is the borrower married?   first
Factor. Is the borrower a first-time home buyer?   selfemp
Factor. Is the borrower self-employed?   tdiff
The difference between the 10-year treasury rate less the 1-year treasury rate.   margin
The margin on the adjustable rate mortgage.   coborrower
Factor. Is there a co-borrower?   liability
Short-term liabilities.   liquid
Liquid assets.     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Dhillon, U.S., Shilling, J.D. and Sirmans, C.F. (1987). Choosing Between Fixed and Adjustable Rate Mortgages. Journal of Money, Credit and Banking , 19 , 260–267.    See Also  
Baltagi2002   Examples    data(""Mortgage"") plot(rate ~ interest, data = Mortgage, breaks = fivenum(Mortgage$interest)) plot(rate ~ margin, data = Mortgage, breaks = fivenum(Mortgage$margin)) plot(rate ~ coborrower, data = Mortgage)"
"AER-MotorCycles","AER","MotorCycles","Motor Cycles in The Netherlands",48,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MotorCycles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MotorCycles.html","MotorCycles R Documentation   Motor Cycles in The Netherlands   Description  
Time series of stock of motor cycles (two wheels) in The Netherlands (in thousands).    Usage   data(""MotorCycles"")   Format  
An annual univariate time series from 1946 to 1993.    Details  
An updated version is available under the name MotorCycles2 . However, the values for the years 1992 and 1993 differ there.   Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998 , MotorCycles2   Examples    data(""MotorCycles"") plot(MotorCycles)"
"AER-MotorCycles2","AER","MotorCycles2","Motor Cycles in The Netherlands",67,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MotorCycles2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MotorCycles2.html","MotorCycles2 R Documentation   Motor Cycles in The Netherlands   Description  
Time series of stock of motor cycles (two wheels) in The Netherlands (in thousands).    Usage   data(""MotorCycles2"")   Format  
An annual univariate time series from 1946 to 2012.    Details  
This is an update of the series that was available with Franses (1998). However, the values for the years 1992 and 1993 differ.   Source  
Online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.   
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    See Also  
Franses1998 , MotorCycles   Examples    data(""MotorCycles2"") plot(MotorCycles2)"
"AER-MSCISwitzerland","AER","MSCISwitzerland","MSCI Switzerland Index",4697,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MSCISwitzerland.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MSCISwitzerland.html","MSCISwitzerland R Documentation   MSCI Switzerland Index   Description  
Time series of the MSCI Switzerland index.    Usage   data(""MSCISwitzerland"")   Format  
A daily univariate time series from 1994-12-30 to 2012-12-31 (of class ""zoo"" with ""Date"" index).    Source  
Online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Ding, Z., Granger, C. W. J. and Engle, R. F. (1993). A Long Memory Property of Stock Market Returns and a New Model. Journal of Empirical Finance , 1(1), 83–106.   
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    Examples    data(""MSCISwitzerland"", package = ""AER"") ## p.190, Fig. 7.6 dlmsci <- 100 * diff(log(MSCISwitzerland)) plot(dlmsci) dlmsci9501 <- window(dlmsci, end = as.Date(""2001-12-31"")) ## Figure 7.7 plot(acf(dlmsci9501^2, lag.max = 200, na.action = na.exclude), ylim = c(-0.1, 0.3), type = ""l"") ## GARCH(1,1) model, p.190, eq. (7.60) ## standard errors using first derivatives (as apparently used by Franses et al.) library(""tseries"") msci9501_g11 <- garch(zooreg(dlmsci9501), trace = FALSE) summary(msci9501_g11) ## standard errors using second derivatives library(""fGarch"") msci9501_g11a <- garchFit( ~ garch(1,1), include.mean = FALSE, data = dlmsci9501, trace = FALSE) summary(msci9501_g11a) round(msci9501_g11a@fit$coef, 3) round(msci9501_g11a@fit$se.coef, 3) ## Fig. 7.8, p.192 plot(msci9501_g11a, which = 2) abline(h = sd(dlmsci9501)) ## TGARCH model (also known as GJR-GARCH model), p. 191, eq. (7.61) msci9501_tg11 <- garchFit( ~ aparch(1,1), include.mean = FALSE, include.delta = FALSE, delta = 2, data = dlmsci9501, trace = FALSE) summary(msci9501_tg11) ## GJR form using reparameterization as given by Ding et al. (1993, pp. 100-101) coef(msci9501_tg11)[""alpha1""] * (1 - coef(msci9501_tg11)[""gamma1""])^2 ## alpha* 4 * coef(msci9501_tg11)[""alpha1""] * coef(msci9501_tg11)[""gamma1""] ## gamma* ## GARCH and GJR-GARCH with rugarch library(""rugarch"") spec_g11 <- ugarchspec(variance.model = list(model = ""sGARCH""), mean.model = list(armaOrder = c(0,0), include.mean = FALSE)) msci9501_g11b <- ugarchfit(spec_g11, data = dlmsci9501) msci9501_g11b spec_gjrg11 <- ugarchspec(variance.model = list(model = ""gjrGARCH"", garchOrder = c(1,1)), mean.model = list(armaOrder = c(0, 0), include.mean = FALSE)) msci9501_gjrg11 <- ugarchfit(spec_gjrg11, data = dlmsci9501) msci9501_gjrg11 round(coef(msci9501_gjrg11), 3)"
"AER-Municipalities","AER","Municipalities","Municipal Expenditure Data",2385,5,0,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Municipalities.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Municipalities.html","Municipalities R Documentation   Municipal Expenditure Data   Description  
Panel data set for 265 Swedish municipalities covering 9 years (1979-1987).    Usage   data(""Municipalities"")   Format  
A data frame containing 2,385 observations on 5 variables.    municipality
factor with ID number for municipality.   year
factor coding year.   expenditures
total expenditures.   revenues
total own-source revenues.   grants
intergovernmental grants received by the municipality.     Details  
Total expenditures contains both capital and current expenditures.  
Expenditures, revenues, and grants are expressed in million SEK. The series are deflated and in per capita form. The implicit deflator is a municipality-specific price index obtained by dividing total local consumption expenditures at current prices by total local consumption expenditures at fixed (1985) prices.  
The data are gathered by Statistics Sweden and obtained from Financial Accounts for the Municipalities (Kommunernas Finanser).   Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/2000-v15.4/dahlberg-johansson/     References  
Dahlberg, M., and Johansson, E. (2000). An Examination of the Dynamic Behavior of Local Governments Using GMM Bootstrapping Methods. Journal of Applied Econometrics , 15 , 401–416.   
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    ## Greene (2003), Table 18.2 data(""Municipalities"") summary(Municipalities)"
"AER-MurderRates","AER","MurderRates","Determinants of Murder Rates in the United States",44,8,1,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/MurderRates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/MurderRates.html","MurderRates R Documentation   Determinants of Murder Rates in the United States   Description  
Cross-section data on states in 1950.    Usage   data(""MurderRates"")   Format  
A data frame containing 44 observations on 8 variables.    rate
Murder rate per 100,000 (FBI estimate, 1950).   convictions
Number of convictions divided by number of murders in 1950.   executions
Average number of executions during 1946–1950 divided by convictions in 1950.   time
Median time served (in months) of convicted murderers released in 1951.   income
Median family income in 1949 (in 1,000 USD).   lfp
Labor force participation rate in 1950 (in percent).   noncauc
Proportion of population that is non-Caucasian in 1950.   southern
Factor indicating region.     Source  
Maddala (2001), Table 8.4, p. 330    References  
Maddala, G.S. (2001). Introduction to Econometrics , 3rd ed. New York: John Wiley.   
McManus, W.S. (1985). Estimates of the Deterrent Effect of Capital Punishment: The Importance of the Researcher's Prior Beliefs. Journal of Political Economy , 93 , 417–425.   
Stokes, H. (2004). On the Advantage of Using Two or More Econometric Software Systems to Solve the Same Problem.  Journal of Economic and Social Measurement , 29 , 307–320.    Examples    data(""MurderRates"") ## Maddala (2001, pp. 331) fm_lm <- lm(rate ~ . + I(executions > 0), data = MurderRates) summary(fm_lm) model <- I(executions > 0) ~ time + income + noncauc + lfp + southern fm_lpm <- lm(model, data = MurderRates) summary(fm_lpm) ## Binomial models. Note: southern coefficient fm_logit <- glm(model, data = MurderRates, family = binomial) summary(fm_logit) fm_logit2 <- glm(model, data = MurderRates, family = binomial, control = list(epsilon = 1e-15, maxit = 50, trace = FALSE)) summary(fm_logit2) fm_probit <- glm(model, data = MurderRates, family = binomial(link = ""probit"")) summary(fm_probit) fm_probit2 <- glm(model, data = MurderRates , family = binomial(link = ""probit""), control = list(epsilon = 1e-15, maxit = 50, trace = FALSE)) summary(fm_probit2) ## Explanation: quasi-complete separation with(MurderRates, table(executions > 0, southern))"
"AER-NaturalGas","AER","NaturalGas","Natural Gas Data",138,10,0,0,3,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/NaturalGas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/NaturalGas.html","NaturalGas R Documentation   Natural Gas Data   Description  
Panel data originating from 6 US states over the period 1967–1989.    Usage   data(""NaturalGas"")   Format  
A data frame containing 138 observations on 10 variables.    state
factor. State abbreviation.   statecode
factor. State Code.   year
factor coding year.   consumption
Consumption of natural gas by the residential sector.   price
Price of natural gas   eprice
Price of electricity.   oprice
Price of distillate fuel oil.   lprice
Price of liquefied petroleum gas.   heating
Heating degree days.   income
Real per-capita personal income.     Source  
The data are from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002   Examples    data(""NaturalGas"") summary(NaturalGas)"
"AER-NMES1988","AER","NMES1988","Demand for Medical Care in NMES 1988",4406,19,7,0,9,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/NMES1988.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/NMES1988.html","NMES1988 R Documentation   Demand for Medical Care in NMES 1988   Description  
Cross-section data originating from the US National Medical Expenditure Survey (NMES) conducted in 1987 and 1988. The NMES is based upon a representative, national probability sample of the civilian non-institutionalized population and individuals admitted to long-term care facilities during 1987. The data are a subsample of individuals ages 66 and over all of whom are covered by Medicare (a public insurance program providing substantial protection against health-care costs).    Usage   data(""NMES1988"")   Format  
A data frame containing 4,406 observations on 19 variables.    visits
Number of physician office visits.   nvisits
Number of non-physician office visits.   ovisits
Number of physician hospital outpatient visits.   novisits
Number of non-physician hospital outpatient visits.   emergency
Emergency room visits.   hospital
Number of hospital stays.   health
Factor indicating self-perceived health status, levels are  ""poor"" , ""average"" (reference category), ""excellent"" .   chronic
Number of chronic conditions.   adl
Factor indicating whether the individual has a condition that limits activities of daily living ( ""limited"" ) or not ( ""normal"" ).   region
Factor indicating region, levels are northeast ,  midwest , west , other (reference category).   age
Age in years (divided by 10).   afam
Factor. Is the individual African-American?   gender
Factor indicating gender.   married
Factor. is the individual married?   school
Number of years of education.   income
Family income in USD 10,000.   employed
Factor. Is the individual employed?   insurance
Factor. Is the individual covered by private insurance?   medicaid
Factor. Is the individual covered by Medicaid?     Source  
Journal of Applied Econometrics Data Archive for Deb and Trivedi (1997).  
http://qed.econ.queensu.ca/jae/1997-v12.3/deb-trivedi/     References  
Cameron, A.C. and Trivedi, P.K. (1998). Regression Analysis of Count Data . Cambridge: Cambridge University Press.   
Deb, P., and Trivedi, P.K. (1997). Demand for Medical Care by the Elderly: A Finite Mixture Approach. Journal of Applied Econometrics ,  12 , 313–336.   
Zeileis, A., Kleiber, C., and Jackman, S. (2008). Regression Models for Count Data in R. Journal of Statistical Software , 27 (8). URL http://www.jstatsoft.org/v27/i08/ .    See Also  
CameronTrivedi1998   Examples    ## packages library(""MASS"") library(""pscl"") ## select variables for analysis data(""NMES1988"") nmes <- NMES1988[, c(1, 7:8, 13, 15, 18)] ## dependent variable hist(nmes$visits, breaks = 0:(max(nmes$visits)+1) - 0.5) plot(table(nmes$visits)) ## convenience transformations for exploratory graphics clog <- function(x) log(x + 0.5) cfac <- function(x, breaks = NULL) { if(is.null(breaks)) breaks <- unique(quantile(x, 0:10/10)) x <- cut(x, breaks, include.lowest = TRUE, right = FALSE) levels(x) <- paste(breaks[-length(breaks)], ifelse(diff(breaks) > 1, c(paste(""-"", breaks[-c(1, length(breaks))] - 1, sep = """"), ""+""), """"), sep = """") return(x) } ## bivariate visualization par(mfrow = c(3, 2)) plot(clog(visits) ~ health, data = nmes, varwidth = TRUE) plot(clog(visits) ~ cfac(chronic), data = nmes) plot(clog(visits) ~ insurance, data = nmes, varwidth = TRUE) plot(clog(visits) ~ gender, data = nmes, varwidth = TRUE) plot(cfac(visits, c(0:2, 4, 6, 10, 100)) ~ school, data = nmes, breaks = 9) par(mfrow = c(1, 1)) ## Poisson regression nmes_pois <- glm(visits ~ ., data = nmes, family = poisson) summary(nmes_pois) ## LM test for overdispersion dispersiontest(nmes_pois) dispersiontest(nmes_pois, trafo = 2) ## sandwich covariance matrix coeftest(nmes_pois, vcov = sandwich) ## quasipoisson model nmes_qpois <- glm(visits ~ ., data = nmes, family = quasipoisson) ## NegBin regression nmes_nb <- glm.nb(visits ~ ., data = nmes) ## hurdle regression nmes_hurdle <- hurdle(visits ~ . | chronic + insurance + school + gender, data = nmes, dist = ""negbin"") ## zero-inflated regression model nmes_zinb <- zeroinfl(visits ~ . | chronic + insurance + school + gender, data = nmes, dist = ""negbin"") ## compare estimated coefficients fm <- list(""ML-Pois"" = nmes_pois, ""Quasi-Pois"" = nmes_qpois, ""NB"" = nmes_nb, ""Hurdle-NB"" = nmes_hurdle, ""ZINB"" = nmes_zinb) round(sapply(fm, function(x) coef(x)[1:7]), digits = 3) ## associated standard errors round(cbind(""ML-Pois"" = sqrt(diag(vcov(nmes_pois))), ""Adj-Pois"" = sqrt(diag(sandwich(nmes_pois))), sapply(fm[-1], function(x) sqrt(diag(vcov(x)))[1:7])), digits = 3) ## log-likelihoods and number of estimated parameters rbind(logLik = sapply(fm, function(x) round(logLik(x), digits = 0)), Df = sapply(fm, function(x) attr(logLik(x), ""df""))) ## predicted number of zeros round(c(""Obs"" = sum(nmes$visits < 1), ""ML-Pois"" = sum(dpois(0, fitted(nmes_pois))), ""Adj-Pois"" = NA, ""Quasi-Pois"" = NA, ""NB"" = sum(dnbinom(0, mu = fitted(nmes_nb), size = nmes_nb$theta)), ""NB-Hurdle"" = sum(predict(nmes_hurdle, type = ""prob"")[,1]), ""ZINB"" = sum(predict(nmes_zinb, type = ""prob"")[,1]))) ## coefficients of zero-augmentation models t(sapply(fm[4:5], function(x) round(x$coefficients$zero, digits = 3)))"
"AER-NYSESW","AER","NYSESW","Daily NYSE Composite Index",4003,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/NYSESW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/NYSESW.html","NYSESW R Documentation   Daily NYSE Composite Index   Description  
A daily time series from 1990 to 2005 of the New York Stock Exchange composite index.    Usage   data(""NYSESW"")   Format  
A daily univariate time series from 1990-01-02 to 2005-11-11 (of class  ""zoo"" with ""Date"" index).    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    ## returns data(""NYSESW"") ret <- 100 * diff(log(NYSESW)) plot(ret) ## Stock and Watson (2007), p. 667, GARCH(1,1) model library(""tseries"") fm <- garch(coredata(ret)) summary(fm)"
"AER-OECDGas","AER","OECDGas","Gasoline Consumption Data",342,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/OECDGas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/OECDGas.html","OECDGas R Documentation   Gasoline Consumption Data   Description  
Panel data on gasoline consumption in 18 OECD countries over 19 years, 1960–1978.   Usage   data(""OECDGas"")   Format  
A data frame containing 342 observations on 6 variables.    country
Factor indicating country.   year
Year.   gas
Logarithm of motor gasoline consumption per car.   income
Logarithm of real per-capita income.   price
Logarithm of real motor gasoline price.   cars
Logarithm of the stock of cars per-capita.     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Baltagi, B.H. and Griffin, J.M. (1983). Gasoline Demand in the OECD: An Application of Pooling and Testing Procedures. European Economic Review , 22 , 117–137.    See Also  
Baltagi2002   Examples    data(""OECDGas"") library(""lattice"") xyplot(exp(cars) ~ year | country, data = OECDGas, type = ""l"") xyplot(exp(gas) ~ year | country, data = OECDGas, type = ""l"")"
"AER-OECDGrowth","AER","OECDGrowth","OECD Macroeconomic Data",22,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/OECDGrowth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/OECDGrowth.html","OECDGrowth R Documentation   OECD Macroeconomic Data   Description  
Cross-section data on OECD countries, used for growth regressions.   Usage   data(""OECDGrowth"")   Format  
A data frame with 22 observations on the following 6 variables.    gdp85
real GDP in 1985 (per person of working age, i.e., age 15 to 65), in 1985 international prices.   gdp60
real GDP in 1960 (per person of working age, i.e., age 15 to 65), in 1985 international prices.   invest
average of annual ratios of real domestic investment to real GDP (1960–1985).   school
percentage of the working-age population that is in secondary school.   randd
average of annual ratios of gross domestic expenditure on research and development to nominal GDP (of available observations during 1960–1985).   popgrowth
annual population growth 1960–1985, computed as log(pop85/pop60)/25 .     Source  
Appendix 1 Nonneman and Vanhoudt (1996), except for one bad misprint: The value of school for Norway is given as 0.01, the correct value is 0.1 (see Mankiw, Romer and Weil, 1992). OECDGrowth contains the corrected data.    References  
Mankiw, N.G., Romer, D., and Weil, D.N. (1992). A Contribution to the Empirics of Economic Growth. Quarterly Journal of Economics , 107 , 407–437.   
Nonneman, W., and Vanhoudt, P. (1996). A Further Augmentation of the Solow Model and the Empirics of Economic Growth. Quarterly Journal of Economics , 111 , 943–953.   
Zaman, A., Rousseeuw, P.J., and Orhan, M. (2001). Econometric Applications of High-Breakdown Robust Regression Techniques. Economics Letters , 71 , 1–8.    See Also  
GrowthDJ , GrowthSW   Examples    data(""OECDGrowth"") ## Nonneman and Vanhoudt (1996), Table II cor(OECDGrowth[, 3:6]) cor(log(OECDGrowth[, 3:6])) ## textbook Solow model ## Nonneman and Vanhoudt (1996), Table IV, and ## Zaman, Rousseeuw and Orhan (2001), Table 2 so_ols <- lm(log(gdp85/gdp60) ~ log(gdp60) + log(invest) + log(popgrowth+.05), data = OECDGrowth) summary(so_ols) ## augmented and extended Solow growth model ## Nonneman and Vanhoudt (1996), Table IV aso_ols <- lm(log(gdp85/gdp60) ~ log(gdp60) + log(invest) + log(school) + log(popgrowth+.05), data = OECDGrowth) eso_ols <- lm(log(gdp85/gdp60) ~ log(gdp60) + log(invest) + log(school) + log(randd) + log(popgrowth+.05), data = OECDGrowth) ## determine unusual observations using LTS library(""MASS"") so_lts <- lqs(log(gdp85/gdp60) ~ log(gdp60) + log(invest) + log(popgrowth+.05), data = OECDGrowth, psamp = 13, nsamp = ""exact"") ## large residuals nok1 <- abs(residuals(so_lts))/so_lts$scale[2] > 2.5 residuals(so_lts)[nok1]/so_lts$scale[2] ## high leverage X <- model.matrix(so_ols)[,-1] cv <- cov.rob(X, nsamp = ""exact"") mh <- sqrt(mahalanobis(X, cv$center, cv$cov)) nok2 <- mh > 2.5 mh[nok2] ## bad leverage nok <- which(nok1 & nok2) nok ## robust results without bad leverage points so_rob <- update(so_ols, subset = -nok) summary(so_rob) ## This is similar to Zaman, Rousseeuw and Orhan (2001), Table 2 ## but uses exact computations (and not sub-optimal results ## for the robust functions lqs and cov.rob)"
"AER-OlympicTV","AER","OlympicTV","Television Rights for Olympic Games",10,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/OlympicTV.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/OlympicTV.html","OlympicTV R Documentation   Television Rights for Olympic Games   Description  
Television rights for Olympic Games for US networks (in millions USD).    Usage   data(""OlympicTV"")   Format  
A data frame with 10 observations and 2 variables.    rights
time series of television rights (in million USD),   network
factor coding television network.     Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""OlympicTV"") plot(OlympicTV$rights)"
"AER-OrangeCounty","AER","OrangeCounty","Orange County Employment",76,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/OrangeCounty.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/OrangeCounty.html","OrangeCounty R Documentation   Orange County Employment   Description  
Quarterly time series data on employment in Orange county, 1965–1983.    Usage   data(""OrangeCounty"")   Format  
A quarterly multiple time series from 1965 to 1983 with 2 variables.    employment
Quarterly employment in Orange county.   gnp
Quarterly real GNP.     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002   Examples    data(""OrangeCounty"") plot(OrangeCounty)"
"AER-Parade2005","AER","Parade2005","Parade Magazine 2005 Earnings Data",130,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/Parade2005.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/Parade2005.html","Parade2005 R Documentation   Parade Magazine 2005 Earnings Data   Description  
US earnings data, as provided in an annual survey of Parade (here from 2005), the Sunday newspaper magazine supplementing the Sunday (or Weekend) edition of many daily newspapers in the USA.   Usage   data(""Parade2005"")   Format  
A data frame containing 130 observations on 5 variables.    earnings
Annual personal earnings.   age
Age in years.   gender
Factor indicating gender.   state
Factor indicating state.   celebrity
Factor. Is the individual a celebrity?     Details  
In addition to the four variables provided by Parade (earnings, age, gender, and state), a fifth variable was introduced, the “celebrity factor” (here actors, athletes, TV personalities, politicians, and CEOs are considered celebrities). The data are quite far from a simple random sample, there being substantial oversampling of celebrities.    Source  
Parade (2005). What People Earn. Issue March 13, 2005.    Examples    ## data data(""Parade2005"") attach(Parade2005) summary(Parade2005) ## bivariate visualizations plot(density(log(earnings), bw = ""SJ""), type = ""l"", main = ""log(earnings)"") rug(log(earnings)) plot(log(earnings) ~ gender, main = ""log(earnings)"") ## celebrity vs. non-celebrity earnings noncel <- subset(Parade2005, celebrity == ""no"") cel <- subset(Parade2005, celebrity == ""yes"") library(""ineq"") plot(Lc(noncel$earnings), main = ""log(earnings)"") lines(Lc(cel$earnings), lty = 2) lines(Lc(earnings), lty = 3) Gini(noncel$earnings) Gini(cel$earnings) Gini(earnings) ## detach data detach(Parade2005)"
"AER-PepperPrice","AER","PepperPrice","Black and White Pepper Prices",271,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/PepperPrice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/PepperPrice.html","PepperPrice R Documentation   Black and White Pepper Prices   Description  
Time series of average monthly European spot prices for black and white pepper (fair average quality) in US dollars per ton.    Usage   data(""PepperPrice"")   Format  
A monthly multiple time series from 1973(10) to 1996(4) with 2 variables.    black
spot price for black pepper,   white
spot price for white pepper.     Source  
Originally available as an online supplement to Franses (1998). Now available via online complements to Franses, van Dijk and Opschoor (2014).   
http://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/time-series-models-business-and-economic-forecasting-2nd-edition     References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.   
Franses, P.H., van Dijk, D. and Opschoor, A. (2014). Time Series Models for Business and Economic Forecasting , 2nd ed. Cambridge, UK: Cambridge University Press.    Examples    ## data data(""PepperPrice"") plot(PepperPrice, plot.type = ""single"", col = 1:2) ## package library(""tseries"") library(""urca"") ## unit root tests adf.test(log(PepperPrice[, ""white""])) adf.test(diff(log(PepperPrice[, ""white""]))) pp.test(log(PepperPrice[, ""white""]), type = ""Z(t_alpha)"") pepper_ers <- ur.ers(log(PepperPrice[, ""white""]), type = ""DF-GLS"", model = ""const"", lag.max = 4) summary(pepper_ers) ## stationarity tests kpss.test(log(PepperPrice[, ""white""])) ## cointegration po.test(log(PepperPrice)) pepper_jo <- ca.jo(log(PepperPrice), ecdet = ""const"", type = ""trace"") summary(pepper_jo) pepper_jo2 <- ca.jo(log(PepperPrice), ecdet = ""const"", type = ""eigen"") summary(pepper_jo2)"
"AER-PhDPublications","AER","PhDPublications","Doctoral Publications",915,6,2,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/PhDPublications.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/PhDPublications.html","PhDPublications R Documentation   Doctoral Publications   Description  
Cross-section data on the scientific productivity of PhD students in biochemistry.   Usage   data(""PhDPublications"")   Format  
A data frame containing 915 observations on 6 variables.    articles
Number of articles published during last 3 years of PhD.   gender
factor indicating gender.   married
factor. Is the PhD student married?   kids
Number of children less than 6 years old.   prestige
Prestige of the graduate program.   mentor
Number of articles published by student's mentor.     Source  
Online complements to Long (1997).  
http://www.indiana.edu/~jslsoc/research_rm4cldvs.htm     References  
Long, J.S. (1990).  Regression Models for Categorical and Limited Dependent Variables . Thousand Oaks: Sage Publications.   
Long, J.S. (1997). The Origin of Sex Differences in Science.  Social Forces , 68 , 1297–1315.    Examples    ## from Long (1997) data(""PhDPublications"") ## Table 8.1, p. 227 summary(PhDPublications) ## Figure 8.2, p. 220 plot(0:10, dpois(0:10, mean(PhDPublications$articles)), type = ""b"", col = 2, xlab = ""Number of articles"", ylab = ""Probability"") lines(0:10, prop.table(table(PhDPublications$articles))[1:11], type = ""b"") legend(""topright"", c(""observed"", ""predicted""), col = 1:2, lty = rep(1, 2), bty = ""n"") ## Table 8.2, p. 228 fm_lrm <- lm(log(articles + 0.5) ~ ., data = PhDPublications) summary(fm_lrm) -2 * logLik(fm_lrm) fm_prm <- glm(articles ~ ., data = PhDPublications, family = poisson) library(""MASS"") fm_nbrm <- glm.nb(articles ~ ., data = PhDPublications) ## Table 8.3, p. 246 library(""pscl"") fm_zip <- zeroinfl(articles ~ . | ., data = PhDPublications) fm_zinb <- zeroinfl(articles ~ . | ., data = PhDPublications, dist = ""negbin"")"
"AER-ProgramEffectiveness","AER","ProgramEffectiveness","Program Effectiveness Data",32,4,2,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ProgramEffectiveness.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ProgramEffectiveness.html","ProgramEffectiveness R Documentation   Program Effectiveness Data   Description  
Data used to study the effectiveness of a program.    Usage   data(""ProgramEffectiveness"")   Format  
A data frame containing 32 cross-section observations on 4 variables.    grade
Factor with levels ""increase"" and ""decrease"" .   average
Grade-point average.   testscore
Test score on economics test.   participation
Factor. Did the individual participate in the program?     Details  
The data are taken form Spencer and Mazzeo (1980) who examined whether a new method of teaching economics significantly influenced performance in later economics courses.    Source  
Online complements to Greene (2003).   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Spector, L. and Mazzeo, M. (1980). Probit Analysis and Economic Education. Journal of Economic Education , 11 , 37–44.    See Also  
Greene2003   Examples    data(""ProgramEffectiveness"") ## Greene (2003), Table 21.1, col. ""Probit"" fm_probit <- glm(grade ~ average + testscore + participation, data = ProgramEffectiveness, family = binomial(link = ""probit"")) summary(fm_probit)"
"AER-PSID1976","AER","PSID1976","Labor Force Participation Data",753,21,4,0,4,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/PSID1976.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/PSID1976.html","PSID1976 R Documentation   Labor Force Participation Data   Description  
Cross-section data originating from the 1976 Panel Study of Income Dynamics (PSID), based on data for the previous year, 1975.   Usage   data(""PSID1976"")   Format  
A data frame containing 753 observations on 21 variables.    participation
Factor. Did the individual participate in the labor force in 1975? (This is essentially wage > 0 or hours > 0 .)   hours
Wife's hours of work in 1975.   youngkids
Number of children less than 6 years old in household.   oldkids
Number of children between ages 6 and 18 in household.   age
Wife's age in years.   education
Wife's education in years.   wage
Wife's average hourly wage, in 1975 dollars.   repwage
Wife's wage reported at the time of the 1976 interview (not the same as the 1975 estimated wage). To use the subsample with this wage, one needs to select 1975 workers with participation == ""yes"" , then select only those women with non-zero wage. Only 325 women work in 1975 and have a non-zero wage in 1976.   hhours
Husband's hours worked in 1975.   hage
Husband's age in years.   heducation
Husband's education in years.   hwage
Husband's wage, in 1975 dollars.   fincome
Family income, in 1975 dollars. (This variable is used to construct the property income variable.)   tax
Marginal tax rate facing the wife, and is taken from published federal tax tables (state and local income taxes are excluded). The taxable income on which this tax rate is calculated includes Social Security, if applicable to wife.   meducation
Wife's mother's educational attainment, in years.   feducation
Wife's father's educational attainment, in years.   unemp
Unemployment rate in county of residence, in percentage points. (This is taken from bracketed ranges.)   city
Factor. Does the individual live in a large city?   experience
Actual years of wife's previous labor market experience.   college
Factor. Did the individual attend college?   hcollege
Factor. Did the individual's husband attend college?     Details  
This data set is also known as the Mroz (1987) data.   
Warning: Typical applications using these data employ the variable  wage (aka earnings in previous versions of the data) as the dependent variable. The variable repwage is the reported wage in a 1976 interview, named RPWG by Greene (2003).    Source  
Online complements to Greene (2003). Table F4.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
McCullough, B.D. (2004). Some Details of Nonlinear Estimation. In: Altman, M., Gill, J., and McDonald, M.P.: Numerical Issues in Statistical Computing for the Social Scientist . Hoboken, NJ: John Wiley, Ch. 8, 199–218.   
Mroz, T.A. (1987). The Sensitivity of an Empirical Model of Married Women's Hours of Work to Economic and Statistical Assumptions. Econometrica , 55 , 765–799.   
Winkelmann, R., and Boes, S. (2009). Analysis of Microdata , 2nd ed. Berlin and Heidelberg: Springer-Verlag.   
Wooldridge, J.M. (2002). Econometric Analysis of Cross-Section and Panel Data . Cambridge, MA: MIT Press.    See Also  
Greene2003 , WinkelmannBoes2009   Examples    ## data and transformations data(""PSID1976"") PSID1976$kids <- with(PSID1976, factor((youngkids + oldkids) > 0, levels = c(FALSE, TRUE), labels = c(""no"", ""yes""))) PSID1976$nwincome <- with(PSID1976, (fincome - hours * wage)/1000) PSID1976$partnum <- as.numeric(PSID1976$participation) - 1 ################### ## Greene (2003) ## ################### ## Example 4.1, Table 4.2 ## (reproduced in Example 7.1, Table 7.1) gr_lm <- lm(log(hours * wage) ~ age + I(age^2) + education + kids, data = PSID1976, subset = participation == ""yes"") summary(gr_lm) vcov(gr_lm) ## Example 4.5 summary(gr_lm) ## or equivalently gr_lm1 <- lm(log(hours * wage) ~ 1, data = PSID1976, subset = participation == ""yes"") anova(gr_lm1, gr_lm) ## Example 21.4, p. 681, and Tab. 21.3, p. 682 gr_probit1 <- glm(participation ~ age + I(age^2) + I(fincome/10000) + education + kids, data = PSID1976, family = binomial(link = ""probit"") ) gr_probit2 <- glm(participation ~ age + I(age^2) + I(fincome/10000) + education, data = PSID1976, family = binomial(link = ""probit"")) gr_probit3 <- glm(participation ~ kids/(age + I(age^2) + I(fincome/10000) + education), data = PSID1976, family = binomial(link = ""probit"")) ## LR test of all coefficients lrtest(gr_probit1) ## Chow-type test lrtest(gr_probit2, gr_probit3) ## equivalently: anova(gr_probit2, gr_probit3, test = ""Chisq"") ## Table 21.3 summary(gr_probit1) ## Example 22.8, Table 22.7, p. 786 library(""sampleSelection"") gr_2step <- selection(participation ~ age + I(age^2) + fincome + education + kids, wage ~ experience + I(experience^2) + education + city, data = PSID1976, method = ""2step"") gr_ml <- selection(participation ~ age + I(age^2) + fincome + education + kids, wage ~ experience + I(experience^2) + education + city, data = PSID1976, method = ""ml"") gr_ols <- lm(wage ~ experience + I(experience^2) + education + city, data = PSID1976, subset = participation == ""yes"") ## NOTE: ML estimates agree with Greene, 5e errata. ## Standard errors are based on the Hessian (here), while Greene has BHHH/OPG. ####################### ## Wooldridge (2002) ## ####################### ## Table 15.1, p. 468 wl_lpm <- lm(partnum ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids, data = PSID1976) wl_logit <- glm(participation ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids, family = binomial, data = PSID1976) wl_probit <- glm(participation ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids, family = binomial(link = ""probit""), data = PSID1976) ## (same as Altman et al.) ## convenience functions pseudoR2 <- function(obj) 1 - as.vector(logLik(obj)/logLik(update(obj, . ~ 1))) misclass <- function(obj) 1 - sum(diag(prop.table(table( model.response(model.frame(obj)), round(fitted(obj)))))) coeftest(wl_logit) logLik(wl_logit) misclass(wl_logit) pseudoR2(wl_logit) coeftest(wl_probit) logLik(wl_probit) misclass(wl_probit) pseudoR2(wl_probit) ## Table 16.2, p. 528 form <- hours ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids wl_ols <- lm(form, data = PSID1976) wl_tobit <- tobit(form, data = PSID1976) summary(wl_ols) summary(wl_tobit) ####################### ## McCullough (2004) ## ####################### ## p. 203 mc_probit <- glm(participation ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids, family = binomial(link = ""probit""), data = PSID1976) mc_tobit <- tobit(hours ~ nwincome + education + experience + I(experience^2) + age + youngkids + oldkids, data = PSID1976) coeftest(mc_probit) coeftest(mc_tobit) coeftest(mc_tobit, vcov = vcovOPG)"
"AER-PSID1982","AER","PSID1982","PSID Earnings Data 1982",595,12,8,0,8,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/PSID1982.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/PSID1982.html","PSID1982 R Documentation   PSID Earnings Data 1982   Description  
Cross-section data originating from the Panel Study on Income Dynamics, 1982.   Usage   data(""PSID1982"")   Format  
A data frame containing 595 observations on 12 variables.    experience
Years of full-time work experience.   weeks
Weeks worked.   occupation
factor. Is the individual a white-collar ( ""white"" ) or blue-collar ( ""blue"" ) worker?   industry
factor. Does the individual work in a manufacturing industry?   south
factor. Does the individual reside in the South?   smsa
factor. Does the individual reside in a SMSA (standard metropolitan statistical area)?   married
factor. Is the individual married?   gender
factor indicating gender.   union
factor. Is the individual's wage set by a union contract?   education
Years of education.   ethnicity
factor indicating ethnicity. Is the individual African-American ( ""afam"" ) or not ( ""other"" )?   wage
Wage.     Details  
PSID1982 is the cross-section for the year 1982 taken from a larger panel data set  PSID7682 for the years 1976–1982, originating from Cornwell and Rupert (1988). Baltagi (2002) just uses the 1982 cross-section; hence PSID1982 is available as a standalone data set because it was included in AER prior to the availability of the full PSID7682 panel version.    Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Cornwell, C., and Rupert, P. (1988). Efficient Estimation with Panel Data: An Empirical Comparison of Instrumental Variables Estimators. Journal of Applied Econometrics , 3 , 149–155.    See Also  
PSID7682 , Baltagi2002   Examples    data(""PSID1982"") plot(density(PSID1982$wage, bw = ""SJ"")) ## Baltagi (2002), Table 4.1 earn_lm <- lm(log(wage) ~ . + I(experience^2), data = PSID1982) summary(earn_lm) ## Baltagi (2002), Table 13.1 union_lpm <- lm(I(as.numeric(union) - 1) ~ . - wage, data = PSID1982) union_probit <- glm(union ~ . - wage, data = PSID1982, family = binomial(link = ""probit"")) union_logit <- glm(union ~ . - wage, data = PSID1982, family = binomial) ## probit OK, logit and LPM rather different."
"AER-PSID7682","AER","PSID7682","PSID Earnings Panel Data (1976-1982)",4165,14,8,0,10,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/PSID7682.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/PSID7682.html","PSID7682 R Documentation   PSID Earnings Panel Data (1976–1982)   Description  
Panel data on earnings of 595 individuals for the years 1976–1982, originating from the Panel Study of Income Dynamics.   Usage   data(""PSID7682"")   Format  
A data frame containing 7 annual observations on 12 variables for 595 individuals.   experience
Years of full-time work experience.   weeks
Weeks worked.   occupation
factor. Is the individual a white-collar ( ""white"" ) or blue-collar ( ""blue"" ) worker?   industry
factor. Does the individual work in a manufacturing industry?   south
factor. Does the individual reside in the South?   smsa
factor. Does the individual reside in a SMSA (standard metropolitan statistical area)?   married
factor. Is the individual married?   gender
factor indicating gender.   union
factor. Is the individual's wage set by a union contract?   education
Years of education.   ethnicity
factor indicating ethnicity. Is the individual African-American ( ""afam"" ) or not ( ""other"" )?   wage
Wage.   year
factor indicating year.   id
factor indicating individual subject ID.     Details  
The data were originally analyzed by Cornwell and Rupert (1988) and employed for assessing various instrumental-variable estimators for panel models (including the Hausman-Taylor model). Baltagi and Khanti-Akom (1990) reanalyzed the data, made corrections to the data and also suggest modeling with a different set of instruments.   
PSID7682 is the version of the data as provided by Baltagi (2005), or Greene (2008).   
Baltagi (2002) just uses the cross-section for the year 1982, i.e., subset(PSID7682, year == ""1982"") . This is also available as a standalone data set PSID1982 because it was included in AER prior to the availability of the full PSID7682 panel version.    Source  
Online complements to Baltagi (2005).   
http://www.wiley.com/legacy/wileychi/baltagi3e/data_sets.html    
Also provided in the online complements to Greene (2008), Table F9.1.   
http://pages.stern.nyu.edu/~wgreene/Text/Edition6/tablelist6.htm     References  
Baltagi, B.H., and Khanti-Akom, S. (1990). On Efficient Estimation with Panel Data: An Empirical Comparison of Instrumental Variables Estimators.  Journal of Applied Econometrics , 5 , 401–406.   
Baltagi, B.H. (2001). Econometric Analysis of Panel Data , 2nd ed. Chichester, UK: John Wiley.   
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Baltagi, B.H. (2005). Econometric Analysis of Panel Data , 3rd ed. Chichester, UK: John Wiley.   
Cornwell, C., and Rupert, P. (1988). Efficient Estimation with Panel Data: An Empirical Comparison of Instrumental Variables Estimators. Journal of Applied Econometrics , 3 , 149–155.   
Greene, W.H. (2008). Econometric Analysis , 6th ed. Upper Saddle River, NJ: Prentice Hall.    See Also  
PSID1982 , Baltagi2002   Examples    data(""PSID7682"") library(""plm"") psid <- pdata.frame(PSID7682, c(""id"", ""year"")) ## Baltagi & Khanti-Akom, Table I, column ""HT"" ## original Cornwell & Rupert choice of exogenous variables psid_ht1 <- plm(log(wage) ~ weeks + south + smsa + married + experience + I(experience^2) + occupation + industry + union + gender + ethnicity + education | weeks + south + smsa + married + gender + ethnicity, data = psid, model = ""ht"") ## Baltagi & Khanti-Akom, Table II, column ""HT"" ## alternative choice of exogenous variables psid_ht2 <- plm(log(wage) ~ occupation + south + smsa + industry + experience + I(experience^2) + weeks + married + union + gender + ethnicity + education | occupation + south + smsa + industry + gender + ethnicity, data = psid, model = ""ht"") ## Baltagi & Khanti-Akom, Table III, column ""HT"" ## original choice of exogenous variables + time dummies ## (see also Baltagi, 2001, Table 7.1) psid$time <- psid$year psid_ht3 <- plm(log(wage) ~ weeks + south + smsa + married + experience + I(experience^2) + occupation + industry + union + gender + ethnicity + education + time | weeks + south + smsa + married + gender + ethnicity + time, data = psid, model = ""ht"")"
"AER-RecreationDemand","AER","RecreationDemand","Recreation Demand Data",659,8,2,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/RecreationDemand.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/RecreationDemand.html","RecreationDemand R Documentation   Recreation Demand Data   Description  
Cross-section data on the number of recreational boating trips to Lake Somerville, Texas, in 1980, based on a survey administered to 2,000 registered leisure boat owners in 23 counties in eastern Texas.   Usage   data(""RecreationDemand"")   Format  
A data frame containing 659 observations on 8 variables.    trips
Number of recreational boating trips.   quality
Facility's subjective quality ranking on a scale of 1 to 5.   ski
factor. Was the individual engaged in water-skiing at the lake?   income
Annual household income of the respondent (in 1,000 USD).   userfee
factor. Did the individual pay an annual user fee at Lake Somerville?   costC
Expenditure when visiting Lake Conroe (in USD).   costS
Expenditure when visiting Lake Somerville (in USD).   costH
Expenditure when visiting Lake Houston (in USD).     Details  
According to the original source (Seller, Stoll and Chavas, 1985, p. 168), the quality rating is on a scale from 1 to 5 and gives 0 for those who had not visited the lake. This explains the remarkably low mean for this variable, but also suggests that its treatment in various more recent publications is far from ideal. For consistency with other sources we handle the variable as a numerical variable, including the zeros.   Source  
Journal of Business \& Economic Statistics Data Archive.  
http://www.amstat.org/publications/jbes/upload/index.cfm?fuseaction=ViewArticles&pub=JBES&issue=96-4-OCT     References  
Cameron, A.C. and Trivedi, P.K. (1998). Regression Analysis of Count Data . Cambridge: Cambridge University Press.   
Gurmu, S. and Trivedi, P.K. (1996). Excess Zeros in Count Models for Recreational Trips. Journal of Business \& Economic Statistics ,  14 , 469–477.   
Ozuna, T. and Gomez, I.A. (1995). Specification and Testing of Count Data Recreation Demand Functions.  Empirical Economics , 20 , 543–550.   
Seller, C., Stoll, J.R. and Chavas, J.-P. (1985). Validation of Empirical Measures of Welfare Change: A Comparison of Nonmarket Techniques. Land Economics , 61 , 156–175.    See Also  
CameronTrivedi1998   Examples    data(""RecreationDemand"") ## Poisson model: ## Cameron and Trivedi (1998), Table 6.11 ## Ozuna and Gomez (1995), Table 2, col. 3 fm_pois <- glm(trips ~ ., data = RecreationDemand, family = poisson) summary(fm_pois) logLik(fm_pois) coeftest(fm_pois, vcov = sandwich) ## Negbin model: ## Cameron and Trivedi (1998), Table 6.11 ## Ozuna and Gomez (1995), Table 2, col. 5 library(""MASS"") fm_nb <- glm.nb(trips ~ ., data = RecreationDemand) coeftest(fm_nb, vcov = vcovOPG) ## ZIP model: ## Cameron and Trivedi (1998), Table 6.11 library(""pscl"") fm_zip <- zeroinfl(trips ~ . | quality + income, data = RecreationDemand) summary(fm_zip) ## Hurdle models ## Cameron and Trivedi (1998), Table 6.13 ## poisson-poisson fm_hp <- hurdle(trips ~ ., data = RecreationDemand, dist = ""poisson"", zero = ""poisson"") ## negbin-negbin fm_hnb <- hurdle(trips ~ ., data = RecreationDemand, dist = ""negbin"", zero = ""negbin"") ## binom-negbin == geo-negbin fm_hgnb <- hurdle(trips ~ ., data = RecreationDemand, dist = ""negbin"") ## Note: quasi-complete separation with(RecreationDemand, table(trips > 0, userfee))"
"AER-ResumeNames","AER","ResumeNames","Are Emily and Greg More Employable Than Lakisha and Jamal?",4870,27,21,0,25,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ResumeNames.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ResumeNames.html","ResumeNames R Documentation   Are Emily and Greg More Employable Than Lakisha and Jamal?   Description  
Cross-section data about resume, call-back and employer information for 4,870 fictitious resumes.    Usage   data(""ResumeNames"")   Format  
A data frame containing 4,870 observations on 27 variables.    name
factor indicating applicant's first name.   gender
factor indicating gender.   ethnicity
factor indicating ethnicity (i.e., Caucasian-sounding vs. African-American sounding first name).   quality
factor indicating quality of resume.   call
factor. Was the applicant called back?   city
factor indicating city: Boston or Chicago.   jobs
number of jobs listed on resume.   experience
number of years of work experience on the resume.   honors
factor. Did the resume mention some honors?   volunteer
factor. Did the resume mention some volunteering experience?   military
factor. Does the applicant have military experience?   holes
factor. Does the resume have some employment holes?   school
factor. Does the resume mention some work experience while at school?   email
factor. Was the e-mail address on the applicant's resume?   computer
factor. Does the resume mention some computer skills?   special
factor. Does the resume mention some special skills?   college
factor. Does the applicant have a college degree or more?   minimum
factor indicating minimum experience requirement of the employer.   equal
factor. Is the employer EOE (equal opportunity employment)?   wanted
factor indicating type of position wanted by employer.   requirements
factor. Does the ad mention some requirement for the job?   reqexp
factor. Does the ad mention some experience requirement?   reqcomm
factor. Does the ad mention some communication skills requirement?   reqeduc
factor. Does the ad mention some educational requirement?   reqcomp
factor. Does the ad mention some computer skills requirement?   reqorg
factor. Does the ad mention some organizational skills requirement?   industry
factor indicating type of employer industry.     Details  
Cross-section data about resume, call-back and employer information for 4,870 fictitious resumes sent in response to employment advertisements in Chicago and Boston in 2001, in a randomized controlled experiment conducted by Bertrand and Mullainathan (2004). The resumes contained information concerning the ethnicity of the applicant. Because ethnicity is not typically included on a resume, resumes were differentiated on the basis of so-called “Caucasian sounding names” (such as Emily Walsh or Gregory Baker) and “African American sounding names” (such as Lakisha Washington or Jamal Jones). A large collection of fictitious resumes were created and the pre-supposed ethnicity (based on the sound of the name) was randomly assigned to each resume. These resumes were sent to prospective employers to see which resumes generated a phone call from the prospective employer.    Source  
Online complements to Stock and Watson (2007).   References  
Bertrand, M. and Mullainathan, S. (2004). Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination. American Economic Review , 94 , 991–1013.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""ResumeNames"") summary(ResumeNames) prop.table(xtabs(~ ethnicity + call, data = ResumeNames), 1)"
"AER-ShipAccidents","AER","ShipAccidents","Ship Accidents",40,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/ShipAccidents.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/ShipAccidents.html","ShipAccidents R Documentation   Ship Accidents   Description  
Data on ship accidents.    Usage   data(""ShipAccidents"")   Format  
A data frame containing 40 observations on 5 ship types in 4 vintages and 2 service periods.   type
factor with levels ""A"" to ""E"" for the different ship types,   construction
factor with levels ""1960-64"" , ""1965-69"" , ""1970-74"" , ""1975-79"" for the periods of construction,   operation
factor with levels ""1960-74"" , ""1975-79"" for the periods of operation,   service
aggregate months of service,   incidents
number of damage incidents.     Details  
The data are from McCullagh and Nelder (1989, p. 205, Table 6.2) and were also used by Greene (2003, Ch. 21), see below.   
There are five ships (observations 7, 15, 23, 31, 39) with an operation period  before the construction period, hence the variables service and  incidents are necessarily 0. An additional observation (34) has entries representing accidentally empty cells (see McCullagh and Nelder, 1989, p. 205).   
It is a bit unclear what exactly the above means. In any case, the models are fit only to those observations with service > 0 .    Source  
Online complements to Greene (2003).   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
McCullagh, P. and Nelder, J.A. (1989). Generalized Linear Models , 2nd edition. London: Chapman \& Hall.    See Also  
Greene2003   Examples    data(""ShipAccidents"") sa <- subset(ShipAccidents, service > 0) ## Greene (2003), Table 21.20 ## (see also McCullagh and Nelder, 1989, Table 6.3) sa_full <- glm(incidents ~ type + construction + operation, family = poisson, data = sa, offset = log(service)) summary(sa_full) sa_notype <- glm(incidents ~ construction + operation, family = poisson, data = sa, offset = log(service)) summary(sa_notype) sa_noperiod <- glm(incidents ~ type + operation, family = poisson, data = sa, offset = log(service)) summary(sa_noperiod) ## model comparison anova(sa_full, sa_notype, test = ""Chisq"") anova(sa_full, sa_noperiod, test = ""Chisq"") ## test for overdispersion dispersiontest(sa_full) dispersiontest(sa_full, trafo = 2)"
"AER-SIC33","AER","SIC33","SIC33 Production Data",27,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/SIC33.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/SIC33.html","SIC33 R Documentation   SIC33 Production Data   Description  
Statewide production data for primary metals industry (SIC 33).    Usage   data(""SIC33"")   Format  
A data frame containing 27 observations on 3 variables.    output
Value added.   labor
Labor input.   capital
Capital stock.     Source  
Online complements to Greene (2003). Table F6.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""SIC33"") ## Example 6.2 in Greene (2003) ## Translog model fm_tl <- lm(output ~ labor + capital + I(0.5 * labor^2) + I(0.5 * capital^2) + I(labor * capital), data = log(SIC33)) ## Cobb-Douglas model fm_cb <- lm(output ~ labor + capital, data = log(SIC33)) ## Table 6.2 in Greene (2003) deviance(fm_tl) deviance(fm_cb) summary(fm_tl) summary(fm_cb) vcov(fm_tl) vcov(fm_cb) ## Cobb-Douglas vs. Translog model anova(fm_cb, fm_tl) ## hypothesis of constant returns linearHypothesis(fm_cb, ""labor + capital = 1"") ## 3D Visualization if(require(""scatterplot3d"")) { s3d <- scatterplot3d(log(SIC33)[,c(2, 3, 1)], pch = 16) s3d$plane3d(fm_cb, lty.box = ""solid"", col = 4) } ## Interactive 3D Visualization if(require(""rgl"")) { x <- log(SIC33)[,2] y <- log(SIC33)[,3] z <- log(SIC33)[,1] rgl.open() rgl.bbox() rgl.spheres(x, y, z, radius = 0.15) x <- seq(4.5, 7.5, by = 0.5) y <- seq(5.5, 10, by = 0.5) z <- outer(x, y, function(x, y) predict(fm_cb, data.frame(labor = x, capital = y))) rgl.surface(x, y, z, color = ""blue"", alpha = 0.5, shininess = 128) }"
"AER-SmokeBan","AER","SmokeBan","Do Workplace Smoking Bans Reduce Smoking?",10000,7,5,0,6,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/SmokeBan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/SmokeBan.html","SmokeBan R Documentation   Do Workplace Smoking Bans Reduce Smoking?   Description  
Estimation of the effect of workplace smoking bans on smoking of indoor workers.    Usage   data(""SmokeBan"")   Format  
A data frame containing 10,000 observations on 7 variables.    smoker
factor. Is the individual a current smoker?   ban
factor. Is there a work area smoking ban?   age
age in years.   education
factor indicating highest education level attained: high school (hs) drop out, high school graduate, some college, college graduate, master's degree (or higher).   afam
factor. Is the individual African-American?   hispanic
factor. Is the individual Hispanic?   gender
factor indicating gender.     Details  
SmokeBank is a cross-sectional data set with observations on 10,000 indoor workers, which is a subset of a 18,090-observation data set collected as part of the National Health Interview Survey in 1991 and then again (with different respondents) in 1993. The data set contains information on whether individuals were, or were not, subject to a workplace smoking ban, whether or not the individuals smoked and other individual characteristics.    Source  
Online complements to Stock and Watson (2007).   References  
Evans, W. N., Farrelly, M.C., and Montgomery, E. (1999). Do Workplace Smoking Bans Reduce Smoking?  American Economic Review , 89 , 728–747.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""SmokeBan"") ## proportion of non-smokers increases with education plot(smoker ~ education, data = SmokeBan) ## proportion of non-smokers constant over age plot(smoker ~ age, data = SmokeBan)"
"AER-SportsCards","AER","SportsCards","Endowment Effect for Sports Cards",148,9,4,0,6,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/SportsCards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/SportsCards.html","SportsCards R Documentation   Endowment Effect for Sports Cards   Description  
Trading sports cards: Does ownership increase the value of goods to consumers?    Usage   data(""SportsCards"")   Format  
A data frame containing 148 observations on 9 variables.    good
factor. Was the individual given good A or B (see below)?   dealer
factor. Was the individual a dealer?   permonth
number of trades per month reported by the individual.   years
number of years that the individual has been trading.   income
factor indicating income group (in 1000 USD).   gender
factor indicating gender.   education
factor indicating highest level of education (8th grade or less, high school, 2-year college, other post-high school, 4-year college or graduate school).   age
age in years.   trade
factor. Did the individual trade the good he was given for the other good?     Details  
SportsCards contains data from 148 randomly selected traders who attended a trading card show in Orlando, Florida, in 1998. Traders were randomly given one of two sports collectables, say good A or good B, that had approximately equal market value. Those receiving good A were then given the option of trading good A for good B with the experimenter; those receiving good B were given the option of trading good B for good A with the experimenter. Good A was a ticket stub from the game that Cal Ripken Jr. set the record for consecutive games played, and Good B was a souvenir from the game that Nolan Ryan won his 300th game.    Source  
Online complements to Stock and Watson (2007).   References  
List, J.A. (2003). Does Market Experience Eliminate Market Anomalies?  Quarterly Journal of Economcis , 118 , 41–71.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""SportsCards"") summary(SportsCards) plot(trade ~ permonth, data = SportsCards, ylevels = 2:1, breaks = c(0, 5, 10, 20, 30, 70)) plot(trade ~ years, data = SportsCards, ylevels = 2:1, breaks = c(0, 5, 10, 20, 60))"
"AER-STAR","AER","STAR","Project STAR: Student-Teacher Achievement Ratio",11598,47,8,0,34,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/STAR.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/STAR.html","STAR R Documentation   Project STAR: Student-Teacher Achievement Ratio   Description  
The Project STAR public access data set, assessing the effect of reducing class size on test scores in the early grades.    Usage   data(""STAR"")   Format  
A data frame containing 11,598 observations on 47 variables.    gender
factor indicating student's gender.   ethnicity
factor indicating student's ethnicity with levels  ""cauc"" (Caucasian), ""afam"" (African-American), ""asian"" (Asian), ""hispanic"" (Hispanic), ""amindian"" (American-Indian) or ""other"" .   birth
student's birth quarter (of class yearqtr ).   stark
factor indicating the STAR class type in kindergarten: regular, small, or regular-with-aide. NA indicates that no STAR class was attended.   star1
factor indicating the STAR class type in 1st grade: regular, small, or regular-with-aide. NA indicates that no STAR class was attended.   star2
factor indicating the STAR class type in 2nd grade: regular, small, or regular-with-aide. NA indicates that no STAR class was attended.   star3
factor indicating the STAR class type in 3rd grade: regular, small, or regular-with-aide. NA indicates that no STAR class was attended.   readk
total reading scaled score in kindergarten.   read1
total reading scaled score in 1st grade.   read2
total reading scaled score in 2nd grade.   read3
total reading scaled score in 3rd grade.   mathk
total math scaled score in kindergarten.   math1
total math scaled score in 1st grade.   math2
total math scaled score in 2nd grade.   math3
total math scaled score in 3rd grade.   lunchk
factor indicating whether the student qualified for free lunch in kindergarten.   lunch1
factor indicating whether the student qualified for free lunch in 1st grade.   lunch2
factor indicating whether the student qualified for free lunch in 2nd grade.   lunch3
factor indicating whether the student qualified for free lunch in 3rd grade.   schoolk
factor indicating school type in kindergarten:  ""inner-city"" , ""suburban"" , ""rural"" or ""urban"" .   school1
factor indicating school type in 1st grade:  ""inner-city"" , ""suburban"" , ""rural"" or ""urban"" .   school2
factor indicating school type in 2nd grade:  ""inner-city"" , ""suburban"" , ""rural"" or ""urban"" .   school3
factor indicating school type in 3rd grade:  ""inner-city"" , ""suburban"" , ""rural"" or ""urban"" .   degreek
factor indicating highest degree of kindergarten teacher:  ""bachelor"" , ""master"" , ""specialist"" , or ""master+"" .   degree1
factor indicating highest degree of 1st grade teacher:  ""bachelor"" , ""master"" , ""specialist"" , or ""phd"" .   degree2
factor indicating highest degree of 2nd grade teacher:  ""bachelor"" , ""master"" , ""specialist"" , or ""phd"" .   degree3
factor indicating highest degree of 3rd grade teacher:  ""bachelor"" , ""master"" , ""specialist"" , or ""phd"" .   ladderk
factor indicating teacher's career ladder level in kindergarten: ""level1"" ,  ""level2"" , ""level3"" , ""apprentice"" , ""probation"" or ""pending"" .   ladder1
factor indicating teacher's career ladder level in 1st grade: ""level1"" ,  ""level2"" , ""level3"" , ""apprentice"" , ""probation"" or ""noladder"" .   ladder2
factor indicating teacher's career ladder level in 2nd grade: ""level1"" ,  ""level2"" , ""level3"" , ""apprentice"" , ""probation"" or ""noladder"" .   ladder3
factor indicating teacher's career ladder level in 3rd grade: ""level1"" ,  ""level2"" , ""level3"" , ""apprentice"" , ""probation"" or ""noladder"" .   experiencek
years of teacher's total teaching experience in kindergarten.   experience1
years of teacher's total teaching experience in 1st grade.   experience2
years of teacher's total teaching experience in 2nd grade.   experience3
years of teacher's total teaching experience in 3rd grade.   tethnicityk
factor indicating teacher's ethnicity in kindergarten with levels  ""cauc"" (Caucasian) or ""afam"" (African-American).   tethnicity1
factor indicating teacher's ethnicity in 1st grade with levels  ""cauc"" (Caucasian) or ""afam"" (African-American).   tethnicity2
factor indicating teacher's ethnicity in 2nd grade with levels  ""cauc"" (Caucasian) or ""afam"" (African-American).   tethnicity3
factor indicating teacher's ethnicity in 3rd grade with levels  ""cauc"" (Caucasian), ""afam"" (African-American), or ""asian"" (Asian).   systemk
factor indicating school system ID in kindergarten.   system1
factor indicating school system ID in 1st grade.   system2
factor indicating school system ID in 2nd grade.   system3
factor indicating school system ID in 3rd grade.   schoolidk
factor indicating school ID in kindergarten.   schoolid1
factor indicating school ID in 1st grade.   schoolid2
factor indicating school ID in 2nd grade.   schoolid3
factor indicating school ID in 3rd grade.     Details  
Project STAR (Student/Teacher Achievement Ratio) was a four-year longitudinal class-size study funded by the Tennessee General Assembly and conducted in the late 1980s by the State Department of Education. Over 7,000 students in 79 schools were randomly assigned into one of three interventions: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher's aide). Classroom teachers were also randomly assigned to the classes they would teach. The interventions were initiated as the students entered school in kindergarten and continued through third grade.   
The Project STAR public access data set contains data on test scores, treatment groups, and student and teacher characteristics for the four years of the experiment, from academic year 1985–1986 to academic year 1988–1989. The test score data analyzed in this chapter are the sum of the scores on the math and reading portion of the Stanford Achievement Test.  
Stock and Watson (2007) obtained the data set from the Project STAR Web site.   
The data is provided in wide format. Reshaping it into long format is illustrated below. Note that the levels of the degree , ladder  and tethnicity variables differ slightly between kindergarten and higher grades.    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""STAR"") ## Stock and Watson, p. 488 fmk <- lm(I(readk + mathk) ~ stark, data = STAR) fm1 <- lm(I(read1 + math1) ~ star1, data = STAR) fm2 <- lm(I(read2 + math2) ~ star2, data = STAR) fm3 <- lm(I(read3 + math3) ~ star3, data = STAR) coeftest(fm3, vcov = sandwich) plot(I(read3 + math3) ~ star3, data = STAR) ## Stock and Watson, p. 489 fmke <- lm(I(readk + mathk) ~ stark + experiencek, data = STAR) coeftest(fmke, vcov = sandwich) ## reshape data from wide into long format ## 1. variables and their levels nam <- c(""star"", ""read"", ""math"", ""lunch"", ""school"", ""degree"", ""ladder"", ""experience"", ""tethnicity"", ""system"", ""schoolid"") lev <- c(""k"", ""1"", ""2"", ""3"") ## 2. reshaping star <- reshape(STAR, idvar = ""id"", ids = row.names(STAR), times = lev, timevar = ""grade"", direction = ""long"", varying = lapply(nam, function(x) paste(x, lev, sep = """"))) ## 3. improve variable names and type names(star)[5:15] <- nam star$id <- factor(star$id) star$grade <- factor(star$grade, levels = lev, labels = c(""kindergarten"", ""1st"", ""2nd"", ""3rd"")) rm(nam, lev) ## fit a single model nested in grade (equivalent to fmk, fm1, fm2, fmk) fm <- lm(I(read + math) ~ 0 + grade/star, data = star) coeftest(fm, vcov = sandwich) ## visualization library(""lattice"") bwplot(I(read + math) ~ star | grade, data = star)"
"AER-StrikeDuration","AER","StrikeDuration","Strike Durations",62,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/StrikeDuration.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/StrikeDuration.html","StrikeDuration R Documentation   Strike Durations   Description  
Data on the duration of strikes in US manufacturing industries, 1968–1976.    Usage   data(""StrikeDuration"")   Format  
A data frame containing 62 observations on 2 variables for the period 1968–1976.    duration
strike duration in days.   uoutput
unanticipated output (a measure of unanticipated aggregate industrial production net of seasonal and trend components).     Details  
The original data provided by Kennan (1985) are on a monthly basis, for the period 1968(1) through 1976(12). Greene (2003) only provides the June data for each year. Also, the duration for observation 36 is given as 3 by Greene while Kennan has 2. Here we use Greene's version.   
uoutput is the residual from a regression of the logarithm of industrial production in manufacturing on time, time squared, and monthly dummy variables.   Source  
Online complements to Greene (2003).   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Kennan, J. (1985). The Duration of Contract Strikes in US Manufacturing. Journal of Econometrics , 28 , 5–28.    See Also  
Greene2003   Examples    data(""StrikeDuration"") library(""MASS"") ## Greene (2003), Table 22.10 fit_exp <- fitdistr(StrikeDuration$duration, ""exponential"") fit_wei <- fitdistr(StrikeDuration$duration, ""weibull"") fit_wei$estimate[2]^(-1) fit_lnorm <- fitdistr(StrikeDuration$duration, ""lognormal"") 1/fit_lnorm$estimate[2] exp(-fit_lnorm$estimate[1]) ## Weibull and lognormal distribution have ## different parameterizations, see Greene p. 794 ## Greene (2003), Example 22.10 library(""survival"") fm_wei <- survreg(Surv(duration) ~ uoutput, dist = ""weibull"", data = StrikeDuration) summary(fm_wei)"
"AER-SwissLabor","AER","SwissLabor","Swiss Labor Market Participation Data",872,7,2,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/SwissLabor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/SwissLabor.html","SwissLabor R Documentation   Swiss Labor Market Participation Data   Description  
Cross-section data originating from the health survey SOMIPOPS for Switzerland in 1981.   Usage   data(""SwissLabor"")   Format  
A data frame containing 872 observations on 7 variables.    participation
Factor. Did the individual participate in the labor force?   income
Logarithm of nonlabor income.   age
Age in decades (years divided by 10).   education
Years of formal education.   youngkids
Number of young children (under 7 years of age).   oldkids
Number of older children (over 7 years of age).   foreign
Factor. Is the individual a foreigner (i.e., not Swiss)?     Source  
Journal of Applied Econometrics Data Archive.  
http://qed.econ.queensu.ca/jae/1996-v11.3/gerfin/     References  
Gerfin, M. (1996). Parametric and Semi-Parametric Estimation of the Binary Response Model of Labour Market Participation. Journal of Applied Econometrics ,  11 , 321–339.    Examples    data(""SwissLabor"") ### Gerfin (1996), Table I. fm_probit <- glm(participation ~ . + I(age^2), data = SwissLabor, family = binomial(link = ""probit"")) summary(fm_probit) ### alternatively fm_logit <- glm(participation ~ . + I(age^2), data = SwissLabor, family = binomial) summary(fm_logit)"
"AER-TeachingRatings","AER","TeachingRatings","Impact of Beauty on Instructor's Teaching Ratings",463,12,6,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/TeachingRatings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/TeachingRatings.html","TeachingRatings R Documentation   Impact of Beauty on Instructor's Teaching Ratings   Description  
Data on course evaluations, course characteristics, and professor characteristics for 463 courses for the academic years 2000–2002 at the University of Texas at Austin.    Usage   data(""TeachingRatings"")   Format  
A data frame containing 463 observations on 13 variables.    minority
factor. Does the instructor belong to a minority (non-Caucasian)?   age
the professor's age.   gender
factor indicating instructor's gender.   credits
factor. Is the course a single-credit elective (e.g., yoga, aerobics, dance)?   beauty
rating of the instructor's physical appearance by a panel of six students, averaged across the six panelists, shifted to have a mean of zero.   eval
course overall teaching evaluation score, on a scale of 1 (very unsatisfactory) to 5 (excellent).   division
factor. Is the course an upper or lower division course? (Lower division courses are mainly large freshman and sophomore courses)?   native
factor. Is the instructor a native English speaker?   tenure
factor. Is the instructor on tenure track?   students
number of students that participated in the evaluation.   allstudents
number of students enrolled in the course.   prof
factor indicating instructor identifier.     Details  
A sample of student instructional ratings for a group of university teachers along with beauty rating (average from six independent judges) and a number of other characteristics.    Source  
The data were provided by Prof. Hamermesh. The first 8 variables are also available in the online complements to Stock and Watson (2007) at    References  
Hamermesh, D.S., and Parker, A. (2005). Beauty in the Classroom: Instructors' Pulchritude and Putative Pedagogical Productivity.  Economics of Education Review , 24 , 369–376.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""TeachingRatings"", package = ""AER"") ## evaluation score vs. beauty plot(eval ~ beauty, data = TeachingRatings) fm <- lm(eval ~ beauty, data = TeachingRatings) abline(fm) summary(fm) ## prediction of Stock & Watson's evaluation score sw <- with(TeachingRatings, mean(beauty) + c(0, 1) * sd(beauty)) names(sw) <- c(""Watson"", ""Stock"") predict(fm, newdata = data.frame(beauty = sw)) ## Hamermesh and Parker, 2005, Table 3 fmw <- lm(eval ~ beauty + gender + minority + native + tenure + division + credits, weights = students, data = TeachingRatings) coeftest(fmw, vcov = vcovCL, cluster = TeachingRatings$prof)"
"AER-TechChange","AER","TechChange","Technological Change Data",41,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/TechChange.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/TechChange.html","TechChange R Documentation   Technological Change Data   Description  
US time series data, 1909–1949.   Usage   data(""TechChange"")   Format  
An annual multiple time series from 1909 to 1949 with 3 variables.    output
Output.   clr
Capital/labor ratio.   technology
Index of technology.     Source  
Online complements to Greene (2003), Table F7.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Solow, R. (1957). Technical Change and the Aggregate Production Function. Review of Economics and Statistics , 39 , 312–320.    See Also  
Greene2003   Examples    data(""TechChange"") ## Greene (2003) ## Exercise 7.1 fm1 <- lm(I(output/technology) ~ log(clr), data = TechChange) fm2 <- lm(I(output/technology) ~ I(1/clr), data = TechChange) fm3 <- lm(log(output/technology) ~ log(clr), data = TechChange) fm4 <- lm(log(output/technology) ~ I(1/clr), data = TechChange) ## Exercise 7.2 (a) and (c) plot(I(output/technology) ~ clr, data = TechChange) library(""strucchange"") sctest(I(output/technology) ~ log(clr), data = TechChange, type = ""Chow"", point = c(1942, 1))"
"AER-TradeCredit","AER","TradeCredit","Trade Credit and the Money Market",21,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/TradeCredit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/TradeCredit.html","TradeCredit R Documentation   Trade Credit and the Money Market   Description  
Macroeconomic time series data from 1946 to 1966 on trade credit and the money market.    Usage   data(""TradeCredit"")   Format  
An annual multiple time series from 1946 to 1966 on 7 variables.    trade
Nominal total trade money.   reserve
Nominal effective reserve money.   gnp
GNP in current dollars.   utilization
Degree of market utilization.   interest
Short-term rate of interest.   size
Mean real size of the representative economic unit (1939 = 100).   price
GNP price deflator (1958 = 100).     Source  
The data are from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.  
Laffer, A.B. (1970). Trade Credit and the Money Market. Journal of Political Economy ,  78 , 239–267.    See Also  
Baltagi2002   Examples    data(""TradeCredit"") plot(TradeCredit)"
"AER-TravelMode","AER","TravelMode","Travel Mode Choice Data",840,9,1,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/TravelMode.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/TravelMode.html","TravelMode R Documentation   Travel Mode Choice Data   Description  
Data on travel mode choice for travel between Sydney and Melbourne, Australia.    Usage   data(""TravelMode"")   Format  
A data frame containing 840 observations on 4 modes for 210 individuals.    individual
Factor indicating individual with levels 1 to 200 .   mode
Factor indicating travel mode with levels  ""car"" , ""air"" , ""train"" , or ""bus"" .   choice
Factor indicating choice with levels ""no"" and ""yes"" .   wait
Terminal waiting time, 0 for car.   vcost
Vehicle cost component.   travel
Travel time in the vehicle.   gcost
Generalized cost measure.   income
Household income.   size
Party size.     Source  
Online complements to Greene (2003).   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""TravelMode"") ## overall proportions for chosen mode with(TravelMode, prop.table(table(mode[choice == ""yes""]))) ## travel vs. waiting time for different travel modes library(""lattice"") xyplot(travel ~ wait | mode, data = TravelMode) ## Greene (2003), Table 21.11, conditional logit model if(require(""mlogit"")) { TravelMode$incair <- with(TravelMode, income * (mode == ""air"")) tm_cl <- mlogit(choice ~ gcost + wait + incair, data = TravelMode, shape = ""long"", alt.var = ""mode"", reflevel = ""car"") summary(tm_cl) }"
"AER-UKInflation","AER","UKInflation","UK Manufacturing Inflation Data",54,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/UKInflation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/UKInflation.html","UKInflation R Documentation   UK Manufacturing Inflation Data   Description  
Time series of observed and expected price changes in British manufacturing.    Usage   data(""UKInflation"")   Format  
A quarterly multiple time series from 1972(1) to 1985(2) with 2 variables.    actual
Actual inflation.   expected
Expected inflation.     Source  
Online complements to Greene (2003), Table F8.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.   
Pesaran, M.H., and Hall, A.D. (1988). Tests of Non-nested Linear Regression Models Subject To Linear Restrictions. Economics Letters , 27 , 341–348.    See Also  
Greene2003   Examples    data(""UKInflation"") plot(UKInflation)"
"AER-UKNonDurables","AER","UKNonDurables","Consumption of Non-Durables in the UK",136,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/UKNonDurables.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/UKNonDurables.html","UKNonDurables R Documentation   Consumption of Non-Durables in the UK   Description  
Time series of consumption of non-durables in the UK (in 1985 prices).    Usage   data(""UKNonDurables"")   Format  
A quarterly univariate time series from 1955(1) to 1988(4).    Source  
Online complements to Franses (1998).    References  
Osborn, D.R. (1988). A Survey of Seasonality in UK Macroeconomic Variables.  International Journal of Forecasting , 6 , 327–336.   
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""UKNonDurables"") plot(UKNonDurables) ## EACF tables (Franses 1998, p. 99) ctrafo <- function(x) residuals(lm(x ~ factor(cycle(x)))) ddiff <- function(x) diff(diff(x, frequency(x)), 1) eacf <- function(y, lag = 12) { stopifnot(all(lag > 0)) if(length(lag) < 2) lag <- 1:lag rval <- sapply( list(y = y, dy = diff(y), cdy = ctrafo(diff(y)), Dy = diff(y, frequency(y)), dDy = ddiff(y)), function(x) acf(x, plot = FALSE, lag.max = max(lag))$acf[lag + 1]) rownames(rval) <- lag return(rval) } ## Franses (1998), Table 5.2 round(eacf(log(UKNonDurables)), digits = 3) ## Franses (1998), Equation 5.51 ## (Franses: sma1 = -0.632 (0.069)) arima(log(UKNonDurables), c(0, 1, 0), c(0, 1, 1))"
"AER-USAirlines","AER","USAirlines","Cost Data for US Airlines",90,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USAirlines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USAirlines.html","USAirlines R Documentation   Cost Data for US Airlines   Description  
Cost data for six US airlines in 1970–1984.    Usage   data(""USAirlines"")   Format  
A data frame containing 90 observations on 6 variables.    firm
factor indicating airline firm.   year
factor indicating year.   output
output revenue passenger miles index number.   cost
total cost (in USD 1000).   price
fuel price.   load
average capacity utilization of the fleet.     Source  
Online complements to Greene (2003). Table F7.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""USAirlines"") ## Example 7.2 in Greene (2003) fm_full <- lm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load + year + firm, data = USAirlines) fm_time <- lm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load + year, data = USAirlines) fm_firm <- lm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load + firm, data = USAirlines) fm_no <- lm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load, data = USAirlines) ## Table 7.2 anova(fm_full, fm_time) anova(fm_full, fm_firm) anova(fm_full, fm_no) ## alternatively, use plm() library(""plm"") usair <- pdata.frame(USAirlines, c(""firm"", ""year"")) fm_full2 <- plm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load, data = usair, model = ""within"", effect = ""twoways"") fm_time2 <- plm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load, data = usair, model = ""within"", effect = ""time"") fm_firm2 <- plm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load, data = usair, model = ""within"", effect = ""individual"") fm_no2 <- plm(log(cost) ~ log(output) + I(log(output)^2) + log(price) + load, data = usair, model = ""pooling"") pFtest(fm_full2, fm_time2) pFtest(fm_full2, fm_firm2) pFtest(fm_full2, fm_no2) ## More examples can be found in: ## help(""Greene2003"")"
"AER-USConsump1950","AER","USConsump1950","US Consumption Data (1940-1950)",11,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USConsump1950.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USConsump1950.html","USConsump1950 R Documentation   US Consumption Data (1940–1950)   Description  
Time series data on US income and consumption expenditure, 1940–1950.    Usage   data(""USConsump1950"")   Format  
An annual multiple time series from 1940 to 1950 with 3 variables.    income
Disposable income.   expenditure
Consumption expenditure.   war
Indicator variable: Was the year a year of war?     Source  
Online complements to Greene (2003). Table F2.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , USConsump1979 , USConsump1993   Examples    ## Greene (2003) ## data data(""USConsump1950"") usc <- as.data.frame(USConsump1950) usc$war <- factor(usc$war, labels = c(""no"", ""yes"")) ## Example 2.1 plot(expenditure ~ income, data = usc, type = ""n"", xlim = c(225, 375), ylim = c(225, 350)) with(usc, text(income, expenditure, time(USConsump1950))) ## single model fm <- lm(expenditure ~ income, data = usc) summary(fm) ## different intercepts for war yes/no fm2 <- lm(expenditure ~ income + war, data = usc) summary(fm2) ## compare anova(fm, fm2) ## visualize abline(fm, lty = 3) abline(coef(fm2)[1:2]) abline(sum(coef(fm2)[c(1, 3)]), coef(fm2)[2], lty = 2) ## Example 3.2 summary(fm)$r.squared summary(lm(expenditure ~ income, data = usc, subset = war == ""no""))$r.squared summary(fm2)$r.squared"
"AER-USConsump1979","AER","USConsump1979","US Consumption Data (1970-1979)",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USConsump1979.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USConsump1979.html","USConsump1979 R Documentation   US Consumption Data (1970–1979)   Description  
Time series data on US income and consumption expenditure, 1970–1979.    Usage   data(""USConsump1979"")   Format  
An annual multiple time series from 1970 to 1979 with 2 variables.    income
Disposable income.   expenditure
Consumption expenditure.     Source  
Online complements to Greene (2003). Table F1.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , USConsump1950 , USConsump1993   Examples    data(""USConsump1979"") plot(USConsump1979) ## Example 1.1 in Greene (2003) plot(expenditure ~ income, data = as.data.frame(USConsump1979), pch = 19) fm <- lm(expenditure ~ income, data = as.data.frame(USConsump1979)) summary(fm) abline(fm)"
"AER-USConsump1993","AER","USConsump1993","US Consumption Data (1950-1993)",44,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USConsump1993.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USConsump1993.html","USConsump1993 R Documentation   US Consumption Data (1950–1993)   Description  
Time series data on US income and consumption expenditure, 1950–1993.    Usage   data(""USConsump1993"")   Format  
An annual multiple time series from 1950 to 1993 with 2 variables.    income
Disposable personal income (in 1987 USD).   expenditure
Personal consumption expenditures (in 1987 USD).     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002 , USConsump1950 , USConsump1979   Examples    ## data from Baltagi (2002) data(""USConsump1993"", package = ""AER"") plot(USConsump1993, plot.type = ""single"", col = 1:2) ## Chapter 5 (p. 122-125) fm <- lm(expenditure ~ income, data = USConsump1993) summary(fm) ## Durbin-Watson test (p. 122) dwtest(fm) ## Breusch-Godfrey test (Table 5.4, p. 124) bgtest(fm) ## Newey-West standard errors (Table 5.5, p. 125) coeftest(fm, vcov = NeweyWest(fm, lag = 3, prewhite = FALSE, adjust = TRUE)) ## Chapter 8 library(""strucchange"") ## Recursive residuals rr <- recresid(fm) rr ## Recursive CUSUM test rcus <- efp(expenditure ~ income, data = USConsump1993) plot(rcus) sctest(rcus) ## Harvey-Collier test harvtest(fm) ## NOTE"" Mistake in Baltagi (2002) who computes ## the t-statistic incorrectly as 0.0733 via mean(rr)/sd(rr)/sqrt(length(rr)) ## whereas it should be (as in harvtest) mean(rr)/sd(rr) * sqrt(length(rr)) ## Rainbow test raintest(fm, center = 23) ## J test for non-nested models library(""dynlm"") fm1 <- dynlm(expenditure ~ income + L(income), data = USConsump1993) fm2 <- dynlm(expenditure ~ income + L(expenditure), data = USConsump1993) jtest(fm1, fm2) ## Chapter 14 ## ACF and PACF for expenditures and first differences exps <- USConsump1993[, ""expenditure""] (acf(exps)) (pacf(exps)) (acf(diff(exps))) (pacf(diff(exps))) ## dynamic regressions, eq. (14.8) fm <- dynlm(d(exps) ~ I(time(exps) - 1949) + L(exps)) summary(fm)"
"AER-USCrudes","AER","USCrudes","US Crudes Data",99,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USCrudes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USCrudes.html","USCrudes R Documentation   US Crudes Data   Description  
Cross-section data originating from 99 US oil field postings.   Usage   data(""USCrudes"")   Format  
A data frame containing 99 observations on 3 variables.    price
Crude prices (USD/barrel).   gravity
Gravity (degree API).   sulphur
Sulphur (in %).     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002   Examples    data(""USCrudes"") plot(price ~ gravity, data = USCrudes) plot(price ~ sulphur, data = USCrudes) fm <- lm(price ~ sulphur + gravity, data = USCrudes) ## 3D Visualization if(require(""scatterplot3d"")) { s3d <- scatterplot3d(USCrudes[, 3:1], pch = 16) s3d$plane3d(fm, lty.box = ""solid"", col = 4) }"
"AER-USGasB","AER","USGasB","US Gasoline Market Data (1950-1987, Baltagi)",38,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USGasB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USGasB.html","USGasB R Documentation   US Gasoline Market Data (1950–1987, Baltagi)   Description  
Time series data on the US gasoline market.    Usage   data(""USGasB"")   Format  
An annual multiple time series from 1950 to 1987 with 6 variables.    cars
Stock of cars.   gas
Consumption of motor gasoline (in 1000 gallons).   price
Retail price of motor gasoline.   population
Population.   gnp
Real gross national product (in 1982 dollars).   deflator
GNP deflator (1982 = 100).     Source  
The data are from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002 , USGasG   Examples    data(""USGasB"") plot(USGasB)"
"AER-USGasG","AER","USGasG","US Gasoline Market Data (1960-1995, Greene)",36,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USGasG.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USGasG.html","USGasG R Documentation   US Gasoline Market Data (1960–1995, Greene)   Description  
Time series data on the US gasoline market.    Usage   data(""USGasG"")   Format  
An annual multiple time series from 1960 to 1995 with 10 variables.    gas
Total US gasoline consumption (computed as total expenditure divided by price index).   price
Price index for gasoline.   income
Per capita disposable income.   newcar
Price index for new cars.   usedcar
Price index for used cars.   transport
Price index for public transportation.   durable
Aggregate price index for consumer durables.   nondurable
Aggregate price index for consumer nondurables.   service
Aggregate price index for consumer services.   population
US total population in millions.     Source  
Online complements to Greene (2003). Table F2.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , USGasB   Examples    data(""USGasG"", package = ""AER"") plot(USGasG) ## Greene (2003) ## Example 2.3 fm <- lm(log(gas/population) ~ log(price) + log(income) + log(newcar) + log(usedcar), data = as.data.frame(USGasG)) summary(fm) ## Example 4.4 ## estimates and standard errors (note different offset for intercept) coef(fm) sqrt(diag(vcov(fm))) ## confidence interval confint(fm, parm = ""log(income)"") ## test linear hypothesis linearHypothesis(fm, ""log(income) = 1"") ## Example 7.6 ## re-used in Example 8.3 trend <- 1:nrow(USGasG) shock <- factor(time(USGasG) > 1973, levels = c(FALSE, TRUE), labels = c(""before"", ""after"")) ## 1960-1995 fm1 <- lm(log(gas/population) ~ log(income) + log(price) + log(newcar) + log(usedcar) + trend, data = as.data.frame(USGasG)) summary(fm1) ## pooled fm2 <- lm(log(gas/population) ~ shock + log(income) + log(price) + log(newcar) + log(usedcar) + trend, data = as.data.frame(USGasG)) summary(fm2) ## segmented fm3 <- lm(log(gas/population) ~ shock/(log(income) + log(price) + log(newcar) + log(usedcar) + trend), data = as.data.frame(USGasG)) summary(fm3) ## Chow test anova(fm3, fm1) library(""strucchange"") sctest(log(gas/population) ~ log(income) + log(price) + log(newcar) + log(usedcar) + trend, data = USGasG, point = c(1973, 1), type = ""Chow"") ## Recursive CUSUM test rcus <- efp(log(gas/population) ~ log(income) + log(price) + log(newcar) + log(usedcar) + trend, data = USGasG, type = ""Rec-CUSUM"") plot(rcus) sctest(rcus) ## Note: Greene's remark that the break is in 1984 (where the process crosses its ## boundary) is wrong. The break appears to be no later than 1976. ## More examples can be found in: ## help(""Greene2003"")"
"AER-USInvest","AER","USInvest","US Investment Data",15,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USInvest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USInvest.html","USInvest R Documentation   US Investment Data   Description  
Time series data on investments in the US, 1968–1982.    Usage   data(""USInvest"")   Format  
An annual multiple time series from 1968 to 1982 with 4 variables.    gnp
Nominal gross national product,   invest
Nominal investment,   price
Consumer price index,   interest
Interest rate (average yearly discount rate at the New York Federal Reserve Bank).     Source  
Online complements to Greene (2003). Table F3.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""USInvest"") ## Chapter 3 in Greene (2003) ## transform (and round) data to match Table 3.1 us <- as.data.frame(USInvest) us$invest <- round(0.1 * us$invest/us$price, digits = 3) us$gnp <- round(0.1 * us$gnp/us$price, digits = 3) us$inflation <- c(4.4, round(100 * diff(us$price)/us$price[-15], digits = 2)) us$trend <- 1:15 us <- us[, c(2, 6, 1, 4, 5)] ## p. 22-24 coef(lm(invest ~ trend + gnp, data = us)) coef(lm(invest ~ gnp, data = us)) ## Example 3.1, Table 3.2 cor(us)[1,-1] pcor <- solve(cor(us)) dcor <- 1/sqrt(diag(pcor)) pcor <- (-pcor * (dcor %o% dcor))[1,-1] ## Table 3.4 fm <- lm(invest ~ trend + gnp + interest + inflation, data = us) fm1 <- lm(invest ~ 1, data = us) anova(fm1, fm) ## More examples can be found in: ## help(""Greene2003"")"
"AER-USMacroB","AER","USMacroB","US Macroeconomic Data (1959-1995, Baltagi)",146,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMacroB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMacroB.html","USMacroB R Documentation   US Macroeconomic Data (1959–1995, Baltagi)   Description  
Time series data on 3 US macroeconomic variables for 1959–1995, extracted from the Citibank data base.    Usage   data(""USMacroB"")   Format  
A quarterly multiple time series from 1959(1) to 1995(2) with 3 variables.    gnp
Gross national product.   mbase
Average of the seasonally adjusted monetary base.   tbill
Average of 3 month treasury-bill rate (per annum).     Source  
The data is from Baltagi (2002).    References  
Baltagi, B.H. (2002). Econometrics , 3rd ed. Berlin, Springer.   See Also  
Baltagi2002 , USMacroSW , USMacroSWQ ,  USMacroSWM , USMacroG   Examples    data(""USMacroB"") plot(USMacroB)"
"AER-USMacroG","AER","USMacroG","US Macroeconomic Data (1950-2000, Greene)",204,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMacroG.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMacroG.html","USMacroG R Documentation   US Macroeconomic Data (1950–2000, Greene)   Description  
Time series data on 12 US macroeconomic variables for 1950–2000.    Usage   data(""USMacroG"")   Format  
A quarterly multiple time series from 1950(1) to 2000(4) with 12 variables.    gdp
Real gross domestic product (in billion USD),   consumption
Real consumption expenditures,   invest
Real investment by private sector,   government
Real government expenditures,   dpi
Real disposable personal income,   cpi
Consumer price index,   m1
Nominal money stock,   tbill
Quarterly average of month end 90 day treasury bill rate,   unemp
Unemployment rate,   population
Population (in million), interpolation of year end figures using constant growth rate per quarter,   inflation
Inflation rate,   interest
Ex post real interest rate (essentially, tbill - inflation ).     Source  
Online complements to Greene (2003). Table F5.1.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003 , USMacroSW , USMacroSWQ ,  USMacroSWM , USMacroB   Examples    ## data and trend as used by Greene (2003) data(""USMacroG"") ltrend <- 1:nrow(USMacroG) - 1 ## Example 6.1 ## Table 6.1 library(""dynlm"") fm6.1 <- dynlm(log(invest) ~ tbill + inflation + log(gdp) + ltrend, data = USMacroG) fm6.3 <- dynlm(log(invest) ~ I(tbill - inflation) + log(gdp) + ltrend, data = USMacroG) summary(fm6.1) summary(fm6.3) deviance(fm6.1) deviance(fm6.3) vcov(fm6.1)[2,3] ## F test linearHypothesis(fm6.1, ""tbill + inflation = 0"") ## alternatively anova(fm6.1, fm6.3) ## t statistic sqrt(anova(fm6.1, fm6.3)[2,5]) ## Example 8.2 ## Ct = b0 + b1*Yt + b2*Y(t-1) + v fm1 <- dynlm(consumption ~ dpi + L(dpi), data = USMacroG) ## Ct = a0 + a1*Yt + a2*C(t-1) + u fm2 <- dynlm(consumption ~ dpi + L(consumption), data = USMacroG) ## Cox test in both directions: coxtest(fm1, fm2) ## ...and do the same for jtest() and encomptest(). ## Notice that in this particular case two of them are coincident. jtest(fm1, fm2) encomptest(fm1, fm2) ## encomptest could also be performed `by hand' via fmE <- dynlm(consumption ~ dpi + L(dpi) + L(consumption), data = USMacroG) waldtest(fm1, fmE, fm2) ## More examples can be found in: ## help(""Greene2003"")"
"AER-USMacroSW","AER","USMacroSW","US Macroeconomic Data (1957-2005, Stock & Watson)",193,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMacroSW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMacroSW.html","USMacroSW R Documentation   US Macroeconomic Data (1957–2005, Stock \& Watson)   Description  
Time series data on 7 (mostly) US macroeconomic variables for 1957–2005.    Usage   data(""USMacroSW"")    Format  
A quarterly multiple time series from 1957(1) to 2005(1) with 7 variables.    unemp
Unemployment rate.   cpi
Consumer price index.   ffrate
Federal funds interest rate.   tbill
3-month treasury bill interest rate.   tbond
1-year treasury bond interest rate.   gbpusd
GBP/USD exchange rate (US dollar in cents per British pound).   gdpjp
GDP for Japan.     Details  
The US Consumer Price Index is measured using monthly surveys and is compiled by the Bureau of Labor Statistics (BLS). The unemployment rate is computed from the BLS's Current Population. The quarterly data used here were computed by averaging the monthly values. The interest data are the monthly average of daily rates as reported by the Federal Reserve and the dollar-pound exchange rate data are the monthly average of daily rates; both are for the final month in the quarter. Japanese real GDP data were obtained from the OECD.    Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , USMacroSWM , USMacroSWQ ,  USMacroB , USMacroG   Examples    ## Stock and Watson (2007) data(""USMacroSW"", package = ""AER"") library(""dynlm"") library(""strucchange"") usm <- ts.intersect(USMacroSW, 4 * 100 * diff(log(USMacroSW[, ""cpi""]))) colnames(usm) <- c(colnames(USMacroSW), ""infl"") ## Equations 14.7, 14.13, 14.16, 14.17, pp. 536 fm_ar1 <- dynlm(d(infl) ~ L(d(infl)), data = usm, start = c(1962,1), end = c(2004,4)) fm_ar4 <- dynlm(d(infl) ~ L(d(infl), 1:4), data = usm, start = c(1962,1), end = c(2004,4)) fm_adl41 <- dynlm(d(infl) ~ L(d(infl), 1:4) + L(unemp), data = usm, start = c(1962,1), end = c(2004,4)) fm_adl44 <- dynlm(d(infl) ~ L(d(infl), 1:4) + L(unemp, 1:4), data = usm, start = c(1962,1), end = c(2004,4)) coeftest(fm_ar1, vcov = sandwich) coeftest(fm_ar4, vcov = sandwich) coeftest(fm_adl41, vcov = sandwich) coeftest(fm_adl44, vcov = sandwich) ## Granger causality test mentioned on p. 547 waldtest(fm_ar4, fm_adl44, vcov = sandwich) ## Figure 14.5, p. 570 ## SW perform partial break test of unemp coefs ## here full model is used mf <- model.frame(fm_adl44) ## re-use fm_adl44 mf <- ts(as.matrix(mf), start = c(1962, 1), freq = 4) colnames(mf) <- c(""y"", paste(""x"", 1:8, sep = """")) ff <- as.formula(paste(""y"", ""~"", paste(""x"", 1:8, sep = """", collapse = "" + ""))) fs <- Fstats(ff, data = mf, from = 0.1) plot(fs) lines(boundary(fs, alpha = 0.01), lty = 2, col = 2) lines(boundary(fs, alpha = 0.1), lty = 3, col = 2) ## More examples can be found in: ## help(""StockWatson2007"")"
"AER-USMacroSWM","AER","USMacroSWM","Monthly US Macroeconomic Data (1947-2004, Stock & Watson)",696,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMacroSWM.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMacroSWM.html","USMacroSWM R Documentation   Monthly US Macroeconomic Data (1947–2004, Stock \& Watson)   Description  
Time series data on 4 US macroeconomic variables for 1947–2004.    Usage   data(""USMacroSWM"")   Format  
A monthly multiple time series from 1947(1) to 2004(4) with 4 variables.    production
index of industrial production.   oil
oil price shocks, starting 1948(1).   cpi
all-items consumer price index.   expenditure
personal consumption expenditures price deflator, starting 1959(1).     Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , USMacroSW , USMacroSWQ ,  USMacroB , USMacroG   Examples    data(""USMacroSWM"") plot(USMacroSWM)"
"AER-USMacroSWQ","AER","USMacroSWQ","Quarterly US Macroeconomic Data (1947-2004, Stock & Watson)",232,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMacroSWQ.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMacroSWQ.html","USMacroSWQ R Documentation   Quarterly US Macroeconomic Data (1947–2004, Stock \& Watson)   Description  
Time series data on 2 US macroeconomic variables for 1947–2004.    Usage   data(""USMacroSWQ"")   Format  
A quarterly multiple time series from 1947(1) to 2004(4) with 2 variables.    gdp
real GDP for the United States in billions of chained (2000) dollars seasonally adjusted, annual rate.   tbill
3-month treasury bill rate. Quarterly averages of daily dates in percentage points at an annual rate.     Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007 , USMacroSW , USMacroSWM ,  USMacroB , USMacroG   Examples    data(""USMacroSWQ"") plot(USMacroSWQ)"
"AER-USMoney","AER","USMoney","USMoney",136,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USMoney.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USMoney.html","USMoney R Documentation   USMoney   Description  
Money, output and price deflator time series data, 1950–1983.   Usage   data(""USMoney"")   Format  
A quarterly multiple time series from 1950 to 1983 with 3 variables.    gnp
nominal GNP.   m1
M1 measure of money stock.   deflator
implicit price deflator for GNP.     Source  
Online complements to Greene (2003), Table F20.2.   
http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm     References  
Greene, W.H. (2003). Econometric Analysis , 5th edition. Upper Saddle River, NJ: Prentice Hall.    See Also  
Greene2003   Examples    data(""USMoney"") plot(USMoney)"
"AER-USProdIndex","AER","USProdIndex","Index of US Industrial Production",128,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USProdIndex.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USProdIndex.html","USProdIndex R Documentation   Index of US Industrial Production   Description  
Index of US industrial production (1985 = 100).    Usage   data(""USProdIndex"")   Format  
A quarterly multiple time series from 1960(1) to 1981(4) with 2 variables.    unadjusted
raw index of industrial production,   adjusted
seasonally adjusted index.     Source  
Online complements to Franses (1998).    References  
Franses, P.H. (1998). Time Series Models for Business and Economic Forecasting . Cambridge, UK: Cambridge University Press.    See Also  
Franses1998   Examples    data(""USProdIndex"") plot(USProdIndex, plot.type = ""single"", col = 1:2) ## EACF tables (Franses 1998, p. 99) ctrafo <- function(x) residuals(lm(x ~ factor(cycle(x)))) ddiff <- function(x) diff(diff(x, frequency(x)), 1) eacf <- function(y, lag = 12) { stopifnot(all(lag > 0)) if(length(lag) < 2) lag <- 1:lag rval <- sapply( list(y = y, dy = diff(y), cdy = ctrafo(diff(y)), Dy = diff(y, frequency(y)), dDy = ddiff(y)), function(x) acf(x, plot = FALSE, lag.max = max(lag))$acf[lag + 1]) rownames(rval) <- lag return(rval) } ## Franses (1998), Table 5.1 round(eacf(log(USProdIndex[,1])), digits = 3) ## Franses (1998), Equation 5.6: Unrestricted airline model ## (Franses: ma1 = 0.388 (0.063), ma4 = -0.739 (0.060), ma5 = -0.452 (0.069)) arima(log(USProdIndex[,1]), c(0, 1, 5), c(0, 1, 0), fixed = c(NA, 0, 0, NA, NA))"
"AER-USSeatBelts","AER","USSeatBelts","Effects of Mandatory Seat Belt Laws in the US",765,12,4,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USSeatBelts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USSeatBelts.html","USSeatBelts R Documentation   Effects of Mandatory Seat Belt Laws in the US   Description  
Balanced panel data for the years 1983–1997 from 50 US States, plus the District of Columbia, for assessing traffic fatalities and seat belt usage.    Usage   data(""USSeatBelts"")   Format  
A data frame containing 765 observations on 12 variables.    state
factor indicating US state (abbreviation).   year
factor indicating year.   miles
millions of traffic miles per year.   fatalities
number of fatalities per million of traffic miles (absolute frequencies of fatalities = fatalities times miles ).   seatbelt
seat belt usage rate, as self-reported by state population surveyed.   speed65
factor. Is there a 65 mile per hour speed limit?   speed70
factor. Is there a 70 (or higher) mile per hour speed limit?   drinkage
factor. Is there a minimum drinking age of 21 years?   alcohol
factor. Is there a maximum of 0.08 blood alcohol content?   income
median per capita income (in current US dollar).   age
mean age.   enforce
factor indicating seat belt law enforcement ( ""no"" , ""primary"" , ""secondary"" ).     Details  
Some data series from Cohen and Einav (2003) have not been included in the data frame.    Source  
Online complements to Stock and Watson (2007).   References  
Cohen, A., and Einav, L. (2003). The Effects of Mandatory Seat Belt Laws on Driving Behavior and Traffic Fatalities.  The Review of Economics and Statistics , 85 , 828–843   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""USSeatBelts"") summary(USSeatBelts) library(""lattice"") xyplot(fatalities ~ as.numeric(as.character(year)) | state, data = USSeatBelts, type = ""l"")"
"AER-USStocksSW","AER","USStocksSW","Monthly US Stock Returns (1931-2002, Stock & Watson)",864,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/USStocksSW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/USStocksSW.html","USStocksSW R Documentation   Monthly US Stock Returns (1931–2002, Stock \& Watson)   Description  
Monthly data from 1931–2002 for US stock prices, measured by the broad-based (NYSE and AMEX) value-weighted index of stock prices as constructed by the Center for Research in Security Prices (CRSP).   Usage   data(""USStocksSW"")   Format  
A monthly multiple time series from 1931(1) to 2002(12) with 2 variables.    returns
monthly excess returns. The monthly return on stocks (in percentage terms) minus the return on a safe asset (in this case: US treasury bill). The return on the stocks includes the price changes plus any dividends you receive during the month.   dividend
100 times log(dividend yield). (Multiplication by 100 means the changes are interpreted as percentage points). It is calculated as the dividends over the past 12 months, divided by the price in the current month.     Source  
Online complements to Stock and Watson (2007).   References  
Campbell, J.Y., and Yogo, M. (2006). Efficient Tests of Stock Return Predictability  Journal of Financial Economics , 81 , 27–60.   
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""USStocksSW"") plot(USStocksSW) ## Stock and Watson, p. 540, Table 14.3 library(""dynlm"") fm1 <- dynlm(returns ~ L(returns), data = USStocksSW, start = c(1960,1)) coeftest(fm1, vcov = sandwich) fm2 <- dynlm(returns ~ L(returns, 1:2), data = USStocksSW, start = c(1960,1)) waldtest(fm2, vcov = sandwich) fm3 <- dynlm(returns ~ L(returns, 1:4), data = USStocksSW, start = c(1960,1)) waldtest(fm3, vcov = sandwich) ## Stock and Watson, p. 574, Table 14.7 fm4 <- dynlm(returns ~ L(returns) + L(d(dividend)), data = USStocksSW, start = c(1960, 1)) fm5 <- dynlm(returns ~ L(returns, 1:2) + L(d(dividend), 1:2), data = USStocksSW, start = c(1960,1)) fm6 <- dynlm(returns ~ L(returns) + L(dividend), data = USStocksSW, start = c(1960,1))"
"AER-WeakInstrument","AER","WeakInstrument","Artificial Weak Instrument Data",200,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/AER/WeakInstrument.csv","https://vincentarelbundock.github.io/Rdatasets/doc/AER/WeakInstrument.html","WeakInstrument R Documentation   Artificial Weak Instrument Data   Description  
Artificial data set to illustrate the problem of weak instruments.    Usage   data(""WeakInstrument"")   Format  
A data frame containing 200 observations on 3 variables.    y
dependent variable.   x
regressor variable.   z
instrument variable.     Source  
Online complements to Stock and Watson (2007).   References  
Stock, J.H. and Watson, M.W. (2007). Introduction to Econometrics , 2nd ed. Boston: Addison Wesley.    See Also  
StockWatson2007   Examples    data(""WeakInstrument"") fm <- ivreg(y ~ x | z, data = WeakInstrument) summary(fm)"
"asaur-ashkenazi","asaur","ashkenazi","ashkenazi",3920,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/ashkenazi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/ashkenazi.html","ashkenazi R Documentation   ashkenazi    Description  
This is a random subset of data from the Struewing et al. (1997) study of Ashkenazi jews and breast cancer. The subset consists of pairs of first-degree female relatives who are also first degree relatives of a proband.    Usage   data(""ashkenazi"")   Format  
A data frame with 3920 observations on the following 4 variables.    famID
family ID indicator   brcancer
1 if subject had breast cancer, 0 if not   age
Age at onset of breast cancer, or current age if no breast cancer   mutant
1 if first degree relative proband was a BRCA mutation carrier, 0 if not     References  
Moore DF, Chatterjee N, Pee D, and Gail MH (2001) Pseudo-likelihood estimates of the cumulative risk of an autosomal dominant disease from a kin-cohort study. Genetic Epidemiology 20, 210-227.)   
Struewing JP, Hartge P, Wacholder S, Baker SM, Berlin M, McAdams M, Timmerman MM, Brody LC, and Tucker MA (1997) The risk of cancer associated with specific mutations of BRCA1 and BRCA2 among ashkenazi jews. New England Journal of Medicine 336, 1401-1408.)    Examples    data(ashkenazi)"
"asaur-ChanningHouse","asaur","ChanningHouse","Channing House Data",457,5,2,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/ChanningHouse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/ChanningHouse.html","ChanningHouse R Documentation    Channing House Data    Description  
The ChanningHouse data frame has 457 rows and 5 columns. This is 5 fewer than the parent channing data frame in the boot package. These 5 were removed because the exit time was not smaller than the entry time.   
Channing House is a retirement centre in Palo Alto, California. These data were collected between the opening of the house in 1964 until July 1, 1975. In that time 97 men and 365 women passed through the centre. For each of these, their age on entry and also on leaving or death was recorded. A large number of the observations were censored mainly due to the resident being alive on July 1, 1975 when the data was collected. Over the time of the study 130 women and 46 men died at Channing House. Differences between the survival of the sexes, taking age into account, was one of the primary concerns of this study.    Usage   data(""ChanningHouse"")   Format  
A data frame with 457 observations on the following 5 variables.    sex
a factor for the sex of each resident with levels Female Male   entry
The residents age (in months) on entry to the center)   exit
The age (in months) of the resident on death, leaving the center or July 1, 1975, whichever event occurred first.)   time
The length of time (in months) that the resident spent at Channing House. ( time=exit-entry )))   cens
The indicator of reight censoring. 1 indicates that the resident died at Channing House, 0 indicates that they left the house prior to July 1, 1975 or that they were still alive and living in the center at that date.     Source  
The current data were derived from the ""channing"" data frame in the ""boot"" package. The original source for the data was   
Hyde, J. (1980) Testing survival with incomplete observations. Biostatistics Casebook. R.G. Miller, B. Efron, B.W. Brown and L.E. Moses (editors), 31-46. John Wiley.   References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application. Cambridge University Press.  
Canty, A. and Ripley, B. (2015) boot package.    Examples    data(ChanningHouse)"
"asaur-gastricXelox","asaur","gastricXelox","gasticXelox",48,2,1,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/gastricXelox.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/gastricXelox.html","gastricXelox R Documentation   gasticXelox    Description  
Data from a Phase II clinical trial of Xeloda and exaliplatin given before surgery to advanced gastric cancer patients with para-aortic lymph node metastasis.    Usage   data(""gastricXelox"")   Format  
A data frame with 48 observations on the following 2 variables.    timeWeeks
survival time in weeks   delta
1 for death, 0 for censored     Details  
The data were extracted from the Kaplan-Meier survival plot.    References  
Wang Y, Yu Y-Y, Li W, Feng Y, Hou J, Ji Y, Sun Y-H, Shen K-T, Shen Z-B, Qin X-Y, and Liu T-S. (2014) A phase II trial of xeloda and oxaliplatin (XELOX) neo-adjuvant chemotherapy followed by surgery for advanced gastric cancer patients with para-aortic lymph node metastasis. Cancer Chemotherapy and Pharmacology 73(6), 1155-1161.))    Examples    data(gastricXelox)"
"asaur-hepatoCellular","asaur","hepatoCellular","hepatoCellular",227,48,15,0,0,0,48,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/hepatoCellular.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/hepatoCellular.html","hepatoCellular R Documentation   hepatoCellular    Description  
Overall and recurrence-free survival of patients with hepatocellular carcinoma.    Usage   data(""hepatoCellular"")   Format  
A data frame with 227 observations on 48 clinical and biomarker variables    Number
Patient ID number   Age
a numeric vector   Gender
a numeric vector   HBsAg
a numeric vector   Cirrhosis
a numeric vector   ALT
a numeric vector   AST
a numeric vector   AFP
a numeric vector   Tumorsize
a numeric vector   Tumordifferentiation
a numeric vector   Vascularinvasion
a numeric vector   Tumormultiplicity
a numeric vector   Capsulation
a numeric vector   TNM
a numeric vector   BCLC
a numeric vector   OS
Overall survival   Death
1 denotes death, 0 censored   RFS
Recurrence-free survival   Recurrence
1 denotes recurrence, 0 censored   CXCL17T
a numeric vector   CXCL17P
a numeric vector   CXCL17N
a numeric vector   CD4T
a numeric vector   CD4N
a numeric vector   CD8T
a numeric vector   CD8N
a numeric vector   CD20T
a numeric vector   CD20N
a numeric vector   CD57T
a numeric vector   CD57N
a numeric vector   CD15T
a numeric vector   CD15N
a numeric vector   CD68T
a numeric vector   CD68N
a numeric vector   CD4NR
a numeric vector   CD8NR
a numeric vector   CD20NR
a numeric vector   CD57NR
a numeric vector   CD15NR
a numeric vector   CD68NR
a numeric vector   CD4TR
a numeric vector   CD8TR
a numeric vector   CD20TR
a numeric vector   CD57TR
a numeric vector   CD15TR
a numeric vector   CD68TR
a numeric vector   Ki67
a numeric vector   CD34
a numeric vector     References  
Li L, Yan J, Xu J, Liu C-Q, Zhen Z-J, Chen H-W, Ji Y, Wu Z-P, Hu J-Y, Zheng L, Lau WY (2014) Cxcl17 expression predicts poor prognosis and correlates with adverse immune infiltration in hepatocellular carcinoma. Plos One 9 (10) e110064.   
Li L, Yan J, Xu J, Liu C-Q, Zhen Z-J, Chen H-W, Ji Y, Wu Z-P, Hu J-Y, Zheng L, Lau WY (2014) Cxcl17 expression predicts poor prognosis and correlates with adverse immune infiltration in hepatocellular carcinoma. Dryad Digital Repository datadryad.org.   Examples    data(hepatoCellular)"
"asaur-pancreatic","asaur","pancreatic","pancreatic",41,4,1,0,4,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/pancreatic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/pancreatic.html","pancreatic R Documentation   pancreatic    Description  
Data from a Phase II clinical trial of patients with locally advanced or metastatic pancreatic cancer.    Usage   data(""pancreatic"")   Format  
A data frame with 41 observations on the following 4 variables.    stage
a factor with levels LA (locally advanced) or M (metastatic)   onstudy
date of enrollment into the clinical trial, in month/day/year format   progression
date of progression, in month/day/year format   death
date of death, in month/day/year format     Details  
Since all patients in this study have known death dates, there is no censoring.    References  
Moss RA, Moore D, Mulcahy MF, Nahum K, Saraiya B, Eddy S, Kleber M, and Poplin EA (2012) A multi-institutional phase 2 study of imatinib mesylate and gemcitabine for first-line treatment of advanced pancreatic cancer. Gastrointestinal Cancer Research 5, 77 - 83.    Examples    data(pancreatic)"
"asaur-pancreatic2","asaur","pancreatic2","pancreatic2",41,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/pancreatic2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/pancreatic2.html","pancreatic2 R Documentation   pancreatic2    Description  
This is the same data as in 'pancreatic', with overall and progression-free survival calculated. Dates have been removed.    Usage   data(""pancreatic2"")   Format  
A data frame with 41 observations on the following 4 variables.    pfs
Progression-free survival: Time from entry until disease progression. If no progression was observed, before death, the time to death is used.   os
Overall survival: Time from entry until death   status
This censoring indicator is 1 for all patients, since all patients died.   stage
a factor with levels LA (locally advanced) or M (metastatic)     References  
Moss RA, Moore D, Mulcahy MF, Nahum K, Saraiya B, Eddy S, Kleber M, and Poplin EA (2012) A multi-institutional phase 2 study of imatinib mesylate and gemcitabine for first-line treatment of advanced pancreatic cancer. Gastrointestinal Cancer Research 5, 77 - 83.    Examples    data(pancreatic2)"
"asaur-pharmacoSmoking","asaur","pharmacoSmoking","pharmacoSmoking",125,14,5,0,7,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/pharmacoSmoking.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/pharmacoSmoking.html","pharmacoSmoking R Documentation   pharmacoSmoking    Description  
Randomized trial of triple therapy vs. patch for smoking cessation.    Usage   data(""pharmacoSmoking"")   Format  
A data frame with 125 observations on the following 14 variables.    id
patient ID number   ttr
Time in days until relapse   relapse
Indicator of relapse (return to smoking)   grp
Randomly assigned treatment group with levels combination or patchOnly   age
Age in years at time of randomization   gender
Female or Male   race
black , hispanic , white , or other   employment
ft (full-time), pt (part-time), or other   yearsSmoking
Number of years the patient had been a smoker   levelSmoking
heavy or light   ageGroup2
Age group with levels 21-49 or 50+   ageGroup4
Age group with levels 21-34 , 35-49 , 50-64 , or 65+   priorAttempts
The number of prior attempts to quit smoking   longestNoSmoke
The longest period of time, in days, that the patient has previously gone without smoking     Source  
This data is from a clinical trial described in Steinberg et al. (2009)    References  
Steinberg, M.B. Greenhaus, S. Schmelzer, A.C. Bover, M.T., Foulds, J., Hoover, D.R., and Carson, J.L. (2009) Triple-combination pharmacotherapy for medically ill smokers: A randomized trial. Annals of Internal Medicine 150, 447-454.    Examples    data(pharmacoSmoking)"
"asaur-prostateSurvival","asaur","prostateSurvival","prostateSurvival",14294,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/asaur/prostateSurvival.csv","https://vincentarelbundock.github.io/Rdatasets/doc/asaur/prostateSurvival.html","prostateSurvival R Documentation   prostateSurvival    Description  
This data set contains survival times for two competing causes: time from prostate cancer diagnosis to death from prostate cancer, and time from prostate cancer diagnosis to death from other causes. The data set also contains information on several risk factors. The data in this data set are simulated from detailed competing risk survival curves and counts of numbers of patients per group presented in Lu-Yao et al. (2009). Thus, the simulated data presented here contain many of the characteristics of the original SEER-Medicare prostate cancer data used in Lu-Yao et al. (2009).    Usage   data(""prostateSurvival"")   Format  
A data frame with 14294 observations on the following 5 variables.    grade
a factor with levels mode (moderately differentiated) and poor (poorly differentiated)   stage
a factor with levels T1ab (Stage T1, clinically diagnoseed),  T1c (Stage T1, diagnosed via a PSA test), and T2 (Stage T2)   ageGroup
a factor with levels 66-69 70-74 75-79 80+   survTime
time from diagnosis to death or last date known alive   status
a censoring variable, 0 , (censored),  1 (death from prostate cancer), and 2 (death from other causes)     Source  
Lu-Yao, GL, Albertsen PC, Moore DF, Shih W, Lin Y, DiPaola RS, Barry MJ, Zietman A, O'Leary M, Walker-Corkery E, Yao S-L (2009) Outcomes of localized prostate cancer following conservative management. Journal of the American Medical Association 302, 1202 - 1209.)   Examples    data(prostateSurvival)"
"boot-acme","boot","acme","Monthly Excess Returns",60,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/acme.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/acme.html","acme R Documentation    Monthly Excess Returns    Description  
The acme data frame has 60 rows and 3 columns.   
The excess return for the Acme Cleveland Corporation are recorded along with those for all stocks listed on the New York and American Stock Exchanges were recorded over a five year period. These excess returns are relative to the return on a risk-less investment such a U.S. Treasury bills.   Usage    acme    Format  
This data frame contains the following columns:    month  
A character string representing the month of the observation.    market  
The excess return of the market as a whole.    acme  
The excess return for the Acme Cleveland Corporation.      Source  
The data were obtained from   
Simonoff, J.S. and Tsai, C.-L. (1994) Use of modified profile likelihood for improved tests of constancy of variance in regression. Applied Statistics , 43 , 353–370.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-aids","boot","aids","Delay in AIDS Reporting in England and Wales",570,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/aids.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/aids.html","aids R Documentation    Delay in AIDS Reporting in England and Wales    Description  
The aids data frame has 570 rows and 6 columns.   
Although all cases of AIDS in England and Wales must be reported to the Communicable Disease Surveillance Centre, there is often a considerable delay between the time of diagnosis and the time that it is reported. In estimating the prevalence of AIDS, account must be taken of the unknown number of cases which have been diagnosed but not reported. The data set here records the reported cases of AIDS diagnosed from July 1983 and until the end of 1992. The data are cross-classified by the date of diagnosis and the time delay in the reporting of the cases.   Usage    aids    Format  
This data frame contains the following columns:    year  
The year of the diagnosis.    quarter  
The quarter of the year in which diagnosis was made.    delay  
The time delay (in months) between diagnosis and reporting. 0 means that the case was reported within one month. Longer delays are grouped in 3 month intervals and the value of delay is the midpoint of the interval (therefore a value of 2 indicates that reporting was delayed for between 1 and 3 months).    dud  
An indicator of censoring. These are categories for which full information is not yet available and the number recorded is a lower bound only.    time  
The time interval of the diagnosis. That is the number of quarters from July 1983 until the end of the quarter in which these cases were diagnosed.    y  
The number of AIDS cases reported.      Source  
The data were obtained from   
De Angelis, D. and Gilks, W.R. (1994) Estimating acquired immune deficiency syndrome accounting for reporting delay.  Journal of the Royal Statistical Society, A , 157 , 31–40.    References  
Davison, A.C. and Hinkley, D.V. (1997)  Bootstrap Methods and Their Application . Cambridge University Press."
"boot-aircondit","boot","aircondit","Failures of Air-conditioning Equipment",12,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/aircondit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/aircondit.html","aircondit R Documentation    Failures of Air-conditioning Equipment    Description  
Proschan (1963) reported on the times between failures of the air-conditioning equipment in 10 Boeing 720 aircraft. The aircondit data frame contains the intervals for the ninth aircraft while aircondit7 contains those for the seventh aircraft.  
Both data frames have just one column. Note that the data have been sorted into increasing order.    Usage    aircondit    Format  
The data frames contain the following column:    hours  
The time interval in hours between successive failures of the air-conditioning equipment      Source  
The data were taken from   
Cox, D.R. and Snell, E.J. (1981) Applied Statistics: Principles and Examples . Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Proschan, F. (1963) Theoretical explanation of observed decreasing failure rate. Technometrics , 5 , 375-383."
"boot-aircondit7","boot","aircondit7","Failures of Air-conditioning Equipment",24,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/aircondit7.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/aircondit7.html","aircondit R Documentation    Failures of Air-conditioning Equipment    Description  
Proschan (1963) reported on the times between failures of the air-conditioning equipment in 10 Boeing 720 aircraft. The aircondit data frame contains the intervals for the ninth aircraft while aircondit7 contains those for the seventh aircraft.  
Both data frames have just one column. Note that the data have been sorted into increasing order.    Usage    aircondit    Format  
The data frames contain the following column:    hours  
The time interval in hours between successive failures of the air-conditioning equipment      Source  
The data were taken from   
Cox, D.R. and Snell, E.J. (1981) Applied Statistics: Principles and Examples . Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Proschan, F. (1963) Theoretical explanation of observed decreasing failure rate. Technometrics , 5 , 375-383."
"boot-amis","boot","amis","Car Speeding and Warning Signs",8437,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/amis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/amis.html","amis R Documentation    Car Speeding and Warning Signs    Description  
The amis data frame has 8437 rows and 4 columns.   
In a study into the effect that warning signs have on speeding patterns, Cambridgeshire County Council considered 14 pairs of locations. The locations were paired to account for factors such as traffic volume and type of road. One site in each pair had a sign erected warning of the dangers of speeding and asking drivers to slow down. No action was taken at the second site. Three sets of measurements were taken at each site. Each set of measurements was nominally of the speeds of 100 cars but not all sites have exactly 100 measurements. These speed measurements were taken before the erection of the sign, shortly after the erection of the sign, and again after the sign had been in place for some time.   Usage    amis    Format  
This data frame contains the following columns:    speed  
Speeds of cars (in miles per hour).    period  
A numeric column indicating the time that the reading was taken. A value of 1 indicates a reading taken before the sign was erected, a 2 indicates a reading taken shortly after erection of the sign and a 3 indicates a reading taken after the sign had been in place for some time.    warning  
A numeric column indicating whether the location of the reading was chosen to have a warning sign erected. A value of 1 indicates presence of a sign and a value of 2 indicates that no sign was erected.    pair  
A numeric column giving the pair number at which the reading was taken. Pairs were numbered from 1 to 14.      Source  
The data were kindly made available by Mr. Graham Amis, Cambridgeshire County Council, U.K.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-aml","boot","aml","Remission Times for Acute Myelogenous Leukaemia",23,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/aml.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/aml.html","aml R Documentation    Remission Times for Acute Myelogenous Leukaemia    Description  
The aml data frame has 23 rows and 3 columns.   
A clinical trial to evaluate the efficacy of maintenance chemotherapy for acute myelogenous leukaemia was conducted by Embury et al. (1977) at Stanford University. After reaching a stage of remission through treatment by chemotherapy, patients were randomized into two groups. The first group received maintenance chemotherapy and the second group did not. The aim of the study was to see if maintenance chemotherapy increased the length of the remission. The data here formed a preliminary analysis which was conducted in October 1974.    Usage    aml    Format  
This data frame contains the following columns:    time  
The length of the complete remission (in weeks).    cens  
An indicator of right censoring. 1 indicates that the patient had a relapse and so time is the length of the remission. 0 indicates that the patient had left the study or was still in remission in October 1974, that is the length of remission is right-censored.    group  
The group into which the patient was randomized. Group 1 received maintenance chemotherapy, group 2 did not.      Note  
Package survival also has a dataset aml . It is the same data with different names and with group replaced by a factor  x .    Source  
The data were obtained from   
Miller, R.G. (1981) Survival Analysis . John Wiley.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Embury, S.H, Elias, L., Heller, P.H., Hood, C.E., Greenberg, P.L. and Schrier, S.L. (1977) Remission maintenance therapy in acute myelogenous leukaemia. Western Journal of Medicine , 126 , 267-272."
"boot-beaver","boot","beaver","Beaver Body Temperature Data",100,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/beaver.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/beaver.html","beaver R Documentation    Beaver Body Temperature Data    Description  
The beaver data frame has 100 rows and 4 columns. It is a multivariate time series of class ""ts"" and also inherits from class ""data.frame"" .   
This data set is part of a long study into body temperature regulation in beavers. Four adult female beavers were live-trapped and had a temperature-sensitive radio transmitter surgically implanted. Readings were taken every 10 minutes. The location of the beaver was also recorded and her activity level was dichotomized by whether she was in the retreat or outside of it since high-intensity activities only occur outside of the retreat.   
The data in this data frame are those readings for one of the beavers on a day in autumn.   Usage    beaver    Format  
This data frame contains the following columns:    day  
The day number. The data includes only data from day 307 and early 308.    time  
The time of day formatted as hour-minute.    temp  
The body temperature in degrees Celsius.    activ  
The dichotomized activity indicator. 1 indicates that the beaver is outside of the retreat and therefore engaged in high-intensity activity.      Source  
The data were obtained from   
Reynolds, P.S. (1994) Time-series analyses of beaver body temperatures. In Case Studies in Biometry . N. Lange, L. Ryan, L. Billard, D. Brillinger, L. Conquest and J. Greenhouse (editors), 211–228. John Wiley.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-bigcity","boot","bigcity","Population of U.S. Cities",49,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/bigcity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/bigcity.html","bigcity R Documentation    Population of U.S. Cities    Description  
The bigcity data frame has 49 rows and 2 columns.  
The city data frame has 10 rows and 2 columns.  
The measurements are the population (in 1000's) of 49 U.S. cities in 1920 and 1930. The 49 cities are a random sample taken from the 196 largest cities in 1920. The city data frame consists of the first 10 observations in bigcity .   Usage    bigcity    Format  
This data frame contains the following columns:    u  
The 1920 population.    x  
The 1930 population.      Source  
The data were obtained from   
Cochran, W.G. (1977) Sampling Techniques . Third edition. John Wiley    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-brambles","boot","brambles","Spatial Location of Bramble Canes",823,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/brambles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/brambles.html","brambles R Documentation    Spatial Location of Bramble Canes    Description  
The brambles data frame has 823 rows and 3 columns.   
The location of living bramble canes in a 9m square plot was recorded. We take 9m to be the unit of distance so that the plot can be thought of as a unit square. The bramble canes were also classified by their age.    Usage    brambles    Format  
This data frame contains the following columns:    x  
The x coordinate of the position of the cane in the plot.    y  
The y coordinate of the position of the cane in the plot.    age  
The age classification of the canes; 0 indicates a newly emerged cane,  1 indicates a one year old cane and 2 indicates a two year old cane.      Source  
The data were obtained from   
Diggle, P.J. (1983) Statistical Analysis of Spatial Point Patterns . Academic Press.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-breslow","boot","breslow","Smoking Deaths Among Doctors",10,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/breslow.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/breslow.html","breslow R Documentation    Smoking Deaths Among Doctors    Description  
The breslow data frame has 10 rows and 5 columns.   
In 1961 Doll and Hill sent out a questionnaire to all men on the British Medical Register enquiring about their smoking habits. Almost 70% of such men replied. Death certificates were obtained for medical practitioners and causes of death were assigned on the basis of these certificates. The  breslow data set contains the person-years of observations and deaths from coronary artery disease accumulated during the first ten years of the study.    Usage    breslow    Format  
This data frame contains the following columns:    age  
The mid-point of the 10 year age-group for the doctors.    smoke  
An indicator of whether the doctors smoked (1) or not (0).    n  
The number of person-years in the category.    y  
The number of deaths attributed to coronary artery disease.    ns  
The number of smoker years in the category ( smoke*n ).      Source  
The data were obtained from   
Breslow, N.E. (1985) Cohort Analysis in Epidemiology. In A Celebration of Statistics A.C. Atkinson and S.E. Fienberg (editors), 109–143. Springer-Verlag.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Doll, R. and Hill, A.B. (1966) Mortality of British doctors in relation to smoking: Observations on coronary thrombosis. National Cancer Institute Monograph , 19 , 205-268."
"boot-calcium","boot","calcium","Calcium Uptake Data",27,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/calcium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/calcium.html","calcium R Documentation    Calcium Uptake Data    Description  
The calcium data frame has 27 rows and 2 columns.   
Howard Grimes from the Botany Department, North Carolina State University, conducted an experiment for biochemical analysis of intracellular storage and transport of calcium across plasma membrane. Cells were suspended in a solution of radioactive calcium for a certain length of time and then the amount of radioactive calcium that was absorbed by the cells was measured. The experiment was repeated independently with 9 different times of suspension each replicated 3 times.   Usage    calcium    Format  
This data frame contains the following columns:    time  
The time (in minutes) that the cells were suspended in the solution.    cal  
The amount of calcium uptake (nmoles/mg).      Source  
The data were obtained from   
Rawlings, J.O. (1988) Applied Regression Analysis . Wadsworth and Brooks/Cole Statistics/Probability Series.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-cane","boot","cane","Sugar-cane Disease Data",180,5,0,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/cane.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/cane.html","cane R Documentation    Sugar-cane Disease Data    Description  
The cane data frame has 180 rows and 5 columns. The data frame represents a randomized block design with 45 varieties of sugar-cane and 4 blocks.   Usage    cane    Format  
This data frame contains the following columns:    n  
The total number of shoots in each plot.    r  
The number of diseased shoots.    x  
The number of pieces of the stems, out of 50, planted in each plot.    var  
A factor indicating the variety of sugar-cane in each plot.    block  
A factor for the blocks.      Details  
The aim of the experiment was to classify the varieties into resistant, intermediate and susceptible to a disease called ""coal of sugar-cane"" (carvao da cana-de-acucar). This is a disease that is common in sugar-cane plantations in certain areas of Brazil.   
For each plot, fifty pieces of sugar-cane stem were put in a solution containing the disease agent and then some were planted in the plot. After a fixed period of time, the total number of shoots and the number of diseased shoots were recorded.    Source  
The data were kindly supplied by Dr. C.G.B. Demetrio of Escola Superior de Agricultura, Universidade de Sao Paolo, Brazil.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-capability","boot","capability","Simulated Manufacturing Process Data",75,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/capability.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/capability.html","capability R Documentation    Simulated Manufacturing Process Data    Description  
The capability data frame has 75 rows and 1 columns.   
The data are simulated successive observations from a process in equilibrium. The process is assumed to have specification limits (5.49, 5.79).    Usage    capability    Format  
This data frame contains the following column:    y  
The simulated measurements.      Source  
The data were obtained from   
Bissell, A.F. (1990) How reliable is your capability index?  Applied Statistics , 39 , 331–340.    References  
Canty, A.J. and Davison, A.C. (1996) Implementation of saddlepoint approximations to resampling distributions. To appear in Computing Science and Statistics; Proceedings of the 28th Symposium on the Interface .   
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-catsM","boot","catsM","Weight Data for Domestic Cats",97,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/catsM.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/catsM.html","catsM R Documentation    Weight Data for Domestic Cats    Description  
The catsM data frame has 97 rows and 3 columns.   
144 adult (over 2kg in weight) cats used for experiments with the drug digitalis had their heart and body weight recorded. 47 of the cats were female and 97 were male. The catsM data frame consists of the data for the male cats. The full data are in dataset cats  in package MASS .    Usage    catsM    Format  
This data frame contains the following columns:    Sex  
A factor for the sex of the cat (levels are F and M : all cases are M in this subset).    Bwt  
Body weight in kg.    Hwt  
Heart weight in g.      Source  
The data were obtained from   
Fisher, R.A. (1947) The analysis of covariance method for the relation between a part and the whole. Biometrics , 3 , 65–68.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Venables, W.N. and Ripley, B.D. (1994) Modern Applied Statistics with S-Plus . Springer-Verlag.    See Also  
cats"
"boot-cav","boot","cav","Position of Muscle Caveolae",138,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/cav.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/cav.html","cav R Documentation    Position of Muscle Caveolae    Description  
The cav data frame has 138 rows and 2 columns.   
The data gives the positions of the individual caveolae in a square region with sides of length 500 units. This grid was originally on a 2.65mum square of muscle fibre. The data are those points falling in the lower left hand quarter of the region used for the dataset caveolae.dat in the spatial package by B.D. Ripley (1994).    Usage    cav    Format  
This data frame contains the following columns:    x  
The x coordinate of the caveola's position in the region.    y  
The y coordinate of the caveola's position in the region.      References  
Appleyard, S.T., Witkowski, J.A., Ripley, B.D., Shotton, D.M. and Dubowicz, V. (1985) A novel procedure for pattern analysis of features present on freeze fractured plasma membranes. Journal of Cell Science , 74 , 105–117.   
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-cd4","boot","cd4","CD4 Counts for HIV-Positive Patients",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/cd4.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/cd4.html","cd4 R Documentation    CD4 Counts for HIV-Positive Patients    Description  
The cd4 data frame has 20 rows and 2 columns.   
CD4 cells are carried in the blood as part of the human immune system. One of the effects of the HIV virus is that these cells die. The count of CD4 cells is used in determining the onset of full-blown AIDS in a patient. In this study of the effectiveness of a new anti-viral drug on HIV, 20 HIV-positive patients had their CD4 counts recorded and then were put on a course of treatment with this drug. After using the drug for one year, their CD4 counts were again recorded. The aim of the experiment was to show that patients taking the drug had increased CD4 counts which is not generally seen in HIV-positive patients.    Usage    cd4    Format  
This data frame contains the following columns:    baseline  
The CD4 counts (in 100's) on admission to the trial.    oneyear  
The CD4 counts (in 100's) after one year of treatment with the new drug.      Source  
The data were obtained from   
DiCiccio, T.J. and Efron B. (1996) Bootstrap confidence intervals (with Discussion). Statistical Science , 11 , 189–228.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-channing","boot","channing","Channing House Data",462,5,2,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/channing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/channing.html","channing R Documentation    Channing House Data    Description  
The channing data frame has 462 rows and 5 columns.   
Channing House is a retirement centre in Palo Alto, California. These data were collected between the opening of the house in 1964 until July 1, 1975. In that time 97 men and 365 women passed through the centre. For each of these, their age on entry and also on leaving or death was recorded. A large number of the observations were censored mainly due to the resident being alive on July 1, 1975 when the data was collected. Over the time of the study 130 women and 46 men died at Channing House. Differences between the survival of the sexes, taking age into account, was one of the primary concerns of this study.    Usage    channing    Format  
This data frame contains the following columns:    sex  
A factor for the sex of each resident ( ""Male"" or ""Female"" ).    entry  
The residents age (in months) on entry to the centre    exit  
The age (in months) of the resident on death, leaving the centre or July 1, 1975 whichever event occurred first.    time  
The length of time (in months) that the resident spent at Channing House. ( time=exit-entry )    cens  
The indicator of right censoring. 1 indicates that the resident died at Channing House, 0 indicates that they left the house prior to July 1, 1975 or that they were still alive and living in the centre at that date.      Source  
The data were obtained from   
Hyde, J. (1980) Testing survival with incomplete observations. Biostatistics Casebook . R.G. Miller, B. Efron, B.W. Brown and L.E. Moses (editors), 31–46. John Wiley.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-city","boot","city","Population of U.S. Cities",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/city.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/city.html","bigcity R Documentation    Population of U.S. Cities    Description  
The bigcity data frame has 49 rows and 2 columns.  
The city data frame has 10 rows and 2 columns.  
The measurements are the population (in 1000's) of 49 U.S. cities in 1920 and 1930. The 49 cities are a random sample taken from the 196 largest cities in 1920. The city data frame consists of the first 10 observations in bigcity .   Usage    bigcity    Format  
This data frame contains the following columns:    u  
The 1920 population.    x  
The 1930 population.      Source  
The data were obtained from   
Cochran, W.G. (1977) Sampling Techniques . Third edition. John Wiley    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-claridge","boot","claridge","Genetic Links to Left-handedness",37,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/claridge.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/claridge.html","claridge R Documentation    Genetic Links to Left-handedness    Description  
The claridge data frame has 37 rows and 2 columns.  
The data are from an experiment which was designed to look for a relationship between a certain genetic characteristic and handedness. The 37 subjects were women who had a son with mental retardation due to inheriting a defective X-chromosome. For each such mother a genetic measurement of their DNA was made. Larger values of this measurement are known to be linked to the defective gene and it was hypothesized that larger values might also be linked to a progressive shift away from right-handednesss. Each woman also filled in a questionnaire regarding which hand they used for various tasks. From these questionnaires a measure of hand preference was found for each mother. The scale of this measure goes from 1, indicating someone who always favours their right hand, to 8, indicating someone who always favours their left hand. Between these two extremes are people who favour one hand for some tasks and the other for other tasks.    Usage    claridge    Format  
This data frame contains the following columns:    dnan  
The genetic measurement on each woman's DNA.    hand  
The measure of left-handedness on an integer scale from 1 to 8.      Source  
The data were kindly made available by Dr. Gordon S. Claridge from the Department of Experimental Psychology, University of Oxford.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-cloth","boot","cloth","Number of Flaws in Cloth",32,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/cloth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/cloth.html","cloth R Documentation    Number of Flaws in Cloth    Description  
The cloth data frame has 32 rows and 2 columns.    Usage    cloth    Format  
This data frame contains the following columns:    x  
The length of the roll of cloth.    y  
The number of flaws found in the roll.      Source  
The data were obtained from   
Bissell, A.F. (1972) A negative binomial model with varying element size.  Biometrika , 59 , 435–441.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-co.transfer","boot","co.transfer","Carbon Monoxide Transfer",7,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/co.transfer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/co.transfer.html","co.transfer R Documentation    Carbon Monoxide Transfer    Description  
The co.transfer data frame has 7 rows and 2 columns. Seven smokers with chickenpox had their levels of carbon monoxide transfer measured on entry to hospital and then again after 1 week. The main question being whether one week of hospitalization has changed the carbon monoxide transfer factor.    Usage    co.transfer    Format  
This data frame contains the following columns:    entry  
Carbon monoxide transfer factor on entry to hospital.    week  
Carbon monoxide transfer one week after admittance to hospital.      Source  
The data were obtained from   
Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E (1994)  A Handbook of Small Data Sets . Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Ellis, M.E., Neal, K.R. and Webb, A.K. (1987) Is smoking a risk factor for pneumonia in patients with chickenpox? British Medical Journal ,  294 , 1002."
"boot-coal","boot","coal","Dates of Coal Mining Disasters",191,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/coal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/coal.html","coal R Documentation    Dates of Coal Mining Disasters   Description  
The coal data frame has 191 rows and 1 columns.   
This data frame gives the dates of 191 explosions in coal mines which resulted in 10 or more fatalities. The time span of the data is from March 15, 1851 until March 22 1962.   Usage    coal    Format  
This data frame contains the following column:    date  
The date of the disaster. The integer part of date gives the year. The day is represented as the fraction of the year that had elapsed on that day.      Source  
The data were obtained from   
Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E. (1994)  A Handbook of Small Data Sets , Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Jarrett, R.G. (1979) A note on the intervals between coal-mining disasters.  Biometrika , 66 , 191-193."
"boot-darwin","boot","darwin","Darwin's Plant Height Differences",15,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/darwin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/darwin.html","darwin R Documentation    Darwin's Plant Height Differences    Description  
The darwin data frame has 15 rows and 1 columns.   
Charles Darwin conducted an experiment to examine the superiority of cross-fertilized plants over self-fertilized plants. 15 pairs of plants were used. Each pair consisted of one cross-fertilized plant and one self-fertilized plant which germinated at the same time and grew in the same pot. The plants were measured at a fixed time after planting and the difference in heights between the cross- and self-fertilized plants are recorded in eighths of an inch.    Usage    darwin    Format  
This data frame contains the following column:    y  
The difference in heights for the pairs of plants (in units of 0.125 inches).      Source  
The data were obtained from   
Fisher, R.A. (1935) Design of Experiments . Oliver and Boyd.    References  
Darwin, C. (1876) The Effects of Cross- and Self-fertilisation in the Vegetable Kingdom . John Murray.   
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-dogs","boot","dogs","Cardiac Data for Domestic Dogs",7,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/dogs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/dogs.html","dogs R Documentation   Cardiac Data for Domestic Dogs   Description  
The dogs data frame has 7 rows and 2 columns.   
Data on the cardiac oxygen consumption and left ventricular pressure were gathered on 7 domestic dogs.    Usage   dogs   Format  
This data frame contains the following columns:    mvo
Cardiac Oxygen Consumption   lvp
Left Ventricular Pressure     References  
Davison, A. C. and Hinkley, D. V. (1997)  Bootstrap Methods and Their Application . Cambridge University Press."
"boot-downs.bc","boot","downs.bc","Incidence of Down's Syndrome in British Columbia",30,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/downs.bc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/downs.bc.html","downs.bc R Documentation    Incidence of Down's Syndrome in British Columbia    Description  
The downs.bc data frame has 30 rows and 3 columns.   
Down's syndrome is a genetic disorder caused by an extra chromosome 21 or a part of chromosome 21 being translocated to another chromosome. The incidence of Down's syndrome is highly dependent on the mother's age and rises sharply after age 30. In the 1960's a large scale study of the effect of maternal age on the incidence of Down's syndrome was conducted at the British Columbia Health Surveillance Registry. These are the data which was collected in that study.  
Mothers were classified by age. Most groups correspond to the age in years but the first group comprises all mothers with ages in the range 15-17 and the last is those with ages 46-49. No data for mothers over 50 or below 15 were collected.   Usage    downs.bc    Format  
This data frame contains the following columns:    age  
The average age of all mothers in the age category.    m  
The total number of live births to mothers in the age category.    r  
The number of cases of Down's syndrome.      Source  
The data were obtained from   
Geyer, C.J. (1991) Constrained maximum likelihood exemplified by isotonic convex logistic regression. Journal of the American Statistical Association , 86 , 717–724.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-ducks","boot","ducks","Behavioral and Plumage Characteristics of Hybrid Ducks",11,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/ducks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/ducks.html","ducks R Documentation    Behavioral and Plumage Characteristics of Hybrid Ducks    Description  
The ducks data frame has 11 rows and 2 columns.   
Each row of the data frame represents a male duck who is a second generation cross of mallard and pintail ducks. For 11 such ducks a behavioural and plumage index were calculated. These were measured on scales devised for this experiment which was to examine whether there was any link between which species the ducks resembled physically and which they resembled in behaviour. The scale for the physical appearance ranged from 0 (identical in appearance to a mallard) to 20 (identical to a pintail). The behavioural traits of the ducks were on a scale from 0 to 15 with lower numbers indicating closer to mallard-like in behaviour.    Usage    ducks    Format  
This data frame contains the following columns:    plumage  
The index of physical appearance based on the plumage of individual ducks.    behaviour  
The index of behavioural characteristics of the ducks.      Source  
The data were obtained from   
Larsen, R.J. and Marx, M.L. (1986) An Introduction to Mathematical Statistics and its Applications (Second Edition). Prentice-Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Sharpe, R.S., and Johnsgard, P.A. (1966) Inheritance of behavioral characters in  F2 mallard x pintail ( Anas Platyrhynchos L. x Anas Acuta L. ) hybrids. Behaviour , 27 , 259-272."
"boot-fir","boot","fir","Counts of Balsam-fir Seedlings",50,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/fir.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/fir.html","fir R Documentation    Counts of Balsam-fir Seedlings    Description  
The fir data frame has 50 rows and 3 columns.   
The number of balsam-fir seedlings in each quadrant of a grid of 50 five foot square quadrants were counted. The grid consisted of 5 rows of 10 quadrants in each row.    Usage    fir    Format  
This data frame contains the following columns:    count  
The number of seedlings in the quadrant.    row  
The row number of the quadrant.   col  
The quadrant number within the row.      Source  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-frets","boot","frets","Head Dimensions in Brothers",25,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/frets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/frets.html","frets R Documentation    Head Dimensions in Brothers    Description  
The frets data frame has 25 rows and 4 columns.   
The data consist of measurements of the length and breadth of the heads of pairs of adult brothers in 25 randomly sampled families. All measurements are expressed in millimetres.    Usage    frets    Format  
This data frame contains the following columns:    l1  
The head length of the eldest son.    b1  
The head breadth of the eldest son.    l2  
The head length of the second son.    b2  
The head breadth of the second son.      Source  
The data were obtained from   
Frets, G.P. (1921) Heredity of head form in man. Genetica , 3 , 193.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Whittaker, J. (1990) Graphical Models in Applied Multivariate Statistics . John Wiley."
"boot-grav","boot","grav","Acceleration Due to Gravity",26,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/grav.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/grav.html","gravity R Documentation    Acceleration Due to Gravity    Description  
The gravity data frame has 81 rows and 2 columns.   
The grav data set has 26 rows and 2 columns.   
Between May 1934 and July 1935, the National Bureau of Standards in Washington D.C. conducted a series of experiments to estimate the acceleration due to gravity, g , at Washington. Each experiment produced a number of replicate estimates of g using the same methodology. Although the basic method remained the same for all experiments, that of the reversible pendulum, there were changes in configuration.   
The gravity data frame contains the data from all eight experiments. The grav data frame contains the data from the experiments 7 and 8. The data are expressed as deviations from 980.000 in centimetres per second squared.    Usage    gravity    Format  
This data frame contains the following columns:    g  
The deviation of the estimate from 980.000 centimetres per second squared.    series  
A factor describing from which experiment the estimate was derived.      Source  
The data were obtained from   
Cressie, N. (1982) Playing safe with misweighted means. Journal of the American Statistical Association , 77 , 754–759.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-gravity","boot","gravity","Acceleration Due to Gravity",81,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/gravity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/gravity.html","gravity R Documentation    Acceleration Due to Gravity    Description  
The gravity data frame has 81 rows and 2 columns.   
The grav data set has 26 rows and 2 columns.   
Between May 1934 and July 1935, the National Bureau of Standards in Washington D.C. conducted a series of experiments to estimate the acceleration due to gravity, g , at Washington. Each experiment produced a number of replicate estimates of g using the same methodology. Although the basic method remained the same for all experiments, that of the reversible pendulum, there were changes in configuration.   
The gravity data frame contains the data from all eight experiments. The grav data frame contains the data from the experiments 7 and 8. The data are expressed as deviations from 980.000 in centimetres per second squared.    Usage    gravity    Format  
This data frame contains the following columns:    g  
The deviation of the estimate from 980.000 centimetres per second squared.    series  
A factor describing from which experiment the estimate was derived.      Source  
The data were obtained from   
Cressie, N. (1982) Playing safe with misweighted means. Journal of the American Statistical Association , 77 , 754–759.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-hirose","boot","hirose","Failure Time of PET Film",44,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/hirose.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/hirose.html","hirose R Documentation    Failure Time of PET Film    Description  
The hirose data frame has 44 rows and 3 columns.   
PET film is used in electrical insulation. In this accelerated life test the failure times for 44 samples in gas insulated transformers. 4 different voltage levels were used.    Usage    hirose    Format  
This data frame contains the following columns:    volt  
The voltage (in kV).    time  
The failure or censoring time in hours.    cens  
The censoring indicator; 1 means right-censored data.      Source  
The data were obtained from   
Hirose, H. (1993) Estimation of threshold stress in accelerated life-testing.  IEEE Transactions on Reliability , 42 , 650–657.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-islay","boot","islay","Jura Quartzite Azimuths on Islay",18,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/islay.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/islay.html","islay R Documentation    Jura Quartzite Azimuths on Islay    Description  
The islay data frame has 18 rows and 1 columns.   
Measurements were taken of paleocurrent azimuths from the Jura Quartzite on the Scottish island of Islay.    Usage    islay    Format  
This data frame contains the following column:    theta  
The angle of the azimuth in degrees East of North.      Source  
The data were obtained from   
Hand, D.J., Daly, F., Lunn, A.D., McConway, K.J. and Ostrowski, E. (1994)  A Handbook of Small Data Sets , Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Till, R. (1974) Statistical Methods for the Earth Scientist . Macmillan."
"boot-manaus","boot","manaus","Average Heights of the Rio Negro river at Manaus",1080,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/manaus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/manaus.html","manaus R Documentation    Average Heights of the Rio Negro river at Manaus    Description  
The manaus time series is of class ""ts"" and has 1080 observations on one variable.   
The data values are monthly averages of the daily stages (heights) of the Rio Negro at Manaus. Manaus is 18km upstream from the confluence of the Rio Negro with the Amazon but because of the tiny slope of the water surface and the lower courses of its flatland affluents, they may be regarded as a good approximation of the water level in the Amazon at the confluence. The data here cover 90 years from January 1903 until December 1992.   
The Manaus gauge is tied in with an arbitrary bench mark of 100m set in the steps of the Municipal Prefecture; gauge readings are usually referred to sea level, on the basis of a mark on the steps leading to the Parish Church (Matriz), which is assumed to lie at an altitude of 35.874 m according to observations made many years ago under the direction of Samuel Pereira, an engineer in charge of the Manaus Sanitation Committee Whereas such an altitude cannot, by any means, be considered to be a precise datum point, observations have been provisionally referred to it. The measurements are in metres.    Source  
The data were kindly made available by Professors H. O'Reilly Sternberg and D. R. Brillinger of the University of California at Berkeley.   References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Sternberg, H. O'R. (1987) Aggravation of floods in the Amazon river as a consequence of deforestation? Geografiska Annaler , 69A , 201-219.   
Sternberg, H. O'R. (1995) Waters and wetlands of Brazilian Amazonia: An uncertain future. In The Fragile Tropics of Latin America: Sustainable Management of Changing Environments , Nishizawa, T. and Uitto, J.I. (editors), United Nations University Press, 113-179."
"boot-melanoma","boot","melanoma","Survival from Malignant Melanoma",205,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/melanoma.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/melanoma.html","melanoma R Documentation    Survival from Malignant Melanoma    Description  
The melanoma data frame has 205 rows and 7 columns.   
The data consist of measurements made on patients with malignant melanoma. Each patient had their tumour removed by surgery at the Department of Plastic Surgery, University Hospital of Odense, Denmark during the period 1962 to 1977. The surgery consisted of complete removal of the tumour together with about 2.5cm of the surrounding skin. Among the measurements taken were the thickness of the tumour and whether it was ulcerated or not. These are thought to be important prognostic variables in that patients with a thick and/or ulcerated tumour have an increased chance of death from melanoma. Patients were followed until the end of 1977.   Usage    melanoma    Format  
This data frame contains the following columns:    time  
Survival time in days since the operation, possibly censored.    status  
The patients status at the end of the study. 1 indicates that they had died from melanoma, 2 indicates that they were still alive and 3 indicates that they had died from causes unrelated to their melanoma.    sex  
The patients sex; 1=male, 0=female.    age  
Age in years at the time of the operation.    year  
Year of operation.    thickness  
Tumour thickness in mm.    ulcer  
Indicator of ulceration; 1=present, 0=absent.      Note  
This dataset is not related to the dataset in the lattice package with the same name.    Source  
The data were obtained from   
Andersen, P.K., Borgan, O., Gill, R.D. and Keiding, N. (1993)  Statistical Models Based on Counting Processes . Springer-Verlag.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Venables, W.N. and Ripley, B.D. (1994) Modern Applied Statistics with S-Plus . Springer-Verlag."
"boot-motor","boot","motor","Data from a Simulated Motorcycle Accident",94,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/motor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/motor.html","motor R Documentation    Data from a Simulated Motorcycle Accident    Description  
The motor data frame has 94 rows and 4 columns. The rows are obtained by removing replicate values of time from the dataset mcycle . Two extra columns are added to allow for strata with a different residual variance in each stratum.    Usage    motor    Format  
This data frame contains the following columns:    times  
The time in milliseconds since impact.    accel  
The recorded head acceleration (in g).    strata  
A numeric column indicating to which of the three strata (numbered 1, 2 and 3) the observations belong.    v  
An estimate of the residual variance for the observation. v is constant within the strata but a different estimate is used for each of the three strata.      Source  
The data were obtained from   
Silverman, B.W. (1985) Some aspects of the spline smoothing approach to non-parametric curve fitting. Journal of the Royal Statistical Society, B , 47 , 1–52.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Venables, W.N. and Ripley, B.D. (1994) Modern Applied Statistics with S-Plus . Springer-Verlag.    See Also  
mcycle"
"boot-neuro","boot","neuro","Neurophysiological Point Process Data",469,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/neuro.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/neuro.html","neuro R Documentation    Neurophysiological Point Process Data    Description  
neuro is a matrix containing times of observed firing of a neuron in windows of 250ms either side of the application of a stimulus to a human subject. Each row of the matrix is a replication of the experiment and there were a total of 469 replicates.    Note  
There are a lot of missing values in the matrix as different numbers of firings were observed in different replicates. The number of firings observed varied from 2 to 6.    Source  
The data were collected and kindly made available by Dr. S.J. Boniface of the Neurophysiology Unit at the Radcliffe Infirmary, Oxford.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Ventura, V., Davison, A.C. and Boniface, S.J. (1997) A stochastic model for the effect of magnetic brain stimulation on a motorneurone. To appear in  Applied Statistics ."
"boot-nitrofen","boot","nitrofen","Toxicity of Nitrofen in Aquatic Systems",50,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/nitrofen.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/nitrofen.html","nitrofen R Documentation    Toxicity of Nitrofen in Aquatic Systems    Description  
The nitrofen data frame has 50 rows and 5 columns.   
Nitrofen is a herbicide that was used extensively for the control of broad-leaved and grass weeds in cereals and rice. Although it is relatively non-toxic to adult mammals, nitrofen is a significant tetragen and mutagen. It is also acutely toxic and reproductively toxic to cladoceran zooplankton. Nitrofen is no longer in commercial use in the U.S., having been the first pesticide to be withdrawn due to tetragenic effects.   
The data here come from an experiment to measure the reproductive toxicity of nitrofen on a species of zooplankton ( Ceriodaphnia dubia ). 50 animals were randomized into batches of 10 and each batch was put in a solution with a measured concentration of nitrofen. Then the number of live offspring in each of the three broods to each animal was recorded.    Usage    nitrofen    Format  
This data frame contains the following columns:    conc  
The nitrofen concentration in the solution (mug/litre).    brood1  
The number of live offspring in the first brood.    brood2  
The number of live offspring in the second brood.    brood3  
The number of live offspring in the third brood.    total  
The total number of live offspring in the first three broods.      Source  
The data were obtained from   
Bailer, A.J. and Oris, J.T. (1994) Assessing toxicity of pollutants in aquatic systems. In Case Studies in Biometry . N. Lange, L. Ryan, L. Billard, D. Brillinger, L. Conquest and J. Greenhouse (editors), 25–40. John Wiley.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-nodal","boot","nodal","Nodal Involvement in Prostate Cancer",53,7,6,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/nodal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/nodal.html","nodal R Documentation    Nodal Involvement in Prostate Cancer    Description  
The nodal data frame has 53 rows and 7 columns.   
The treatment strategy for a patient diagnosed with cancer of the prostate depend highly on whether the cancer has spread to the surrounding lymph nodes. It is common to operate on the patient to get samples from the nodes which can then be analysed under a microscope but clearly it would be preferable if an accurate assessment of nodal involvement could be made without surgery.   
For a sample of 53 prostate cancer patients, a number of possible predictor variables were measured before surgery. The patients then had surgery to determine nodal involvement. It was required to see if nodal involvement could be accurately predicted from the predictor variables and which ones were most important.    Usage    nodal    Format  
This data frame contains the following columns:    m  
A column of ones.    r  
An indicator of nodal involvement.   aged  
The patients age dichotomized into less than 60 ( 0 ) and 60 or over 1 .    stage  
A measurement of the size and position of the tumour observed by palpitation with the fingers via the rectum. A value of 1 indicates a more serious case of the cancer.    grade  
Another indicator of the seriousness of the cancer, this one is determined by a pathology reading of a biopsy taken by needle before surgery. A value of 1 indicates a more serious case of the cancer.    xray  
A third measure of the seriousness of the cancer taken from an X-ray reading. A value of 1 indicates a more serious case of the cancer.    acid  
The level of acid phosphatase in the blood serum.      Source  
The data were obtained from   
Brown, B.W. (1980) Prediction analysis for binary data. In Biostatistics Casebook . R.G. Miller, B. Efron, B.W. Brown and L.E. Moses (editors), 3–18. John Wiley.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-nuclear","boot","nuclear","Nuclear Power Station Construction Data",32,11,5,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/nuclear.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/nuclear.html","nuclear R Documentation    Nuclear Power Station Construction Data    Description  
The nuclear data frame has 32 rows and 11 columns.   
The data relate to the construction of 32 light water reactor (LWR) plants constructed in the U.S.A in the late 1960's and early 1970's. The data was collected with the aim of predicting the cost of construction of further LWR plants. 6 of the power plants had partial turnkey guarantees and it is possible that, for these plants, some manufacturers' subsidies may be hidden in the quoted capital costs.    Usage    nuclear    Format  
This data frame contains the following columns:    cost  
The capital cost of construction in millions of dollars adjusted to 1976 base.    date  
The date on which the construction permit was issued. The data are measured in years since January 1 1990 to the nearest month.    t1  
The time between application for and issue of the construction permit.    t2  
The time between issue of operating license and construction permit.    cap  
The net capacity of the power plant (MWe).    pr  
A binary variable where 1 indicates the prior existence of a LWR plant at the same site.    ne  
A binary variable where 1 indicates that the plant was constructed in the north-east region of the U.S.A.    ct  
A binary variable where 1 indicates the use of a cooling tower in the plant.    bw  
A binary variable where 1 indicates that the nuclear steam supply system was manufactured by Babcock-Wilcox.    cum.n  
The cumulative number of power plants constructed by each architect-engineer.    pt  
A binary variable where 1 indicates those plants with partial turnkey guarantees.      Source  
The data were obtained from   
Cox, D.R. and Snell, E.J. (1981) Applied Statistics: Principles and Examples . Chapman and Hall.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-paulsen","boot","paulsen","Neurotransmission in Guinea Pig Brains",346,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/paulsen.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/paulsen.html","paulsen R Documentation    Neurotransmission in Guinea Pig Brains    Description  
The paulsen data frame has 346 rows and 1 columns.  
Sections were prepared from the brain of adult guinea pigs. Spontaneous currents that flowed into individual brain cells were then recorded and the peak amplitude of each current measured. The aim of the experiment was to see if the current flow was quantal in nature (i.e. that it is not a single burst but instead is built up of many smaller bursts of current). If the current was indeed quantal then it would be expected that the distribution of the current amplitude would be multimodal with modes at regular intervals. The modes would be expected to decrease in magnitude for higher current amplitudes.    Usage    paulsen    Format  
This data frame contains the following column:    y  
The current flowing into individual brain cells. The currents are measured in pico-amperes.      Source  
The data were kindly made available by Dr. O. Paulsen from the Department of Pharmacology at the University of Oxford.  
Paulsen, O. and Heggelund, P. (1994) The quantal size at retinogeniculate synapses determined from spontaneous and evoked EPSCs in guinea-pig thalamic slices. Journal of Physiology , 480 , 505–511.   References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-poisons","boot","poisons","Animal Survival Times",48,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/poisons.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/poisons.html","poisons R Documentation    Animal Survival Times    Description  
The poisons data frame has 48 rows and 3 columns.   
The data form a 3x4 factorial experiment, the factors being three poisons and four treatments. Each combination of the two factors was used for four animals, the allocation to animals having been completely randomized.    Usage    poisons    Format  
This data frame contains the following columns:    time  
The survival time of the animal in units of 10 hours.    poison  
A factor with levels 1 , 2 and 3 giving the type of poison used.    treat  
A factor with levels A , B , C and D giving the treatment.      Source  
The data were obtained from   
Box, G.E.P. and Cox, D.R. (1964) An analysis of transformations (with Discussion). Journal of the Royal Statistical Society, B , 26 , 211–252.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-polar","boot","polar","Pole Positions of New Caledonian Laterites",50,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/polar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/polar.html","polar R Documentation    Pole Positions of New Caledonian Laterites    Description  
The polar data frame has 50 rows and 2 columns.   
The data are the pole positions from a paleomagnetic study of New Caledonian laterites.    Usage    polar    Format  
This data frame contains the following columns:    lat  
The latitude (in degrees) of the pole position. Note that all latitudes are negative as the axis is taken to be in the lower hemisphere.    long  
The longitude (in degrees) of the pole position.      Source  
The data were obtained from   
Fisher, N.I., Lewis, T. and Embleton, B.J.J. (1987) Statistical Analysis of Spherical Data . Cambridge University Press.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-remission","boot","remission","Cancer Remission and Cell Activity",27,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/remission.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/remission.html","remission R Documentation    Cancer Remission and Cell Activity    Description  
The remission data frame has 27 rows and 3 columns.    Usage    remission    Format  
This data frame contains the following columns:    LI  
A measure of cell activity.    m  
The number of patients in each group (all values are actually 1 here).    r  
The number of patients (out of m ) who went into remission.      Source  
The data were obtained from   
Freeman, D.H. (1987) Applied Categorical Data Analysis . Marcel Dekker.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-salinity","boot","salinity","Water Salinity and River Discharge",28,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/salinity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/salinity.html","salinity R Documentation    Water Salinity and River Discharge    Description  
The salinity data frame has 28 rows and 4 columns.   
Biweekly averages of the water salinity and river discharge in Pamlico Sound, North Carolina were recorded between the years 1972 and 1977. The data in this set consists only of those measurements in March, April and May.    Usage    salinity    Format  
This data frame contains the following columns:    sal  
The average salinity of the water over two weeks.    lag  
The average salinity of the water lagged two weeks. Since only spring is used, the value of lag is not always equal to the previous value of sal .    trend  
A factor indicating in which of the 6 biweekly periods between March and May, the observations were taken. The levels of the factor are from 0 to 5 with 0 being the first two weeks in March.    dis  
The amount of river discharge during the two weeks for which sal is the average salinity.      Source  
The data were obtained from   
Ruppert, D. and Carroll, R.J. (1980) Trimmed least squares estimation in the linear model. Journal of the American Statistical Association , 75 , 828–838.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-survival","boot","survival","Survival of Rats after Radiation Doses",14,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/survival.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/survival.html","survival R Documentation    Survival of Rats after Radiation Doses    Description  
The survival data frame has 14 rows and 2 columns.   
The data measured the survival percentages of batches of rats who were given varying doses of radiation. At each of 6 doses there were two or three replications of the experiment.    Usage    survival    Format  
This data frame contains the following columns:    dose  
The dose of radiation administered (rads).    surv  
The survival rate of the batches expressed as a percentage.      Source  
The data were obtained from   
Efron, B. (1988) Computer-intensive methods in statistical regression.  SIAM Review , 30 , 421–449.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-tau","boot","tau","Tau Particle Decay Modes",60,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/tau.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/tau.html","tau R Documentation    Tau Particle Decay Modes    Description  
The tau data frame has 60 rows and 2 columns.   
The tau particle is a heavy electron-like particle discovered in the 1970's by Martin Perl at the Stanford Linear Accelerator Center. Soon after its production the tau particle decays into various collections of more stable particles. About 86% of the time the decay involves just one charged particle. This rate has been measured independently 13 times.  
The one-charged-particle event is made up of four major modes of decay as well as a collection of other events. The four main types of decay are denoted rho, pi, e and mu. These rates have been measured independently 6, 7, 14 and 19 times respectively. Due to physical constraints each experiment can only estimate the composite one-charged-particle decay rate or the rate of one of the major modes of decay.  
Each experiment consists of a major research project involving many years work. One of the goals of the experiments was to estimate the rate of decay due to events other than the four main modes of decay. These are uncertain events and so cannot themselves be observed directly.    Usage    tau    Format  
This data frame contains the following columns:    rate  
The decay rate expressed as a percentage.    decay  
The type of decay measured in the experiment. It is a factor with levels  1 , rho , pi , e and mu .      Source  
The data were obtained from   
Efron, B. (1992) Jackknife-after-bootstrap standard errors and influence functions (with Discussion). Journal of the Royal Statistical Society, B , 54 , 83–127.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press.   
Hayes, K.G., Perl, M.L. and Efron, B. (1989) Application of the bootstrap statistical method to the tau-decay-mode problem. Physical Review, D , 39 , 274-279."
"boot-tuna","boot","tuna","Tuna Sighting Data",64,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/tuna.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/tuna.html","tuna R Documentation    Tuna Sighting Data    Description  
The tuna data frame has 64 rows and 1 columns.  
The data come from an aerial line transect survey of Southern Bluefin Tuna in the Great Australian Bight. An aircraft with two spotters on board flies randomly allocated line transects. Each school of tuna sighted is counted and its perpendicular distance from the transect measured. The survey was conducted in summer when tuna tend to stay on the surface.    Usage    tuna    Format  
This data frame contains the following column:    y  
The perpendicular distance, in miles, from the transect for 64 independent sightings of tuna schools.      Source  
The data were obtained from   
Chen, S.X. (1996) Empirical likelihood confidence intervals for nonparametric density estimation. Biometrika , 83 , 329–341.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-urine","boot","urine","Urine Analysis Data",79,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/urine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/urine.html","urine R Documentation    Urine Analysis Data    Description  
The urine data frame has 79 rows and 7 columns.   
79 urine specimens were analyzed in an effort to determine if certain physical characteristics of the urine might be related to the formation of calcium oxalate crystals.   Usage    urine    Format  
This data frame contains the following columns:    r  
Indicator of the presence of calcium oxalate crystals.    gravity  
The specific gravity of the urine.    ph  
The pH reading of the urine.    osmo  
The osmolarity of the urine. Osmolarity is proportional to the concentration of molecules in solution.    cond  
The conductivity of the urine. Conductivity is proportional to the concentration of charged ions in solution.    urea  
The urea concentration in millimoles per litre.    calc  
The calcium concentration in millimoles per litre.      Source  
The data were obtained from   
Andrews, D.F. and Herzberg, A.M. (1985) Data: A Collection of Problems from Many Fields for the Student and Research Worker . Springer-Verlag.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"boot-wool","boot","wool","Australian Relative Wool Prices",309,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/boot/wool.csv","https://vincentarelbundock.github.io/Rdatasets/doc/boot/wool.html","wool R Documentation    Australian Relative Wool Prices    Description  
wool is a time series of class ""ts"" and contains 309 observations.   
Each week that the market is open the Australian Wool Corporation set a floor price which determines their policy on intervention and is therefore a reflection of the overall price of wool for the week in question. Actual prices paid can vary considerably about the floor price. The series here is the log of the ratio between the price for fine grade wool and the floor price, each market week between July 1976 and Jun 1984.    Source  
The data were obtained from   
Diggle, P.J. (1990) Time Series: A Biostatistical Introduction . Oxford University Press.    References  
Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application . Cambridge University Press."
"carData-Adler","carData","Adler","Experimenter Expectations",108,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Adler.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Adler.html","Adler R Documentation   Experimenter Expectations   Description  
The Adler data frame has 108 rows and 3 columns.  
The “experimenters” were the actual subjects of the study. They collected ratings of the apparent success of people in pictures who were pre-selected for their average appearance of success. The experimenters were told prior to collecting data that particular subjects were either high or low in their tendency to rate appearance of success, and were instructed to get good data, scientific data, or were given no such instruction. Each experimenter collected ratings from 18 randomly assigned subjects. This version of the Adler data is taken from Erickson and Nosanchuk (1977). The data described in the original source, Adler (1973), have a more complex structure.    Usage    Adler    Format  
This data frame contains the following columns:    instruction  
a factor with levels:  good , good data;  none , no stress;  scientific , scientific data.    expectation  
a factor with levels:  high , expect high ratings;  low , expect low ratings.    rating  
The average rating obtained.     Source  
Erickson, B. H., and Nosanchuk, T. A. (1977)  Understanding Data. McGraw-Hill Ryerson.    References  
Adler, N. E. (1973) Impact of prior sets given experimenters and subjects on the experimenter expectancy effect.  Sociometry 36 , 113–126."
"carData-AMSsurvey","carData","AMSsurvey","American Math Society Survey Data",24,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/AMSsurvey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/AMSsurvey.html","AMSsurvey R Documentation    American Math Society Survey Data    Description  
Counts of new PhDs in the mathematical sciences for 2008-09 and 2011-12 categorized by type of institution, gender, and US citizenship status.    Usage   AMSsurvey   Format  
A data frame with 24 observations on the following 5 variables.    type
a factor with levels I(Pu) for group I public universities, I(Pr) for group I private universities, II  and III for groups II and III, IV for statistics and biostatistics programs, and Va for applied mathemeatics programs.   sex
a factor with levels Female , Male of the recipient   citizen
a factor with levels Non-US , US giving citizenship status   count
The number of individuals of each type in 2008-09   count11
The number of individuals of each type in 2011-12     Details  
These data are produced yearly by the American Math Society.    Source  
http://www.ams.org/employment/surveyreports.html  Supplementary Table 4 in the 2008-09 data. See http://www.ams.org/profession/data/annual-survey/docsgrtd for more recent data.    References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Phipps, Polly, Maxwell, James W. and Rose, Colleen (2009), 2009 Annual Survey of the Mathematical Sciences , 57, 250–259, Supplementary Table 4, orginally downloaded from http://www.ams.org/employment/2009Survey-First-Report-Supp-Table4.pdf"
"carData-Angell","carData","Angell","Moral Integration of American Cities",43,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Angell.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Angell.html","Angell R Documentation   Moral Integration of American Cities   Description  
The Angell data frame has 43 rows and 4 columns. The observations are 43 U. S. cities around 1950.    Usage    Angell    Format  
This data frame contains the following columns:    moral  
Moral Integration: Composite of crime rate and welfare expenditures.    hetero  
Ethnic Heterogenity: From percentages of nonwhite and foreign-born white residents.    mobility  
Geographic Mobility: From percentages of residents moving into and out of the city.    region  
A factor with levels: E Northeast;  MW Midwest;  S Southeast;  W West.      Source  
Angell, R. C. (1951) The moral integration of American Cities.  American Journal of Sociology 57 (part 2), 1–140.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Anscombe","carData","Anscombe","U. S. State Public-School Expenditures",51,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Anscombe.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Anscombe.html","Anscombe R Documentation   U. S. State Public-School Expenditures   Description  
The Anscombe data frame has 51 rows and 4 columns. The observations are the U. S. states plus Washington, D. C. in 1970.    Usage    Anscombe    Format  
This data frame contains the following columns:    education  
Per-capita education expenditures, dollars.    income  
Per-capita income, dollars.   young  
Proportion under 18, per 1000.   urban  
Proportion urban, per 1000.     Source  
Anscombe, F. J. (1981)  Computing in Statistical Science Through APL . Springer-Verlag.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Arrests","carData","Arrests","Arrests for Marijuana Possession",5226,8,5,0,5,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Arrests.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Arrests.html","Arrests R Documentation   Arrests for Marijuana Possession   Description  
Data on police treatment of individuals arrested in Toronto for simple possession of small quantities of marijuana. The data are part of a larger data set featured in a series of articles in the Toronto Star newspaper.    Usage   Arrests   Format  
A data frame with 5226 observations on the following 8 variables.    released
Whether or not the arrestee was released with a summons; a factor with levels:  No ;  Yes .   colour
The arrestee's race; a factor with levels:  Black ; White .   year
1997 through 2002; a numeric vector.   age
in years; a numeric vector.   sex
a factor with levels:  Female ;  Male .   employed
a factor with levels:  No ;  Yes .   citizen
a factor with levels:  No ;  Yes .   checks
Number of police data bases (of previous arrests, previous convictions, parole status, etc. – 6 in all) on which the arrestee's name appeared; a numeric vector     Source  
Personal communication from Michael Friendly, York University.    Examples    summary(Arrests)"
"carData-Baumann","carData","Baumann","Methods of Teaching Reading Comprehension",66,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Baumann.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Baumann.html","Baumann R Documentation   Methods of Teaching Reading Comprehension   Description  
The Baumann data frame has 66 rows and 6 columns. The data are from an experimental study conducted by Baumann and Jones, as reported by Moore and McCabe (1993) Students were randomly assigned to one of three experimental groups.    Usage    Baumann    Format  
This data frame contains the following columns:    group 
Experimental group; a factor with levels:  Basal , traditional method of teaching;  DRTA , an innovative method;  Strat , another innovative method.    pretest.1  
First pretest.    pretest.2  
Second pretest.    post.test.1  
First post-test.    post.test.2  
Second post-test.    post.test.3  
Third post-test.      Source  
Moore, D. S. and McCabe, G. P. (1993)  Introduction to the Practice of Statistics, Second Edition.  Freeman, p. 794–795.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-BEPS","carData","BEPS","British Election Panel Study",1525,10,1,0,2,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/BEPS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/BEPS.html","BEPS R Documentation   British Election Panel Study   Description  
These data are drawn from the 1997-2001 British Election Panel Study (BEPS).    Usage   BEPS   Format  
A data frame with 1525 observations on the following 10 variables.    vote
Party choice: Conservative , Labour , or Liberal Democrat   age
in years   economic.cond.national
Assessment of current national economic conditions, 1 to 5.   economic.cond.household
Assessment of current household economic conditions, 1 to 5.   Blair
Assessment of the Labour leader, 1 to 5.   Hague
Assessment of the Conservative leader, 1 to 5.   Kennedy
Assessment of the leader of the Liberal Democrats, 1 to 5.   Europe
an 11-point scale that measures respondents' attitudes toward European integration. High scores represent ‘Eurosceptic’ sentiment.   political.knowledge
Knowledge of parties' positions on European integration, 0 to 3.   gender
female or male .     References  
J. Fox and R. Andersen (2006) Effect displays for multinomial and proportional-odds logit models.  Sociological Methodology 36 , 225–255.    Examples    summary(BEPS)"
"carData-Bfox","carData","Bfox","Canadian Women's Labour-Force Participation",30,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Bfox.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Bfox.html","Bfox R Documentation   Canadian Women's Labour-Force Participation   Description  
The Bfox data frame has 30 rows and 7 columns. Time-series data on Canadian women's labor-force participation, 1946–1975.    Usage    Bfox    Format  
This data frame contains the following columns:    partic  
Percent of adult women in the workforce.    tfr  
Total fertility rate: expected births to a cohort of 1000 women at current age-specific fertility rates.    menwage  
Men's average weekly wages, in constant 1935 dollars and adjusted for current tax rates.    womwage  
Women's average weekly wages.    debt  
Per-capita consumer debt, in constant dollars.    parttime  
Percent of the active workforce working 34 hours per week or less.      Warning  
The value of tfr for 1973 is misrecorded as 2931; it should be 1931.    Source  
Fox, B. (1980) Women's Domestic Labour and their Involvement in Wage Work. Unpublished doctoral dissertation, p. 449.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Blackmore","carData","Blackmore","Exercise Histories of Eating-Disordered and Control Subjects",945,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Blackmore.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Blackmore.html","Blackmore R Documentation   Exercise Histories of Eating-Disordered and Control Subjects   Description  
The Blackmore data frame has 945 rows and 4 columns. Blackmore and Davis's data on exercise histories of 138 teenaged girls hospitalized for eating disorders and 98 control subjects.    Usage   Blackmore   Format  
This data frame contains the following columns:    subject
a factor with subject id codes. There are several observations for each subject, but because the girls were hospitalized at different ages, the number of cases and the age at the last case vary.   age
subject's age in years at the time of observation; all but the last observation for each subject were collected retrospectively at intervals of two years, starting at age 8.   exercise
the amount of exercise in which the subject engaged, expressed as estimated hours per week.   group
a factor with levels:  control , Control subjects;  patient , Eating-disordered patients.      Source  
Personal communication from Elizabeth Blackmore and Caroline Davis, York University."
"carData-Burt","carData","Burt","Fraudulent Data on IQs of Twins Raised Apart",27,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Burt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Burt.html","Burt R Documentation   Fraudulent Data on IQs of Twins Raised Apart   Description  
The Burt data frame has 27 rows and 4 columns. The “data” were simply (and notoriously) manufactured. The same data are in the dataset “twins"" in the alr3  package, but with different labels.    Usage    Burt    Format  
This data frame contains the following columns:    IQbio  
IQ of twin raised by biological parents    IQfoster  
IQ of twin raised by foster parents    class  
A factor with levels (note: out of order):  high ;  low ;  medium .      Source  
Burt, C. (1966) The genetic determination of differences in intelligence: A study of monozygotic twins reared together and apart. British Journal of Psychology 57 , 137–153."
"carData-CanPop","carData","CanPop","Canadian Population Data",16,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/CanPop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/CanPop.html","CanPop R Documentation   Canadian Population Data   Description  
The CanPop data frame has 16 rows and 2 columns. Decennial time-series of Canadian population, 1851–2001.    Usage    CanPop    Format  
This data frame contains the following columns:    year  
census year.    population  
Population, in millions      Source  
Urquhart, M. C. and Buckley, K. A. H. (Eds.) (1965)  Historical Statistics of Canada . Macmillan, p. 1369.   
Canada (1994)  Canada Year Book . Statistics Canada, Table 3.2.   
Statistics Canada:  http://www12.statcan.ca/english/census01/products/standard/popdwell/Table-PR.cfm .    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-CES11","carData","CES11","2011 Canadian National Election Study, With Attitude Toward Abortion",2231,9,3,0,6,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/CES11.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/CES11.html","CES11 R Documentation    2011 Canadian National Election Study, With Attitude Toward Abortion   Description  
Data are drawn from the 2011 Canadian National Election Study, including a question on banning abortion and variables related to the sampling design.   Usage   data(""CES11"")   Format  
A data frame with 2231 observations on the following 9 variables.    id
Household ID number.   province
a factor with (alphabetical) levels AB , BC , MB , NB , NL , NS , ON , PE , QC , SK ; the sample was stratified by province.   population
population of the respondent's province, number over age 17.   weight
weight sample to size of population, taking into account unequal sampling probabilities by province and household size.   gender
a factor with levels Female , Male .   abortion
attitude toward abortion, a factor with levels No , Yes ; answer to the question ""Should abortion be banned?""   importance
importance of religion, a factor with (alphabetical) levels not , notvery , somewhat , very ; answer to the question, ""In your life, would you say that religion is very important, somewhat important, not very important, or not important at all?""   education
a factor with (alphabetical) levels bachelors (Bachelors degree), college (community college or technical school), higher (graduate degree), HS (high-school graduate), lessHS (less than high-school graduate), somePS (some post-secondary).   urban
place of residence, a factor with levels rural , urban .     Details  
This is an extract from the data set for the 2011 Canadian National Election Study distributed by the Institute for Social Research, York University.    References  
Fournier, P., Cutler, F., Soroka, S., and Stolle, D. (2013). Canadian Election Study 2011: Study documentation. Technical report, Canadian Opinion Research Archive, Queen's University, Kingson,Ontario.   
Northrup, D. (2012). The 2011 Canadian Election Survey: Technical documention. Technical report, Institute for Social Research, York University, Toronto, Ontario.    Examples    summary(CES11)"
"carData-Chile","carData","Chile","Voting Intentions in the 1988 Chilean Plebiscite",2700,8,1,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Chile.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Chile.html","Chile R Documentation   Voting Intentions in the 1988 Chilean Plebiscite   Description  
The Chile data frame has 2700 rows and 8 columns. The data are from a national survey conducted in April and May of 1988 by FLACSO/Chile. There are some missing data.    Usage    Chile    Format  
This data frame contains the following columns:    region  
A factor with levels:  C , Central;  M , Metropolitan Santiago area;  N , North;  S , South;  SA , city of Santiago.    population  
Population size of respondent's community.    sex  
A factor with levels:  F , female;  M , male.    age  
in years.    education  
A factor with levels (note: out of order):  P , Primary;  PS , Post-secondary;  S , Secondary.    income  
Monthly income, in Pesos.    statusquo  
Scale of support for the status-quo.    vote  
a factor with levels:  A , will abstain; N , will vote no (against Pinochet);  U , undecided;  Y , will vote yes (for Pinochet).      Source  
Personal communication from FLACSO/Chile.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Chirot","carData","Chirot","The 1907 Romanian Peasant Rebellion",32,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Chirot.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Chirot.html","Chirot R Documentation   The 1907 Romanian Peasant Rebellion   Description  
The Chirot data frame has 32 rows and 5 columns. The observations are counties in Romania.    Usage    Chirot    Format  
This data frame contains the following columns:    intensity  
Intensity of the rebellion    commerce  
Commercialization of agriculture    tradition  
Traditionalism    midpeasant  
Strength of middle peasantry    inequality  
Inequality of land tenure      Source  
Chirot, D. and C. Ragin (1975) The market, tradition and peasant rebellion: The case of Romania.  American Sociological Review 40 , 428–444 [Table 1].    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Cowles","carData","Cowles","Cowles and Davis's Data on Volunteering",1421,4,2,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Cowles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Cowles.html","Cowles R Documentation   Cowles and Davis's Data on Volunteering   Description  
The Cowles data frame has 1421 rows and 4 columns. These data come from a study of the personality determinants of volunteering for psychological research.    Usage   Cowles   Format  
This data frame contains the following columns:    neuroticism
scale from Eysenck personality inventory   extraversion
scale from Eysenck personality inventory   sex
a factor with levels: female ; male   volunteer
volunteeing, a factor with levels: no ; yes     Source  
Cowles, M. and C. Davis (1987) The subject matter of psychology: Volunteers.  British Journal of Social Psychology 26 , 97–102."
"carData-Davis","carData","Davis","Self-Reports of Height and Weight",200,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Davis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Davis.html","Davis R Documentation   Self-Reports of Height and Weight   Description  
The Davis data frame has 200 rows and 5 columns. The subjects were men and women engaged in regular exercise. There are some missing data.    Usage    Davis    Format  
This data frame contains the following columns:    sex  
A factor with levels:  F , female;  M , male.    weight  
Measured weight in kg.   height  
Measured height in cm.   repwt  
Reported weight in kg.   repht  
Reported height in cm.     Source  
Personal communication from C. Davis, Departments of Physical Education and Psychology, York University.    References  
Davis, C. (1990) Body image and weight preoccupation: A comparison between exercising and non-exercising women.  Appetite , 15 , 13–21.   
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-DavisThin","carData","DavisThin","Davis's Data on Drive for Thinness",191,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/DavisThin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/DavisThin.html","DavisThin R Documentation   Davis's Data on Drive for Thinness   Description  
The DavisThin data frame has 191 rows and 7 columns. This is part of a larger dataset for a study of eating disorders. The seven variables in the data frame comprise a ""drive for thinness"" scale, to be formed by summing the items.    Usage   DavisThin   Format  
This data frame contains the following columns:    DT1
a numeric vector   DT2
a numeric vector   DT3
a numeric vector   DT4
a numeric vector   DT5
a numeric vector   DT6
a numeric vector   DT7
a numeric vector     Source  
Davis, C., G. Claridge, and D. Cerullo (1997) Personality factors predisposing to weight preoccupation: A continuum approach to the association between eating disorders and personality disorders. Journal of Psychiatric Research 31 , 467–480. [personal communication from the authors.]    References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Depredations","carData","Depredations","Minnesota Wolf Depredation Data",434,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Depredations.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Depredations.html","Depredations R Documentation    Minnesota Wolf Depredation Data    Description  
Wolf depredations of livestock on Minnesota farms, 1976-1998.    Usage   Depredations   Format  
A data frame with 434 observations on the following 5 variables.    longitude
longitude of the farm   latitude
latitude of the farm   number
number of depredations 1976-1998   early
number of depredations 1991 or before   late
number of depredations 1992 or later     References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Harper, Elizabeth K. and Paul, William J. and Mech, L. David and Weisberg, Sanford (2008), Effectiveness of Lethal, Directed Wolf-Depredation Control in Minnesota,  Journal of Wildlife Management , 72, 3, 778-784.  http://dx.doi.org/10.2193/2007-273"
"carData-Duncan","carData","Duncan","Duncan's Occupational Prestige Data",45,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Duncan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Duncan.html","Duncan R Documentation   Duncan's Occupational Prestige Data   Description  
The Duncan data frame has 45 rows and 4 columns. Data on the prestige and other characteristics of 45 U. S. occupations in 1950.    Usage    Duncan    Format  
This data frame contains the following columns:    type
Type of occupation. A factor with the following levels:  prof , professional and managerial;  wc , white-collar;  bc , blue-collar.    income
Percentage of occupational incumbents in the 1950 US Census who earned $3,500 or more per year (about $36,000 in 2017 US dollars).   education
Percentage of occupational incumbents in 1950 who were high school graduates (which, were we cynical, we would say is roughly equivalent to a PhD in 2017)    prestige
Percentage of respondents in a social survey who rated the occupation as “good” or better in prestige     Source  
Duncan, O. D. (1961) A socioeconomic index for all occupations. In Reiss, A. J., Jr. (Ed.)  Occupations and Social Status. Free Press [Table VI-1].    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.   
Fox, J. and Weisberg, S. (2019)  An R Companion to Applied Regression , Third Edition, Sage."
"carData-Ericksen","carData","Ericksen","The 1980 U.S. Census Undercount",66,9,1,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Ericksen.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Ericksen.html","Ericksen R Documentation   The 1980 U.S. Census Undercount   Description  
The Ericksen data frame has 66 rows and 9 columns. The observations are 16 large cities, the remaining parts of the states in which these cities are located, and the other U. S. states.    Usage    Ericksen    Format  
This data frame contains the following columns:    minority  
Percentage black or Hispanic.    crime  
Rate of serious crimes per 1000 population.    poverty  
Percentage poor.    language  
Percentage having difficulty speaking or writing English.    highschool  
Percentage age 25 or older who had not finished highschool.    housing  
Percentage of housing in small, multiunit buildings.    city
A factor with levels: city , major city; state , state or state-remainder.    conventional  
Percentage of households counted by conventional personal enumeration.    undercount  
Preliminary estimate of percentage undercount.      Source  
Ericksen, E. P., Kadane, J. B. and Tukey, J. W. (1989) Adjusting the 1980 Census of Population and Housing. Journal of the American Statistical Association 84 , 927–944 [Tables 7 and 8].    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Florida","carData","Florida","Florida County Voting",67,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Florida.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Florida.html","Florida R Documentation   Florida County Voting   Description  
The Florida data frame has 67 rows and 11 columns. Vote by county in Florida for President in the 2000 election.    Usage    Florida    Format  
This data frame contains the following columns:    GORE  
Number of votes for Gore    BUSH  
Number of votes for Bush.    BUCHANAN  
Number of votes for Buchanan.    NADER  
Number of votes for Nader.    BROWNE  
Number of votes for Browne (whoever that is).    HAGELIN  
Number of votes for Hagelin (whoever that is).    HARRIS  
Number of votes for Harris (whoever that is).    MCREYNOLDS  
Number of votes for McReynolds (whoever that is).    MOOREHEAD  
Number of votes for Moorehead (whoever that is).    PHILLIPS  
Number of votes for Phillips (whoever that is).    Total  
Total number of votes.      Source  
Adams, G. D. and Fastnow, C. F. (2000) A note on the voting irregularities in Palm Beach, FL. Formerly at http://madison.hss.cmu.edu/ , but no longer available there."
"carData-Freedman","carData","Freedman","Crowding and Crime in U. S. Metropolitan Areas",110,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Freedman.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Freedman.html","Freedman R Documentation   Crowding and Crime in U. S. Metropolitan Areas   Description  
The Freedman data frame has 110 rows and 4 columns. The observations are U. S. metropolitan areas with 1968 populations of 250,000 or more. There are some missing data.    Usage    Freedman    Format  
This data frame contains the following columns:    population  
Total 1968 population, 1000s.    nonwhite  
Percent nonwhite population, 1960.    density  
Population per square mile, 1968.    crime  
Crime rate per 100,000, 1969.      Source  
United States (1970)  Statistical Abstract of the United States . Bureau of the Census.    References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Freedman, J. (1975)  Crowding and Behavior. Viking."
"carData-Friendly","carData","Friendly","Format Effects on Recall",30,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Friendly.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Friendly.html","Friendly R Documentation   Format Effects on Recall   Description  
The Friendly data frame has 30 rows and 2 columns. The data are from an experiment on subjects' ability to remember words based on the presentation format.    Usage    Friendly    Format  
This data frame contains the following columns:    condition  
A factor with levels:  Before , Recalled words presented before others;  Meshed , Recalled words meshed with others; SFR , Standard free recall.    correct  
Number of words correctly recalled, out of 40 on final trial of the experiment.      Source  
Friendly, M. and Franklin, P. (1980) Interactive presentation in multitrial free recall. Memory and Cognition   8 265–270 [Personal communication from M. Friendly].    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Ginzberg","carData","Ginzberg","Data on Depression",82,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Ginzberg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Ginzberg.html","Ginzberg R Documentation   Data on Depression   Description  
The Ginzberg data frame has 82 rows and 6 columns. The data are for psychiatric patients hospitalized for depression.    Usage    Ginzberg    Format  
This data frame contains the following columns:    simplicity  
Measures subject's need to see the world in black and white.    fatalism  
Fatalism scale.    depression  
Beck self-report depression scale.    adjsimp  
Adjusted Simplicity: Simplicity adjusted (by regression) for other variables thought to influence depression.    adjfatal  
Adjusted Fatalism.    adjdep  
Adjusted Depression.      Source  
Personal communication from Georges Monette, Department of Mathematics and Statistics, York University, with the permission of the original investigator.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Greene","carData","Greene","Refugee Appeals",384,7,3,0,6,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Greene.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Greene.html","Greene R Documentation   Refugee Appeals   Description  
The Greene data frame has 384 rows and 7 columns. These are cases filed in 1990, in which refugee claimants rejected by the Canadian Immigration and Refugee Board asked the Federal Court of Appeal for leave to appeal the negative ruling of the Board.    Usage    Greene    Format  
This data frame contains the following columns:    judge  
Name of judge hearing case. A factor with levels:  Desjardins , Heald , Hugessen , Iacobucci , MacGuigan , Mahoney , Marceau , Pratte , Stone , Urie .   nation  
Nation of origin of claimant. A factor with levels:  Argentina , Bulgaria , China , Czechoslovakia ,  El.Salvador , Fiji , Ghana , Guatemala , India , Iran , Lebanon , Nicaragua , Nigeria , Pakistan , Poland , Somalia , Sri.Lanka .    rater  
Judgment of independent rater. A factor with levels:  no , case has no merit;  yes , case has some merit (leave to appeal should be granted).    decision  
Judge's decision. A factor with levels:  no , leave to appeal not granted;  yes , leave to appeal granted.    language  
Language of case. A factor with levels:  English ,  French .    location  
Location of original refugee claim. A factor with levels:  Montreal ,  other ,  Toronto .    success  
Logit of success rate, for all cases from the applicant's nation.      Source  
Personal communication from Ian Greene, Department of Political Science, York University.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-GSSvocab","carData","GSSvocab","Data from the General Social Survey (GSS) from the National Opinion Research Center of the University of Chicago.",28867,8,2,0,5,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/GSSvocab.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/GSSvocab.html","GSSvocab R Documentation    Data from the General Social Survey (GSS) from the National Opinion Research Center of the University of Chicago.    Description  
This data set illustrates analyis of a multifactor observational study, with response given by subject's score on a vocabulary test, and factors for age group, education level, natality status, gender and year of the survey.    Usage   data(""GSSvocab"")   Format  
A data frame with 28867 observations on the following 8 variables.    year
a factor with levels 1978 1982 1984 1987 1988 1989 1990 1991 1993 1994 1996 1998 2000 2004 2006 2008 2010 2012 2014 2016 . Data are included from the GSS for each of these years.   gender
a factor with levels female male   nativeBorn
Was the respondent born in the US? A factor with levels no and yes .   ageGroup
a factor with levels 18-29 30-39 40-49 50-59 60+ , grouped age of the respondent.   educGroup
a factor with levels <12 yrs 12 yrs 13-15 yrs 16 yrs >16 yrs , grouped education level of the respondent. 12 years corresponds to high school graduate, 16 years to college graduate.   vocab
Number of words out of 10 correct on a vocabulary test   age
age of the respondent in years   educ
years of education of the respondent     Details  
This file includes the years of the GSS for which the vocab and nativeBorn items were included.    Source  
These data were collected from the GSS data explorer https://gssdataexplorer.norc.org , using the data fields year , id_ , age , educ , sex , born and wordsum . The GSS began in 1972, and has included several thousand data items, some regularly and some only once, on topics of interest to social scientists. Data have been slightly edited to change entires like No answer and Not applicable to missing value codes.    Examples    data(GSSvocab)"
"carData-Guyer","carData","Guyer","Anonymity and Cooperation",20,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Guyer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Guyer.html","Guyer R Documentation   Anonymity and Cooperation   Description  
The Guyer data frame has 20 rows and 3 columns. The data are from an experiment in which four-person groups played a prisoner's dilemma game for 30 trails, each person making either a cooperative or competitive choice on each trial. Choices were made either anonymously or in public; groups were composed either of females or of males. The observations are 20 groups.    Usage    Guyer    Format  
This data frame contains the following columns:    cooperation  
Number of cooperative choices (out of 120 in all).    condition  
A factor with levels:  anonymous , Anonymous choice;  public , Public choice.    sex  
Sex. A factor with levels:  female and  male .      Source  
Fox, J. and Guyer, M. (1978) Public choice and cooperation in n-person prisoner's dilemma.  Journal of Conflict Resolution 22 , 469–481.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.   
Fox, J. and Weisberg, S. (2013)  An R Companion to Applied Regression , Third Edition, Sage."
"carData-Hartnagel","carData","Hartnagel","Canadian Crime-Rates Time Series",38,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Hartnagel.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Hartnagel.html","Hartnagel R Documentation   Canadian Crime-Rates Time Series   Description  
The Hartnagel data frame has 38 rows and 7 columns. The data are an annual time-series from 1931 to 1968. There are some missing data.    Usage    Hartnagel    Format  
This data frame contains the following columns:    year  
1931–1968.    tfr  
Total fertility rate per 1000 women.    partic  
Women's labor-force participation rate per 1000.    degrees  
Women's post-secondary degree rate per 10,000.    fconvict  
Female indictable-offense conviction rate per 100,000.    ftheft  
Female theft conviction rate per 100,000.    mconvict  
Male indictable-offense conviction rate per 100,000.    mtheft  
Male theft conviction rate per 100,000.      Details  
The post-1948 crime rates have been adjusted to account for a difference in method of recording. Some of your results will differ in the last decimal place from those in Table 14.1 of Fox (1997) due to rounding of the data. Missing values for 1950 were interpolated.    Source  
Personal communication from T. Hartnagel, Department of Sociology, University of Alberta.    References  
Fox, J., and Hartnagel, T. F (1979) Changing social roles and female crime in Canada: A time series analysis.  Canadian Review of Sociology and Anthroplogy , 16 , 96–104.   
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Highway1","carData","Highway1","Highway Accidents",39,12,0,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Highway1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Highway1.html","Highway1 R Documentation   Highway Accidents   Description  
The data comes from a unpublished master's paper by Carl Hoffstedt. They relate the automobile accident rate, in accidents per million vehicle miles to several potential terms. The data include 39 sections of large highways in the state of Minnesota in 1973. The goal of this analysis was to understand the impact of design variables, Acpts , Slim , Sig , and Shld that are under the control of the highway department, on accidents.    Usage    Highway1    Format  
This data frame contains the following columns:    rate  
1973 accident rate per million vehicle miles    len  
length of the Highway1 segment in miles    adt  
average daily traffic count in thousands    trks  
truck volume as a percent of the total volume    sigs1  
(number of signalized interchanges per mile times len + 1)/len, the number of signals per mile of roadway, adjusted to have no zero values.    slim  
speed limit in 1973    shld  
width in feet of outer shoulder on the roadway    lane  
total number of lanes of traffic    acpt  
number of access points per mile    itg  
number of freeway-type interchanges per mile    lwid  
lane width, in feet    htype
An indicator of the type of roadway or the source of funding for the road, either MC, FAI, PA, or MA      Source  
Carl Hoffstedt. This differs from the dataset Highway in the  alr4 package only by addition of transformation of some of the columns.   References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Weisberg, S. (2014) Applied Linear Regression , Fourth Edition, Wiley, Section 7.2."
"carData-KosteckiDillon","carData","KosteckiDillon","Treatment of Migraine Headaches",4152,9,2,0,4,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/KosteckiDillon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/KosteckiDillon.html","KosteckiDillon R Documentation   Treatment of Migraine Headaches   Description  
Subset of data on migraine treatments collected by Tammy Kostecki-Dillon.   Usage   KosteckiDillon   Format  
A data frame with 4152 observations on 133 subjects for the following 9 variables.    id
Patient id.   time
time in days relative to the onset of treatment, which occurs at time 0.   dos
time in days from the start of the study, January 1 of the first year of the study.   hatype
a factor with levels Aura Mixed No Aura , the type of migraine experienced by a subject.   age
at onset of treatment, in years.   airq
a measure of air quality.   medication
a factor with levels none reduced continuing , representing subjects who discontinued their medication, who continued but at a reduced dose, or who continued at the previous dose.   headache
a factor with levels no yes .   sex
a factor with levels female male .     Details  
The data consist of headache logs kept by 133 patients in a treatment program in which bio-feedback was used to attempt to reduce migraine frequency and severity. Patients entered the program at different times over a period of about 3 years. Patients were encouraged to begin their logs four weeks before the onset of treatment and to continue for one month afterwards, but only 55 patients have data preceding the onset of treatment.    Source  
Personal communication from Georges Monette (and adapted from his description of the data).    References  
Kostecki-Dillon, T., Monette, G., and Wong, P. (1999). Pine trees, comas, and migraines.  York University Institute for Social Research Newsletter , 14:2.    Examples    summary(KosteckiDillon)"
"carData-Leinhardt","carData","Leinhardt","Data on Infant-Mortality",105,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Leinhardt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Leinhardt.html","Leinhardt R Documentation   Data on Infant-Mortality   Description  
The Leinhardt data frame has 105 rows and 4 columns. The observations are nations of the world around 1970.    Usage    Leinhardt    Format  
This data frame contains the following columns:    income  
Per-capita income in U. S. dollars.    infant  
Infant-mortality rate per 1000 live births.    region  
A factor with levels:  Africa ; Americas ;  Asia , Asia and Oceania;  Europe .    oil  
Oil-exporting country. A factor with levels:  no , yes .      Details  
The infant-mortality rate for Jamaica is misprinted in Leinhardt and Wasserman; the correct value is given here. Some of the values given in Leinhardt and Wasserman do not appear in the original New York Times table and are of dubious validity.    Source  
Leinhardt, S. and Wasserman, S. S. (1979) Exploratory data analysis: An introduction to selected methods. In Schuessler, K. (Ed.) Sociological Methodology 1979 Jossey-Bass.   
The New York Times , 28 September 1975, p. E-3, Table 3.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-LoBD","carData","LoBD","Cancer drug data use to provide an example of the use of the skew power distributions.",84,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/LoBD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/LoBD.html","LoBD R Documentation    Cancer drug data use to provide an example of the use of the skew power distributions.    Description  
A portion of an experiment to determine the limit of blank/limit of detection in a biochemical assay.    Usage   LoBD   Format  
A data frame with 84 observations on the following 9 variables.    pool
a factor with levels 1 2 3 4   5 6 7 8 9 10 11 12  denoting the 12 pools used in the experiment; each pool had a different level of drug.   I1L1
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I1L2
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I2L1
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I2L2
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I3L1
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I3L2
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I4L1
a numeric vector giving the measured concentration in pmol/L of drug in the assay   I4L2
a numeric vector giving the measured concentration in pmol/L of drug in the assay     Details  
Important characteristics of a clinical chemistry assay are its limit of blank (LoB), and its limit of detection (LoD). The LoB, conceptually the highest reading likely to be obtained from a zero-concentration sample, is defined operationally by the upper 95% point of readings obtained from samples that do not contain the analyte. The LoD, conceptually the lowest level of analyte that can be reliably determined not to be blank, is defined operationally as true value at which there is a 95% chance of the reading being above the LoB.   
These data are from a portion of a LoB/D study of an assay for a drug used to treat certain cancers. Twelve pools were used, four of them blanks of different types, and eight with successively increasing drug levels. The 8 columns of the data set refer to measurements made using different instruments I and reagent lots L.    Source  
Used as an illustrative example for Box-Cox type transformations with negative readings in Hawkins and Weisberg (2015). For examples of its use, see bcnPower .    References  
Hawkins, D. and Weisberg, S. (2015) Combining the Box-Cox Power and Generalized Log Transformations to Accommodate Negative Responses, submitted for publication.    Examples    LoBD"
"carData-Mandel","carData","Mandel","Contrived Collinear Data",8,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Mandel.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Mandel.html","Mandel R Documentation   Contrived Collinear Data   Description  
The Mandel data frame has 8 rows and 3 columns.    Usage    Mandel    Format  
This data frame contains the following columns:    x1  
first predictor.    x2  
second predictor.    y  
response.      Source  
Mandel, J. (1982) Use of the singular value decomposition in regression analysis.  The American Statistician 36 , 15–24.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Migration","carData","Migration","Canadian Interprovincial Migration Data",90,8,0,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Migration.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Migration.html","Migration R Documentation   Canadian Interprovincial Migration Data   Description  
The Migration data frame has 90 rows and 8 columns.    Usage    Migration    Format  
This data frame contains the following columns:    source  
Province of origin (source). A factor with levels:  ALTA , Alberta;  BC , British Columbia;  MAN , Manitoba;  NB , New Brunswick;  NFLD , New Foundland;  NS , Nova Scotia;  ONT , Ontario;  PEI , Prince Edward Island;  QUE , Quebec;  SASK , Saskatchewan.    destination  
Province of destination (1971 residence). A factor with levels:  ALTA , Alberta;  BC , British Columbia;  MAN , Manitoba;  NB , New Brunswick;  NFLD , New Foundland;  NS , Nova Scotia;  ONT , Ontario;  PEI , Prince Edward Island;  QUE , Quebec;  SASK , Saskatchewan.    migrants  
Number of migrants (from source to destination) in the period 1966–1971.    distance  
Distance (between principal cities of provinces): NFLD, St. John; PEI, Charlottetown; NS, Halifax; NB, Fredricton; QUE, Montreal; ONT, Toronto; MAN, Winnipeg; SASK, Regina; ALTA, Edmonton; BC, Vancouver.    pops66  
1966 population of source province.    pops71  
1971 population of source province.    popd66  
1966 population of destination province.    popd71  
1971 population of destination province.      Details  
There is one record in the data file for each migration stream. You can average the 1966 and 1971 population figures for each of the source and destination provinces.    Source  
Canada (1962)  Map . Department of Mines and Technical Surveys.   
Canada (1971)  Census of Canada . Statistics Canada, Vol. 1, Part 2 [Table 32].  
Canada (1972)  Canada Year Book . Statistics Canada [p. 1369].    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Moore","carData","Moore","Status, Authoritarianism, and Conformity",45,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Moore.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Moore.html","Moore R Documentation   Status, Authoritarianism, and Conformity   Description  
The Moore data frame has 45 rows and 4 columns. The data are for subjects in a social-psychological experiment, who were faced with manipulated disagreement from a partner of either of low or high status. The subjects could either conform to the partner's judgment or stick with their own judgment.    Usage    Moore    Format  
This data frame contains the following columns:    partner.status  
Partner's status. A factor with levels:  high ,  low .    conformity  
Number of conforming responses in 40 critical trials.    fcategory  
F-Scale Categorized. A factor with levels (note levels out of order):  high ,  low ,  medium .    fscore  
Authoritarianism: F-Scale score.      Source  
Moore, J. C., Jr. and Krupat, E. (1971) Relationship between source status, authoritarianism and conformity in a social setting. Sociometry 34 , 122–134.  
Personal communication from J. Moore, Department of Sociology, York University.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-MplsDemo","carData","MplsDemo","Minneapolis Demographic Data 2015, by Neighborhood",84,8,0,1,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/MplsDemo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/MplsDemo.html","MplsDemo R Documentation    Minneapolis Demographic Data 2015, by Neighborhood    Description  
Minneapolis Demographic Data 2015, by Neighborhood, from the 2015 American Community Survey    Format  
A data frame with 84 observations on the following 7 variables.    neighborhood
name of the neighborhood   population
total population   black
fraction of the population estimated to be black   white
fraction of the population estimated to be white   foreignBorn
fraction of the population estimated to be foreign born   hhIncome
estimated median household income   poverty
estimated fraction earning less than twice the poverty level   collegeGrad
estimated fraction with a college degree     Details  
The data frame MplsStops contains 2017 Minneapolis Police stop data, using the same neighborhood names as this data file.    Source  
http://www.mncompass.org/profiles/neighborhoods/minneapolis-saint-paul#!community-areas    Examples    str(MplsDemo)"
"carData-MplsStops","carData","MplsStops","Minneapolis Police Department 2017 Stop Data",51920,14,5,0,10,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/MplsStops.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/MplsStops.html","MplsStops R Documentation    Minneapolis Police Department 2017 Stop Data    Description  
Results of nearly all stops made by the Minneapolis Police Department for the year 2017.    Format  
A data frame with 51857 observations on the following 14 variables.    idNum
character vector of incident identifiers   date
a POSIXlt date variable giving the date and time of the stop   problem
a factor with levels suspicious for suspicious vehicle or person stops and traffic for traffic stops   citationIssued
a factor with levels no yes indicating if a citation was issued   personSearch
a factor with levels no yes indicating if the stopped person was searched   vehicleSearch
a factor with levels no or yes indicating if a vehicle was searched   preRace
a factor with levels white , black , east african , latino , native american , asian , other , unknown for the officer's assessment of race of the person stopped before speaking with the person stopped   race
a factor with levels white , black , east african , latino , native american , asian , other , unknown , officer's determination of race after the incident   gender
a factor with levels female , male , unknown , gender of person stopped   lat
latitude of the location of the incident, somewhat rounded   long
latitude of the location of the incident, somewhat rounded   policePrecinct
Minneapolis Police Precinct number   neighborhood
a factor with 84 levels giving the name of the Minneapolis neighborhood of the incident   MDC
a factor with levels mdc for data collected via in-vehicle computer, and other for data submitted by officers not in a vehicle, either on foot, bicycle or horseback. Several of the variables above were recorded only in-vehicle     Details  
A few stops have been deleted, either because thesu location data was missing, or a few very rare categories were also removed. The data frame MplsDemo contains 2015 demongraphic data on Minneapolis neighborhoods, using the same neighborhood names as this data file. Demographics are available for 84 of Minneaolis' 87 neighborhoods. The remaining 3 presumably have no housing.    Source  
These are public data obtained from <http://opendata.minneapolismn.gov/datasets/police-stop-data>. A few more fields, and more data, are available at the original source    Examples    summary(MplsStops)"
"carData-Mroz","carData","Mroz","U.S. Women's Labor-Force Participation",753,8,3,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Mroz.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Mroz.html","Mroz R Documentation   U.S. Women's Labor-Force Participation   Description  
The Mroz data frame has 753 rows and 8 columns. The observations, from the Panel Study of Income Dynamics (PSID), are married women.    Usage   Mroz   Format  
This data frame contains the following columns:    lfp
labor-force participation; a factor with levels:  no ;  yes .    k5
number of children 5 years old or younger.   k618
number of children 6 to 18 years old.   age
in years.   wc
wife's college attendance; a factor with levels:  no ;  yes .    hc
husband's college attendance; a factor with levels:  no ;  yes .    lwg
log expected wage rate; for women in the labor force, the actual wage rate; for women not in the labor force, an imputed value based on the regression of lwg on the other variables.   inc
family income exclusive of wife's income.     Source  
Mroz, T. A. (1987) The sensitivity of an empirical model of married women's hours of work to economic and statistical assumptions. Econometrica 55 , 765–799.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. (2000)  Multiple and Generalized Nonparametric Regression. Sage.   
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Long. J. S. (1997)  Regression Models for Categorical and Limited Dependent Variables.  Sage."
"carData-OBrienKaiser","carData","OBrienKaiser","O'Brien and Kaiser's Repeated-Measures Data",16,17,1,0,2,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/OBrienKaiser.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/OBrienKaiser.html","OBrienKaiser R Documentation   O'Brien and Kaiser's Repeated-Measures Data   Description  
These contrived repeated-measures data are taken from O'Brien and Kaiser (1985). The data are from an imaginary study in which 16 female and male subjects, who are divided into three treatments, are measured at a pretest, postest, and a follow-up session; during each session, they are measured at five occasions at intervals of one hour. The design, therefore, has two between-subject and two within-subject factors.   
The contrasts for the treatment factor are set to -2, 1, 1 and  0, -1, 1 . The contrasts for the gender factor are set to  contr.sum .    Usage   OBrienKaiser   Format  
A data frame with 16 observations on the following 17 variables.    treatment
a factor with levels control A B   gender
a factor with levels F M   pre.1
pretest, hour 1   pre.2
pretest, hour 2   pre.3
pretest, hour 3   pre.4
pretest, hour 4   pre.5
pretest, hour 5   post.1
posttest, hour 1   post.2
posttest, hour 2   post.3
posttest, hour 3   post.4
posttest, hour 4   post.5
posttest, hour 5   fup.1
follow-up, hour 1   fup.2
follow-up, hour 2   fup.3
follow-up, hour 3   fup.4
follow-up, hour 4   fup.5
follow-up, hour 5     Source  
O'Brien, R. G., and Kaiser, M. K. (1985) MANOVA method for analyzing repeated measures designs: An extensive primer.  Psychological Bulletin 97 , 316–333, Table 7.    Examples    OBrienKaiser contrasts(OBrienKaiser$treatment) contrasts(OBrienKaiser$gender)"
"carData-OBrienKaiserLong","carData","OBrienKaiserLong","O'Brien and Kaiser's Repeated-Measures Data in ""Long"" Format",240,6,1,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/OBrienKaiserLong.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/OBrienKaiserLong.html","OBrienKaiserLong R Documentation   O'Brien and Kaiser's Repeated-Measures Data in ""Long"" Format   Description  
Contrived repeated-measures data from O'Brien and Kaiser (1985). For details see OBrienKaiser , which is for the ""wide"" form of the same data.   Usage   OBrienKaiserLong   Format  
A data frame with 240 observations on the following 6 variables.    treatment
a between-subjects factor with levels control , A , B .   gender
a between-subjects factor with levels F , M.   score
the numeric response variable.   id
the subject id number.   phase
a within-subjects factor with levels pre , post , fup .   hour
a within-subjects factor with levels 1 , 2 , 3 , 4 , 5 .     Source  
O'Brien, R. G., and Kaiser, M. K. (1985) MANOVA method for analyzing repeated measures designs: An extensive primer.  Psychological Bulletin 97 , 316–333, Table 7.    See Also  
OBrienKaiser .   Examples    head(OBrienKaiserLong, 15) # first subject"
"carData-Ornstein","carData","Ornstein","Interlocking Directorates Among Major Canadian Firms",248,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Ornstein.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Ornstein.html","Ornstein R Documentation   Interlocking Directorates Among Major Canadian Firms   Description  
The Ornstein data frame has 248 rows and 4 columns. The observations are the 248 largest Canadian firms with publicly available information in the mid-1970s. The names of the firms were not available.    Usage    Ornstein    Format  
This data frame contains the following columns:    assets  
Assets in millions of dollars.    sector  
Industrial sector. A factor with levels:  AGR , agriculture, food, light industry;  BNK , banking; CON , construction; FIN , other financial;  HLD , holding companies; MAN , heavy manufacturing; MER , merchandizing;  MIN , mining, metals, etc.;  TRN , transport;  WOD , wood and paper.    nation  
Nation of control. A factor with levels:  CAN , Canada;  OTH , other foreign;  UK , Britain;  US , United States.    interlocks  
Number of interlocking director and executive positions shared with other major firms.      Source  
Ornstein, M. (1976) The boards and executives of the largest Canadian corporations. Canadian Journal of Sociology 1 , 411–437.   
Personal communication from M. Ornstein, Department of Sociology, York University.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Pottery","carData","Pottery","Chemical Composition of Pottery",26,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Pottery.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Pottery.html","Pottery R Documentation   Chemical Composition of Pottery   Description  
The data give the chemical composition of ancient pottery found at four sites in Great Britain. They appear in Hand, et al. (1994), and are used to illustrate MANOVA in the SAS Manual. (Suggested by Michael Friendly.)    Usage    Pottery    Format  
A data frame with 26 observations on the following 6 variables.    Site
a factor with levels AshleyRails Caldicot IsleThorns Llanedyrn   Al
Aluminum   Fe
Iron   Mg
Magnesium   Ca
Calcium   Na
Sodium     Source  
Hand, D. J., Daly, F., Lunn, A. D., McConway, K. J., and E., O. (1994)  A Handbook of Small Data Sets . Chapman and Hall.    Examples    Pottery"
"carData-Prestige","carData","Prestige","Prestige of Canadian Occupations",102,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Prestige.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Prestige.html","Prestige R Documentation   Prestige of Canadian Occupations   Description  
The Prestige data frame has 102 rows and 6 columns. The observations are occupations.    Usage    Prestige    Format  
This data frame contains the following columns:    education  
Average education of occupational incumbents, years, in 1971.   income  
Average income of incumbents, dollars, in 1971.    women  
Percentage of incumbents who are women.    prestige  
Pineo-Porter prestige score for occupation, from a social survey conducted in the mid-1960s.    census  
Canadian Census occupational code.    type  
Type of occupation. A factor with levels (note: out of order):  bc , Blue Collar;  prof , Professional, Managerial, and Technical;  wc , White Collar.     Source  
Canada (1971)  Census of Canada . Vol. 3, Part 6. Statistics Canada [pp. 19-1–19-21].   
Personal communication from B. Blishen, W. Carroll, and C. Moore, Departments of Sociology, York University and University of Victoria.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Quartet","carData","Quartet","Four Regression Datasets",11,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Quartet.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Quartet.html","Quartet R Documentation   Four Regression Datasets   Description  
The Quartet data frame has 11 rows and 5 columns. These are contrived data.    Usage    Quartet    Format  
This data frame contains the following columns:    x  
X-values for datasets 1–3.    y1  
Y-values for dataset 1.    y2  
Y-values for dataset 2.    y3  
Y-values for dataset 3.    x4  
X-values for dataset 4.    y4  
Y-values for dataset 4.      Source  
Anscombe, F. J. (1973) Graphs in statistical analysis.  American Statistician 27 , 17–21."
"carData-Robey","carData","Robey","Fertility and Contraception",50,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Robey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Robey.html","Robey R Documentation   Fertility and Contraception   Description  
The Robey data frame has 50 rows and 3 columns. The observations are developing nations around 1990.    Usage    Robey    Format  
This data frame contains the following columns:    region  
A factor with levels:  Africa ;  Asia , Asia and Pacific;  Latin.Amer , Latin America and Caribbean;  Near.East , Near East and North Africa.    tfr  
Total fertility rate (children per woman).    contraceptors  
Percent of contraceptors among married women of childbearing age.      Source  
Robey, B., Shea, M. A., Rutstein, O. and Morris, L. (1992) The reproductive revolution: New survey findings. Population Reports . Technical Report M-11.   References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Rossi","carData","Rossi","Rossi et al.'s Criminal Recidivism Data",432,62,58,0,57,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Rossi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Rossi.html","Rossi R Documentation   Rossi et al.'s Criminal Recidivism Data   Description  
This data set is originally from Rossi et al. (1980), and is used as an example in Allison (1995). The data pertain to 432 convicts who were released from Maryland state prisons in the 1970s and who were followed up for one year after release. Half the released convicts were assigned at random to an experimental treatment in which they were given financial aid; half did not receive aid.    Usage   Rossi   Format  
A data frame with 432 observations on the following 62 variables.    week
week of first arrest after release or censoring; all censored observations are censored at 52 weeks.   arrest
1 if arrested, 0 if not arrested.   fin
financial aid: no yes .   age
in years at time of release.   race
black or other .   wexp
full-time work experience before incarceration: no or yes .   mar
marital status at time of release: married or not married .   paro
released on parole? no or yes .   prio
number of convictions prior to current incarceration.   educ
level of education: 2 = 6th grade or less;  3 = 7th to 9th grade; 4 = 10th to 11th grade;  5 = 12th grade; 6 = some college.   emp1
employment status in the first week after release: no or yes .   emp2
as above.   emp3
as above.   emp4
as above.   emp5
as above.   emp6
as above.   emp7
as above.   emp8
as above.   emp9
as above.   emp10
as above.   emp11
as above.   emp12
as above.   emp13
as above.   emp14
as above.   emp15
as above.   emp16
as above.   emp17
as above.   emp18
as above.   emp19
as above.   emp20
as above.   emp21
as above.   emp22
as above.   emp23
as above.   emp24
as above.   emp25
as above.   emp26
as above.   emp27
as above.   emp28
as above.   emp29
as above.   emp30
as above.   emp31
as above.   emp32
as above.   emp33
as above.   emp34
as above.   emp35
as above.   emp36
as above.   emp37
as above.   emp38
as above.   emp39
as above.   emp40
as above.   emp41
as above.   emp42
as above.   emp43
as above.   emp44
as above.   emp45
as above.   emp46
as above.   emp47
as above.   emp48
as above.   emp49
as above.   emp50
as above.   emp51
as above.   emp52
as above.     Source  
Allison, P.D. (1995). Survival Analysis Using the SAS System: A Practical Guide.  Cary, NC: SAS Institute.    References  
Rossi, P.H., R.A. Berk, and K.J. Lenihan (1980). Money, Work, and Crime: Some Experimental Results. New York: Academic Press.   
John Fox, Marilia Sa Carvalho (2012). The RcmdrPlugin.survival Package: Extending the R Commander Interface to Survival Analysis.  Journal of Statistical Software , 49(7), 1-32.    Examples    summary(Rossi)"
"carData-Sahlins","carData","Sahlins","Agricultural Production in Mazulu Village",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Sahlins.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Sahlins.html","Sahlins R Documentation   Agricultural Production in Mazulu Village   Description  
The Sahlins data frame has 20 rows and 2 columns. The observations are households in a Central African village.    Usage    Sahlins    Format  
This data frame contains the following columns:    consumers  
Consumers/Gardener, ratio of consumers to productive individuals.    acres  
Acres/Gardener, amount of land cultivated per gardener.      Source  
Sahlins, M. (1972)  Stone Age Economics. Aldine [Table 3.1].   References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Salaries","carData","Salaries","Salaries for Professors",397,6,2,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Salaries.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Salaries.html","Salaries R Documentation    Salaries for Professors    Description  
The 2008-09 nine-month academic salary for Assistant Professors, Associate Professors and Professors in a college in the U.S. The data were collected as part of the on-going effort of the college's administration to monitor salary differences between male and female faculty members.   Usage   Salaries   Format  
A data frame with 397 observations on the following 6 variables.    rank
a factor with levels AssocProf AsstProf Prof   discipline
a factor with levels A (“theoretical” departments) or B (“applied” departments).   yrs.since.phd
years since PhD.   yrs.service
years of service.   sex
a factor with levels Female Male   salary
nine-month salary, in dollars.     References  
Fox J. and Weisberg, S. (2019)  An R Companion to Applied Regression , Third Edition, Sage."
"carData-SLID","carData","SLID","Survey of Labour and Income Dynamics",7425,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/SLID.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/SLID.html","SLID R Documentation   Survey of Labour and Income Dynamics   Description  
The SLID data frame has 7425 rows and 5 columns. The data are from the 1994 wave of the Canadian Survey of Labour and Income Dynamics, for the province of Ontario. There are missing data, particularly for wages.    Usage    SLID    Format  
This data frame contains the following columns:    wages  
Composite hourly wage rate from all jobs.    education  
Number of years of schooling.    age  
in years.    sex  
A factor with levels:  Female ,  Male .    language  
A factor with levels:  English ,  French ,  Other .      Source  
The data are taken from the public-use dataset made available by Statistics Canada, and prepared by the Institute for Social Research, York University.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Soils","carData","Soils","Soil Compositions of Physical and Chemical Characteristics",48,14,0,0,5,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Soils.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Soils.html","Soils R Documentation   Soil Compositions of Physical and Chemical Characteristics   Description  
Soil characteristics were measured on samples from three types of contours (Top, Slope, and Depression) and at four depths (0-10cm, 10-30cm, 30-60cm, and 60-90cm). The area was divided into 4 blocks, in a randomized block design. (Suggested by Michael Friendly.)    Usage   Soils   Format  
A data frame with 48 observations on the following 14 variables. There are 3 factors and 9 response variables.    Group
a factor with 12 levels, corresponding to the combinations of Contour and Depth   Contour
a factor with 3 levels: Depression Slope Top   Depth
a factor with 4 levels: 0-10 10-30 30-60 60-90   Gp
a factor with 12 levels, giving abbreviations for the groups: D0 D1 D3 D6 S0 S1 S3 S6 T0 T1 T3 T6   Block
a factor with levels 1 2 3 4   pH
soil pH   N
total nitrogen in %   Dens
bulk density in gm/cm$^3$   P
total phosphorous in ppm   Ca
calcium in me/100 gm.   Mg
magnesium in me/100 gm.   K
phosphorous in me/100 gm.   Na
sodium in me/100 gm.   Conduc
conductivity     Details  
These data provide good examples of MANOVA and canonical discriminant analysis in a somewhat complex multivariate setting. They may be treated as a one-way design (ignoring Block ), by using either Group or Gp as the factor, or a two-way randomized block design using Block , Contour and Depth (quantitative, so orthogonal polynomial contrasts are useful).    Source  
Horton, I. F.,Russell, J. S., and Moore, A. W. (1968) Multivariate-covariance and canonical analysis: A method for selecting the most effective discriminators in a multivariate situation.  Biometrics 24 , 845–858. Originally from http://www.stat.lsu.edu/faculty/moser/exst7037/soils.sas but no longer available there.    References  
Khattree, R., and Naik, D. N. (2000)  Multivariate Data Reduction and Discrimination with SAS Software.  SAS Institute.   
Friendly, M. (2006) Data ellipses, HE plots and reduced-rank displays for multivariate linear models: SAS software and examples.  Journal of Statistical Software , 17(6),  http://www.jstatsoft.org/v17/i06 ."
"carData-States","carData","States","Education and Related Statistics for the U.S. States",51,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/States.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/States.html","States R Documentation   Education and Related Statistics for the U.S. States   Description  
The States data frame has 51 rows and 8 columns. The observations are the U. S. states and Washington, D. C.    Usage    States    Format  
This data frame contains the following columns:    region  
U. S. Census regions. A factor with levels:  ENC , East North Central;  ESC , East South Central;  MA , Mid-Atlantic;  MTN , Mountain; NE , New England;  PAC , Pacific; SA , South Atlantic;  WNC , West North Central; WSC , West South Central.   pop  
Population: in 1,000s.    SATV  
Average score of graduating high-school students in the state on the verbal component of the Scholastic Aptitude Test (a standard university admission exam).    SATM  
Average score of graduating high-school students in the state on the math component of the Scholastic Aptitude Test.    percent  
Percentage of graduating high-school students in the state who took the SAT exam.    dollars  
State spending on public education, in \$1000s per student.    pay  
Average teacher's salary in the state, in $1000s.      Source  
United States (1992)  Statistical Abstract of the United States. Bureau of the Census.    References  
Moore, D. (1995)  The Basic Practice of Statistics . Freeman, Table 2.1."
"carData-TitanicSurvival","carData","TitanicSurvival","Survival of Passengers on the Titanic",1309,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/TitanicSurvival.html","TitanicSurvival R Documentation   Survival of Passengers on the Titanic   Description  
Information on the survival status, sex, age, and passenger class of 1309 passengers in the Titanic disaster of 1912.   Usage   TitanicSurvival   Format  
A data frame with 1309 observations on the following 4 variables.    survived
no or yes .   sex
female or male   age
in years (and for some children, fractions of a year); age is missing for 263 of the passengers.   passengerClass
1st , 2nd , or 3rd class.     Details  
This is part of a larger data set compiled by Thomas Cason. Many additional details are given in the sources cited below.    Source  
Data set titanic3 from http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/DataSets .    References  
http://www.encyclopedia-titanica.org/    
F. E. Harrell, Jr. (2001)  Regression Modeling Strategies  New York: Springer.    Examples    summary(TitanicSurvival)"
"carData-Transact","carData","Transact","Transaction data",261,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Transact.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Transact.html","Transact R Documentation   Transaction data   Description  
Data on transaction times in branch offices of a large Australian bank.    Usage    Transact    Format  
This data frame contains the following columns:    t1  
number of type 1 transactions    t2  
number of type 2 transactions    time  
total transaction time, minutes      Source  
Cunningham, R. and Heathcote, C. (1989), Estimating a non-Gaussian regression model with multicollinearity. Australian Journal of Statistics, 31,12-17.   References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Weisberg, S. (2014) Applied Linear Regression , Fourth Edition, Wiley, Section 4.6.1."
"carData-UN","carData","UN","National Statistics from the United Nations, Mostly From 2009-2011",213,7,0,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/UN.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/UN.html","UN R Documentation    National Statistics from the United Nations, Mostly From 2009–2011    Description  
National health, welfare, and education statistics for 213 places, mostly UN members, but also other areas like Hong Kong that are not independent countries.    Usage   data(UN)   Format  
A data frame with 213 rows on the following 7 variables.    region
Region of the world: Africa , Asia , Caribbean , Europe , Latin Amer , North America , NorthAtlantic , Oceania .   group
A factor with levels oecd for countries that are members of the OECD, the Organization for Economic Co-operation and Development, as of May 2012, africa for countries on the African continent, and other for all other countries. No OECD countries are located in Africa.   fertility
Total fertility rate, number of children per woman.   ppgdp
Per capita gross domestic product in US dollars.   lifeExpF
Female life expectancy, years.   pctUrban
Percent urban.   infantMortality
Infant deaths by age 1 year per 1000 live births     Note  
Similar data, from the period 2000-2003, appear in the alr3 package under the name UN3 . This data set was formerly named UNlla and replaces the older dataset named UN .    Source  
All data were collected from UN tables accessed at http://unstats.un.org/unsd/demographic/products/socind/  on April 23, 2012. OECD membership is from https://www.oecd.org/ , accessed May 25, 2012.    References  
Weisberg, S. (2014). Applied Linear Regression , 4th edition. Hoboken NJ: Wiley.    Examples    summary(UN)"
"carData-UN98","carData","UN98","United Nations Social Indicators Data 1998]",207,13,0,0,1,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/UN98.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/UN98.html","UN98 R Documentation    United Nations Social Indicators Data 1998]    Description  
Social indicators data on 207 nations distributed by the United Nations circa 1998.    Usage   data(""UN98"")   Format  
A data frame with 207 observations on the following 13 variables.    region
a factor with alphabetical levels Africa , America , Asia , Europe , Oceania .   tfr
total fertility rate, number of children per woman.   contraception
percentage of married women using any method of contraception.   educationMale
average number of years of education for men.   educationFemale
average number of years of education for women.   lifeMale
expectation of life at birth for males.   lifeFemale
expectation of life at birth for females.   infantMortality
infant deaths per 1000 live births.   GDPperCapita
gross domestic product per person in U.S. dollars.   economicActivityMale
percentage of men who are economically active.   economicActivityFemale
percentage of women who are economically active.   illiteracyMale
percentage of males 15 years of age and older who are illiterate.   illiteracyFemale
percentage of females 15 years of age and older who are illiterate.     Details  
In a few cases where the percentages of males and females 15 and older who are illiterate were unavailable, these variables were filled in by regression imputation from the corresponding percentages 25 and older who are illiterate.    Source  
Downloaded from http://www.un.org/Depts/unsd/social/main.htm in 1998.    Examples    summary(UN98)"
"carData-USPop","carData","USPop","Population of the United States",22,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/USPop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/USPop.html","USPop R Documentation   Population of the United States   Description  
The USPop data frame has 22 rows and 1 columns. This is a decennial time-series, from 1790 to 2000.    Usage    USPop    Format  
This data frame contains the following columns:    year  
census year.    population  
Population in millions.      Source  
U.S.~Census Bureau: http://www.census-charts.com/Population/pop-us-1790-2000.html , downloaded 1 May 2008.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage."
"carData-Vocab","carData","Vocab","Vocabulary and Education",30351,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Vocab.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Vocab.html","Vocab R Documentation   Vocabulary and Education   Description  
The Vocab data frame has 30,351 rows and 4 columns. The observations are respondents to U.S. General Social Surveys, 1972-2016.    Usage    Vocab    Format  
This data frame contains the following columns:    year
Year of the survey.   sex
Sex of the respondent, Female or Male .   education  
Education, in years.    vocabulary  
Vocabulary test score: number correct on a 10-word test.      Source  
National Opinion Research Center  General Social Survey. GSS Cumulative Datafile 1972-2016, downloaded from http://gss.norc.org/ .    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-WeightLoss","carData","WeightLoss","Weight Loss Data",34,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/WeightLoss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/WeightLoss.html","WeightLoss R Documentation    Weight Loss Data    Description  
Contrived data on weight loss and self esteem over three months, for three groups of individuals: Control, Diet and Diet + Exercise. The data constitute a double-multivariate design.    Usage   WeightLoss   Format  
A data frame with 34 observations on the following 7 variables.    group
a factor with levels Control Diet DietEx .   wl1
Weight loss at 1 month   wl2
Weight loss at 2 months   wl3
Weight loss at 3 months   se1
Self esteem at 1 month   se2
Self esteem at 2 months   se3
Self esteem at 3 months     Details  
Helmert contrasts are assigned to group , comparing Control vs. ( Diet DietEx ) and Diet vs. DietEx .    Source  
Originally taken from http://www.csun.edu/~ata20315/psy524/main.htm , but modified slightly. Courtesy of Michael Friendly."
"carData-Wells","carData","Wells","Well Switching in Bangladesh",3020,5,2,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Wells.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Wells.html","Wells R Documentation   Well Switching in Bangladesh   Description  
Data on whether or not households in Bangladesh changed the wells that they were using.    Usage   Wells   Format  
A data frame with 3020 observations on the following 5 variables.    switch
whether or not the household switched to another well from an unsafe well: no or yes .   arsenic
the level of arsenic contamination in the household's original well, in hundreds of micrograms per liter; all are above 0.5, which was the level identified as “safe”.   distance
in meters to the closest known safe well.   education
in years of the head of the household.   association
whether or not any members of the household participated in any community organizations: no or yes .     Details  
The data are for an area of Arahazar upazila, Bangladesh. The researchers labelled each well with its level of arsenic and an indication of whether the well was “safe” or “unsafe.” Those using unsafe wells were encouraged to switch. After several years, it was determined whether each household using an unsafe well had changed its well. These data are used by Gelman and Hill (2007) for a logistic-regression example.    Source  
http://www.stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat .    References  
A. Gelman and J. Hill (2007)  Data Analysis Using Regression and Multilevel/Hierarchical Models.  Cambridge: Cambridge University Press.    Examples    summary(Wells)"
"carData-Womenlf","carData","Womenlf","Canadian Women's Labour-Force Participation",263,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Womenlf.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Womenlf.html","Womenlf R Documentation   Canadian Women's Labour-Force Participation   Description  
The Womenlf data frame has 263 rows and 4 columns. The data are from a 1977 survey of the Canadian population.    Usage    Womenlf    Format  
This data frame contains the following columns:    partic  
Labour-Force Participation. A factor with levels (note: out of order):  fulltime , Working full-time;  not.work , Not working outside the home;  parttime , Working part-time.    hincome  
Husband's income, $1000s.    children  
Presence of children in the household. A factor with levels:  absent , present .    region  
A factor with levels:  Atlantic , Atlantic Canada;  BC , British Columbia;  Ontario ; Prairie , Prairie provinces;  Quebec .      Source  
Social Change in Canada Project. York Institute for Social Research.    References  
Fox, J. (2016)  Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage."
"carData-Wong","carData","Wong","Post-Coma Recovery of IQ",331,7,1,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Wong.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Wong.html","Wong R Documentation    Post-Coma Recovery of IQ    Description  
The Wong data frame has 331 row and 7 columns. The observations are longitudinal data on recovery of IQ after comas of varying duration for 200 subjects.    Usage   Wong   Format  
This data frame contains the following columns:    id
patient ID number.   days
number of days post coma at which IQs were measured.   duration
duration of the coma in days.   sex
a factor with levels Female and Male .   age
in years at the time of injury.   piq
performance (i.e., mathematical) IQ.   viq
verbal IQ.     Details  
The data are from Wong, Monette, and Weiner (2001) and are for 200 patients who sustained traumatic brain injuries resulting in comas of varying duration. After awakening from their comas, patients were periodically administered a standard IQ test, but the average number of measurements per patient is small (331/200 = 1.7).    Source  
Wong, P. P., Monette, G., and Weiner, N. I. (2001) Mathematical models of cognitive recovery. Brain Injury , 15 , 519–530.    References  
Fox, J. (2016) Applied Regression Analysis and Generalized Linear Models , Third Edition. Sage.    Examples    summary(Wong)"
"carData-Wool","carData","Wool","Wool data",27,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/Wool.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/Wool.html","Wool R Documentation   Wool data   Description  
This is a three-factor experiment with each factor at three levels, for a total of 27 runs. Samples of worsted yarn were with different levels of the three factors were given a cyclic load until the sample failed. The goal is to understand how cycles to failure depends on the factors.    Usage    Wool    Format  
This data frame contains the following columns:    len  
length of specimen (250, 300, 350 mm)    amp  
amplitude of loading cycle (8, 9, 10 min)    load  
load (40, 45, 50g)    cycles  
number of cycles until failure      Source  
Box, G. E. P. and Cox, D. R. (1964). An analysis of transformations (with discussion). J. Royal Statist. Soc. , B26, 211-46.   References  
Fox, J. and Weisberg, S. (2019) An R Companion to Applied Regression , Third Edition, Sage.   
Weisberg, S. (2014) Applied Linear Regression , Fourth Edition, Wiley, Section 6.3."
"carData-WVS","carData","WVS","World Values Surveys",5381,6,3,0,5,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/carData/WVS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/carData/WVS.html","WVS R Documentation   World Values Surveys   Description  
Data from the World Values Surveys 1995-1997 for Australia, Norway, Sweden, and the United States.    Usage   WVS   Format  
A data frame with 5381 observations on the following 6 variables.    poverty
“Do you think that what the government is doing for people in poverty in this country is about the right amount, too much, or too little?” (ordered): Too Little , About Right , Too Much    
.    religion
Member of a religion: no or yes .   degree
Held a university degree: no or yes .   country
Australia , Norway , Sweden , or USA .   age
in years.   gender
male or female .     References  
J. Fox and R. Andersen (2006) Effect displays for multinomial and proportional-odds logit models.  Sociological Methodology 36 , 225–255.    Examples    summary(WVS)"
"causaldata-abortion","causaldata","abortion","Data on abortion legalization and sexually transmitted infections",19584,21,8,0,0,0,21,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/abortion.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/abortion.html","abortion R Documentation   Data on abortion legalization and sexually transmitted infections   Description  
This data looks at the effect of abortion legalization on the incidence of gonnorhea among 15-19 year olds, as a measure of risky behavior. Treatment is whether abortion is legalized at the time that the eventual 15-19 year olds are born.    Usage    abortion    Format  
A data frame with 19584 rows and 21 variables    fip
State FIPS code   age
Age in years   race
Race - 1 = white, 2 = black   year
Year   sex
Sex: 1 = male, 2 = female   totpop
Total population   ir
Incarcerated Males per 100,000   crack
Crack index   alcohol
Alcohol consumption per capita   income
Real income per capita   ur
State unemployment rate   poverty
Poverty rate   repeal
In a state with an early repeal of abortion prohibition   acc
AIDS mortality per 100,000 cumulative in t, t-1, t-2, t-3   wht
White Indicator   male
Male Indicator   lnr
Logged gonnorhea cases per 100,000 in 15-19 year olds   younger
From the younger group   fa
State-younger interaction   pi
Parental involvement law in effect   bf15
Is a black female in the 15-19 age group     Details  
This data is used in the Difference-in-Differences chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham, Scott, and Christopher Cornwell. 2013. “The Long-Run Effect of Abortion on Sexually Transmitted Infections.” American Law and Economics Review 15 (1): 381–407.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-adult_services","causaldata","adult_services","Data from a survey of internet-mediated sex workers",1787,31,20,0,0,0,31,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/adult_services.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/adult_services.html","adult_services R Documentation   Data from a survey of internet-mediated sex workers   Description  
This data comes from a survey of 700 internet-mediated sex workers in 2008 and 2009, asking the same sex workers standard labor market information over several time periods.    Usage    adult_services    Format  
A data frame with 1787 rows and 31 variables    id
Provider identifier   session
Client session identifier   age
Age of provider   age_cl
Age of Client   appearance_cl
Client Attractiveness (Scale of 1 to 10)   bmi
Body Mass Index   schooling
Imputed Years of Schooling   asq_cl
Age of Client Squared   provider_second
Second Provider Involved   asian_cl
Asian Client   black_cl
Black Client   hispanic_cl
Hispanic Client   othrace_cl
Other Ethnicity Client   reg
Client was a Regular   hot
Met Client in Hotel   massage_cl
Gave Client a Massage   lnw
Log of Hourly Wage   llength
Ln(Length)   unsafe
Unprotected sex with client of any kind   asian
race==1. Asian   black
race==2. Black   hispanic
race==3. Hispanic   other
race==4. Other   white
race==5. White   asq
Age of provider squared   cohab
ms==Cohabitating (living with a partner) but unmarried   married
ms==Currently married and living with your spouse   divorced
ms==Divorced and not remarried   separated
ms==Married but not currently living with your spouse   nevermarried
ms==Single and never married   widowed
ms==Widowed and not remarried     Details  
This data is used in the Panel Data chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham, Scott, and Todd D. Kendall. 2011. “Prostitution 2.0: The Changing Face of Sex Work.” Journal of Urban Economics 69: 273–87.   
Cunningham, Scott, and Todd D. Kendall. 2014. “Examining the Role of Client Reviews and Reputation Within Online Prostitution.” In, edited by Scott Cunningham and Manisha Shah. Vol. Handbook on the Economics of Prostitution. Oxford University Press.   
Cunningham, Scott, and Todd D. Kendall. 2016. “Prostitution Labor Supply and Education.” Review of Economics of the Household. Forthcoming.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-auto","causaldata","auto","Automobile data from Stata",74,12,1,1,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/auto.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/auto.html","auto R Documentation   Automobile data from Stata   Description  
This data, which comes standard in Stata, originally came from the April 1979 issue of Consumer Reports and from the United States Government EPA statistics on fuel consumption; they were compiled and published by Chambers et al. (1983).    Usage    auto    Format  
A data frame with 74 rows and 12 variables    make
Make and Model   price
Price   mpg
Mileage (mpg)   rep78
Repair Record 1978   headroom
Headroom (in.)   trunk
Trunk space (cu. ft.)   weight
Weight (lbs.)   length
Length (in.)   turn
Turn Circle (ft.)   displacement
Displacement (cu. in.)   gear_ratio
Gear Ratio   foreign
Car type; 0 = Domestic, 1 = Foreign     Details  
This data is used in the Probability and Regression Review chapter of Causal Inference: The Mixtape .    Source  
Chambers, J. M., W. S. Cleveland, B. Kleiner, and P. A. Tukey. 1983. Graphical Methods for Data Analysis. Belmont, CA: Wadsworth.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-avocado","causaldata","avocado","Data on avocado sales",169,3,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/avocado.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/avocado.html","avocado R Documentation   Data on avocado sales   Description  
This data set includes information on the average price and total amount of avocados sold across 169 weeks from 2015 to 2018. This data covers only sales of 'conventional' avocados that take place in California.    Usage    avocado    Format  
A data frame with 169 rows and 3 variables:    Date
Date of observation   AveragePrice
Average avocado price   TotalVolume
Total volume of avocados sold     Details  
This data was used in the Identification chapter of The Effect by Huntington-Klein    Source  
Kiggins, Justin. 2018. https://www.kaggle.com/neuromusic/avocado-prices/     References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-black_politicians","causaldata","black_politicians","Data from ""Black Politicians are More Intrinsically Motivated to Advance Blacks' Interests""",5593,14,7,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/black_politicians.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/black_politicians.html","black_politicians R Documentation   Data from ""Black Politicians are More Intrinsically Motivated to Advance Blacks' Interests""   Description  
The black_politicians data contains data from Broockman (2013) on a field experiment where the author sent fictional emails purportedly sent by Black people to legislators in the United States. The experiment sought to determine whether the effect of the email being from ""out-of-district"" (someone who can't vote for you and so provides no extrinsic motivation to reply) would have a smaller effect on response rates for Black legislators than for non-Black ones, providing evidence of additional intrinsic motivation on the part of Black legislators to help Black people.    Usage    black_politicians    Format  
A data frame with 5593 rows and 14 variables    leg_black
Legislator receiving email is Black   treat_out
Email is from out-of-district   responded
Legislator responded to email   totalpop
District population   medianhhincom
District median household income   black_medianhh
District median household income among Black people   white_medianhh
District median household income among White people   blackpercent
Percentage of district that is Black   statessquireindex
State's Squire index   nonblacknonwhite
Legislator receiving email is neither Black nor White   urbanpercent
Percentage of district that is urban   leg_senator
Legislator receiving email is a senator   leg_democrat
Legislator receiving email is in the Democratic party   south
Legislator receiving email is in the Southern United States     Details  
This data is used in the Matching chapter of The Effect .    Source  
Broockman, D.E., 2013. Black politicians are more intrinsically motivated to advance blacks’ interests: A field experiment manipulating political incentives. American Journal of Political Science , 57(3), pp.521-536.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-castle","causaldata","castle","Data on castle-doctrine statutes and violent crime",550,138,59,0,0,0,138,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/castle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/castle.html","castle R Documentation   Data on castle-doctrine statutes and violent crime   Description  
This data looks at the impact of castle-doctrine statutes on violent crime. Data from the FBI Uniform Crime Reports Summary files are combined with information on castle-doctrine/stand-your-ground law impementation in different states.    Usage    castle    Format  
A data frame with 19584 rows and 21 variables    year
Year   sid
state id   robbery_gun_r
Region-quarter fixed effects   jhcitizen_c
justifiable homicide by private citizen count   jhpolice_c
justifiable homicide by police count   homicide
homicide count per 100,000 state population   robbery
Region-quarter fixed effects   assault
aggravated assault count per 100,000 state population   burglary
burglary count per 100,000 state population   larceny
larceny count per 100,000 state population   motor
motor vehicle theft count per 100,000 state population   murder
murder count per 100,000 state population   unemployrt
unemployment rate   blackm_15_24
% of black male aged 15-24   whitem_15_24
% of white male aged 15-24   blackm_25_44
% of black male aged 25-44   whitem_25_44
% of white male aged 25-44   poverty
poverty rate   l_homicide
Logged crime rate   l_larceny
Logged crime rate   l_motor
Logged crime rate   l_police
Logged police presence   l_income
Logged income   l_prisoner
Logged number of prisoners   l_lagprisoner
Lagged log prisoners   l_exp_subsidy
Logged subsidy spending   l_exp_pubwelfare
Logged public welfare spending   lead1,lead2,lead3,lead4,lead5,lead6,lead7,lead8,lead9,lag0,lag1,lag2,lag3,lag4,lag5
Indicators of how many time periods until/since treatment   popwt
Population weight   r20001,r20002,r20003,r20004,r20011,r20012,r20013,r20014,r20021,r20022,r20023,r20024,r20031,r20032,r20033,r20034,r20041,r20042,r20043,r20044,r20051,r20052,r20053,r20054,r20061,r20062,r20063,r20064,r20071,r20072,r20073,r20074,r20081,r20082,r20083,r20084,r20091,r20092,r20093,r20094,r20101,r20102,r20103,r20104
Region-quarter fixed effects   trend_1,trend_10,trend_11,trend_12,trend_13,trend_14,trend_15,trend_16,trend_17,trend_18,trend_19,trend_2,trend_20,trend_21,trend_22,trend_23,trend_24,trend_25,trend_26,trend_27,trend_28,trend_29,trend_3,trend_30,trend_31,trend_32,trend_33,trend_34,trend_35,trend_36,trend_37,trend_38,trend_39,trend_4,trend_40,trend_41,trend_42,trend_43,trend_44,trend_45,trend_46,trend_47,trend_48,trend_49,trend_5,trend_50,trend_51,trend_6,trend_7,trend_8,trend_9
State linear time trends     Details  
This data is used in the Difference-in-Differences chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cheng, Cheng, and Mark Hoekstra. 2013. “Does Strengthening Self-Defense Law Deter Crime or Escalate Violence? Evidence from Expansions to Castle Doctrine.” Journal of Human Resources 48 (3): 821–54.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-close_college","causaldata","close_college","Data from Card (1995) to estimate the effect of college education on earnings",3010,8,4,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/close_college.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/close_college.html","close_college R Documentation   Data from Card (1995) to estimate the effect of college education on earnings   Description  
Data from the National Longitudinal Survey Young Men Cohort. This data is used to estimate the effect of college education on earnings, using the presence of a nearby (in-county) college as an instrument for college attendance.    Usage    close_college    Format  
A data frame with 3010 rows and 8 variables    lwage
Log wages   educ
Years of education   exper
Years of work experience   black
Race: Black   south
In the southern United States   married
Is married   smsa
In a Standard Metropolitan Statistical Area (urban)   nearc4
There is a four-year college in the county     Details  
This data is used in the Instrumental Variables chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Card, David. 1995. “Aspects of Labour Economics: Essays in Honour of John Vanderkamp.” In. University of Toronto Press.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-close_elections_lmb","causaldata","close_elections_lmb","A close-elections regression discontinuity study from Lee, Moretti, and Butler (2004)",13588,9,2,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/close_elections_lmb.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/close_elections_lmb.html","close_elections_lmb R Documentation   A close-elections regression discontinuity study from Lee, Moretti, and Butler (2004)   Description  
This data comes from a close-elections regression discontinuity study from Lee, Moretti, and Butler (2004). The design is intended to test convergence and divergence in policy. Major effects of electing someone from a particular party on policy outcomes *in a close race* indicates that the victor does what they want. Small or null effects indicate that the electee moderates their position towards their nearly-split electorate.    Usage    close_elections_lmb    Format  
A data frame with 13588 rows and 9 variables    state
ICPSR state code   district
district code   id
Election ID   score
ADA voting score (higher = more liberal)   year
Year of election   demvoteshare
Democratic share of the vote   democrat
Democratic victory   lagdemocrat
Lagged Democratic victory   lagdemvoteshare
Lagged democratic share of the vote     Details  
This data is used in the Regression Discontinuity chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Lee, David S., Enrico Moretti, and Matthew J. Butler. 2004. “Do Voters Affect or Elect Policies: Evidence from the U.S. House.” Quarterly Journal of Economics 119 (3): 807–59.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-cps_mixtape","causaldata","cps_mixtape","Observational counterpart to nsw_mixtape data",15992,11,4,1,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/cps_mixtape.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/cps_mixtape.html","cps_mixtape R Documentation   Observational counterpart to nsw_mixtape data   Description  
Data from the Current Population Survey on participation in the National Supported Work Demonstration (NSW) job-training program experiment. This is used as an observational comparison to the NSW experimental data from the nsw_mixtape data.    Usage    cps_mixtape    Format  
A data frame with 15992 rows and 11 variables    data_id
Individual ID   treat
In the National Supported Work Demonstration Job Training Program   age
Age in years   educ
Years of education   black
Race: Black   hisp
Ethnicity: Hispanic   marr
Married   nodegree
Has no degree   re74
Real earnings 1974   re75
Real earnings 1975   re78
Real earnings 1978     Details  
This data is used in the Matching and Subclassification chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Dehejia, Rajeev H., and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62."".    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-credit_cards","causaldata","credit_cards","Data on Taiwanese Credit Card Holders",30000,4,2,0,0,2,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/credit_cards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/credit_cards.html","credit_cards R Documentation   Data on Taiwanese Credit Card Holders   Description  
Data from the UCI Machine Learning Repository on Taiwanese credit card holders, the amount of their credit card bill, and whether their payment was late.    Usage    credit_cards    Format  
A data frame with 30000 rows and 4 variables    LateSept
Credit card payment is late in Sept 2005   LateApril
Credit card payment is late in April 2005   BillApril
Total bill in April 2005 in thousands of New Taiwan Dollars   AGE
Age of card-holder     Details  
This data is used in the Matching chapter of The Effect by Huntington-Klein.    Source  
Lichman, Moshe. 2013. UCI Machine Learning Repository.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-gapminder","causaldata","gapminder","Gapminder data",1704,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/gapminder.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/gapminder.html","gapminder R Documentation   Gapminder data   Description  
The gapminder data contains data on life expectancy and GDP per capita by country and year.    Usage    gapminder    Format  
A data frame with 1704 rows and 6 variables    country
The country   continent
The continent the country is in   year
The year data was collected. Ranges from 1952 to 2007 in increments of 5 years   lifeExp
Life expectancy at birth, in years   pop
Population   gdpPercap
GDP per capita (US$, inflation-adjusted)     Details  
This data set is the same one found in the gapminder package in R as of 2020. This data set is used in the Fixed Effects chapter of The Effect .    Source  
https://www.gapminder.org/data/    
Jennifer Bryan (2017). gapminder: Data from Gapminder. R package version 0.3.0. https://CRAN.R-project.org/package=gapminder     References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-google_stock","causaldata","google_stock","Google Stock Data",84,3,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/google_stock.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/google_stock.html","google_stock R Documentation   Google Stock Data   Description  
The google_stock data contains data on daily stock returns for Google and the S&P 500 for May through Augut 2015, centering around the August 10, 2015 announcement that Google would reorganize under parent company Alphabet.    Usage    google_stock    Format  
A data frame with 84 rows and 3 variables    Date
The date   Google_Return
Daily GOOG Stock Return (1 = 100 percent daily return)   SP500_Return
Daily S&P 500 Index Return (1 = 100 percent daily return)     Details  
This data was downloaded using the tidyquant package, and is used in the Event Studies chapter of The Effect .    Source  
Matt Dancho and Davis Vaughan (2021). tidyquant: Tidy Quantitative Financial Analysis. R package version 1.0.3. https://CRAN.R-project.org/package=tidyquant     References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-gov_transfers","causaldata","gov_transfers","Data from ""Government Transfers and Political Support""",1948,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/gov_transfers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/gov_transfers.html","gov_transfers R Documentation   Data from ""Government Transfers and Political Support""   Description  
The gov_transfers data contains data from Manacorda, Miguel, and Vigorito (2011) on government transfer program that was administered based on an income cutoff. Data is pre-limited to households that were just around the income cutoff.    Usage    gov_transfers    Format  
A data frame with 1948 rows and 5 variables    Income_Centered
Income measure, centered around program cutoff (negative value = eligible)   Education
Household average years of education among those 16+   Age
Household average age   Participation
Participation in transfers   Support
Measure of support for the government     Details  
This data is used in the Regression Discontinuity chapter of The Effect .    Source  
Manacorda, M., Miguel, E. and Vigorito, A., 2011. Government transfers and political support. American Economic Journal: Applied Economics , 3(3), pp.1-28.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-gov_transfers_density","causaldata","gov_transfers_density","Data from ""Government Transfers and Political Support"" for Density Tests",52549,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/gov_transfers_density.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/gov_transfers_density.html","gov_transfers_density R Documentation   Data from ""Government Transfers and Political Support"" for Density Tests   Description  
The gov_transfers_density data contains data from Manacorda, Miguel, and Vigorito (2011) on government transfer program that was administered based on an income cutoff. As opposed to the gov_transfers data set, this data set only contains income information, but has a wider range of it, for use with density discontinuity tests.    Usage    gov_transfers_density    Format  
A data frame with 52549 rows and 1 variable:    Income_Centered
Income measure, centered around program cutoff (negative value = eligible)     Details  
This data is used in the Regression Discontinuity chapter of The Effect .    Source  
Manacorda, M., Miguel, E. and Vigorito, A., 2011. Government transfers and political support. American Economic Journal: Applied Economics , 3(3), pp.1-28.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-greek_data","causaldata","greek_data","Data from a fictional randomized heart transplant study",20,4,3,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/greek_data.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/greek_data.html","greek_data R Documentation   Data from a fictional randomized heart transplant study   Description  
greek_data is a fictional data set from Table 2.2 in Chapter 2 of Causal Inference. From the book: ""Table 2.2 shows the data from our heart transplant randomized study. Besides data on treatment A (1 if the individual received a transplant, 0 otherwise) and outcome Y (1 if the individual died, 0 otherwise), Table 2.2 also contains data on the prognostic factor L (1 if the individual was in critical condition, 0 otherwise), which we measured before treatment was assigned.""    Usage    greek_data    Format  
A data frame with 20 rows and 4 variables:    name
The name of a Greek god   l
A prognostic factor   a
The treatment, a heart transplant   y
The outcome, death     Source  
Hernán and Robins. Causal Inference. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/"
"causaldata-mortgages","causaldata","mortgages","Data from ""How do Mortgage Subsidies Affect Home Ownership? Evidence from the Mid-Century GI Bills""",214144,6,3,1,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/mortgages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/mortgages.html","mortgages R Documentation   Data from ""How do Mortgage Subsidies Affect Home Ownership? Evidence from the Mid-Century GI Bills""   Description  
The mortgages data contains data from Fetter (2015) on home ownership rates by men, focusing on whether they were born at the right time to be eligible for mortgage subsidies based on their military service.    Usage    mortgages    Format  
A data frame with 214144 rows and 6 variables    bpl
Birth State   qob
Quarter of birth   nonwhite
White/nonwhite race indicator. 1 = Nonwhite   vet_wwko
Veteran of either the Korean war or World War II   home_ownership
Owns a home   qob_minus_kw
Quarter of birth centered on eligibility for mortgage subsidy (0+ = eligible)     Details  
This data is used in the Regression Discontinuity chapter of The Effect .    Source  
Fetter, D.K., 2013. How do mortgage subsidies affect home ownership? Evidence from the mid-century GI bills. American Economic Journal: Economic Policy , 5(2), pp.111-47.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-Mroz","causaldata","Mroz","U.S. Women's Labor-Force Participation",753,8,3,0,0,3,5,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/Mroz.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/Mroz.html","Mroz R Documentation   U.S. Women's Labor-Force Participation   Description  
The Mroz data frame has 753 rows and 8 columns. The observations, from the Panel Study of Income Dynamics (PSID), are married women.    Usage    Mroz    Format  
A data frame with 753 rows and 8 variables    lfp
Labor-force participation   k5
Number of children 5 years old or younger   k618
Number of children 6 to 17 years old   age
Age in years   wc
Wife attended college   hc
Husband attended college   lwg
Log expected wage rate. For women in the labor force, the actual wage rate; for women not in the labor force, an imputed value based on the regression of lwg on the other variables.   inc
Family income exclusive of wife's income     Details  
This data set is a lightly edited version of the one found in the carData package in R. It is used in the Describing Relationships chapter of The Effect .    Source  
Mroz, T. A. (1987) The sensitivity of an empirical model of married women's hours of work to economic and statistical assumptions. *Econometrica* 55, 765–799.   
John Fox, Sanford Weisberg and Brad Price (2020). carData: Companion to Applied Regression Data Sets. R package version 3.0-4. https://CRAN.R-project.org/package=carData     References  
Fox, J. (2016) *Applied Regression Analysis and Generalized Linear Models,* Third Edition. Sage.   
Fox, J. (2000) *Multiple and Generalized Nonparametric Regression.* Sage.   
Fox, J. and Weisberg, S. (2019) *An R Companion to Applied Regression.* Third Edition, Sage.   
Long. J. S. (1997) *Regression Models for Categorical and Limited Dependent Variables.* Sage.   
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-nhefs","causaldata","nhefs","National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study",1629,67,27,0,5,0,62,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nhefs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/nhefs.html","nhefs R Documentation   National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study   Description  
nhefs is a cleaned data set of the data used in Causal Inference by Hernán and Robins. nhefs is dataset containing data from the National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study (NHEFS). The NHEFS was jointly initiated by the National Center for Health Statistics and the National Institute on Aging in collaboration with other agencies of the United States Public Health Service. A detailed description of the NHEFS, together with publicly available data sets and documentation, can be found at https://wwwn.cdc.gov/nchs/nhanes/nhefs/ .    Usage    nhefs    Format  
A data frame with 1629 rows and 67 variables. The codebook is available as nhefs_codebook .    Source  
https://wwwn.cdc.gov/nchs/nhanes/nhefs/     References  
Hernán and Robins. Causal Inference. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/"
"causaldata-nhefs_codebook","causaldata","nhefs_codebook","NHEFS Codebook",64,2,0,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nhefs_codebook.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/nhefs_codebook.html","nhefs_codebook R Documentation   NHEFS Codebook   Description  
nhefs_codebook is the codebook for nhefs and nhefs_complete .    Usage    nhefs_codebook    Format  
A data frame with 64 rows and 2 variables.    variable
The variable being described   description
The variable description     Source  
https://wwwn.cdc.gov/nchs/nhanes/nhefs/     References  
Hernán and Robins. Causal Inference. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/"
"causaldata-nhefs_complete","causaldata","nhefs_complete","Complete-Data National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study",1566,67,26,0,5,0,62,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nhefs_complete.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/nhefs_complete.html","nhefs_complete R Documentation   Complete-Data National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study   Description  
nhefs_complete is the same as nhefs , but only participants with complete data are included. The variables that need to be complete to be included are: qsmk , sex , race , age , school , smokeintensity , smokeyrs , exercise , active , wt71 , wt82 , and wt82_71 .    Usage    nhefs_complete    Format  
A data frame with 1556 rows and 67 variables. The codebook is available as nhefs_codebook .    Source  
https://wwwn.cdc.gov/nchs/nhanes/nhefs/     References  
Hernán and Robins. Causal Inference. https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/"
"causaldata-nsw_mixtape","causaldata","nsw_mixtape","Data from the National Supported Work Demonstration (NSW) job-training program",445,11,5,1,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/nsw_mixtape.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/nsw_mixtape.html","nsw_mixtape R Documentation   Data from the National Supported Work Demonstration (NSW) job-training program   Description  
Data from the National Supported Work Demonstration (NSW) job-training program experiment, where those treated were guaranteed a job for 9-18 months.    Usage    nsw_mixtape    Format  
A data frame with 445 rows and 11 variables    data_id
Individual ID   treat
In the National Supported Work Demonstration Job Training Program   age
Age in years   educ
Years of education   black
Race: Black   hisp
Ethnicity: Hispanic   marr
Married   nodegree
Has no degree   re74
Real earnings 1974   re75
Real earnings 1975   re78
Real earnings 1978     Details  
This data is used in the Matching and Subclassification chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Lalonde, Robert. 1986. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data.” American Economic Review 76 (4): 604–20.   
Dehejia, Rajeev H., and Sadek Wahba. 1999. “Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs.” Journal of the American Statistical Association 94 (448): 1053–62."".    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-organ_donations","causaldata","organ_donations","Organ Donation Data",162,4,0,2,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/organ_donations.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/organ_donations.html","organ_donations R Documentation   Organ Donation Data   Description  
The organ_donation data contains data from Kessler and Roth (2014) on organ donation rates by state and quarter. The state of California enacted an active-choice phrasing for their organ donation sign-up questoin in Q32011. The only states included in the data are California and those that can serve as valid controls; see Kessler and Roth (2014).    Usage    organ_donations    Format  
A data frame with 162 rows and 3 variables    State
The state, where California is the Treated group   Quarter
Quarter of observation, in ""Q""QYYYY format   Rate
Organ donation rate   Quarter_Num
Quarter of observation in numerical format. 1 = Quarter 4, 2010     Details  
This data is used in the Difference-in-Differences chapter of The Effect .    Source  
Kessler, J.B. and Roth, A.E., 2014. Don't take 'no' for an answer: An experiment with actual organ donor registrations. National Bureau of Economic Research working paper No. 20378. https://www.nber.org/papers/w20378     References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-restaurant_inspections","causaldata","restaurant_inspections","Data on Restaurant Inspections",27178,5,1,1,0,1,3,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/restaurant_inspections.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/restaurant_inspections.html","restaurant_inspections R Documentation   Data on Restaurant Inspections   Description  
The restaurant_inspections data contains data on restaurant health inspections performed in Anchorage, Alaska.    Usage    restaurant_inspections    Format  
A data frame with 27178 rows and 5 variables    business_name
Name of restaurant/chain   inspection_score
Health Inspection Score   Year
Year of inspection   NumberofLocations
Number of locations in restaurant chain   Weekend
Was the inspection performed on a weekend?     Details  
This data set is used in the Regression chapter of The Effect .    Source  
Camus, Louis-Ashley. 2020. https://www.kaggle.com/loulouashley/inspection-score-restaurant-inspection     References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-ri","causaldata","ri","A simple simulated data set for calculating p-values",8,5,1,3,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/ri.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/ri.html","ri R Documentation   A simple simulated data set for calculating p-values   Description  
This simulated data allows for a quick and easy calculation of a p-value using randomization inference.    Usage    ri    Format  
A data frame with 8 rows and 5 variables    name
Fictional Name   d
Treatment   y
Outcome   y0
Outcome if untreated   y1
Outcome if treated     Details  
This data is used in the Potential Outcomes Causal Model chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html .    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-scorecard","causaldata","scorecard","Earnings and Loan Repayment in US Four-Year Colleges",48445,8,0,2,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/scorecard.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/scorecard.html","scorecard R Documentation   Earnings and Loan Repayment in US Four-Year Colleges   Description  
From the College Scorecard, this data set contains by-college-by-year data on how students who attended those colleges are doing.    Usage    scorecard    Format  
A data frame with 48,445 rows and 8 variables:    unitid
College identifiers   inst_name
Name of the college or university   state_abbr
Two-letter abbreviation for the state the college is in   pred_degree_awarded_ipeds
Predominant degree awarded. 1 = less-than-two-year, 2 = two-year, 3 = four-year+   year
Year in which outcomes are measured   earnings_med
Median earnings among students (a) who received federal financial aid, (b) who began as undergraduates at the institution ten years prior, (c) with positive yearly earnings   count_not_working
Number of students who are (a) not working (not necessarily unemployed), (b) received federal financial aid, and (c) who began as undergraduates at the institution ten years prior   count_working
Number of students who are (a) working, (b) who received federal financial aid, and (c) who began as undergraduates at the institution ten years prior     Details  
This data is not just limited to four-year colleges and includes a very wide variety of institutions.   
Note that the labor market (earnings, working) and repayment rate data do not refer to the same cohort of students, but rather are matched on the year in which outcomes are recorded. Labor market data refers to cohorts beginning college as undergraduates ten years prior, repayment rate data refers to cohorts entering repayment seven years prior.   
Data was downloaded using the Urban Institute's educationdata package.   
This data was used in the Describing Variables chapter of The Effect by Huntington-Klein    Source  
Education Data Portal (Version 0.4.0 - Beta), Urban Institute, Center on Education Data and Policy, accessed June 28, 2019. https://educationdata.urban.org/documentation/ , Scorecard.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-snow","causaldata","snow","Data from John Snow's 1855 study of the cause of cholera",4,4,3,2,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/snow.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/snow.html","snow R Documentation   Data from John Snow's 1855 study of the cause of cholera   Description  
A subset of the aggregated death rate data from Snow's legendary study of the source of the London Cholera outbreak.    Usage    snow    Format  
A data frame with 4 rows and 4 variables    year
Year   supplier
Water pump supplier   treatment
Status of water pump   deathrate
Deaths per 10k 1851 population     Details  
This data is used in the Difference-in-Differences chapter of The Effect by Huntington-Klein.    Source  
Snow, John. 1855. 'On the Mode of Communication of Cholera'. John Churchill.""   
Coleman, Thomas. 2019. 'Causality in the time of cholera: John Snow as a prototype for causal inference.' SSRN 3262234.""    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-social_insure","causaldata","social_insure","Data from ""Social Networks and the Decision to Insure""",1410,13,5,2,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/social_insure.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/social_insure.html","social_insure R Documentation   Data from ""Social Networks and the Decision to Insure""   Description  
The social_insure data contains data from Jai, De Janvry, and Saoudlet (2015) on a two-round social network-based experiment on getting farmers to get insurance. See the paper for more details.    Usage    social_insure    Format  
A data frame with 1410 rows and 13 variables    address
Natural village   village
Administrative village   takeup_survey
Whether farmer ended up purchasing insurance. (1 = yes)   age
Household Characteristics - Age   agpop
Household Characteristics - Household Size   ricearea_2010
Area of Rice Production   disaster_prob
Perceived Probability of Disasters Next Year   male
Household Caracteristics: Gender of Household Head (1 = male)   default
""Default option"" in experimental format assigned to. (1 = default is to buy, 0 = default is to not buy)   intensive
Whether or not was assigned to ""intensive"" experimental session (1 = yes)   risk_averse
Risk aversion measurement   literacy
1 = literate, 0 = illiterate   pre_takeup_rate
Takeup rate prior to experiment     Details  
This data is used in the Instrumental Variables chapter of The Effect .    Source  
Cai, J., De Janvry, A. and Sadoulet, E., 2015. Social networks and the decision to insure. American Economic Journal: Applied Economics , 7(2), pp.81-108.    References  
Huntington-Klein. 2021. The Effect: An Introduction to Research Design and Causality. https://theeffectbook.net ."
"causaldata-texas","causaldata","texas","Data on prison capacity expansion in Texas",816,12,0,1,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/texas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/texas.html","texas R Documentation   Data on prison capacity expansion in Texas   Description  
This data looks at the massive expansion in prison capacity in Texas that occurred in 1993 under Governor Ann Richards, and the effect of that expansion on the number of Black men in prison.    Usage    texas    Format  
A data frame with 816 rows and 12 variables    statefip
State FIPS code   year
Year   bmprison
Number of Black men in prison   wmprison
Number of White men in prison   alcohol
Alcohol consumption per capita   income
Median income   ur
Unemployment rate   poverty
Poverty rate   black
Percentage of the population that is Black   perc1519
Percentage of the population that is age 15-19   aidscapita
AIDS mortality per 100,000 in t   state
State name     Details  
This data is used in the Synthetic Control chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham and Kang. 2019. “Studying the Effect of Incarceration Shocks to Drug Markets.” Unpublished manuscript. http://www.scunning.com/files/mass_incarceration_and_drug_abuse.pdf     References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-thornton_hiv","causaldata","thornton_hiv","Data from HIV information experiment in Thornton (2008)",4820,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/thornton_hiv.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/thornton_hiv.html","thornton_hiv R Documentation   Data from HIV information experiment in Thornton (2008)   Description  
thornton_hiv comes from an experiment in Malawi looking at whether cash incentives could encourage people to learn the results of their HIV tests.    Usage    thornton_hiv    Format  
A data frame with 4820 rows and 7 variables    villnum
Village ID   got
Got HIV results   distvct
Distance in kilometers   tinc
Total incentive   any
Received any incentive   age
Age   hiv2004
HIV results     Details  
This data is used in the Potential Outcomes Causal Model chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Thornton, Rebecca L. 2008. 'The Demand for, and Impact of, Learning Hiv Status.' American Economic Review 98 (5): 1829–63.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-titanic","causaldata","titanic","Data from the sinking of the Titanic",2201,4,3,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/titanic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/titanic.html","titanic R Documentation   Data from the sinking of the Titanic   Description  
titanic comes from the sinking of the Titanic, and can be used to look at survival by different demographic characteristics.    Usage    titanic    Format  
A data frame with 4820 rows and 7 variables    class
class (ticket)   age
Age (Child vs. Adult)   sex
Gender   survived
Survived     Details  
This data is used in the Matching and Subclassification chapter of Causal Inference: The Mixtape by Cunningham.    Source  
British Board of Trade (1990), Report on the Loss of the ‘Titanic’ (S.S.). British Board of Trade Inquiry Report (reprint). Gloucester, UK: Allan Sutton Publishing.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-training_bias_reduction","causaldata","training_bias_reduction","Simulated data from a job training program for a bias reduction method",8,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/training_bias_reduction.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/training_bias_reduction.html","training_bias_reduction R Documentation   Simulated data from a job training program for a bias reduction method   Description  
This simulated data is used to demonstrate the bias-reduction method in matching as per Abadie and Imbens (2011).    Usage    training_bias_reduction    Format  
A data frame with 8 rows and 4 variables    Unit
Unit ID   Y
Outcome   D
Treatment   X
Matching variable     Details  
This data is used in the Matching and Subclassification chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html .    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-training_example","causaldata","training_example","Simulated data from a job training program",25,9,0,1,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/training_example.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/training_example.html","training_example R Documentation   Simulated data from a job training program   Description  
This simulated data, which is presented in the form of a full results, table, is used to demonstrate a matching procedure.    Usage    training_example    Format  
A data frame with 25 rows and 9 variables    unit_treat
Unit ID for treated observations   age_treat
age for treated observations   earnings_treat
earnings for treated observations   unit_control
Unit ID for control observations   age_control
age for control observations   earnings_control
earnings for control observations   unit_matched
Unit ID for matched controls   age_matched
age for matched controls   earnings_matched
earnings for matched controls     Details  
This data is used in the Matching and Subclassification chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html .    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"causaldata-yule","causaldata","yule","Data on 19th century English Poverty from Yule (1899)",32,5,0,1,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/yule.csv","https://vincentarelbundock.github.io/Rdatasets/doc/causaldata/yule.html","yule R Documentation   Data on 19th century English Poverty from Yule (1899)   Description  
yule allows for a look at the correlation between poverty relief and poverty rates in England in the 19th century.    Usage    yule    Format  
A data frame with 32 rows and 5 variables    location
Location in England   paup
Pauperism Growth   outrelief
Poverty Relief Growth   old
Annual growth in aged population   pop
Annual growth in population     Details  
This data is used in the Potential Outcomes Causal Model chapter of Causal Inference: The Mixtape by Cunningham.    Source  
Yule, G. Udny. 1899. 'An Investigation into the Causes of Changes in Pauperism in England, Chiefly During the Last Two Interensal Decades.' Journal of Royal Statistical Society 62: 249–95.    References  
Cunningham. 2021. Causal Inference: The Mixtape. Yale Press. https://mixtape.scunning.com/index.html ."
"cluster-agriculture","cluster","agriculture","European Union Agricultural Workforces",12,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/agriculture.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/agriculture.html","agriculture R Documentation   European Union Agricultural Workforces   Description  
Gross National Product (GNP) per capita and percentage of the population working in agriculture for each country belonging to the European Union in 1993.    Usage   data(agriculture)   Format  
A data frame with 12 observations on 2 variables:   
 [ , 1] x numeric per capita GNP
 [ , 2] y numeric percentage in agriculture   
The row names of the data frame indicate the countries.    Details  
The data seem to show two clusters, the “more agricultural” one consisting of Greece, Portugal, Spain, and Ireland.    Source  
Eurostat (European Statistical Agency, 1994):  Cijfers en feiten: Een statistisch portret van de Europese Unie .    References  
see those in agnes .    See Also  
agnes , daisy , diana .    Examples    data(agriculture) ## Compute the dissimilarities using Euclidean metric and without ## standardization daisy(agriculture, metric = ""euclidean"", stand = FALSE) ## 2nd plot is similar to Figure 3 in Struyf et al (1996) plot(pam(agriculture, 2)) ## Plot similar to Figure 7 in Struyf et al (1996) ## Not run: plot(agnes(agriculture), ask = TRUE) ## Plot similar to Figure 8 in Struyf et al (1996) ## Not run: plot(diana(agriculture), ask = TRUE)"
"cluster-animals","cluster","animals","Attributes of Animals",20,6,6,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/animals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/animals.html","animals R Documentation   Attributes of Animals   Description  
This data set considers 6 binary attributes for 20 animals.    Usage   data(animals)   Format  
A data frame with 20 observations on 6 variables:   
 [ , 1] war warm-blooded
 [ , 2] fly can fly
 [ , 3] ver vertebrate
 [ , 4] end endangered
 [ , 5] gro live in groups
 [ , 6] hai have hair
   
All variables are encoded as 1 = 'no', 2 = 'yes'.    Details  
This dataset is useful for illustrating monothetic (only a single variable is used for each split) hierarchical clustering.    Source  
Leonard Kaufman and Peter J. Rousseeuw (1990):  Finding Groups in Data  (pp 297ff). New York: Wiley.    References  
see Struyf, Hubert & Rousseeuw (1996), in agnes .    Examples    data(animals) apply(animals,2, table) # simple overview ma <- mona(animals) ma ## Plot similar to Figure 10 in Struyf et al (1996) plot(ma)"
"cluster-chorSub","cluster","chorSub","Subset of C-horizon of Kola Data",61,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/chorSub.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/chorSub.html","chorSub R Documentation   Subset of C-horizon of Kola Data   Description  
This is a small rounded subset of the C-horizon data  chorizon from package mvoutlier .    Usage   data(chorSub)   Format  
A data frame with 61 observations on 10 variables. The variables contain scaled concentrations of chemical elements.    Details  
This data set was produced from chorizon via these statements:     data(chorizon, package = ""mvoutlier"") chorSub <- round(100*scale(chorizon[,101:110]))[190:250,] storage.mode(chorSub) <- ""integer"" colnames(chorSub) <- gsub(""_.*"", '', colnames(chorSub))    Source  
Kola Project (1993-1998)    See Also  
chorizon in package mvoutlier and other Kola data in the same package.    Examples    data(chorSub) summary(chorSub) pairs(chorSub, gap= .1)# some outliers"
"cluster-flower","cluster","flower","Flower Characteristics",18,8,3,0,6,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/flower.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/flower.html","flower R Documentation   Flower Characteristics   Description  
8 characteristics for 18 popular flowers.   Usage   data(flower)   Format  
A data frame with 18 observations on 8 variables:   
 [ , ""V1""] factor winters
 [ , ""V2""] factor shadow
 [ , ""V3""] factor tubers
 [ , ""V4""] factor color
 [ , ""V5""] ordered soil
 [ , ""V6""] ordered preference
 [ , ""V7""] numeric height
 [ , ""V8""] numeric distance    V1
winters, is binary and indicates whether the plant may be left in the garden when it freezes.   V2
shadow, is binary and shows whether the plant needs to stand in the shadow.   V3
tubers, is asymmetric binary and distinguishes between plants with tubers and plants that grow in any other way.   V4
color, is nominal and specifies the flower's color (1 = white, 2 = yellow, 3 = pink, 4 = red, 5 = blue).   V5
soil, is ordinal and indicates whether the plant grows in dry (1), normal (2), or wet (3) soil.   V6
preference, is ordinal and gives someone's preference ranking going from 1 to 18.   V7
height, is interval scaled, the plant's height in centimeters.   V8
distance, is interval scaled, the distance in centimeters that should be left between the plants.     References  
Struyf, Hubert and Rousseeuw (1996), see agnes .    Examples    data(flower) ## Example 2 in ref daisy(flower, type = list(asymm = 3)) daisy(flower, type = list(asymm = c(1, 3), ordratio = 7))"
"cluster-plantTraits","cluster","plantTraits","Plant Species Traits Data",136,31,20,0,28,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/plantTraits.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/plantTraits.html","plantTraits R Documentation   Plant Species Traits Data   Description  
This dataset constitutes a description of 136 plant species according to biological attributes (morphological or reproductive)    Usage   data(plantTraits)    Format  
A data frame with 136 observations on the following 31 variables.    pdias
Diaspore mass (mg)   longindex
Seed bank longevity   durflow
Flowering duration   height
Plant height, an ordered factor with levels  1 < 2 < ... < 8 .     begflow
Time of first flowering, an ordered factor with levels 1 < 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9     mycor
Mycorrhizas, an ordered factor with levels 0 never < 1 sometimes< 2 always   vegaer
aerial vegetative propagation, an ordered factor with levels 0 never < 1 present but limited< 2 important.   vegsout
underground vegetative propagation, an ordered factor with 3 levels identical to vegaer above.   autopoll
selfing pollination, an ordered factor with levels 0 never < 1 rare < 2 often< the rule 3   insects
insect pollination, an ordered factor with 5 levels 0 < ... < 4 .   wind
wind pollination, an ordered factor with 5 levels 0 < ... < 4 .   lign
a binary factor with levels 0:1 , indicating if plant is woody.   piq
a binary factor indicating if plant is thorny.   ros
a binary factor indicating if plant is rosette.   semiros
semi-rosette plant, a binary factor ( 0 : no; 1 : yes).   leafy
leafy plant, a binary factor.   suman
summer annual, a binary factor.   winan
winter annual, a binary factor.   monocarp
monocarpic perennial, a binary factor.   polycarp
polycarpic perennial, a binary factor.   seasaes
seasonal aestival leaves, a binary factor.   seashiv
seasonal hibernal leaves, a binary factor.   seasver
seasonal vernal leaves, a binary factor.   everalw
leaves always evergreen, a binary factor.   everparti
leaves partially evergreen, a binary factor.   elaio
fruits with an elaiosome (dispersed by ants), a binary factor.   endozoo
endozoochorous fruits, a binary factor.   epizoo
epizoochorous fruits, a binary factor.   aquat
aquatic dispersal fruits, a binary factor.   windgl
wind dispersed fruits, a binary factor.   unsp
unspecialized mechanism of seed dispersal, a binary factor.     Details  
Most of factor attributes are not disjunctive. For example, a plant can be usually pollinated by insects but sometimes self-pollination can occured.    Source  
Vallet, Jeanne (2005)  Structuration de communautés végétales et analyse comparative de traits biologiques le long d'un gradient d'urbanisation . Mémoire de Master 2 'Ecologie-Biodiversité-Evolution'; Université Paris Sud XI, 30p.+ annexes (in french)    Examples    data(plantTraits) ## Calculation of a dissimilarity matrix library(cluster) dai.b <- daisy(plantTraits, type = list(ordratio = 4:11, symm = 12:13, asymm = 14:31)) ## Hierarchical classification agn.trts <- agnes(dai.b, method=""ward"") plot(agn.trts, which.plots = 2, cex= 0.6) plot(agn.trts, which.plots = 1) cutree6 <- cutree(agn.trts, k=6) cutree6 ## Principal Coordinate Analysis cmdsdai.b <- cmdscale(dai.b, k=6) plot(cmdsdai.b[, 1:2], asp = 1, col = cutree6)"
"cluster-pluton","cluster","pluton","Isotopic Composition Plutonium Batches",45,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/pluton.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/pluton.html","pluton R Documentation   Isotopic Composition Plutonium Batches   Description  
The pluton data frame has 45 rows and 4 columns, containing percentages of isotopic composition of 45 Plutonium batches.    Usage   data(pluton)   Format  
This data frame contains the following columns:    Pu238
the percentages of (238)Pu , always less than 2 percent.   Pu239
the percentages of (239)Pu , typically between 60 and 80 percent (from neutron capture of Uranium,  (238)U ).   Pu240
percentage of the plutonium 240 isotope.   Pu241
percentage of the plutonium 241 isotope.     Details  
Note that the percentage of plutonium~242 can be computed from the other four percentages, see the examples.   
In the reference below it is explained why it is very desirable to combine these plutonium patches in three groups of similar size.    Source  
Available as ‘ pluton.dat ’ from the archive of the University of Antwerpen, ‘ ..../datasets/clusplot-examples.tar.gz ’, no longer available.    References  
Rousseeuw, P.J. and Kaufman, L and Trauwaert, E. (1996) Fuzzy clustering using scatter matrices,  Computational Statistics and Data Analysis 23 (1), 135–151.    Examples    data(pluton) hist(apply(pluton,1,sum), col = ""gray"") # between 94% and 100% pu5 <- pluton pu5$Pu242 <- 100 - apply(pluton,1,sum) # the remaining isotope. pairs(pu5)"
"cluster-ruspini","cluster","ruspini","Ruspini Data",75,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/ruspini.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/ruspini.html","ruspini R Documentation   Ruspini Data   Description  
The Ruspini data set, consisting of 75 points in four groups that is popular for illustrating clustering techniques.    Usage   data(ruspini)   Format  
A data frame with 75 observations on 2 variables giving the x and y coordinates of the points, respectively.    Source  
E. H. Ruspini (1970) Numerical methods for fuzzy clustering.  Inform. Sci. 2 , 319–350.    References  
see those in agnes .    Examples    data(ruspini) ## Plot similar to Figure 4 in Stryuf et al (1996) ## Not run: plot(pam(ruspini, 4), ask = TRUE) ## Plot similar to Figure 6 in Stryuf et al (1996) plot(fanny(ruspini, 5))"
"cluster-votes.repub","cluster","votes.repub","Votes for Republican Candidate in Presidential Elections",50,31,0,0,0,0,31,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/votes.repub.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/votes.repub.html","votes.repub R Documentation   Votes for Republican Candidate in Presidential Elections   Description  
A data frame with the percents of votes given to the republican candidate in presidential elections from 1856 to 1976. Rows represent the 50 states, and columns the 31 elections.    Usage   data(votes.repub)   Source  
S. Peterson (1973):  A Statistical History of the American Presidential Elections . New York: Frederick Ungar Publishing Co.   
Data from 1964 to 1976 is from R. M. Scammon, American Votes 12 , Congressional Quarterly."
"cluster-xclara","cluster","xclara","Bivariate Data Set with 3 Clusters",3000,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/cluster/xclara.csv","https://vincentarelbundock.github.io/Rdatasets/doc/cluster/xclara.html","xclara R Documentation   Bivariate Data Set with 3 Clusters   Description  
An artificial data set consisting of 3000 points in 3 quite well-separated clusters.    Usage   data(xclara)   Format  
A data frame with 3000 observations on 2 numeric variables (named  V1 and V2 ) giving the  x and y coordinates of the points, respectively.    Note  
Our version of the xclara is slightly more rounded than the one from read.table(""xclara.dat"") and the relative difference measured by all.equal is 1.15e-7 for  V1 and 1.17e-7 for V2 which suggests that our version has been the result of a options(digits = 7)  formatting.   
Previously (before May 2017), it was claimed the three cluster were each of size 1000, which is clearly wrong. pam(*, 3)  gives cluster sizes of 899, 1149, and 952, which apart from seven “outliers” (or “mislabellings”) correspond to observation indices 1:900 , 901:2050 , and  2051:3000 , see the example.    Source  
Sample data set accompanying the reference below (file ‘ xclara.dat ’ in side ‘ clus_examples.tar.gz ’).    References  
Anja Struyf, Mia Hubert & Peter J. Rousseeuw (1996) Clustering in an Object-Oriented Environment.  Journal of Statistical Software 1 . doi: 10.18637/jss.v001.i04     Examples    ## Visualization: Assuming groups are defined as {1:1000}, {1001:2000}, {2001:3000} plot(xclara, cex = 3/4, col = rep(1:3, each=1000)) p.ID <- c(78, 1411, 2535) ## PAM's medoid indices == pam(xclara, 3)$id.med text(xclara[p.ID,], labels = 1:3, cex=2, col=1:3) px <- pam(xclara, 3) ## takes ~2 seconds cxcl <- px$clustering ; iCl <- split(seq_along(cxcl), cxcl) boxplot(iCl, range = 0.7, horizontal=TRUE, main = ""Indices of the 3 clusters of pam(xclara, 3)"") ## Look more closely now: bxCl <- boxplot(iCl, range = 0.7, plot=FALSE) ## We see 3 + 2 + 2 = 7 clear ""outlier""s or ""wrong group"" observations: with(bxCl, rbind(out, group)) ## out 1038 1451 1610 30 327 562 770 ## group 1 1 1 2 2 3 3 ## Apart from these, what are the robust ranges of indices? -- Robust range: t(iR <- bxCl$stats[c(1,5),]) ## 1 900 ## 901 2050 ## 2051 3000 gc <- adjustcolor(""gray20"",1/2) abline(v = iR, col = gc, lty=3) axis(3, at = c(0, iR[2,]), padj = 1.2, col=gc, col.axis=gc)"
"COUNT-affairs","COUNT","affairs","affairs",601,18,17,0,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/affairs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/affairs.html","affairs R Documentation   affairs   Description  
Data from Fair (1978). Although Fair used a tobit model with the data, the outcome measure can be modeled as a count. In fact, Greene (2003) modeled it as Poisson, but given the amount of overdispersion in the data, employing a negative binomial model is an appropriate strategy. The data is stored in the affairs data set. Naffairs is the response variable, indicating the number of affairs reported by the participant in the past year.   Usage   data(affairs)   Format  
A data frame with 601 observations on the following 18 variables.    naffairs
number of affairs within last year   kids
1=have children;0= no children   vryunhap
(1/0) very unhappily married   unhap
(1/0) unhappily married   avgmarr
(1/0) average married   hapavg
(1/0) happily married   vryhap
(1/0) very happily married   antirel
(1/0) anti religious   notrel
(1/0) not religious   slghtrel
(1/0) slightly religious   smerel
(1/0) somewhat religious   vryrel
(1/0) very religious   yrsmarr1
(1/0) >0.75 yrs   yrsmarr2
(1/0) >1.5 yrs   yrsmarr3
(1/0) >4.0 yrs   yrsmarr4
(1/0) >7.0 yrs   yrsmarr5
(1/0) >10.0 yrs   yrsmarr6
(1/0) >15.0 yrs     Details  
rwm5yr is saved as a data frame. Count models use naffairs as response variable. 0 counts are included.    Source  
Fair, R. (1978). A Theory of Extramarital Affairs, Journal of Political Economy, 86: 45-61. Greene, W.H. (2003). Econometric Analysis, Fifth Edition, New York: Macmillan.    References  
Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic regression Models, Chapman & Hall/CRC    Examples    data(affairs) glmaffp <- glm(naffairs ~ kids + yrsmarr2 + yrsmarr3 + yrsmarr4 + yrsmarr5, family = poisson, data = affairs) summary(glmaffp) exp(coef(glmaffp)) require(MASS) glmaffnb <- glm.nb(naffairs ~ kids + yrsmarr2 + yrsmarr3 + yrsmarr4 + yrsmarr5, data=affairs) summary(glmaffnb) exp(coef(glmaffnb))"
"COUNT-azcabgptca","COUNT","azcabgptca","azcabgptca",1959,6,4,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/azcabgptca.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/azcabgptca.html","azcabgptca R Documentation   azcabgptca   Description  
Random subset of the 1991 Arizona Medicare data for patients hospitalized subsequent to undergoing a CABG (DRGs 106, 107) or PTCA (DRG 112) cardiovascular procedure.   Usage   data(azcabgptca)   Format  
A data frame with 1959 observations on the following 6 variables.    died
systolic blood pressure of subject   procedure
1=CABG; 0=PTCA   gender
1=male; 0=female   age
age of subject   los
hospital length of stay   type
1=emerg/urgent; 0=elective     Details  
azcabgptca is saved as a data frame.    Source  
Hilbe, Negative Binomial Regression, 2nd ed, Cambridge Univ Press    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press    Examples    data(azcabgptca); attach(azcabgptca) table(los); table(procedure, type); table(los, procedure) summary(los) summary(c91a <- glm(los ~ procedure+ type, family=poisson, data=azcabgptca)) modelfit(c91a) summary(c91b <- glm(los ~ procedure+ type, family=quasipoisson, data=azcabgptca)) modelfit(c91b) library(sandwich) sqrt(diag(vcovHC(c91a, type=""HC0"")))"
"COUNT-azdrg112","COUNT","azdrg112","azdrg112",1798,4,3,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/azdrg112.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/azdrg112.html","azdrg112 R Documentation   azdrg112   Description  
The data set relates to the hospital length of stay for patients having a CABG or PTCA (typel) heart procedure. The data comes from the 1995 Arizona Medicare data for DRG (Diagnostic Related Group) 112. Other predictors include gender(1=female) and age75 (1-age 75+). Type is labeled as 1=emergency or urgent admission; 0= elective. Length of stay (los) ranges from 1 to 53 days.   Usage   data(azdrg112)   Format  
A data frame with 1,798 observations on the following 4 variables.    los
hospital length of stay: 1-53 days   gender
1=male; 0=female   type1
1=emergency/urgent admission; 0=elective admission   age75
1=age>75; 0=age<=75     Details  
azdrg112 is saved as a data frame. Count models typically use los as response variable. 0 counts are not included    Source  
DRG 112 data from the 1995 Arizona Medicare (MedPar) State files    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press    Examples    data(azdrg112) glmazp <- glm(los ~ type1 + gender + age75, family=poisson, data=azdrg112) summary(glmazp) exp(coef(glmazp)) library(MASS) glmaznb <- glm.nb(los ~ type1 + gender + age75, data=azdrg112) summary(glmaznb) exp(coef(glmaznb))"
"COUNT-azpro","COUNT","azpro","azpro",3589,6,4,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/azpro.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/azpro.html","azpro R Documentation    azpro    Description  
Data come from the 1991 Arizona cardiovascular patient files. A subset of the fields was selected to model the differential length of stay for patients entering the hospital to receive one of two standard cardiovascular procedures: CABG and PTCA. CABG is the standard acronym for Coronary Artery Bypass Graft, where the flow of blood in a diseased or blocked coronary artery or vein has been grafted to bypass the diseased sections. PTCA, or Percutaneous Transluminal Coronary Angioplasty, is a method of placing a balloon in a blocked coronary artery to open it to blood flow. It is a much less severe method of treatment for those having coronary blockage, with a corresponding reduction in risk.   Usage   data(azpro)   Format  
A data frame with 3589 observations on the following 6 variables.    los
length of hospital stay   procedure
1=CABG;0=PTCA   sex
1=Male; 0=female   admit
1=Urgent/Emerg; 0=elective (type of admission)   age75
1= Age>75; 0=Age<=75   hospital
encrypted facility code (string)     Details  
azpro is saved as a data frame. Count models use los as response variable. 0 counts are structurally excluded   Source  
1991 Arizona Medpar data, cardiovascular patient files, National Health Economics & Research Co.    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    data(azpro) glmazp <- glm(los ~ procedure + sex + admit, family=poisson, data=azpro) summary(glmazp) exp(coef(glmazp)) #glmaznb < -glm.nb(los ~ procedure + sex + admit, data=azpro) #summary(glmaznb) #exp(coef(glmaznb))"
"COUNT-azprocedure","COUNT","azprocedure","azprocedure",3589,6,4,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/azprocedure.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/azprocedure.html","azprocedure R Documentation   azprocedure   Description  
Data come from the 1991 Arizona cardiovascular patient files. A subset of the fields was selected to model the differential length of stay for patients entering the hospital to receive one of two standard cardiovascular procedures: CABG and PTCA. CABG is the standard acronym for Coronary Artery Bypass Graft, where the flow of blood in a diseased or blocked coronary artery or vein has been grafted to bypass the diseased sections. PTCA, or Percutaneous Transluminal Coronary Angioplasty, is a method of placing a balloon in a blocked coronary artery to open it to blood flow. It is a much less severe method of treatment for those having coronary blockage, with a corresponding reduction in risk.   Usage   data(azprocedure)   Format  
A data frame with 3589 observations on the following 6 variables.    los
length of hospital stay   procedure
1=CABG;0=PTCA   sex
1=Male; 0=female   admit
1=Urgent/Emerg; 0=elective (type of admission)   age75
1= Age>75; 0=Age<=75   hospital
encrypted facility code (string)     Details  
azprocedure is saved as a data frame. Count models use los as response variable. 0 counts are structurally excluded   Source  
1991 Arizona Medpar data, cardiovascular patient files, National Health Economics & Research Co.    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    library(MASS) library(msme) data(azprocedure) glmazp <- glm(los ~ procedure + sex + admit, family=poisson, data=azprocedure) summary(glmazp) exp(coef(glmazp)) nb2 <- nbinomial(los ~ procedure + sex + admit, data=azprocedure) summary(nb2) exp(coef(nb2)) glmaznb <- glm.nb(los ~ procedure + sex + admit, data=azprocedure) summary(glmaznb) exp(coef(glmaznb))"
"COUNT-badhealth","COUNT","badhealth","badhealth",1127,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/badhealth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/badhealth.html","badhealth R Documentation   badhealth   Description  
From German health survey data for the year 1998 only.   Usage   data(badhealth)   Format  
A data frame with 1,127 observations on the following 3 variables.    numvisit
number of visits to doctor during 1998   badh
1=patient claims to be in bad health; 0=not in bad health   age
age of patient: 20-60     Details  
badhealth is saved as a data frame. Count models use numvisit as the response variable, 0 counts are included.    Source  
German Health Survey, amended in Hilbe and Greene (2008).    References  
Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, Elsevier Handbook of Statistics Series. London, UK: Elsevier.    Examples    data(badhealth) glmbadp <- glm(numvisit ~ badh + age, family=poisson, data=badhealth) summary(glmbadp) exp(coef(glmbadp)) library(MASS) glmbadnb <- glm.nb(numvisit ~ badh + age, data=badhealth) summary(glmbadnb) exp(coef(glmbadnb))"
"COUNT-fasttrakg","COUNT","fasttrakg","fasttrakg",15,9,6,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/fasttrakg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/fasttrakg.html","fasttrakg R Documentation   fasttrakg   Description  
Data are from the Canadian National Cardiovascular Disease registry called, FASTRAK. years covered at 1996-1998. They have been grouped by covariate patterns from individual observations.   Usage   data(fasttrakg)   Format  
A data frame with 15 observations on the following 9 variables.    die
number died from MI   cases
number of cases with same covariate pattern   anterior
1=anterior site MI; 0=inferior site MI   hcabg
1=history of CABG; 0=no history of CABG   killip
Killip level of cardiac event severity (1-4)age75    
1= Age>75; 0=Age<=75    kk1
(1/0) angina; not MI   kk2
(1/0) moderate severity cardiac event   kk3
(1/0) Severe cardiac event   kk4
(1/0) Severe cardiac event; death     Details  
fasttrakg is saved as a data frame. Count models use died as response numerator and cases as the demoninator   Source  
1996-1998 FASTRAK data, Hoffman-LaRoche Canada, National Health Economics & Research Co.    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press    Examples    library(MASS) data(fasttrakg) glmfp <- glm(die ~ anterior + factor(killip) + offset(log(cases)), family=poisson, data=fasttrakg) summary(glmfp) exp(coef(glmfp))"
"COUNT-fishing","COUNT","fishing","fishing",147,7,1,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/fishing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/fishing.html","fishing R Documentation   fishing   Description  
The fishing data is adapted from Zuur, Hilbe and Ieno (2013) to determine whether the data appears to be generated from more than one generating mechanism. The data are originally adapted from Bailey et al. (2008) who were interested in how certain deep-sea fish populations were impacted when commercial fishing began in locations with deeper water than in previous years. Given that there are 147 sites that were researched, the model is of (1) the total number of fish counted per site (totabund); ( 2) on the mean water depth per site (meandepth); (3) adjusted by the area of the site (sweptarea); (4) the log of which is the model offset.   Usage   data(fishing)   Format  
A data frame with 147 observations on the following variables.    totabund
total fish counted per site   meandepth
mean water depth per site   sweptarea
adjusted area of site   density
folage density index   site
catch site   year
1977-2002   period
0=1977-1989; 1=2000+     Details  
fishing is saved as a data frame. Count models use totabund as response variable. Counts start at 2   Source  
Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R,   References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands. Bailey M. et al (2008), ""Longterm changes in deep-water fish populations in the North East Atlantic"", Proc Roy Soc B 275:1965-1969.    Examples    ## Not run: library(MASS) library(flexmix) data(fishing) attach(fishing) fmm_pg <- flexmix(totabund~meandepth + offset(log(sweptarea)), data=rwm1984, k=2, model=list(FLXMRglm(totabund~., family=""NB1""), FLXMRglm(tpdocvis~., family=""NB1""))) parameters(fmm_pg, component=1, model=1) parameters(fmm_pg, component=2, model=1) summary(fmm_pg) ## End(Not run)"
"COUNT-lbw","COUNT","lbw","lbw",189,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbw.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/lbw.html","lbw R Documentation   lbw   Description  
The data come to us from Hosmer and Lemeshow (2000). Called the low birth weight (lbw) data, the response is a binary variable, low, which indicates whether the birth weight of a baby is under 2500g (low=1), or over (low=0).   Usage   data(lbw)   Format  
A data frame with 189 observations on the following 10 variables.    low
1=low birthweight baby; 0=norml weight   smoke
1=history of mother smoking; 0=mother nonsmoker   race
categorical 1-3: 1=white; 2-=black; 3=other   age
age of mother: 14-45   lwt
weight (lbs) at last menstrual period: 80-250 lbs   ptl
number of false of premature labors: 0-3   ht
1=history of hypertension; 0 =no hypertension   ui
1=uterine irritability; 0 no irritability   ftv
number of physician visits in 1st trimester: 0-6   bwt
birth weight in grams: 709 - 4990 gr     Details  
lbw is saved as a data frame. Count models can use ftv as a response variable, or convert it to grouped format    Source  
Hosmer, D and S. Lemeshow (2000), Applied Logistic Regression, Wiley   References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    data(lbw) glmbwp <- glm(ftv ~ low + smoke + factor(race), family=poisson, data=lbw) summary(glmbwp) exp(coef(glmbwp)) library(MASS) glmbwnb <- glm.nb(ftv ~ low + smoke + factor(race), data=lbw) summary(glmbwnb) exp(coef(glmbwnb))"
"COUNT-lbwgrp","COUNT","lbwgrp","lbwgrp",6,7,5,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbwgrp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/lbwgrp.html","lbwgrp R Documentation   lbwgrp   Description  
grouped format of the lbw data. The observation level data come to us form Hosmer and Lemeshow (2000). Grouping is such that lowbw is the numerator, and cases the denominator of a binomial model, or cases may be an offset to the count variable, lowbw. Birthweights under 2500g classifies a low birthweight baby.    Usage   data(lbwgrp)   Format  
A data frame with 6 observations on the following 7 variables.    lowbw
Number of low weight babies per covariate pattern: 12-60   cases
Number of observations with same covariate pattern: 30-165   smoke
1=history of mother smoking; 0=mother nonsmoker   race1
(1/0): Caucasian   race2
(1/0): Black   race3
(1/0): Other   low
low birth weight (not valid variable in grouped format)     Details  
lbwgrp is saved as a data frame. Count models: count response=lowbt; offset=log(cases); Binary: binomial numerator= lowbt; binomial denominator=cases    Source  
Hosmer, D and S. Lemeshow (2000), Applied Logistic Regression, Wiley   References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    data(lbwgrp) glmgp <- glm(lowbw ~ smoke + race2 + race3 + offset(log(cases)), family=poisson, data=lbwgrp) summary(glmgp) exp(coef(glmgp)) library(MASS) glmgnb <- glm.nb(lowbw ~ smoke + race2 + race3, data=lbwgrp) summary(glmgnb) exp(coef(glmgnb))"
"COUNT-loomis","COUNT","loomis","loomis",410,11,8,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/loomis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/loomis.html","loomis R Documentation   loomis   Description  
Data are taken from Loomis (2003). The study relates to a survey taken on reported frequency of visits to national parks during the year. The survey was taken at park sites, thus incurring possible effects of endogenous stratification.   Usage   data(loomis)   Format  
A data frame with 410 observations on the following 11 variables.    anvisits
number of annual visits to park   gender
1=male;0=female   income
income in US dollars per year, categorical: 4 levels   income1
<=$25000   income2
>$25000 - $55000   income3
>$55000 - $95000   income4
>$95000   travel
travel time, categorical: 3 levels   travel1
<.25 hrs   travel2
>=.25 - <4 hrs   travel3
>=4 hrs     Details  
loomis is saved as a data frame. Count models typically use anvisits as response variable. 0 counts are included    Source  
from Loomis (2003)    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Loomis, J. B. (2003). Travel cost demand model based river recreation benefit estimates with on-site and household surveys: Comparative results and a correction procedure, Water Resources Research, 39(4): 1105    Examples    data(loomis) glmlmp <- glm(anvisits ~ gender + factor(income) + factor(travel), family=poisson, data=loomis) summary(glmlmp) exp(coef(glmlmp)) library(MASS) glmlmnb <- glm.nb(anvisits ~ gender + factor(income) + factor(travel), data=loomis) summary(glmlmnb) exp(coef(glmlmnb))"
"COUNT-mdvis","COUNT","mdvis","mdvis",2227,13,8,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/mdvis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/mdvis.html","mdvis R Documentation   mdvis   Description  
Data from a subset of the German Socio-Economic Panel (SOEP). The subset was created by Rabe-Hesketh and Skrondal (2005). Only working women are included in these data. Beginning in 1997, German health reform in part entailed a 200 co-payment as well as limits in provider reimbursement. Patients were surveyed for the one year panel (1996) prior to and the one year panel (1998) after reform to assess whether the number of physician visits by patients declined - which was the goal of reform legislation. The response, or variable to be explained by the model, is numvisit, which indicates the number of patient visits to a physician's office during a three month period.   Usage   data(mdvis)   Format  
A data frame with 2,227 observations on the following 13 variables.    numvisit
visits to MD office 3mo prior   reform
1=interview yr post-reform: 1998;0=pre-reform:1996   badh
1=bad health; 0 = not bad health   age
Age(yrs 20-60)   educ
education(1:7-10;2=10.5-12;3=HSgrad+)   educ1
educ1= 7-10 years   educ2
educ2= 10.5-12 years   educ3
educ3= post secondary or high school   agegrp
age: 1=20-39; 2=40-49; 3=50-60   age1
age 20-39   age2
age 40-49   age3
age 50-60   loginc
log(household income in DM)     Details  
mdvis is saved as a data frame. Count models typically use docvis as response variable. 0 counts are included    Source  
German Socio-Economic Panel (SOEP), 1995 pre-reform; 1998 post reform. Created by Rabe-Hesketh and Skrondal (2005).    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC Rabe-Hesketh, S. and A. Skrondal (2005). Multilevel and Longitudinal Modeling Using Stata, College Station: Stata Press.    Examples    data(mdvis) glmmdp <- glm(numvisit ~ reform + factor(educ) + factor(agegrp), family=poisson, data=mdvis) summary(glmmdp) exp(coef(glmmdp)) library(MASS) glmmdnb <- glm.nb(numvisit ~ reform + factor(educ) + factor(agegrp), data=mdvis) summary(glmmdnb) exp(coef(glmmdnb))"
"COUNT-medpar","COUNT","medpar","medpar",1495,10,7,1,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/medpar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/medpar.html","medpar R Documentation   medpar   Description  
The US national Medicare inpatient hospital database is referred to as the Medpar data, which is prepared yearly from hospital filing records. Medpar files for each state are also prepared. The full Medpar data consists of 115 variables. The national Medpar has some 14 million records, with one record for each hospilitiztion. The data in the medpar file comes from 1991 Medicare files for the state of Arizona. The data are limited to only one diagnostic group (DRG 112). Patient data have been randomly selected from the original data.   Usage   data(medpar)   Format  
A data frame with 1495 observations on the following 10 variables.    los
length of hospital stay   hmo
Patient belongs to a Health Maintenance Organization, binary   white
Patient identifies themselves as Caucasian, binary   died
Patient died, binary   age80
Patient age 80 and over, binary   type
Type of admission, categorical   type1
Elective admission, binary   type2
Urgent admission,binary   type3
Elective admission, binary   provnum
Provider ID     Details  
medpar is saved as a data frame. Count models use los as response variable. 0 counts are structurally excluded   Source  
1991 National Medpar data, National Health Economics & Research Co.    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC first used in Hardin, JW and JM Hilbe (2001, 2007), Generalized Linear Models and Extensions, Stata Press    Examples    library(MASS) library(msme) data(medpar) glmp <- glm(los ~ hmo + white + factor(type), family=poisson, data=medpar) summary(glmp) exp(coef(glmp)) nb2 <- nbinomial(los ~ hmo + white + factor(type), data=medpar) summary(nb2) exp(coef(nb2)) glmnb <- glm.nb(los ~ hmo + white + factor(type), data=medpar) summary(glmnb) exp(coef(glmnb))"
"COUNT-nuts","COUNT","nuts","nuts",52,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/nuts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/nuts.html","nuts R Documentation   nuts   Description  
Squirrel data set (nuts) from Zuur, Hilbe, and Ieno (2013). As originally reported by Flaherty et al (2012), researchers recorded information about squirrel behavior and forest attributes across various plots in Scotland's Abernathy Forest. The study focused on the following variables. response cones number of cones stripped by red squirrels per plot predictor sntrees standardized number of trees per plot sheight standardized mean tree height per plot scover standardized percentage of canopy cover per plot The stripped cone count was only taken when the mean diameter of trees was under 0.6m (dbh).   Usage   data(nuts)   Format  
A data frame with 52 observations on the following 8 variables.    cones
number cones stripped by squirrels   ntrees
number of trees per plot   dbh
number DBH per plot   height
mean tree height per plot   cover
canopy closure (as a percentage)   sntrees
standardized number of trees per plot   sheight
standardized mean tree height per plot   scover
standardized canopy closure (as a percentage)     Details  
nuts is saved as a data frame. Count models use ntrees as response variable. Counts start at 3   Source  
Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Zuur, Hilbe, Ieno (2013), A Beginner's Guide to GLM and GLMM using R, Highlands. Flaherty, S et al (2012), ""The impact of forest stand structure on red squirrels habitat use"", Forestry 85:437-444.    Examples    data(nuts) nut <- subset(nuts, dbh < 0.6) # sntrees <- scale(nuts$ntrees) # sheigtht <- scale(nuts$height) # scover <- scale(nuts$cover) summary(PO <- glm(cones ~ sntrees + sheight + scover, family=quasipoisson, data=nut))"
"COUNT-rwm","COUNT","rwm","rwm",27326,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/rwm.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/rwm.html","rwm R Documentation   rwm   Description  
German health registry for the years 1984-1988. Health information for years prior to health reform.   Usage   data(rwm)   Format  
A data frame with 27,326 observations on the following 4 variables.    docvis
number of visits to doctor during year (0-121)   age
age: 25-64   educ
years of formal education (7-18)   hhninc
household yearly income in DM/1000)     Details  
rwm is saved as a data frame. Count models typically use docvis as response variable. 0 counts are included    Source  
German Health Reform Registry, years pre-reform 1984-1988, From Hilbe and Greene (2008)    References  
Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press Hilbe, J.M. and W.H. Greene (2008), ""Count Response Regression Models"", in Rao, CR, JP Miller and DC Rao (eds), Handbook of Statistics 27: Epidemiology and Medical Statistics, Amsterdam: Elsevier. pp. 210-252.    Examples    data(rwm) glmrwp <- glm(docvis ~ age + educ + hhninc, family=poisson, data=rwm) summary(glmrwp) exp(coef(glmrwp)) library(MASS) glmrwnb <- glm.nb(docvis ~ age + educ + hhninc, data=rwm) summary(glmrwnb) exp(coef(glmrwnb))"
"COUNT-rwm1984","COUNT","rwm1984","rwm1984",3874,15,9,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/rwm1984.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/rwm1984.html","rwm1984 R Documentation   rwm1984   Description  
German health registry for the year 1984.   Usage   data(rwm1984)   Format  
A data frame with 3,874 observations on the following 17 variables.    docvis
number of visits to doctor during year (0-121)   hospvis
number of days in hospital during year (0-51)     edlevel
educational level (categorical: 1-4)   age
age: 25-64   outwork
out of work=1; 0=working   female
female=1; 0=male   married
married=1; 0=not married   kids
have children=1; no children=0   hhninc
household yearly income in marks (in Marks)   educ
years of formal education (7-18)   self
self-employed=1; not self employed=0   edlevel1
(1/0) not high school graduate   edlevel2
(1/0) high school graduate   edlevel3
(1/0) university/college   edlevel4
(1/0) graduate school     Details  
rwm1984 is saved as a data frame. Count models typically use docvis as response variable. 0 counts are included    Source  
German Health Reform Registry, year=1984, in Hilbe and Greene (2007)    References  
Hilbe, Joseph, M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, Elsevier Handbook of Statistics Series. London, UK: Elsevier.    Examples    library(MASS) library(msme) data(rwm1984) glmrp <- glm(docvis ~ outwork + female + age + factor(edlevel), family=poisson, data=rwm1984) summary(glmrp) exp(coef(glmrp)) summary(nb2 <- nbinomial(docvis ~ outwork + female + age + factor(edlevel), data=rwm1984)) exp(coef(nb2)) summary(glmrnb <- glm.nb(docvis ~ outwork + female + age + factor(edlevel), data=rwm1984)) exp(coef(glmrnb))"
"COUNT-rwm5yr","COUNT","rwm5yr","rwm5yr",19609,17,9,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/rwm5yr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/rwm5yr.html","rwm5yr R Documentation   rwm5yr   Description  
German health registry for the years 1984-1988. Health information for years immediately prior to health reform.   Usage   data(rwm5yr)   Format  
A data frame with 19,609 observations on the following 17 variables.    id
patient ID (1=7028)   docvis
number of visits to doctor during year (0-121)   hospvis
number of days in hospital during year (0-51)   year
year; (categorical: 1984, 1985, 1986, 1987, 1988)   edlevel
educational level (categorical: 1-4)   age
age: 25-64   outwork
out of work=1; 0=working   female
female=1; 0=male   married
married=1; 0=not married   kids
have children=1; no children=0   hhninc
household yearly income in marks (in Marks)   educ
years of formal education (7-18)   self
self-employed=1; not self employed=0   edlevel1
(1/0) not high school graduate   edlevel2
(1/0) high school graduate   edlevel3
(1/0) university/college   edlevel4
(1/0) graduate school     Details  
rwm5yr is saved as a data frame. Count models typically use docvis as response variable. 0 counts are included    Source  
German Health Reform Registry, years pre-reform 1984-1988, in Hilbe and Greene (2007)    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2011), Negative Binomial Regression, Cambridge University Press Hilbe, J. and W. Greene (2008). Count Response Regression Models, in ed. C.R. Rao, J.P Miller, and D.C. Rao, Epidemiology and Medical Statistics, Elsevier Handbook of Statistics Series. London, UK: Elsevier.    Examples    library(MASS) data(rwm5yr) glmrp <- glm(docvis ~ outwork + female + age + factor(edlevel), family=poisson, data=rwm5yr) summary(glmrp) exp(coef(glmrp)) ## Not run: library(msme) nb2 <- nbinomial(docvis ~ outwork + female + age + factor(edlevel), data=rwm5yr) summary(nb2) exp(coef(nb2)) glmrnb <- glm.nb(docvis ~ outwork + female + age + factor(edlevel), data=rwm5yr) summary(glmrnb) exp(coef(glmrnb)) ## End(Not run)"
"COUNT-ships","COUNT","ships","ships",40,7,4,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/ships.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/ships.html","ships R Documentation   ships   Description  
Data set used in McCullagh & Nelder (1989), Hardin & Hilbe (2003), and other sources. The data contains values on the number of reported accidents for ships belonging to a company over a given time period. When a ship was constructed is also recorded.   Usage   data(ships)   Format  
A data frame with 40 observations on the following 7 variables.    accident
number of shipping accidents   op
1=ship operated 1975-1979;0=1965-74   co.65.69
ship was in construction 1965-1969 (1/0)   co.70.74
ship was in construction 1970-1974 (1/0)   co.75.79
ship was in construction 1975-1979 (1/0)   service
months in service   ship
ship identification : 1-5     Details  
ships is saved as a data frame. Count models use accident as the response variable, with log(service) as the offset. ship can be used as a panel identifier.   Source  
McCullagh and Nelder, 1989.    References  
Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC Hardin, JW and JM Hilbe (2001, 2007), Generalized Linear Models and Extensions, Stata Press McCullagh, P.A, and J. Nelder (1989), Generalized Linear Models, Chapman & Hall    Examples    data(ships) glmshp <- glm(accident ~ op + co.70.74 + co.75.79 + offset(log(service)), family=poisson, data=ships) summary(glmshp) exp(coef(glmshp)) library(MASS) glmshnb <- glm.nb(accident ~ op + co.70.74 + co.75.79 + offset(log(service)), data=ships) summary(glmshnb) exp(coef(glmshnb)) ## Not run: library(gee) shipgee <- gee(accident ~ op + co.70.74 + co.75.79 + offset(log(service)), data=ships, family=poisson, corstr=""exchangeable"", id=ship) summary(shipgee) ## End(Not run)"
"COUNT-smoking","COUNT","smoking","smoking",6,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/smoking.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/smoking.html","smoking R Documentation   smoking   Description  
A simple data set with only 6 observations.   Usage   data(smoking)   Format  
A data frame with 6 observations on the following 4 variables.    sbp
systolic blood pressure of subject   male
1=male; 0=female   smoker
1=hist of smoking; 0= no hist of smoking   age
age of subject     Details  
smoking is saved as a data frame.    Source  
none   References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press    Examples    sbp <- c(131,132,122,119,123,115) male <- c(1,1,1,0,0,0) smoker <- c(1,1,0,0,1,0) age <- c(34,36,30,32,26,23) summary(reg1 <- lm(sbp~ male+smoker+age))"
"COUNT-titanic","COUNT","titanic","titanic",1316,4,3,0,4,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/titanic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/titanic.html","titanic R Documentation   titanic   Description  
The data is an observation-based version of the 1912 Titanic passenger survival log,   Usage   data(titanic)   Format  
A data frame with 1316 observations on the following 4 variables.    class
a factor with levels 1st class 2nd class 3rd class crew   age
a factor with levels child adults   sex
a factor with levels women man   survived
a factor with levels no yes     Details  
titanic is saved as a data frame. Used to assess risk ratios   Source  
Found in many other texts    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    data(titanic) titanic$survival <- titanic$survived == ""yes"" glmlr <- glm(survival ~ age + sex + factor(class), family=binomial, data=titanic) summary(glmlr)"
"COUNT-titanicgrp","COUNT","titanicgrp","titanicgrp",12,5,2,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/titanicgrp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/titanicgrp.html","titanicgrp R Documentation   titanicgrp   Description  
The data is an grouped version of the 1912 Titanic passenger survival log,   Usage   data(titanicgrp)   Format  
A data frame with 12 observations on the following 5 variables.    survive
number of passengers who survived   cases
number of passengers with same pattern of covariates   age
1=adult; 0=child   sex
1=Male; 0=female   class
ticket class 1= 1st class; 2= second class; 3= third class     Details  
titanicgrp is saved as a data frame. Used to assess risk ratios   Source  
Found in many other texts    References  
Hilbe, Joseph M (2014), Modeling Count Data, Cambridge University Press Hilbe, Joseph M (2007, 2011), Negative Binomial Regression, Cambridge University Press Hilbe, Joseph M (2009), Logistic Regression Models, Chapman & Hall/CRC    Examples    library(MASS) library(msme) data(titanicgrp) glmlr <- glm(survive ~ age + sex + factor(class) + offset(log(cases)), family=poisson, data=titanicgrp) summary(glmlr) exp(coef(glmlr)) lcases <- titanicgrp$cases nb2o <- nbinomial(survive ~ age + sex + factor(class), formula2 =~ age + sex, offset = lcases, mean.link=""log"", scale.link=""log_s"", data=titanicgrp) summary(nb2o) exp(coef(nb2o))"
"crch-RainIbk","crch","RainIbk","Precipitation Observations and Forecasts for Innsbruck",4971,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/crch/RainIbk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/crch/RainIbk.html","Missing[""KeyAbsent"", ""crch-RainIbk""]"
"DAAG-ACF1","DAAG","ACF1","Aberrant Crypt Foci in Rat Colons",22,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/ACF1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/ACF1.html","ACF1 R Documentation   Aberrant Crypt Foci in Rat Colons   Description  
Numbers of aberrant crypt foci (ACF) in the section 1 of the colons of 22 rats subjected to a single dose of the carcinogen azoxymethane (AOM), sacrificed at 3 different times.   Usage   ACF1   Format  
This data frame contains the following columns:    count
The number of ACF observed in section 1 of each rat colon   endtime
Time of sacrifice, in weeks following injection of AOM     Source  
Ranjana P. Bird, Faculty of Human Ecology, University of Manitoba, Winnipeg, Canada.    References  
E.A. McLellan, A. Medline and R.P. Bird. Dose response and proliferative characteristics of aberrant crypt foci: putative preneoplastic lesions in rat colon. Carcinogenesis, 12(11): 2093-2098, 1991.    Examples    sapply(split(ACF1$count,ACF1$endtime),var) plot(count ~ endtime, data=ACF1, pch=16) pause() print(""Poisson Regression - Example 8.3"") ACF.glm0 <- glm(formula = count ~ endtime, family = poisson, data = ACF1) summary(ACF.glm0) # Is there a quadratic effect? pause() ACF.glm <- glm(formula = count ~ endtime + I(endtime^2), family = poisson, data = ACF1) summary(ACF.glm) # But is the data really Poisson? If not, try quasipoisson: pause() ACF.glm <- glm(formula = count ~ endtime + I(endtime^2), family = quasipoisson, data = ACF1) summary(ACF.glm)"
"DAAG-ais","DAAG","ais","Australian athletes data set",202,13,1,0,2,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/ais.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/ais.html","ais R Documentation   Australian athletes data set   Description  
These data were collected in a study of how data on various characteristics of the bloood varied with sport body size and sex of the athlete.    Usage   data(ais)   Format  
A data frame with 202 observations on the following 13 variables.    rcc
red blood cell count, in   wcc
while blood cell count, in per liter   hc
hematocrit, percent   hg
hemaglobin concentration, in g per decaliter   ferr
plasma ferritins, ng   bmi
Body mass index, kg   ssf
sum of skin folds   pcBfat
percent Body fat   lbm
lean body mass, kg   ht
height, cm   wt
weight, kg   sex
a factor with levels f m   sport
a factor with levels B_Ball Field  Gym Netball Row Swim T_400m  T_Sprnt Tennis W_Polo     Details  
Do blood hemoglobin concentrations of athletes in endurance-related events differ from those in power-related events?    Source  
These data were the basis for the analyses that are reported in Telford and Cunningham (1991).    References  
Telford, R.D. and Cunningham, R.B. 1991. Sex, sport and body-size dependency of hematology in highly trained athletes. Medicine and Science in Sports and Exercise 23: 788-794."
"DAAG-allbacks","DAAG","allbacks","Measurements on a Selection of Books",15,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/allbacks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/allbacks.html","allbacks R Documentation   Measurements on a Selection of Books   Description  
The allbacks data frame gives measurements on the volume and weight of 15 books, some of which are softback (pb) and some of which are hardback (hb). Area of the hardback covers is also included.    Usage   allbacks   Format  
This data frame contains the following columns:    volume
book volumes in cubic centimeters   area
hard board cover areas in square centimeters   weight
book weights in grams   cover
a factor with levels  hb hardback, pb paperback     Source  
The bookshelf of J. H. Maindonald.    Examples    print(""Multiple Regression - Example 6.1"") attach(allbacks) volume.split <- split(volume, cover) weight.split <- split(weight, cover) plot(weight.split$hb ~ volume.split$hb, pch=16, xlim=range(volume), ylim=range(weight), ylab=""Weight (g)"", xlab=""Volume (cc)"") points(weight.split$pb ~ volume.split$pb, pch=16, col=2) pause() allbacks.lm <- lm(weight ~ volume+area) summary(allbacks.lm) detach(allbacks) pause() anova(allbacks.lm) pause() model.matrix(allbacks.lm) pause() print(""Example 6.1.1"") allbacks.lm0 <- lm(weight ~ -1+volume+area, data=allbacks) summary(allbacks.lm0) pause() print(""Example 6.1.2"") oldpar <- par(mfrow=c(2,2)) plot(allbacks.lm0) par(oldpar) allbacks.lm13 <- lm(weight ~ -1+volume+area, data=allbacks[-13,]) summary(allbacks.lm13) pause() print(""Example 6.1.3"") round(coef(allbacks.lm0),2) # Baseline for changes round(lm.influence(allbacks.lm0)$coef,2)"
"DAAG-anesthetic","DAAG","anesthetic","Anesthetic Effectiveness",30,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/anesthetic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/anesthetic.html","anesthetic R Documentation   Anesthetic Effectiveness   Description  
Thirty patients were given an anesthetic agent maintained at a predetermined level (conc) for 15 minutes before making an incision. It was then noted whether the patient moved, i.e. jerked or twisted.   Usage   anesthetic   Format  
This data frame contains the following columns:    move
a binary numeric vector coded for patient movement (0 = no movement, 1 = movement)   conc
anesthetic concentration   logconc
logarithm of concentration   nomove
the complement of move     Details  
The interest is in estimating how the probability of jerking or twisting varies with increasing concentration of the anesthetic agent.    Source  
unknown    Examples    print(""Logistic Regression - Example 8.1.4"") z <- table(anesthetic$nomove, anesthetic$conc) tot <- apply(z, 2, sum) # totals at each concentration prop <- z[2, ]/(tot) # proportions at each concentration oprop <- sum(z[2, ])/sum(tot) # expected proportion moving if concentration had no effect conc <- as.numeric(dimnames(z)[[2]]) plot(conc, prop, xlab = ""Concentration"", ylab = ""Proportion"", xlim = c(.5,2.5), ylim = c(0, 1), pch = 16) chw <- par()$cxy[1] text(conc - 0.75 * chw, prop, paste(tot), adj = 1) abline(h = oprop, lty = 2) pause() anes.logit <- glm(nomove ~ conc, family = binomial(link = logit), data = anesthetic) anova(anes.logit) summary(anes.logit)"
"DAAG-ant111b","DAAG","ant111b","Averages by block of corn yields, for treatment 111 only",32,9,0,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/ant111b.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/ant111b.html","ant111b R Documentation   Averages by block of corn yields, for treatment 111 only   Description  
These data frames have averages by blocks (parcels) for the treatment  111 .    Usage   ant111b   Format  
A data frame with 36 observations on 9 variables.    site
a factor with levels ( ant111b :) DBAN   LFAN NSAN ORAN OVAN TEAN   WEAN WLAN     parcel
a factor with levels I II III IV   code
a numeric vector   island
a numeric vector   id
a numeric vector   plot
a numeric vector   trt
a numeric vector   ears
a numeric vector   harvwt
a numeric vector     Source  
Andrews DF; Herzberg AM, 1985. Data. A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag. (pp. 339-353)"
"DAAG-antigua","DAAG","antigua","Averages by block of yields for the Antigua Corn data",288,7,0,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/antigua.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/antigua.html","antigua R Documentation   Averages by block of yields for the Antigua Corn data   Description  
These data frames have yield averages by blocks (parcels). The  ant111b data set is a subset of this.    Usage   antigua   Format  
A data frame with 324 observations on 7 variables.    id
a numeric vector   site
a factor with 8 levels.   block
a factor with levels I II III IV   plot
a numeric vector   trt
a factor consisting of 12 levels   ears
a numeric vector; note that -9999 is used as a missing value code.   harvwt
a numeric vector; the average yield     Source  
Andrews DF; Herzberg AM, 1985. Data. A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag. (pp. 339-353)"
"DAAG-appletaste","DAAG","appletaste","Tasting experiment that compared four apple varieties",60,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/appletaste.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/appletaste.html","appletaste R Documentation   Tasting experiment that compared four apple varieties   Description  
Each of 20 tasters each assessed three out of the four varieties. The experiment was conducted according to a balanced incomplete block design.    Usage   data(appletaste)   Format  
A data frame with 60 observations on the following 3 variables.    aftertaste
a numeric vector    
Apple samples were rated for  aftertaste , by making a mark on a continuous scale that ranged from 0 (extreme dislike) to 150 (like very much).    panelist
a factor with levels a b c d e f g h i j k l m n o p q r s t   product
a factor with levels 298 493 649 937     Examples    data(appletaste) appletaste.aov <- aov(aftertaste ~ panelist + product, data=appletaste) termplot(appletaste.aov)"
"DAAG-aulatlong","DAAG","aulatlong","Latitudes and longitudes for ten Australian cities",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/aulatlong.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/aulatlong.html","aulatlong R Documentation   Latitudes and longitudes for ten Australian cities   Description  
Latitudes and longitudes for Adelaide, Alice, Brisbane, Broome, Cairns, Canberra, Darwin, Melbourne, Perth and Sydney; i.e., for the cities to which the road distances in audists relate.    Usage   aulatlong   Format  
A data frame with 10 observations on the following 2 variables.    latitude
Latitude, as a decimal number   longitude
Latitude, as a decimal number     Source  
Map of Australia showing latitude and longitude information.    Examples    data(aulatlong) ## maybe str(aulatlong) ; plot(aulatlong) ..."
"DAAG-austpop","DAAG","austpop","Population figures for Australian States and Territories",9,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/austpop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/austpop.html","austpop R Documentation   Population figures for Australian States and Territories   Description  
Population figures for Australian states and territories for 1917, 1927, ..., 1997.    Usage   austpop   Format  
This data frame contains the following columns:    year
a numeric vector   NSW
New South Wales population counts   Vic
Victoria population counts   Qld
Queensland population counts   SA
South Australia population counts   WA
Western Australia population counts   Tas
Tasmania population counts   NT
Northern Territory population counts   ACT
Australian Capital Territory population counts   Aust
Population counts for the whole country     Source  
Australian Bureau of Statistics    Examples    print(""Looping - Example 1.7"") growth.rates <- numeric(8) for (j in seq(2,9)) { growth.rates[j-1] <- (austpop[9, j]-austpop[1, j])/austpop[1, j] } growth.rates <- data.frame(growth.rates) row.names(growth.rates) <- names(austpop[c(-1,-10)]) # Note the use of row.names() to name the rows of the data frame growth.rates pause() print(""Avoiding Loops - Example 1.7b"") sapply(austpop[,-c(1,10)], function(x){(x[9]-x[1])/x[1]}) pause() print(""Plot - Example 1.8a"") attach(austpop) plot(year, ACT, type=""l"") # Join the points (""l"" = ""line"") detach(austpop) pause() print(""Exerice 1.12.9"") attach(austpop) oldpar <- par(mfrow=c(2,4)) for (i in 2:9){ plot(austpop[,1], log(austpop[, i]), xlab=""Year"", ylab=names(austpop)[i], pch=16, ylim=c(0,10))} par(oldpar) detach(austpop)"
"DAAG-biomass","DAAG","biomass","Biomass Data",153,8,0,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/biomass.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/biomass.html","biomass R Documentation   Biomass Data   Description  
The biomass data frame has 135 rows and 8 columns. The  rainforest data frame is a subset of this one.    Usage   biomass   Format  
This data frame contains the following columns:    dbh
a numeric vector   wood
a numeric vector   bark
a numeric vector   fac26
a factor with 3 levels   root
a numeric vector   rootsk
a numeric vector   branch
a numeric vector   species
a factor with levels  Acacia mabellae ,  C. fraseri ,  Acmena smithii ,  B. myrtifolia     Source  
J. Ash, Australian National University    References  
Ash, J. and Helman, C. (1990) Floristics and vegetation biomass of a forest catchment, Kioloa, south coastal N.S.W. Cunninghamia, 2: 167-182."
"DAAG-bomregions","DAAG","bomregions","Australian and Related Historical Annual Climate Data, by region",109,22,0,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bomregions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bomregions.html","bomregions R Documentation   Australian and Related Historical Annual Climate Data, by region   Description  
Australian regional temperature data, Australian regional rainfall data, and Annual SOI, are given for the years 1900-2008 or 1900-2011 or 1900-2012. The regional rainfall and temperature data are area-weighted averages for the respective regions. The Southern Oscillation Index (SOI) is the difference in barometric pressure at sea level between Tahiti and Darwin.    Usage   bomregions   Format  
This data frame contains the following columns:    Year
Year   eastAVt
Eastern temperature   seAVt
Southeastern region average temperature (degrees C)   southAVt
Southern temperature   swAVt
Southwestern temperature   westAVt
Western temperature   northAVt
Northern temperature   mdbAVt
Murray-Darling basin temperature   auAVt
Australian average temperature, area-weighted mean   eastRain
Eastern rainfall   seRain
Southeast Australian annual rainfall (mm)   southRain
Southern rainfall   swRain
Southwest rainfall   westRain
Western rainfall   northRain
Northern rainfall   mdbRain
Murray-Darling basin rainfall   auRain
Australian average rainfall, area weighted   SOI
Annual average Southern Oscillation Index   co2mlo
Moana Loa CO2 concentrations, from 1959   co2law
Moana Loa CO2 concentrations, 1900 to 1978   CO2
CO2 concentrations, composite series   sunspot
Annual average sunspot counts     Source  
Australian Bureau of Meteorology web pages:   
http://www.bom.gov.au/climate/change/index.shtml    
The CO2 series co2law , for Law Dome ice core data. is from  http://cdiac.ornl.gov/trends/co2/lawdome.html .   
The CO2 series co2mlo is from Dr. Pieter Tans, NOAA/ESRL ( https://www.esrl.noaa.gov/gmd/ccgg/trends/ )   
The series CO2 is a composite series, obtained by adding 0.46 to he Law data for 1900 to 1958, then following this with the Moana Loa data that is avaiable from 1959. The addition of 0.46 is designed so that the averages from the two series agree for the period 1959 to 1968   
Sunspot data is from http://sidc.oma.be/sunspot-data/     References  
D.M. Etheridge, L.P. Steele, R.L. Langenfelds, R.J. Francey, J.-M. Barnola and V.I. Morgan, 1998, Historical CO2 records from the Law Dome DE08, DE08-2, and DSS ice cores , in Trends: A Compendium of Data on Global Change, on line at Carbon Dioxide Information Analysis Center, Oak Ridge National Laboratory, U.S. Department of Energy, Oak Ridge, Tenn., U.S.A. http://cdiac.ornl.gov/trends/co2/lawdome.html    
Lavery, B., Joung, G. and Nicholls, N. 1997. An extended high-quality historical rainfall dataset for Australia. Australian Meteorological Magazine, 46, 27-38.   
Nicholls, N., Lavery, B., Frederiksen, C.\ and Drosdowsky, W. 1996. Recent apparent changes in relationships between the El Nino – southern oscillation and Australian rainfall and temperature. Geophysical Research Letters 23: 3357-3360.   
SIDC-team, World Data Center for the Sunspot Index, Royal Observatory of Belgium, Monthly Report on the International Sunspot Number, online catalogue of the sunspot index: http://www.sidc.be/sunspot-data/ , 1900-2011    Examples    plot(ts(bomregions[, c(""mdbRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(bomregions$Year, y,...)) avrain <- bomregions[,""mdbRain""] xbomsoi <- with(bomregions, data.frame(Year=Year, SOI=SOI, cuberootRain=avrain^0.33)) xbomsoi$trendSOI <- lowess(xbomsoi$SOI, f=0.1)$y xbomsoi$trendRain <- lowess(xbomsoi$cuberootRain, f=0.1)$y xbomsoi$detrendRain <- with(xbomsoi, cuberootRain - trendRain + mean(trendRain)) xbomsoi$detrendSOI <- with(xbomsoi, SOI - trendSOI + mean(trendSOI)) ## Plot time series avrain and SOI: ts object xbomsoi plot(ts(xbomsoi[, c(""cuberootRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(xbomsoi$Year, y,...), xlab = ""Year"", main="""", ylim=list(c(250, 800),c(-20,25))) par(mfrow=c(1,2)) rainpos <- pretty(xbomsoi$cuberootRain^3, 6) plot(cuberootRain ~ SOI, data = xbomsoi, ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) mtext(side = 3, line = 0.8, ""A"", adj = -0.025) with(xbomsoi, lines(lowess(cuberootRain ~ SOI, f=0.75))) plot(detrendRain ~ detrendSOI, data = xbomsoi, xlab=""Detrended SOI"", ylab = ""Detrended rainfall"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI, f=0.75))) mtext(side = 3, line = 0.8, ""B"", adj = -0.025) par(mfrow=c(1,1))"
"DAAG-bomregions2011","DAAG","bomregions2011","Australian and Related Historical Annual Climate Data, by region",112,22,0,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bomregions2011.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bomregions2011.html","bomregions R Documentation   Australian and Related Historical Annual Climate Data, by region   Description  
Australian regional temperature data, Australian regional rainfall data, and Annual SOI, are given for the years 1900-2008 or 1900-2011 or 1900-2012. The regional rainfall and temperature data are area-weighted averages for the respective regions. The Southern Oscillation Index (SOI) is the difference in barometric pressure at sea level between Tahiti and Darwin.    Usage   bomregions   Format  
This data frame contains the following columns:    Year
Year   eastAVt
Eastern temperature   seAVt
Southeastern region average temperature (degrees C)   southAVt
Southern temperature   swAVt
Southwestern temperature   westAVt
Western temperature   northAVt
Northern temperature   mdbAVt
Murray-Darling basin temperature   auAVt
Australian average temperature, area-weighted mean   eastRain
Eastern rainfall   seRain
Southeast Australian annual rainfall (mm)   southRain
Southern rainfall   swRain
Southwest rainfall   westRain
Western rainfall   northRain
Northern rainfall   mdbRain
Murray-Darling basin rainfall   auRain
Australian average rainfall, area weighted   SOI
Annual average Southern Oscillation Index   co2mlo
Moana Loa CO2 concentrations, from 1959   co2law
Moana Loa CO2 concentrations, 1900 to 1978   CO2
CO2 concentrations, composite series   sunspot
Annual average sunspot counts     Source  
Australian Bureau of Meteorology web pages:   
http://www.bom.gov.au/climate/change/index.shtml    
The CO2 series co2law , for Law Dome ice core data. is from  http://cdiac.ornl.gov/trends/co2/lawdome.html .   
The CO2 series co2mlo is from Dr. Pieter Tans, NOAA/ESRL ( https://www.esrl.noaa.gov/gmd/ccgg/trends/ )   
The series CO2 is a composite series, obtained by adding 0.46 to he Law data for 1900 to 1958, then following this with the Moana Loa data that is avaiable from 1959. The addition of 0.46 is designed so that the averages from the two series agree for the period 1959 to 1968   
Sunspot data is from http://sidc.oma.be/sunspot-data/     References  
D.M. Etheridge, L.P. Steele, R.L. Langenfelds, R.J. Francey, J.-M. Barnola and V.I. Morgan, 1998, Historical CO2 records from the Law Dome DE08, DE08-2, and DSS ice cores , in Trends: A Compendium of Data on Global Change, on line at Carbon Dioxide Information Analysis Center, Oak Ridge National Laboratory, U.S. Department of Energy, Oak Ridge, Tenn., U.S.A. http://cdiac.ornl.gov/trends/co2/lawdome.html    
Lavery, B., Joung, G. and Nicholls, N. 1997. An extended high-quality historical rainfall dataset for Australia. Australian Meteorological Magazine, 46, 27-38.   
Nicholls, N., Lavery, B., Frederiksen, C.\ and Drosdowsky, W. 1996. Recent apparent changes in relationships between the El Nino – southern oscillation and Australian rainfall and temperature. Geophysical Research Letters 23: 3357-3360.   
SIDC-team, World Data Center for the Sunspot Index, Royal Observatory of Belgium, Monthly Report on the International Sunspot Number, online catalogue of the sunspot index: http://www.sidc.be/sunspot-data/ , 1900-2011    Examples    plot(ts(bomregions[, c(""mdbRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(bomregions$Year, y,...)) avrain <- bomregions[,""mdbRain""] xbomsoi <- with(bomregions, data.frame(Year=Year, SOI=SOI, cuberootRain=avrain^0.33)) xbomsoi$trendSOI <- lowess(xbomsoi$SOI, f=0.1)$y xbomsoi$trendRain <- lowess(xbomsoi$cuberootRain, f=0.1)$y xbomsoi$detrendRain <- with(xbomsoi, cuberootRain - trendRain + mean(trendRain)) xbomsoi$detrendSOI <- with(xbomsoi, SOI - trendSOI + mean(trendSOI)) ## Plot time series avrain and SOI: ts object xbomsoi plot(ts(xbomsoi[, c(""cuberootRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(xbomsoi$Year, y,...), xlab = ""Year"", main="""", ylim=list(c(250, 800),c(-20,25))) par(mfrow=c(1,2)) rainpos <- pretty(xbomsoi$cuberootRain^3, 6) plot(cuberootRain ~ SOI, data = xbomsoi, ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) mtext(side = 3, line = 0.8, ""A"", adj = -0.025) with(xbomsoi, lines(lowess(cuberootRain ~ SOI, f=0.75))) plot(detrendRain ~ detrendSOI, data = xbomsoi, xlab=""Detrended SOI"", ylab = ""Detrended rainfall"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI, f=0.75))) mtext(side = 3, line = 0.8, ""B"", adj = -0.025) par(mfrow=c(1,1))"
"DAAG-bomregions2012","DAAG","bomregions2012","Australian and Related Historical Annual Climate Data, by region",113,22,0,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bomregions2012.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bomregions2012.html","bomregions R Documentation   Australian and Related Historical Annual Climate Data, by region   Description  
Australian regional temperature data, Australian regional rainfall data, and Annual SOI, are given for the years 1900-2008 or 1900-2011 or 1900-2012. The regional rainfall and temperature data are area-weighted averages for the respective regions. The Southern Oscillation Index (SOI) is the difference in barometric pressure at sea level between Tahiti and Darwin.    Usage   bomregions   Format  
This data frame contains the following columns:    Year
Year   eastAVt
Eastern temperature   seAVt
Southeastern region average temperature (degrees C)   southAVt
Southern temperature   swAVt
Southwestern temperature   westAVt
Western temperature   northAVt
Northern temperature   mdbAVt
Murray-Darling basin temperature   auAVt
Australian average temperature, area-weighted mean   eastRain
Eastern rainfall   seRain
Southeast Australian annual rainfall (mm)   southRain
Southern rainfall   swRain
Southwest rainfall   westRain
Western rainfall   northRain
Northern rainfall   mdbRain
Murray-Darling basin rainfall   auRain
Australian average rainfall, area weighted   SOI
Annual average Southern Oscillation Index   co2mlo
Moana Loa CO2 concentrations, from 1959   co2law
Moana Loa CO2 concentrations, 1900 to 1978   CO2
CO2 concentrations, composite series   sunspot
Annual average sunspot counts     Source  
Australian Bureau of Meteorology web pages:   
http://www.bom.gov.au/climate/change/index.shtml    
The CO2 series co2law , for Law Dome ice core data. is from  http://cdiac.ornl.gov/trends/co2/lawdome.html .   
The CO2 series co2mlo is from Dr. Pieter Tans, NOAA/ESRL ( https://www.esrl.noaa.gov/gmd/ccgg/trends/ )   
The series CO2 is a composite series, obtained by adding 0.46 to he Law data for 1900 to 1958, then following this with the Moana Loa data that is avaiable from 1959. The addition of 0.46 is designed so that the averages from the two series agree for the period 1959 to 1968   
Sunspot data is from http://sidc.oma.be/sunspot-data/     References  
D.M. Etheridge, L.P. Steele, R.L. Langenfelds, R.J. Francey, J.-M. Barnola and V.I. Morgan, 1998, Historical CO2 records from the Law Dome DE08, DE08-2, and DSS ice cores , in Trends: A Compendium of Data on Global Change, on line at Carbon Dioxide Information Analysis Center, Oak Ridge National Laboratory, U.S. Department of Energy, Oak Ridge, Tenn., U.S.A. http://cdiac.ornl.gov/trends/co2/lawdome.html    
Lavery, B., Joung, G. and Nicholls, N. 1997. An extended high-quality historical rainfall dataset for Australia. Australian Meteorological Magazine, 46, 27-38.   
Nicholls, N., Lavery, B., Frederiksen, C.\ and Drosdowsky, W. 1996. Recent apparent changes in relationships between the El Nino – southern oscillation and Australian rainfall and temperature. Geophysical Research Letters 23: 3357-3360.   
SIDC-team, World Data Center for the Sunspot Index, Royal Observatory of Belgium, Monthly Report on the International Sunspot Number, online catalogue of the sunspot index: http://www.sidc.be/sunspot-data/ , 1900-2011    Examples    plot(ts(bomregions[, c(""mdbRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(bomregions$Year, y,...)) avrain <- bomregions[,""mdbRain""] xbomsoi <- with(bomregions, data.frame(Year=Year, SOI=SOI, cuberootRain=avrain^0.33)) xbomsoi$trendSOI <- lowess(xbomsoi$SOI, f=0.1)$y xbomsoi$trendRain <- lowess(xbomsoi$cuberootRain, f=0.1)$y xbomsoi$detrendRain <- with(xbomsoi, cuberootRain - trendRain + mean(trendRain)) xbomsoi$detrendSOI <- with(xbomsoi, SOI - trendSOI + mean(trendSOI)) ## Plot time series avrain and SOI: ts object xbomsoi plot(ts(xbomsoi[, c(""cuberootRain"",""SOI"")], start=1900), panel=function(y,...)panel.smooth(xbomsoi$Year, y,...), xlab = ""Year"", main="""", ylim=list(c(250, 800),c(-20,25))) par(mfrow=c(1,2)) rainpos <- pretty(xbomsoi$cuberootRain^3, 6) plot(cuberootRain ~ SOI, data = xbomsoi, ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) mtext(side = 3, line = 0.8, ""A"", adj = -0.025) with(xbomsoi, lines(lowess(cuberootRain ~ SOI, f=0.75))) plot(detrendRain ~ detrendSOI, data = xbomsoi, xlab=""Detrended SOI"", ylab = ""Detrended rainfall"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI, f=0.75))) mtext(side = 3, line = 0.8, ""B"", adj = -0.025) par(mfrow=c(1,1))"
"DAAG-bomsoi","DAAG","bomsoi","Southern Oscillation Index Data",106,21,0,0,0,0,21,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bomsoi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bomsoi.html","bomsoi R Documentation   Southern Oscillation Index Data   Description  
The Southern Oscillation Index (SOI) is the difference in barometric pressure at sea level between Tahiti and Darwin. Annual SOI and Australian rainfall data, for the years 1900-2001, are given. Australia's annual mean rainfall is an area-weighted average of the total annual precipitation at approximately 370 rainfall stations around the country.    Usage   bomsoi   Format  
This data frame contains the following columns:    Year
a numeric vector   Jan
average January SOI values for each year   Feb
average February SOI values for each year   Mar
average March SOI values for each year   Apr
average April SOI values for each year   May
average May SOI values for each year   Jun
average June SOI values for each year   Jul
average July SOI values for each year   Aug
average August SOI values for each year   Sep
average September SOI values for each year   Oct
average October SOI values for each year   Nov
average November SOI values for each year   Dec
average December SOI values for each year   SOI
a numeric vector consisting of average annual SOI values   avrain
a numeric vector consisting of a weighted average annual rainfall at a large number of Australian sites   NTrain
Northern Territory rain   northRain
north rain   seRain
southeast rain   eastRain
east rain   southRain
south rain   swRain
southwest rain     Source  
Australian Bureau of Meteorology web pages:   
http://www.bom.gov.au/climate/change/rain02.txt and http://www.bom.gov.au/climate/current/soihtm1.shtml    References  
Nicholls, N., Lavery, B., Frederiksen, C.\ and Drosdowsky, W. 1996. Recent apparent changes in relationships between the El Nino – southern oscillation and Australian rainfall and temperature. Geophysical Research Letters 23: 3357-3360.    Examples   plot(ts(bomsoi[, 15:14], start=1900), panel=function(y,...)panel.smooth(1900:2005, y,...)) pause() # Check for skewness by comparing the normal probability plots for # different a, e.g. par(mfrow = c(2,3)) for (a in c(50, 100, 150, 200, 250, 300)) qqnorm(log(bomsoi[, ""avrain""] - a)) # a = 250 leads to a nearly linear plot pause() par(mfrow = c(1,1)) plot(bomsoi$SOI, log(bomsoi$avrain - 250), xlab = ""SOI"", ylab = ""log(avrain = 250)"") lines(lowess(bomsoi$SOI)$y, lowess(log(bomsoi$avrain - 250))$y, lwd=2) # NB: separate lowess fits against time lines(lowess(bomsoi$SOI, log(bomsoi$avrain - 250))) pause() xbomsoi <- with(bomsoi, data.frame(SOI=SOI, cuberootRain=avrain^0.33)) xbomsoi$trendSOI <- lowess(xbomsoi$SOI)$y xbomsoi$trendRain <- lowess(xbomsoi$cuberootRain)$y rainpos <- pretty(bomsoi$avrain, 5) with(xbomsoi, {plot(cuberootRain ~ SOI, xlab = ""SOI"", ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) ## Relative changes in the two trend curves lines(lowess(cuberootRain ~ SOI)) lines(lowess(trendRain ~ trendSOI), lwd=2) }) pause() xbomsoi$detrendRain <- with(xbomsoi, cuberootRain - trendRain + mean(trendRain)) xbomsoi$detrendSOI <- with(xbomsoi, SOI - trendSOI + mean(trendSOI)) oldpar <- par(mfrow=c(1,2), pty=""s"") plot(cuberootRain ~ SOI, data = xbomsoi, ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(cuberootRain ~ SOI))) plot(detrendRain ~ detrendSOI, data = xbomsoi, xlab=""Detrended SOI"", ylab = ""Detrended rainfall"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI))) pause() par(oldpar) attach(xbomsoi) xbomsoi.ma0 <- arima(detrendRain, xreg=detrendSOI, order=c(0,0,0)) # ordinary regression model xbomsoi.ma12 <- arima(detrendRain, xreg=detrendSOI, order=c(0,0,12)) # regression with MA(12) errors -- all 12 MA parameters are estimated xbomsoi.ma12 pause() xbomsoi.ma12s <- arima(detrendRain, xreg=detrendSOI, seasonal=list(order=c(0,0,1), period=12)) # regression with seasonal MA(1) (lag 12) errors -- only 1 MA parameter # is estimated xbomsoi.ma12s pause() xbomsoi.maSel <- arima(x = detrendRain, order = c(0, 0, 12), xreg = detrendSOI, fixed = c(0, 0, 0, NA, rep(0, 4), NA, 0, NA, NA, NA, NA), transform.pars=FALSE) # error term is MA(12) with fixed 0's at lags 1, 2, 3, 5, 6, 7, 8, 10 # NA's are used to designate coefficients that still need to be estimated # transform.pars is set to FALSE, so that MA coefficients are not # transformed (see help(arima)) detach(xbomsoi) pause() Box.test(resid(lm(detrendRain ~ detrendSOI, data = xbomsoi)), type=""Ljung-Box"", lag=20) pause() attach(xbomsoi) xbomsoi2.maSel <- arima(x = detrendRain, order = c(0, 0, 12), xreg = poly(detrendSOI,2), fixed = c(0, 0, 0, NA, rep(0, 4), NA, 0, rep(NA,5)), transform.pars=FALSE) xbomsoi2.maSel qqnorm(resid(xbomsoi.maSel, type=""normalized"")) detach(xbomsoi)"
"DAAG-bomsoi2001","DAAG","bomsoi2001","Southern Oscillation Index Data",102,15,0,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bomsoi2001.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bomsoi2001.html","bomsoi2001 R Documentation   Southern Oscillation Index Data   Description  
The Southern Oscillation Index (SOI) is the difference in barometric pressure at sea level between Tahiti and Darwin. Annual SOI and Australian rainfall data, for the years 1900-2001, are given. Australia's annual mean rainfall is an area-weighted average of the total annual precipitation at approximately 370 rainfall stations around the country.    Usage   bomsoi2001   Format  
This data frame contains the following columns:    Year
a numeric vector   Jan
average January SOI values for each year   Feb
average February SOI values for each year   Mar
average March SOI values for each year   Apr
average April SOI values for each year   May
average May SOI values for each year   Jun
average June SOI values for each year   Jul
average July SOI values for each year   Aug
average August SOI values for each year   Sep
average September SOI values for each year   Oct
average October SOI values for each year   Nov
average November SOI values for each year   Dec
average December SOI values for each year   SOI
a numeric vector consisting of average annual SOI values   avrain
a numeric vector consisting of a weighted average annual rainfall at a large number of Australian sites     Source  
Australian Bureau of Meteorology web pages:   
http://www.bom.gov.au/climate/change/rain02.txt and http://www.bom.gov.au/climate/current/soihtm1.shtml    References  
Nicholls, N., Lavery, B., Frederiksen, C.\ and Drosdowsky, W. 1996. Recent apparent changes in relationships between the El Nino – southern oscillation and Australian rainfall and temperature. Geophysical Research Letters 23: 3357-3360.    See Also  
bomsoi   Examples   bomsoi <- bomsoi2001 plot(ts(bomsoi[, 15:14], start=1900), panel=function(y,...)panel.smooth(1900:2001, y,...)) pause() # Check for skewness by comparing the normal probability plots for # different a, e.g. par(mfrow = c(2,3)) for (a in c(50, 100, 150, 200, 250, 300)) qqnorm(log(bomsoi[, ""avrain""] - a)) # a = 250 leads to a nearly linear plot pause() par(mfrow = c(1,1)) plot(bomsoi$SOI, log(bomsoi$avrain - 250), xlab = ""SOI"", ylab = ""log(avrain = 250)"") lines(lowess(bomsoi$SOI)$y, lowess(log(bomsoi$avrain - 250))$y, lwd=2) # NB: separate lowess fits against time lines(lowess(bomsoi$SOI, log(bomsoi$avrain - 250))) pause() xbomsoi <- with(bomsoi, data.frame(SOI=SOI, cuberootRain=avrain^0.33)) xbomsoi$trendSOI <- lowess(xbomsoi$SOI)$y xbomsoi$trendRain <- lowess(xbomsoi$cuberootRain)$y rainpos <- pretty(bomsoi$avrain, 5) with(xbomsoi, {plot(cuberootRain ~ SOI, xlab = ""SOI"", ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) ## Relative changes in the two trend curves lines(lowess(cuberootRain ~ SOI)) lines(lowess(trendRain ~ trendSOI), lwd=2) }) pause() xbomsoi$detrendRain <- with(xbomsoi, cuberootRain - trendRain + mean(trendRain)) xbomsoi$detrendSOI <- with(xbomsoi, SOI - trendSOI + mean(trendSOI)) oldpar <- par(mfrow=c(1,2), pty=""s"") plot(cuberootRain ~ SOI, data = xbomsoi, ylab = ""Rainfall (cube root scale)"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(cuberootRain ~ SOI))) plot(detrendRain ~ detrendSOI, data = xbomsoi, xlab=""Detrended SOI"", ylab = ""Detrended rainfall"", yaxt=""n"") axis(2, at = rainpos^0.33, labels=paste(rainpos)) with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI))) pause() par(oldpar) attach(xbomsoi) xbomsoi.ma0 <- arima(detrendRain, xreg=detrendSOI, order=c(0,0,0)) # ordinary regression model xbomsoi.ma12 <- arima(detrendRain, xreg=detrendSOI, order=c(0,0,12)) # regression with MA(12) errors -- all 12 MA parameters are estimated xbomsoi.ma12 pause() xbomsoi.ma12s <- arima(detrendRain, xreg=detrendSOI, seasonal=list(order=c(0,0,1), period=12)) # regression with seasonal MA(1) (lag 12) errors -- only 1 MA parameter # is estimated xbomsoi.ma12s pause() xbomsoi.maSel <- arima(x = detrendRain, order = c(0, 0, 12), xreg = detrendSOI, fixed = c(0, 0, 0, NA, rep(0, 4), NA, 0, NA, NA, NA, NA), transform.pars=FALSE) # error term is MA(12) with fixed 0's at lags 1, 2, 3, 5, 6, 7, 8, 10 # NA's are used to designate coefficients that still need to be estimated # transform.pars is set to FALSE, so that MA coefficients are not # transformed (see help(arima)) detach(xbomsoi) pause() Box.test(resid(lm(detrendRain ~ detrendSOI, data = xbomsoi)), type=""Ljung-Box"", lag=20) pause() attach(xbomsoi) xbomsoi2.maSel <- arima(x = detrendRain, order = c(0, 0, 12), xreg = poly(detrendSOI,2), fixed = c(0, 0, 0, NA, rep(0, 4), NA, 0, rep(NA,5)), transform.pars=FALSE) xbomsoi2.maSel qqnorm(resid(xbomsoi.maSel, type=""normalized"")) detach(xbomsoi)"
"DAAG-bostonc","DAAG","bostonc","Boston Housing Data - Corrected",517,1,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/bostonc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/bostonc.html","bostonc R Documentation   Boston Housing Data – Corrected   Description  
The corrected Boston housing data (from http://lib.stat.cmu.edu/datasets/).    Usage   bostonc   Format  
A single vector containing the contents of ""boston\_corrected.txt"".   Source  
Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978. corrected by Kelley Pace (kpace@unix1.sncc.lsu.edu)"
"DAAG-carprice","DAAG","carprice","US Car Price Data",48,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/carprice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/carprice.html","carprice R Documentation   US Car Price Data   Description  
U.S. data extracted from Cars93 , a data frame in the MASS package.    Usage   carprice   Format  
This data frame contains the following columns:    Type
Type of car, e.g. Sporty, Van, Compact   Min.Price
Price for a basic model   Price
Price for a mid-range model   Max.Price
Price for a ‘premium’ model   Range.Price
Difference between Max.Price and Min.Price   RoughRange
Rough.Range plus some N(0,.0001) noise   gpm100
The number of gallons required to travel 100 miles   MPG.city
Average number of miles per gallon for city driving   MPG.highway
Average number of miles per gallon for highway driving     Source  
MASS package    References  
Venables, W.N.\ and Ripley, B.D., 4th edn 2002. Modern Applied Statistics with S. Springer, New York.   
See also ‘R’ Complements to Modern Applied Statistics with S-Plus, available from http://www.stats.ox.ac.uk/pub/MASS3/     Examples   print(""Multicollinearity - Example 6.8"") pairs(carprice[,-c(1,8,9)]) carprice1.lm <- lm(gpm100 ~ Type+Min.Price+Price+Max.Price+Range.Price, data=carprice) round(summary(carprice1.lm)$coef,3) pause() alias(carprice1.lm) pause() carprice2.lm <- lm(gpm100 ~ Type+Min.Price+Price+Max.Price+RoughRange, data=carprice) round(summary(carprice2.lm)$coef, 2) pause() carprice.lm <- lm(gpm100 ~ Type + Price, data = carprice) round(summary(carprice.lm)$coef,4) pause() summary(carprice1.lm)$sigma # residual standard error when fitting all 3 price variables pause() summary(carprice.lm)$sigma # residual standard error when only price is used pause() vif(lm(gpm100 ~ Price, data=carprice)) # Baseline Price pause() vif(carprice1.lm) # includes Min.Price, Price & Max.Price pause() vif(carprice2.lm) # includes Min.Price, Price, Max.Price & RoughRange pause() vif(carprice.lm) # Price alone"
"DAAG-Cars93.summary","DAAG","Cars93.summary","A Summary of the Cars93 Data set",6,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/Cars93.summary.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/Cars93.summary.html","Cars93.summary R Documentation   A Summary of the Cars93 Data set   Description  
The Cars93.summary data frame has 6 rows and 4 columns created from information in the Cars93 data set in the Venables and Ripley MASS package. Each row corresponds to a different class of car (e.g. Compact, Large, etc.).    Usage   Cars93.summary   Format  
This data frame contains the following columns:    Min.passengers
minimum passenger capacity for each class of car   Max.passengers
maximum passenger capacity for each class of car   No.of.cars
number of cars in each class   abbrev
a factor with levels  C Compact, L Large, M Mid-Size, Sm Small, Sp Sporty, V Van     Source  
Lock, R. H. (1993) 1993 New Car Data. Journal of Statistics Education 1(1)    References  
MASS library    Examples    type <- Cars93.summary$abbrev type <- Cars93.summary[,4] type <- Cars93.summary[,""abbrev""] type <- Cars93.summary[[4]] # Take the object that is stored # in the fourth list element. type pause() attach(Cars93.summary) # R can now access the columns of Cars93.summary directly abbrev detach(""Cars93.summary"") pause() # To change the name of the \verb!abbrev! variable (the fourth column) names(Cars93.summary)[4] <- ""code"" pause() # To change all of the names, try names(Cars93.summary) <- c(""minpass"",""maxpass"",""number"",""code"")"
"DAAG-cerealsugar","DAAG","cerealsugar","Percentage of Sugar in Breakfast Cereal",100,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cerealsugar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cerealsugar.html","cerealsugar R Documentation   Percentage of Sugar in Breakfast Cereal   Description  
Measurements of sugar content in frosted flakes breakfast cereal.    Usage   cerealsugar   Format  
A vector of 100 measurements."
"DAAG-cfseal","DAAG","cfseal","Cape Fur Seal Data",30,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cfseal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cfseal.html","cfseal R Documentation   Cape Fur Seal Data   Description  
The cfseal data frame has 30 rows and 11 columns consisting of weight measurements for various organs taken from 30 Cape Fur Seals that died as an unintended consequence of commercial fishing.    Usage   cfseal   Format  
This data frame contains the following columns:    age
a numeric vector   weight
a numeric vector   heart
a numeric vector   lung
a numeric vector   liver
a numeric vector   spleen
a numeric vector   stomach
a numeric vector   leftkid
a numeric vector   rightkid
a numeric vector   kidney
a numeric vector   intestines
a numeric vector     Source  
Stewardson, C.L., Hemsley, S., Meyer, M.A., Canfield, P.J. and Maindonald, J.H. 1999. Gross and microscopic visceral anatomy of the male Cape fur seal, Arctocephalus pusillus pusillus (Pinnepedia: Otariidae), with reference to organ size and growth. Journal of Anatomy (Cambridge) 195: 235-255. (WWF project ZA-348)    Examples    print(""Allometric Growth - Example 5.7"") cfseal.lm <- lm(log(heart) ~ log(weight), data=cfseal); summary(cfseal.lm) plot(log(heart) ~ log(weight), data = cfseal, pch=16, xlab = ""Heart Weight (g, log scale)"", ylab = ""Body weight (kg, log scale)"", axes=FALSE) heartaxis <- 100*(2^seq(0,3)) bodyaxis <- c(20,40,60,100,180) axis(1, at = log(bodyaxis), lab = bodyaxis) axis(2, at = log(heartaxis), lab = heartaxis) box() abline(cfseal.lm)"
"DAAG-cities","DAAG","cities","Populations of Major Canadian Cities (1992-96)",25,7,0,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cities.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cities.html","cities R Documentation   Populations of Major Canadian Cities (1992-96)   Description  
Population estimates for several Canadian cities.    Usage   cities   Format  
This data frame contains the following columns:    CITY
a factor, consisting of the city names   REGION
a factor with 5 levels (ATL=Atlantic, ON=Ontario, QC=Quebec, PR=Prairies, WEST=Alberta and British Columbia) representing the location of the cities   POP1992
a numeric vector giving population in 1000's for 1992   POP1993
a numeric vector giving population in 1000's for 1993   POP1994
a numeric vector giving population in 1000's for 1994   POP1995
a numeric vector giving population in 1000's for 1995   POP1996
a numeric vector giving population in 1000's for 1996     Source  
Statistics Canada    Examples    cities$have <- factor((cities$REGION==""ON"")|(cities$REGION==""WEST"")) plot(POP1996~POP1992, data=cities, col=as.integer(cities$have))"
"DAAG-codling","DAAG","codling","Dose-mortality data, for fumigation of codling moth with methyl bromide",99,10,1,1,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/codling.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/codling.html","codling R Documentation   Dose-mortality data, for fumigation of codling moth with methyl bromide   Description  
Data are from trials that studied the mortality response of codling moth to fumigation with methyl bromide.    Usage   data(codling)   Format  
A data frame with 99 observations on the following 10 variables.    dose
Injected dose of methyl bromide, in gm per cubic meter   tot
Number of insects in chamber   dead
Number of insects dying   pobs
Proportion dying   cm
Control mortality, i.e., at dose 0   ct
Concentration-time sum   Cultivar
a factor with levels BRAEBURN FUJI GRANNY Gala ROYAL Red Delicious Splendour   gp
a factor which has a different level for each different combination of Cultivar , year and rep (replicate).   year
a factor with levels 1988 1989   numcm
a numeric vector: total number of control insects     Details  
The research that generated these data was in part funded by New Zealand pipfruit growers. The published analysis was funded by New Zealand pipfruit growers. See also sorption .    Source  
Maindonald, J.H.; Waddell, B.C.; Petry, R.J. 2001. Apple cultivar effects on codling moth (Lepidoptera: Tortricidae) egg mortality following fumigation with methyl bromide. Postharvest Biology and Technology 22: 99-110."
"DAAG-cottonworkers","DAAG","cottonworkers","Occupation and wage profiles of British cotton workers",14,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cottonworkers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cottonworkers.html","cottonworkers R Documentation   Occupation and wage profiles of British cotton workers   Description  
Numbers are given in different categories of worker, in each of two investigations. The first source of information is the Board of Trade Census that was conducted on 1886. The second is a relatively informal survey conducted by US Bureau of Labor representatives in 1889, for use in official reports.    Usage   data(cottonworkers)   Format  
A data frame with 14 observations on the following 3 variables.    census1886
Numbers of workers in each of 14 different categories, according to the Board of Trade wage census that was conducted in 1886   survey1889
Numbers of workers in each of 14 different categories, according to data collected in 1889 by the US Bureau of Labor, for use in a report to the US Congress and House of Representatives   avwage
Average wage, in pence, as estimated in the US Bureau of Labor survey     Details  
The data in survey1889 were collected in a relatively informal manner, by approaching individuals on the street. Biases might therefore be expected.    Source  
United States congress, House of Representatives, Sixth Annual Report of the Commissioner of Labor, 1890, Part III, Cost of Living (Washington D.C. 1891); idem., Seventh Annual Report of the Commissioner of Labor, 1891, Part III, Cost of Living (Washington D.C. 1892)   
Return of wages in the principal textile trades of the United Kingdom, with report therein. (P.P. 1889, LXX). United Kingdom Official Publication.    References  
Boot, H. M. and Maindonald, J. H. 2007. New estimates of age- and sex- specific earnings and the male-female earnings gap in the British cotton industry, 1833-1906. Economic History Review . Published online 28-Aug-2007 doi: 10.1111/j.1468-0289.2007.00398.x    Examples    data(cottonworkers) str(cottonworkers) plot(survey1889 ~ census1886, data=cottonworkers) plot(I(avwage*survey1889) ~ I(avwage*census1886), data=cottonworkers)"
"DAAG-cps1","DAAG","cps1","Labour Training Evaluation Data",15992,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cps1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cps1.html","cps1 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   cps1 cps2 cps3    Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. 2005,""Does Matching overcome LaLonde's critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-cps2","DAAG","cps2","Labour Training Evaluation Data",2369,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cps2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cps2.html","cps1 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   cps1 cps2 cps3    Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. 2005,""Does Matching overcome LaLonde's critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-cps3","DAAG","cps3","Labour Training Evaluation Data",429,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cps3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cps3.html","cps1 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   cps1 cps2 cps3    Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. 2005,""Does Matching overcome LaLonde's critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-cricketer","DAAG","cricketer","Lifespans of UK 1st class cricketers born 1840-1960",5960,8,5,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cricketer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cricketer.html","cricketer R Documentation   Lifespans of UK 1st class cricketers born 1840-1960   Description  
Year and birth, lifespan, etc, of British first class cricketers, born 1840-1960, whose handedness could be determined from information in the Who's who of cricketers. The status (alive=0, dead =1), and lifetime or lifespan, is for 1992.    Usage   data(cricketer)   Format  
A data frame with 5960 observations on the following 8 variables.    left
a factor with levels right left   year
numeric, year of birth   life
numeric, lifetime or lifespan to 1992   dead
numeric (0 = alive (censored), 1 = dead, in 1992)   acd
numeric (0 = not accidental or not dead, 1 = accidental death)   kia
numeric (0 = not killed in action, 1 = killed in action)   inbed
numeric (0 = did not die in bed, 1 = died in bed)   cause
a factor with levels alive acd  (accidental death) inbed (died in bed)     Details  
Note that those 'killed in action' (mostly during World Wars I and II) form a subset of those who died by accident.    Source  
John Aggleton, Martin Bland. Data were collated as described in Aggleton et al.    References  
Aggleton JP, Bland JM, Kentridge RW, Neave NJ 1994. Handedness and longevity: an archival study of cricketers. British Medical Journal 309, 1681-1684.   
Bailey P, Thorne P, Wynne-Thomas P. 1993. Who's Who of Cricketers. 2nd ed, London, Hamlyn.   
Bland M and Altman D. 2005. Do the left-handed die young? Significance 2, 166-170.    See Also  
earlycrcktr .   Examples    data(cricketer) numLH <- xtabs(~ left+year, data=cricketer) propLH <- prop.table(numLH, margin=2)[2,] yr <- as.numeric(colnames(numLH)) plot(propLH ~ yr) cricketer$lh <- unclass(cricketer$left)-1 left2.hat <- fitted(lm(lh ~ poly(year,2), data=cricketer)) ord <- order(cricketer$year) lines(left2.hat[ord] ~ cricketer$year[ord]) library(splines) ns3.hat <- fitted(lm(lh ~ ns(year,3), data=cricketer)) lines(ns3.hat[ord] ~ cricketer$year[ord], col=""red"") require(survival) summary(coxph(Surv(life, kia) ~ bs(year,3) +left, data=cricketer)) cricketer$notacdDead <- with(cricketer, {dead[acd==1]<-0; dead}) summary(coxph(Surv(life, notacdDead) ~ ns(year,2) +left, data=cricketer))"
"DAAG-cuckoohosts","DAAG","cuckoohosts","Comparison of cuckoo eggs with host eggs",10,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cuckoohosts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cuckoohosts.html","cuckoohosts R Documentation   Comparison of cuckoo eggs with host eggs   Description  
These data compare mean length, mean breadth, and egg color, between cuckoos and their hosts.    Usage   cuckoohosts   Format  
A data frame with 10 observations on the following 12 variables.    clength
mean length of cuckoo eggs in given host's nest   cl.sd
standard deviation of cuckoo egg lengths   cbreadth
mean breadth of cuckoo eggs in given host's nest   cb.sd
standard deviation of cuckoo egg breadths   cnum
number of cuckoo eggs   hlength
length of host eggs   hl.sd
standard deviation of host egg lengths   hbreadth
breadth of host eggs   hb.sd
standard deviation of host egg breadths   hnum
number of host eggs   match
number of eggs where color matched   nomatch
number where color did not match     Details  
Although from the same study that generated data in the data frame  cuckoos , the data do not match precisely. The cuckoo egg lengths and breadths are from the tables on page 168, the host egg lengths and breadths from Appendix IV on page 176, and the color match counts from the table on page 171.    Source  
Latter, O.H., 1902. The egg of cuculus canorus . an inquiry into the dimensions of the cuckoo's egg and the relation of the variations to the size of the eggs of the foster-parent, with notes on coloration, &c.  Biometrika , 1:164–176.    Examples    cuckoohosts str(cuckoohosts) plot(cuckoohosts) with(cuckoohosts, plot(c(clength,hlength),c(cbreadth,hbreadth),col=rep(1:2,c(6,6))))"
"DAAG-cuckoos","DAAG","cuckoos","Cuckoo Eggs Data",120,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/cuckoos.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/cuckoos.html","cuckoos R Documentation   Cuckoo Eggs Data   Description  
Length and breadth measurements of 120 eggs lain in the nests of six different species of host bird.    Usage   cuckoos   Format  
This data frame contains the following columns:    length
the egg lengths in millimeters   breadth
the egg breadths in millimeters   species
a factor with levels  hedge.sparrow , meadow.pipit , pied.wagtail , robin , tree.pipit , wren    id
a numeric vector     Source  
Latter, O.H. (1902). The eggs of Cuculus canorus. An Inquiry into the dimensions of the cuckoo's egg and the relation of the variations to the size of the eggs of the foster-parent, with notes on coloration, &c. Biometrika i, 164.   References  
Tippett, L.H.C. 1931: ""The Methods of Statistics"". Williams & Norgate, London.    Examples   print(""Strip and Boxplots - Example 2.1.2"") attach(cuckoos) oldpar <- par(las = 2) # labels at right angle to axis. stripchart(length ~ species) boxplot(split(cuckoos$length, cuckoos$species), xlab=""Length of egg"", horizontal=TRUE) detach(cuckoos) par(oldpar) pause() print(""Summaries - Example 2.2.2"") sapply(split(cuckoos$length, cuckoos$species), sd) pause() print(""Example 4.1.4"") wren <- split(cuckoos$length, cuckoos$species)$wren median(wren) n <- length(wren) sqrt(pi/2)*sd(wren)/sqrt(n) # this s.e. computation assumes normality"
"DAAG-dengue","DAAG","dengue","Dengue prevalence, by administrative region",2000,13,1,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/dengue.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/dengue.html","dengue R Documentation   Dengue prevalence, by administrative region   Description  
Data record, for each of 2000 administrative regions, whether or not dengue was recorded at any time between 1961 and 1990.    Usage   data(dengue)   Format  
A data frame with 2000 observations on the following 13 variables.    humid
Average vapour density: 1961-1990   humid90
90th percentile of humid   temp
Average temperature: 1961-1990   temp90
90th percentile of temp   h10pix
maximum of humid , within a 10 pixel radius   h10pix90
maximum of humid90 , within a 10 pixel radius   trees
Percent tree cover, from satellite data   trees90
90th percentile of trees   NoYes
Was dengue observed? (1=yes)   Xmin
minimum longitude   Xmax
maximum longitude   Ymin
minimum latitude   Ymax
maximum latitude     Details  
This is derived from a data set in which the climate and tree cover information were given for each half degree of latitude by half degreee of longitude pixel. The variable NoYes was given by administrative region. The climate data and tree cover data given here are 50th or 90th percentiles, where percetiles were calculates across pixels for an administrative region.    Source  
Simon Hales, Environmental Research New Zealand Ltd.    References  
Hales, S., de Wet, N., Maindonald, J. and Woodward, A. 2002. Potential effect of population and climate change global distribution of dengue fever: an empirical model. The Lancet 2002; 360: 830-34.   Examples    str(dengue) glm(NoYes ~ humid, data=dengue, family=binomial) glm(NoYes ~ humid90, data=dengue, family=binomial)"
"DAAG-dewpoint","DAAG","dewpoint","Dewpoint Data",72,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/dewpoint.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/dewpoint.html","dewpoint R Documentation   Dewpoint Data   Description  
The dewpoint data frame has 72 rows and 3 columns. Monthly data were obtained for a number of sites (in Australia) and a number of months.   Usage   dewpoint   Format  
This data frame contains the following columns:    maxtemp
monthly minimum temperatures   mintemp
monthly maximum temperatures   dewpt
monthly average dewpoint for each combination of minimum and maximum temperature readings (formerly dewpoint)     Source  
Dr Edward Linacre, visiting fellow in the Australian National University Department of Geography.   Examples    print(""Additive Model - Example 7.5"") require(splines) attach(dewpoint) ds.lm <- lm(dewpt ~ bs(maxtemp,5) + bs(mintemp,5), data=dewpoint) ds.fit <-predict(ds.lm, type=""terms"", se=TRUE) oldpar <- par(mfrow=c(1,2)) plot(maxtemp, ds.fit$fit[,1], xlab=""Maximum temperature"", ylab=""Change from dewpoint mean"",type=""n"") lines(maxtemp,ds.fit$fit[,1]) lines(maxtemp,ds.fit$fit[,1]-2*ds.fit$se[,1],lty=2) lines(maxtemp,ds.fit$fit[,1]+2*ds.fit$se[,1],lty=2) plot(mintemp,ds.fit$fit[,2],xlab=""Minimum temperature"", ylab=""Change from dewpoint mean"",type=""n"") ord<-order(mintemp) lines(mintemp[ord],ds.fit$fit[ord,2]) lines(mintemp[ord],ds.fit$fit[ord,2]-2*ds.fit$se[ord,2],lty=2) lines(mintemp[ord],ds.fit$fit[ord,2]+2*ds.fit$se[ord,2],lty=2) detach(dewpoint) par(oldpar)"
"DAAG-droughts","DAAG","droughts","Periods Between Rain Events",2042,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/droughts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/droughts.html","droughts R Documentation   Periods Between Rain Events   Description  
Data collected at Winnipeg International Airport (Canada) on periods (in days) between rain events.   Usage   droughts   Format  
This data frame contains the following columns:    length
the length of time from the completion of the last rain event to the beginning of the next rain event.   year
the calendar year.     Examples    boxplot(length ~ year, data=droughts) boxplot(log(length) ~ year, data=droughts) hist(droughts$length, main=""Winnipeg Droughts"", xlab=""length (in days)"") hist(log(droughts$length), main=""Winnipeg Droughts"", xlab=""length (in days, log scale)"")"
"DAAG-edcCO2","DAAG","edcCO2","EPICA Dome C Ice Core 800KYr Carbon Dioxide Data",1096,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/edcCO2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/edcCO2.html","edcCO2 R Documentation   EPICA Dome C Ice Core 800KYr Carbon Dioxide Data   Description  
Carbon dioxide record from the EPICA (European Project for Ice Coring in Antarctica) Dome C ice core covering 0 to 800 kyr BP.   Usage   data(edcCO2)   Format  
A data frame with 1096 observations on the following 2 variables.    age
Age in years before present (BP)   co2
CO2 level (ppmv)     Details  
Data are a composite series.    Source  
http://www.ncdc.noaa.gov/paleo/icecore/antarctica/domec/domec_epica_data.html    References  
Luthi, D., M. et al. 2008. High-resolution carbon dioxide concentration record 650,000-800,000 years before present. Nature, Vol. 453, pp. 379-382, 15 May 2008. doi:10.1038/nature06949   
Indermuhle, A., E. et al, 1999, Atmospheric CO2 concentration from 60 to 20 kyr BP from the Taylor Dome ice core, Antarctica. Geophysical Research Letters, 27, 735-738.   
Monnin, E., A. et al. 2001. Atmospheric CO2 concentrations over the last glacial termination. Science, Vol. 291, pp. 112-114.   
Petit, J.R. et al. 1999. Climate and atmospheric history of the past 420,000 years from the Vostok ice core, Antarctica. Nature 399: 429-436.   
Siegenthaler, U. et al. 2005. Stable Carbon Cycle-Climate Relationship During the Late Pleistocene. Science, v. 310 , pp. 1313-1317, 25 November 2005.    Examples    data(edcCO2)"
"DAAG-edcT","DAAG","edcT","EPICA Dome C Ice Core 800KYr Temperature Estimates",5788,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/edcT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/edcT.html","edcT R Documentation   EPICA Dome C Ice Core 800KYr Temperature Estimates   Description  
Temperature record, using Deuterium as a proxy, from the EPICA (European Project for Ice Coring in Antarctica) Dome C ice core covering 0 to 800 kyr BP.   Usage   data(edcT)   Format  
A data frame with 5788 observations on the following 5 variables.    Bag
Bag number   ztop
Top depth (m)   Age
Years before 1950   Deuterium
Deuterium dD data   dT
Temperature difference from the average of the last 1000 years ~ -54.5degC     Details  
Temperature was estimated from the deuterium data, after making various corrections.    Source  
http://www.ncdc.noaa.gov/paleo/icecore/antarctica/domec/domec_epica_data.html     References  
Jouzel, J., et al. 2007. EPICA Dome C Ice Core 800KYr Deuterium Data and Temperature Estimates. IGBP PAGES/World Data Center for Paleoclimatology Data Contribution Series \# 2007-091. NOAA/NCDC Paleoclimatology Program, Boulder CO, USA.   
Jouzel, J., et al. 2007. Orbital and Millennial Antarctic Climate Variability over the Past 800,000 Years. Science, Vol. 317, No. 5839, pp.793-797, 10 August 2007.   Examples   data(edcT)"
"DAAG-elastic1","DAAG","elastic1","Elastic Band Data Replicated",7,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/elastic1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/elastic1.html","elastic1 R Documentation   Elastic Band Data Replicated   Description  
The elastic1 data frame has 7 rows and 2 columns giving, for each amount by which an elastic band is stretched over the end of a ruler, the distance that the band traveled when released.    Usage   elastic1   Format  
This data frame contains the following columns:    stretch
the amount by which the elastic band was stretched   distance
the distance traveled     Source  
J. H. Maindonald    Examples    ## Not run: plot(elastic1) print(""Inline Functions - Example 12.2.2"") sapply(elastic1, mean) pause() sapply(elastic1, function(x)mean(x)) pause() sapply(elastic1, function(x)sum(log(x))) pause() print(""Data Output - Example 12.3.2"") write.table(elastic1, file=""bandsframe.txt"") ## End(Not run)"
"DAAG-elastic2","DAAG","elastic2","Elastic Band Data Replicated Again",9,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/elastic2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/elastic2.html","elastic2 R Documentation   Elastic Band Data Replicated Again   Description  
The elastic2 data frame has 9 rows and 2 columns giving, for each amount by which an elastic band is stretched over the end of a ruler, the distance that the band traveled when released.    Usage   elastic2   Format  
This data frame contains the following columns:    stretch
the amount by which the elastic band was stretched   distance
the distance traveled     Source  
J. H. Maindonald    Examples    plot(elastic2) pause() print(""Chapter 5 Exercise"") yrange <- range(c(elastic1$distance, elastic2$distance)) xrange <- range(c(elastic1$stretch, elastic2$stretch)) plot(distance ~ stretch, data = elastic1, pch = 16, ylim = yrange, xlim = xrange) points(distance ~ stretch, data = elastic2, pch = 15, col = 2) legend(xrange[1], yrange[2], legend = c(""Data set 1"", ""Data set 2""), pch = c(16, 15), col = c(1, 2)) elastic1.lm <- lm(distance ~ stretch, data = elastic1) elastic2.lm <- lm(distance ~ stretch, data = elastic2) abline(elastic1.lm) abline(elastic2.lm, col = 2) summary(elastic1.lm) summary(elastic2.lm) pause() predict(elastic1.lm, se.fit=TRUE) predict(elastic2.lm, se.fit=TRUE)"
"DAAG-elasticband","DAAG","elasticband","Elastic Band Data",7,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/elasticband.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/elasticband.html","elasticband R Documentation   Elastic Band Data   Description  
The elasticband data frame has 7 rows and 2 columns giving, for each amount by which an elastic band is stretched over the end of a ruler, the distance that the band traveled when released.    Usage   elasticband   Format  
This data frame contains the following columns:    stretch
the amount by which the elastic band was stretched   distance
the distance traveled     Source  
J. H. Maindonald    Examples    ## Not run: print(""Example 1.8.1"") attach(elasticband) # R now knows where to find stretch and distance plot(stretch, distance) # Alternative: plot(distance ~ stretch) detach(elasticband) pause() print(""Output of Data Frames - Example 12.3.2"") write(t(elasticband),file=""bands.txt"",ncol=2) sink(""bands2.txt"") elasticband # NB: No output on screen sink() print(""Lists - Example 12.7"") elastic.lm <- lm(distance ~ stretch, data=elasticband) names(elastic.lm) elastic.lm$coefficients elastic.lm[[""coefficients""]] pause() elastic.lm[[1]] pause() elastic.lm[1] pause() options(digits=3) elastic.lm$residuals pause() elastic.lm$call pause() mode(elastic.lm$call) ## End(Not run)"
"DAAG-fossilfuel","DAAG","fossilfuel","Fossil Fuel Data",5,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/fossilfuel.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/fossilfuel.html","fossilfuel R Documentation   Fossil Fuel Data   Description  
Estimates of total worldwide carbon emissions from fossil fuel use.    Usage   fossilfuel   Format  
This data frame contains the following columns:    year
a numeric vector giving the year the measurement was taken.   carbon
a numeric vector giving the total worldwide carbon emissions from fossil fuel use, in millions of tonnes.     Source  
Marland et al (2003)    Examples    plot(fossilfuel)"
"DAAG-fossum","DAAG","fossum","Female Possum Measurements",43,14,1,0,2,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/fossum.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/fossum.html","fossum R Documentation   Female Possum Measurements   Description  
The fossum data frame consists of nine morphometric measurements on each of 43 female mountain brushtail possums, trapped at seven sites from Southern Victoria to central Queensland. This is a subset of the possum data frame.    Usage   fossum   Format  
This data frame contains the following columns:    case
observation number   site
one of seven locations where possums were trapped   Pop
a factor which classifies the sites as  Vic Victoria,  other New South Wales or Queensland   sex
a factor with levels  f female,  m male   age
age   hdlngth
head length   skullw
skull width   totlngth
total length   taill
tail length   footlgth
foot length   earconch
ear conch length   eye
distance from medial canthus to lateral canthus of right eye   chest
chest girth (in cm)   belly
belly girth (in cm)     Source  
Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458.   Examples    boxplot(fossum$totlngth)"
"DAAG-frogs","DAAG","frogs","Frogs Data",212,10,1,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/frogs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/frogs.html","frogs R Documentation   Frogs Data   Description  
The frogs data frame has 212 rows and 11 columns. The data are on the distribution of the Southern Corroboree frog, which occurs in the Snowy Mountains area of New South Wales, Australia.    Usage   frogs   Format  
This data frame contains the following columns:    pres.abs
0 = frogs were absent, 1 = frogs were present   northing
reference point   easting
reference point   altitude
altitude , in meters   distance
distance in meters to nearest extant population   NoOfPools
number of potential breeding pools   NoOfSites
(number of potential breeding sites within a 2 km radius   avrain
mean rainfall for Spring period   meanmin
mean minimum Spring temperature   meanmax
mean maximum Spring temperature     Source  
Hunter, D. (2000) The conservation and demography of the southern corroboree frog (Pseudophryne corroboree). M.Sc. thesis, University of Canberra, Canberra.    Examples    print(""Multiple Logistic Regression - Example 8.2"") plot(northing ~ easting, data=frogs, pch=c(1,16)[frogs$pres.abs+1], xlab=""Meters east of reference point"", ylab=""Meters north"") pairs(frogs[,4:10]) attach(frogs) pairs(cbind(altitude,log(distance),log(NoOfPools),NoOfSites), panel=panel.smooth, labels=c(""altitude"",""log(distance)"", ""log(NoOfPools)"",""NoOfSites"")) detach(frogs) frogs.glm0 <- glm(formula = pres.abs ~ altitude + log(distance) + log(NoOfPools) + NoOfSites + avrain + meanmin + meanmax, family = binomial, data = frogs) summary(frogs.glm0) frogs.glm <- glm(formula = pres.abs ~ log(distance) + log(NoOfPools) + meanmin + meanmax, family = binomial, data = frogs) oldpar <- par(mfrow=c(2,2)) termplot(frogs.glm, data=frogs) termplot(frogs.glm, data=frogs, partial.resid=TRUE) cv.binary(frogs.glm0) # All explanatory variables pause() cv.binary(frogs.glm) # Reduced set of explanatory variables for (j in 1:4){ rand <- sample(1:10, 212, replace=TRUE) all.acc <- cv.binary(frogs.glm0, rand=rand, print.details=FALSE)$acc.cv reduced.acc <- cv.binary(frogs.glm, rand=rand, print.details=FALSE)$acc.cv cat(""\nAll:"", round(all.acc,3), "" Reduced:"", round(reduced.acc,3)) }"
"DAAG-frostedflakes","DAAG","frostedflakes","Frosted Flakes data",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/frostedflakes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/frostedflakes.html","frostedflakes R Documentation   Frosted Flakes data   Description  
The frosted flakes data frame has 101 rows and 2 columns giving the sugar concentration (in percent) for 25 g samples of a cereal as measured by 2 methods – high performance liquid chromatography (a slow accurate lab method) and a quick method using the infra-analyzer 400.    Usage   elastic1   Format  
This data frame contains the following columns:    Lab
careful laboratory analysis measurements using high performance liquid chromatography   IA400
measurements based on the infra-analyzer 400     Source  
W. J. Braun"
"DAAG-fruitohms","DAAG","fruitohms","Electrical Resistance of Kiwi Fruit",128,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/fruitohms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/fruitohms.html","fruitohms R Documentation   Electrical Resistance of Kiwi Fruit   Description  
Data are from a study that examined how the electrical resistance of a slab of kiwifruit changed with the apparent juice content.    Usage   fruitohms   Format  
This data frame contains the following columns:    juice
apparent juice content (percent)   ohms
electrical resistance (in ohms)     Source  
Harker, F. R. and Maindonald J.H. 1994. Ripening of nectarine fruit. Plant Physiology 106: 165 - 171.    Examples    plot(ohms ~ juice, xlab=""Apparent juice content (%)"",ylab=""Resistance (ohms)"", data=fruitohms) lines(lowess(fruitohms$juice, fruitohms$ohms), lwd=2) pause() require(splines) attach(fruitohms) plot(ohms ~ juice, cex=0.8, xlab=""Apparent juice content (%)"", ylab=""Resistance (ohms)"", type=""n"") fruit.lmb4 <- lm(ohms ~ bs(juice,4)) ord <- order(juice) lines(juice[ord], fitted(fruit.lmb4)[ord], lwd=2) ci <- predict(fruit.lmb4, interval=""confidence"") lines(juice[ord], ci[ord,""lwr""]) lines(juice[ord], ci[ord,""upr""])"
"DAAG-gaba","DAAG","gaba","Effect of pentazocine on post-operative pain (average VAS scores)",9,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/gaba.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/gaba.html","gaba R Documentation   Effect of pentazocine on post-operative pain (average VAS scores)   Description  
The table shows, separately for males and females, the effect of pentazocine on post-operative pain profiles (average VAS scores), with (mbac and fbac) and without (mpl and fpl) preoperatively administered baclofen. Pain scores are recorded every 20 minutes, from 10 minutes to 170 minutes.    Usage   gaba   Format  
A data frame with 9 observations on the following 7 variables.    min
a numeric vector   mbac
a numeric vector   mpl
a numeric vector   fbac
a numeric vector   fpl
a numeric vector   avbac
a numeric vector   avplac
a numeric vector     Details  
15 females were given baclofen, as against 3 males. 7 females received the placebo, as against 16 males. Averages for the two treatments (baclofen/placebo), taken over all trial participants and ignoring sex, are misleading.    Source  
Gordon, N. C. et al.(1995): 'Enhancement of Morphine Analgesia by the GABA _B against Baclofen'. Neuroscience 69: 345-349.    Examples    data(gaba) mr <- range(gaba$min) tran <- range(gaba[, c(""mbac"",""mpl"",""fbac"",""fpl"")]) ## Means by treatment and sex par(mfrow=c(1,2)) plot(mr, tran, xlab = ""Time post pentazocine (min)"", ylab = ""Reduction in VAS pain rating"", type = ""n"", xlim = c(0, 170), ylim = tran) points(gaba$min, gaba$fbac, pch = 1, col = 8, lwd = 2, lty = 2, type = ""b"") points(gaba$min, gaba$fpl, pch = 0, col = 8, lwd = 2, lty = 2, type = ""b"") points(gaba$min, gaba$mbac, pch = 16, col = 8, lty = 2, type = ""b"") points(gaba$min, gaba$mpl, pch = 15, col = 8, lty = 2, type = ""b"") box() ## Now plot means, by treatment, averaged over all participants plot(mr, tran, xlab = ""Time post pentazocine (min)"", ylab = ""Reduction in VAS pain rating"", type = ""n"", xlim = c(0, 170), ylim = tran) bac <- (15 * gaba$fbac + 3 * gaba$mbac)/18 plac <- (7 * gaba$fpl + 9 * gaba$mpl)/16 points(gaba$min, plac, pch = 15, lty = 1, col=1, type = ""b"") points(gaba$min, bac, pch = 16, lty = 1, col=1, type = ""b"") box() par(mfrow=c(1,1))"
"DAAG-geophones","DAAG","geophones","Seismic Timing Data",56,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/geophones.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/geophones.html","geophones R Documentation   Seismic Timing Data   Description  
The geophones data frame has 56 rows and 2 columns. Thickness of a layer of Alberta substratum as measured by a line of geophones.    Usage   geophones   Format  
This data frame contains the following columns:    distance
location of geophone.   thickness
time for signal to pass through substratum.     Examples    plot(geophones) lines(lowess(geophones, f=.25))"
"DAAG-greatLakes","DAAG","greatLakes","Yearly averages of Great Lake heights: 1918 - 2009",92,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/greatLakes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/greatLakes.html","greatLakes R Documentation    Yearly averages of Great Lake heights: 1918 - 2009    Description  
Heights, stored as a multivariate time series, are for the lakes Erie, Michigan/Huron, Ontario and St Clair    Usage   data(greatLakes)   Format  
The format is: mts [1:92, 1:4] 174 174 174 174 174 ... - attr(*, ""dimnames"")=List of 2 ..$ : NULL ..$ : chr [1:4] ""Erie"" ""michHuron"" ""Ontario"" ""StClair"" - attr(*, ""tsp"")= num [1:3] 1918 2009 1 - attr(*, ""class"")= chr [1:2] ""mts"" ""ts""    Details  
For more details, go to the website that is the source of the data.    Source  
http://www.lre.usace.army.mil/Missions/GreatLakesInformation/GreatLakesWaterLevels/HistoricalData.aspx     Examples    data(greatLakes) plot(greatLakes) ## maybe str(greatLakes)"
"DAAG-grog","DAAG","grog","Alcohol consumption in Australia and New Zealand",18,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/grog.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/grog.html","grog R Documentation   Alcohol consumption in Australia and New Zealand   Description  
Data are annual apparent alcohol consumption in Australia and New Zealand, in liters of pure alcohol content per annum, separately for beer, wine, and spirits (including spirit-based products).    Usage   data(grog)   Format  
A data frame with 18 observations on the following 5 variables.    Beer
liters per annum   Wine
liters per annum   Spirit
liters per annum   Country
a factor with levels Australia   NewZealand   Year
Year ending in June of the given year     Details  
Data are total available pure alcohol content, for the three categories, divided by numbers of persons aged 15 years or more. The source data for New Zealand included quarterly figures from December 1997, and annual data to December for all years. The annual New Zealand figure to June 1998 required an estimate for September 1997 that was obtained by extrapolating back the third quarter trend line from later years.    Source  
Australian data are from http://www.abs.gov.au . For New Zealand data, go to  http://www.stats.govt.nz/infoshare/ Click on 'Industry sectors' and then on 'Alcohol Available for Consumption - ALC'.    Examples    data(grog) library(lattice) xyplot(Beer+Wine+Spirit ~ Year | Country, data=grog) xyplot(Beer+Wine+Spirit ~ Year, groups=Country, data=grog, outer=TRUE)"
"DAAG-head.injury","DAAG","head.injury","Minor Head Injury (Simulated) Data",3121,11,11,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/head.injury.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/head.injury.html","head.injury R Documentation   Minor Head Injury (Simulated) Data   Description  
The head.injury data frame has 3121 rows and 11 columns. The data were simulated according to a simple logistic regression model to match roughly the clinical characteristics of a sample of individuals who suffered minor head injuries.    Usage   head.injury   Format  
This data frame contains the following columns:    age.65
age factor (0 = under 65, 1 = over 65).   amnesia.before
amnesia before impact (less than 30 minutes = 0, more than 30 minutes =1).   basal.skull.fracture
(0 = no fracture, 1 = fracture).   GCS.decrease
Glasgow Coma Scale decrease (0 = no deterioration, 1 = deterioration).   GCS.13
initial Glasgow Coma Scale (0 = not ‘13’, 1 = ‘13’).   GCS.15.2hours
Glasgow Coma Scale after 2 hours (0 = not ‘15’, 1 = '15').   high.risk
assessed by clinician as high risk for neurological intervention (0 = not high risk, 1 = high risk).   loss.of.consciousness
(0 = conscious, 1 = loss of consciousness).   open.skull.fracture
(0 = no fracture, 1 = fracture)   vomiting
(0 = no vomiting, 1 = vomiting)   clinically.important.brain.injury
any acute brain finding revealed on CT (0 = not present, 1 = present).     References  
Stiell, I.G., Wells, G.A., Vandemheen, K., Clement, C., Lesiuk, H., Laupacis, A., McKnight, R.D., Verbee, R., Brison, R., Cass, D., Eisenhauer, M., Greenberg, G.H., and Worthington, J. (2001) The Canadian CT Head Rule for Patients with Minor Head Injury, The Lancet. 357: 1391-1396."
"DAAG-headInjury","DAAG","headInjury","Minor Head Injury (Simulated) Data",3121,11,11,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/headInjury.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/headInjury.html","headInjury R Documentation   Minor Head Injury (Simulated) Data   Description  
The headInjury data frame has 3121 rows and 11 columns. The data were simulated according to a simple logistic regression model to match roughly the clinical characteristics of a sample of individuals who suffered minor head injuries.    Usage   headInjury   Format  
This data frame contains the following columns:    age.65
age factor (0 = under 65, 1 = over 65).   amnesia.before
amnesia before impact (less than 30 minutes = 0, more than 30 minutes =1).   basal.skull.fracture
(0 = no fracture, 1 = fracture).   GCS.decrease
Glasgow Coma Scale decrease (0 = no deterioration, 1 = deterioration).   GCS.13
initial Glasgow Coma Scale (0 = not ‘13’, 1 = ‘13’).   GCS.15.2hours
Glasgow Coma Scale after 2 hours (0 = not ‘15’, 1 = '15').   high.risk
assessed by clinician as high risk for neurological intervention (0 = not high risk, 1 = high risk).   loss.of.consciousness
(0 = conscious, 1 = loss of consciousness).   open.skull.fracture
(0 = no fracture, 1 = fracture)   vomiting
(0 = no vomiting, 1 = vomiting)   clinically.important.brain.injury
any acute brain finding revealed on CT (0 = not present, 1 = present).     References  
Stiell, I.G., Wells, G.A., Vandemheen, K., Clement, C., Lesiuk, H., Laupacis, A., McKnight, R.D., Verbee, R., Brison, R., Cass, D., Eisenhauer, M., Greenberg, G.H., and Worthington, J. (2001) The Canadian CT Head Rule for Patients with Minor Head Injury, The Lancet. 357: 1391-1396."
"DAAG-hills","DAAG","hills","Scottish Hill Races Data",35,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/hills.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/hills.html","hills R Documentation   Scottish Hill Races Data   Description  
The record times in 1984 for 35 Scottish hill races.    Usage   hills   Format  
This data frame contains the following columns:    dist
distance, in miles (on the map)   climb
total height gained during the route, in feet   time
record time in hours     Source  
A.C. Atkinson (1986) Comment: Aspects of diagnostic regression analysis. Statistical Science 1, 397-402.   
Also, in MASS library, with time in minutes.    References  
A.C. Atkinson (1988) Transformations unmasked. Technometrics 30, 311-318. [ ""corrects"" the time for Knock Hill from 78.65 to 18.65. It is unclear if this based on the original records.]    Examples    print(""Transformation - Example 6.4.3"") pairs(hills, labels=c(""dist\n\n(miles)"", ""climb\n\n(feet)"", ""time\n\n(hours)"")) pause() pairs(log(hills), labels=c(""dist\n\n(log(miles))"", ""climb\n\n(log(feet))"", ""time\n\n(log(hours))"")) pause() hills0.loglm <- lm(log(time) ~ log(dist) + log(climb), data = hills) oldpar <- par(mfrow=c(2,2)) plot(hills0.loglm) pause() hills.loglm <- lm(log(time) ~ log(dist) + log(climb), data = hills[-18,]) summary(hills.loglm) plot(hills.loglm) pause() hills2.loglm <- lm(log(time) ~ log(dist)+log(climb)+log(dist):log(climb), data=hills[-18,]) anova(hills.loglm, hills2.loglm) pause() step(hills2.loglm) pause() summary(hills.loglm, corr=TRUE)$coef pause() summary(hills2.loglm, corr=TRUE)$coef par(oldpar) pause() print(""Nonlinear - Example 6.9.4"") hills.nls0 <- nls(time ~ (dist^alpha)*(climb^beta), start = c(alpha = .909, beta = .260), data = hills[-18,]) summary(hills.nls0) plot(residuals(hills.nls0) ~ predict(hills.nls0)) # residual plot pause() hills$climb.mi <- hills$climb/5280 hills.nls <- nls(time ~ alpha + beta*dist + gamma*(climb.mi^delta), start=c(alpha = 1, beta = 1, gamma = 1, delta = 1), data=hills[-18,]) summary(hills.nls) plot(residuals(hills.nls) ~ predict(hills.nls)) # residual plot"
"DAAG-hills2000","DAAG","hills2000","Scottish Hill Races Data - 2000",56,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/hills2000.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/hills2000.html","hills2000 R Documentation   Scottish Hill Races Data - 2000   Description  
The record times in 2000 for 56 Scottish hill races. We believe the data are, for the most part, trustworthy. This is the subset of races2000 for which type  is hill .    Usage   hills2000   Format  
This data frame contains the following columns:    dist
distance, in miles (on the map)   climb
total height gained during the route, in feet   time
record time in hours   timef
record time in hours for females     Source  
The Scottish Running Resource, http://www.hillrunning.co.uk    Examples    pairs(hills2000)"
"DAAG-hotspots","DAAG","hotspots","Hawaian island chain hotspot Potassium-Argon ages",35,6,0,3,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/hotspots.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/hotspots.html","hotspots R Documentation   Hawaian island chain hotspot Potassium-Argon ages   Description  
K-Ar Ages (millions of years) and distances (km) from Kilauea along the trend of the chain of Hawaian volcanic islands and other seamounts that are believed to have been created by a moving ""hot spot"". The age of Kilauea is given as 0-0.4 Ma.    Usage   data(hotspots)   Format  
A data frame with 36 observations on the following 6 variables.    ID
Volcano identifier   name
Name   distance
Distance in kilometers   age
K-Ar age in millions of years   error
Standard error of estimate?   source
Data source; see information on web site below.     Details  
For details of the way that errors werre calculated, refer to the original papers. See also the comments under hotspots2006 . In general, errors do not account for geological uncertainty.    Source  
http://www.soest.hawaii.edu/GG/HCV/haw_formation.html     Examples    data(hotspots) plot(age ~ distance, data=hotspots) abline(lm(age ~ distance, data=hotspots))"
"DAAG-hotspots2006","DAAG","hotspots2006","Hawaian island chain hotspot Argon-Argon ages",10,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/hotspots2006.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/hotspots2006.html","hotspots2006 R Documentation   Hawaian island chain hotspot Argon-Argon ages   Description  
Ar-Ar Ages (millions of years) and distances (km) from Kilauea along the trend of the chain of Hawaian volcanic islands and other seamounts that are believed to have been created by a moving ""hot spot"".   Usage   data(hotspots2006)   Format  
A data frame with 10 observations on the following 6 variables.    age
Ar-Ar age   CI95lim
Measurement error; 95% CI   geoErr
Geological Uncertainty   totplus
Total uncertainty (+)   totminus
Total uncertainty (-)   distance
Distance in kilometers     Details  
Note that measurement error is small relative to geological uncertainty. Geological uncertainty arises because lavas are likely to have erupted, over a period of up to 2 million years, somewhat after passage over the hot spot's centre. Dredging or drilling will in general have accessed larvas from the younger half of this interval. Hence the asymmetry in the geological uncertainty.    Source  
Warren D. Sharp and David A. Clague, 50-Ma initiation of Hawaiian-Emperor bend records major change in Pacific Plate motion. Science 313: 1281-1284 (2006).    Examples    data(hotspots2006)"
"DAAG-houseprices","DAAG","houseprices","Aranda House Prices",15,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/houseprices.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/houseprices.html","houseprices R Documentation   Aranda House Prices   Description  
The houseprices data frame consists of the floor area, price, and the number of bedrooms for a sample of houses sold in Aranda in 1999. Aranda is a suburb of Canberra, Australia.    Usage   houseprices   Format  
This data frame contains the following columns:    area
a numeric vector giving the floor area   bedrooms
a numeric vector giving the number of bedrooms   sale.price
a numeric vector giving the sale price in thousands of Australian dollars     Source  
J.H. Maindonald    Examples    plot(sale.price~area, data=houseprices) pause() coplot(sale.price~area|bedrooms, data=houseprices) pause() print(""Cross-Validation - Example 5.5.2"") houseprices.lm <- lm(sale.price ~ area, data=houseprices) summary(houseprices.lm)$sigma^2 pause() CVlm() pause() print(""Bootstrapping - Example 5.5.3"") houseprices.fn <- function (houseprices, index){ house.resample <- houseprices[index,] house.lm <- lm(sale.price ~ area, data=house.resample) coef(house.lm)[2] # slope estimate for resampled data } require(boot) # ensure that the boot package is loaded houseprices.boot <- boot(houseprices, R=999, statistic=houseprices.fn) houseprices1.fn <- function (houseprices, index){ house.resample <- houseprices[index,] house.lm <- lm(sale.price ~ area, data=house.resample) predict(house.lm, newdata=data.frame(area=1200)) } houseprices1.boot <- boot(houseprices, R=999, statistic=houseprices1.fn) boot.ci(houseprices1.boot, type=""perc"") # ""basic"" is an alternative to ""perc"" houseprices2.fn <- function (houseprices, index){ house.resample <- houseprices[index,] house.lm <- lm(sale.price ~ area, data=house.resample) houseprices$sale.price-predict(house.lm, houseprices) # resampled prediction errors } n <- length(houseprices$area) R <- 200 houseprices2.boot <- boot(houseprices, R=R, statistic=houseprices2.fn) house.fac <- factor(rep(1:n, rep(R, n))) plot(house.fac, as.vector(houseprices2.boot$t), ylab=""Prediction Errors"", xlab=""House"") pause() plot(apply(houseprices2.boot$t,2, sd)/predict.lm(houseprices.lm, se.fit=TRUE)$se.fit, ylab=""Ratio of Bootstrap SE's to Model-Based SE's"", xlab=""House"", pch=16) abline(1,0)"
"DAAG-humanpower1","DAAG","humanpower1","Oxygen uptake versus mechanical power, for humans",28,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/humanpower1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/humanpower1.html","humanpower R Documentation   Oxygen uptake versus mechanical power, for humans   Description  
The data set from Daedalus project.    Usage   data(humanpower1)   Format  
A data frame with 28 observations on the following 3 variables.    wattsPerKg
a numeric vector: watts per kilogram of body weight   o2
a numeric vector: ml/min/kg   id
a factor with levels 1 - 5 ( humanpower1 ) or 1 - 4 ( humanpower2 ), identifying the different athletes     Details  
Data in humanpower1 are from investigations (Bussolari 1987) designed to assess the feasibility of a proposed 119 kilometer human powered flight from the island of Crete – in the initial phase of the Daedalus project. Data are for five athletes – a female hockey player, a male amateur tri-athlete, a female amateur triathlete, a male wrestler and a male cyclist – who were selected from volunteers who were recruited through the news media, Data in humanpower2) are for four out of the 25 applicants who were selected for further testing, in the lead-up to the eventual selection of a pilot for the Daedalus project (Nadel and Bussolari 1988).      Source  
Bussolari, S.R.(1987). Human factors of long-distance human-powered aircraft flights. Human Power 5: 8-12.   
Nadel and Bussolari, S.R.(1988). The Daedalus project: physiological problems and solutions. American Scientist 76: 351-360.    References  
Nadel and Bussolari, S.R.(1989). The physiological limits of long-duration human-power production – lessons learned from the Daedalus project. Human Power 7: 7-10.    Examples    str(humanpower1) plot(humanpower1) lm(o2 ~ id + wattsPerKg:id, data=humanpower1) lm(o2 ~ id + wattsPerKg:id, data=humanpower2)"
"DAAG-humanpower2","DAAG","humanpower2","Oxygen uptake versus mechanical power, for humans",26,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/humanpower2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/humanpower2.html","humanpower R Documentation   Oxygen uptake versus mechanical power, for humans   Description  
The data set from Daedalus project.    Usage   data(humanpower1)   Format  
A data frame with 28 observations on the following 3 variables.    wattsPerKg
a numeric vector: watts per kilogram of body weight   o2
a numeric vector: ml/min/kg   id
a factor with levels 1 - 5 ( humanpower1 ) or 1 - 4 ( humanpower2 ), identifying the different athletes     Details  
Data in humanpower1 are from investigations (Bussolari 1987) designed to assess the feasibility of a proposed 119 kilometer human powered flight from the island of Crete – in the initial phase of the Daedalus project. Data are for five athletes – a female hockey player, a male amateur tri-athlete, a female amateur triathlete, a male wrestler and a male cyclist – who were selected from volunteers who were recruited through the news media, Data in humanpower2) are for four out of the 25 applicants who were selected for further testing, in the lead-up to the eventual selection of a pilot for the Daedalus project (Nadel and Bussolari 1988).      Source  
Bussolari, S.R.(1987). Human factors of long-distance human-powered aircraft flights. Human Power 5: 8-12.   
Nadel and Bussolari, S.R.(1988). The Daedalus project: physiological problems and solutions. American Scientist 76: 351-360.    References  
Nadel and Bussolari, S.R.(1989). The physiological limits of long-duration human-power production – lessons learned from the Daedalus project. Human Power 7: 7-10.    Examples    str(humanpower1) plot(humanpower1) lm(o2 ~ id + wattsPerKg:id, data=humanpower1) lm(o2 ~ id + wattsPerKg:id, data=humanpower2)"
"DAAG-hurricNamed","DAAG","hurricNamed","Named US Atlantic Hurricanes",94,12,1,2,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/hurricNamed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/hurricNamed.html","hurricNamed R Documentation    Named US Atlantic Hurricanes    Description  
Details are given of atmospheric pressure at landfall, estimated damage in millions of dollars, and deaths, for named hurricanes that made landfall in the US mainland from 1950 through to 2012.    Usage   data(""hurricNamed"")   Format  
A data frame with 94 observations on the following 11 variables.    Name
Hurricane name   Year
Numeric   LF.WindsMPH
Maximum sustained windspeed (>= 1 minute) to occur along the US coast. Prior to 1980, this is estimated from the maximum windspeed associated with the Saffir-Simpson index at landfall. If 2 or more landfalls, the maximum is taken   LF.PressureMB
Atmospheric pressure at landfall in millibars. If 2 or more landfalls, the minimum is taken   LF.times
Date of first landfall   BaseDam2014
Property damage (millions of 2014 US dollars)   BaseDamage
Property damage (in millions of dollars for that year)   NDAM2014
Damage, had hurricane appeared in 2014   AffectedStates
Affected states (2-digit abbreviations), pasted together   firstLF
Date of first landfall   deaths
Number of continental US direct and indirect deaths   mf
Gender of name; a factor with levels f m     Details  
An earlier version of these data was the subject of a controversial paper that claimed to have found that hurricanes with female names, presumably because taken less seriously, did more human damage after adjusting for the severity of the storm than those with male names.    Source  
http://www.icatdamageestimator.com/  Deaths except for Audrey and Katrina, are in the Excel file that is available from  http://www.pnas.org/content/suppl/2014/05/30/1402786111.DCSupplemental  NOAA Monthly Weather Reports (MWRs) supplied the numbers of deaths for all except Donna, Celia, Audrey and Katrina. The figure for Celia is from http://www.nhc.noaa.gov/pdf/NWS-TPC-5.pdf . For the other three hurricanes it is from the Atlantic hurricane list in Wikipedia (see the references.)    References  
http://www.icatdamageestimator.com/   https://www.aoml.noaa.gov/hrd/hurdat/mwr_pdf/   http://en.wikipedia.org/wiki/List_of_Atlantic_hurricanes   http://www.pnas.org/cgi/doi/10.1073/pnas.1402786111     Examples    data(hurricNamed) str(hurricNamed) plot(log(deaths+0.5) ~ log(NDAM2014), data=hurricNamed) with(hurricNamed, lines(lowess(log(deaths+0.5) ~ log(NDAM2014)))) plot(log(deaths+0.5) ~ I(NDAM2014^0.14), data=hurricNamed) with(hurricNamed, lines(lowess(log(deaths+0.1) ~ I(NDAM2014^0.14))))"
"DAAG-intersalt","DAAG","intersalt","Blood pressure versus Salt; inter-population data",52,4,0,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/intersalt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/intersalt.html","intersalt R Documentation   Blood pressure versus Salt; inter-population data   Description  
Median blood pressure, as a fuction of salt intake, for each of 52 human populations.    Usage   intersalt   Format  
A data frame with 52 observations on the following 4 variables.    b
a numeric vector   bp
mean diastolic blood pressure (mm Hg)   na
mean sodium excretion (mmol/24h)   country
a character vector     Details  
For each population took a sample of 25 males and 25 females from each decade in the age range 20 - 50, i.e. 200 individuals in all.    Source  
Intersalt Cooperative Research Group. 1988. Intersalt: an international study of electrolyte excretion and blood pressure: results for 24 hour urinary sodium and potassium excretion. British Medical Journal  297: 319-328.   References  
Maindonald, J.H. The Design of Research Studies ? A Statistical Perspective , viii + 109pp. Graduate School Occasional Paper 00/2, Australian National University 2000.    Examples    data(intersalt) plot(bp ~ na, data=intersalt, xlab=""Median sodium excretion (mmol/24h)"", ylab=""Median diatoluc blood pressure (mm Hg)"")"
"DAAG-ironslag","DAAG","ironslag","Iron Content Measurements",53,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/ironslag.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/ironslag.html","ironslag R Documentation   Iron Content Measurements   Description  
The ironslag data frame has 53 rows and 2 columns. Two methods for measuring the iron content in samples of slag were compared, a chemical and a magnetic method. The chemical method requires greater effort than the magnetic method.    Usage   ironslag   Format  
This data frame contains the following columns:    chemical
a numeric vector containing the measurements coming from the chemical method   magnetic
a numeric vector containing the measurments coming from the magnetic method     Source  
Hand, D.J., Daly, F., McConway, K., Lunn, D., and Ostrowski, E. eds (1993) A Handbook of Small Data Sets. London: Chapman & Hall.   Examples    iron.lm <- lm(chemical ~ magnetic, data = ironslag) oldpar <- par(mfrow = c(2,2)) plot(iron.lm) par(oldpar)"
"DAAG-jobs","DAAG","jobs","Canadian Labour Force Summary Data (1995-96)",24,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/jobs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/jobs.html","jobs R Documentation   Canadian Labour Force Summary Data (1995-96)   Description  
The number of workers in the Canadian labour force broken down by region (BC, Alberta, Prairies, Ontario, Quebec, Atlantic) for the 24-month period from January, 1995 to December, 1996 (a time when Canada was emerging from a deep economic recession).    Usage   jobs   Format  
This data frame contains the following columns:    BC
monthly labour force counts in British Columbia   Alberta
monthly labour force counts in Alberta   Prairies
monthly labour force counts in Saskatchewan and Manitoba   Ontario
monthly labour force counts in Ontario   Quebec
monthly labour force counts in Quebec   Atlantic
monthly labour force counts in Newfoundland, Nova Scotia, Prince Edward Island and New Brunswick   Date
year (in decimal form)     Details  
These data have been seasonally adjusted.    Source  
Statistics Canada    Examples    print(""Multiple Variables and Times - Example 2.1.4"") sapply(jobs, range) pause() matplot(jobs[,7], jobs[,-7], type=""l"", xlim=c(95,97.1)) # Notice that we have been able to use a data frame as the second argument to matplot(). # For more information on matplot(), type help(matplot) text(rep(jobs[24,7], 6), jobs[24,1:6], names(jobs)[1:6], adj=0) pause() sapply(log(jobs[,-7]), range) apply(sapply(log(jobs[,-7]), range), 2, diff) pause() oldpar <- par(mfrow=c(2,3)) range.log <- sapply(log(jobs[,-7], 2), range) maxdiff <- max(apply(range.log, 2, diff)) range.log[2,] <- range.log[1,] + maxdiff titles <- c(""BC Jobs"",""Alberta Jobs"",""Prairie Jobs"", ""Ontario Jobs"", ""Quebec Jobs"", ""Atlantic Jobs"") for (i in 1:6){ plot(jobs$Date, log(jobs[,i], 2), type = ""l"", ylim = range.log[,i], xlab = ""Time"", ylab = ""Number of jobs"", main = titles[i]) } par(oldpar)"
"DAAG-kiwishade","DAAG","kiwishade","Kiwi Shading Data",48,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/kiwishade.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/kiwishade.html","kiwishade R Documentation   Kiwi Shading Data   Description  
The kiwishade data frame has 48 rows and 4 columns. The data are from a designed experiment that compared different kiwifruit shading treatments. There are four vines in each plot, and four plots (one for each of four treatments: none, Aug2Dec, Dec2Feb, and Feb2May) in each of three blocks (locations: west, north, east). Each plot has the same number of vines, each block has the same number of plots, with each treatment occurring the same number of times.    Usage   kiwishade   Format  
This data frame contains the following columns:    yield
Total yield (in kg)   plot
a factor with levels east.Aug2Dec ,  east.Dec2Feb , east.Feb2May ,  east.none , north.Aug2Dec ,  north.Dec2Feb , north.Feb2May ,  north.none , west.Aug2Dec ,  west.Dec2Feb , west.Feb2May ,  west.none   block
a factor indicating the location of the plot with levels  east , north , west   shade
a factor representing the period for which the experimenter placed shading over the vines; with levels:  none no shading, Aug2Dec August - December,  Dec2Feb December - February, Feb2May February - May     Details  
The northernmost plots were grouped together because they were similarly affected by shading from the sun in the north. For the remaining two blocks shelter effects, whether from the west or from the east, were thought more important.    Source  
Snelgar, W.P., Manson. P.J., Martin, P.J. 1992. Influence of time of shading on flowering and yield of kiwifruit vines. Journal of Horticultural Science 67: 481-487.    References  
Maindonald J H 1992. Statistical design, analysis and presentation issues. New Zealand Journal of Agricultural Research 35: 121-141.    Examples    print(""Data Summary - Example 2.2.1"") attach(kiwishade) kiwimeans <- aggregate(yield, by=list(block, shade), mean) names(kiwimeans) <- c(""block"",""shade"",""meanyield"") kiwimeans[1:4,] pause() print(""Multilevel Design - Example 9.3"") kiwishade.aov <- aov(yield ~ shade+Error(block/shade),data=kiwishade) summary(kiwishade.aov) pause() sapply(split(yield, shade), mean) pause() kiwi.table <- t(sapply(split(yield, plot), as.vector)) kiwi.means <- sapply(split(yield, plot), mean) kiwi.means.table <- matrix(rep(kiwi.means,4), nrow=12, ncol=4) kiwi.summary <- data.frame(kiwi.means, kiwi.table-kiwi.means.table) names(kiwi.summary)<- c(""Mean"", ""Vine 1"", ""Vine 2"", ""Vine 3"", ""Vine 4"") kiwi.summary mean(kiwi.means) # the grand mean (only for balanced design) if(require(lme4, quietly=TRUE)) { kiwishade.lmer <- lmer(yield ~ shade + (1|block) + (1|block:plot), data=kiwishade) ## block:shade is an alternative to block:plot kiwishade.lmer ## Residuals and estimated effects xyplot(residuals(kiwishade.lmer) ~ fitted(kiwishade.lmer)|block, data=kiwishade, groups=shade, layout=c(3,1), par.strip.text=list(cex=1.0), xlab=""Fitted values (Treatment + block + plot effects)"", ylab=""Residuals"", pch=1:4, grid=TRUE, scales=list(x=list(alternating=FALSE), tck=0.5), key=list(space=""top"", points=list(pch=1:4), text=list(labels=levels(kiwishade$shade)),columns=4)) ploteff <- ranef(kiwishade.lmer, drop=TRUE)[[1]] qqmath(ploteff, xlab=""Normal quantiles"", ylab=""Plot effect estimates"", scales=list(tck=0.5)) }"
"DAAG-leafshape","DAAG","leafshape","Full Leaf Shape Data Set",286,9,1,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/leafshape.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/leafshape.html","leafshape R Documentation   Full Leaf Shape Data Set   Description  
Leaf length, width and petiole measurements taken at various sites in Australia.    Usage   leafshape   Format  
This data frame contains the following columns:    bladelen
leaf length (in mm)   petiole
a numeric vector   bladewid
leaf width (in mm)   latitude
latitude   logwid
natural logarithm of width   logpet
logarithm of petiole   loglen
logarithm of length   arch
leaf architecture (0 = plagiotropic, 1 = orthotropic   location
a factor with levels  Sabah , Panama , Costa Rica ,  N Queensland , S Queensland , Tasmania     Source  
King, D.A. and Maindonald, J.H. 1999. Tree architecture in relation to leaf dimensions and tree stature in temperate and tropical rain forests. Journal of Ecology 87: 1012-1024."
"DAAG-leafshape17","DAAG","leafshape17","Subset of Leaf Shape Data Set",61,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/leafshape17.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/leafshape17.html","leafshape17 R Documentation   Subset of Leaf Shape Data Set   Description  
The leafshape17 data frame has 61 rows and 8 columns. These are leaf length, width and petiole measurements taken at several sites in Australia. This is a subset of the leafshape data frame.    Usage   leafshape17   Format  
This data frame contains the following columns:    bladelen
leaf length (in mm)   petiole
a numeric vector   bladewid
leaf width (in mm)   latitude
latitude   logwid
natural logarithm of width   logpet
logarithm of petiole measurement   loglen
logarithm of length   arch
leaf architecture (0 = orthotropic, 1 = plagiotropic)     Source  
King, D.A. and Maindonald, J.H. 1999. Tree architecture in relation to leaf dimensions and tree stature in temperate and tropical rain forests. Journal of Ecology 87: 1012-1024.    Examples    print(""Discriminant Analysis - Example 11.2"") require(MASS) leaf17.lda <- lda(arch ~ logwid+loglen, data=leafshape17) leaf17.hat <- predict(leaf17.lda) leaf17.lda table(leafshape17$arch, leaf17.hat$class) pause() tab <- table(leafshape17$arch, leaf17.hat$class) sum(tab[row(tab)==col(tab)])/sum(tab) leaf17cv.lda <- lda(arch ~ logwid+loglen, data=leafshape17, CV=TRUE) tab <- table(leafshape17$arch, leaf17cv.lda$class) pause() leaf17.glm <- glm(arch ~ logwid + loglen, family=binomial, data=leafshape17) options(digits=3) summary(leaf17.glm)$coef pause() leaf17.one <- cv.binary(leaf17.glm) table(leafshape17$arch, round(leaf17.one$internal)) # Resubstitution pause() table(leafshape17$arch, round(leaf17.one$cv)) # Cross-validation"
"DAAG-leaftemp","DAAG","leaftemp","Leaf and Air Temperature Data",62,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/leaftemp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/leaftemp.html","leaftemp R Documentation   Leaf and Air Temperature Data   Description  
These data consist of measurements of vapour pressure and of the difference between leaf and air temperature.    Usage   leaftemp   Format  
This data frame contains the following columns:    CO2level
Carbon Dioxide level  low , medium , high   vapPress
Vapour pressure   tempDiff
Difference between leaf and air temperature   BtempDiff
a numeric vector     Source  
Katharina Siebke and Susan von Cammerer, Australian National University.    Examples    print(""Fitting Multiple Lines - Example 7.3"") leaf.lm1 <- lm(tempDiff ~ 1 , data = leaftemp) leaf.lm2 <- lm(tempDiff ~ vapPress, data = leaftemp) leaf.lm3 <- lm(tempDiff ~ CO2level + vapPress, data = leaftemp) leaf.lm4 <- lm(tempDiff ~ CO2level + vapPress + vapPress:CO2level, data = leaftemp) anova(leaf.lm1, leaf.lm2, leaf.lm3, leaf.lm4) summary(leaf.lm2) plot(leaf.lm2)"
"DAAG-leaftemp.all","DAAG","leaftemp.all","Full Leaf and Air Temperature Data Set",62,9,0,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/leaftemp.all.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/leaftemp.all.html","leaftemp.all R Documentation   Full Leaf and Air Temperature Data Set   Description  
The leaftemp.all data frame has 62 rows and 9 columns.    Usage   leaftemp.all   Format  
This data frame contains the following columns:    glasshouse
a factor with levels  A ,  B ,  C   CO2level
a factor with Carbon Dioxide Levels:  high ,  low ,  medium   day
a factor   light
a numeric vector   CO2
a numeric vector   tempDiff
Difference between Leaf and Air Temperature   BtempDiff
a numeric vector   airTemp
Air Temperature   vapPress
Vapour Pressure     Source  
J.H. Maindonald"
"DAAG-litters","DAAG","litters","Mouse Litters",20,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/litters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/litters.html","litters R Documentation   Mouse Litters   Description  
Data on the body and brain weights of 20 mice, together with the size of the litter. Two mice were taken from each litter size.    Usage   litters   Format  
This data frame contains the following columns:    lsize
litter size   bodywt
body weight   brainwt
brain weight     Source  
Wainright P, Pelkman C and Wahlsten D 1989. The quantitative relationship between nutritional effects on preweaning growth and behavioral development in mice. Developmental Psychobiology 22: 183-193.    Examples    print(""Multiple Regression - Example 6.2"") pairs(litters, labels=c(""lsize\n\n(litter size)"", ""bodywt\n\n(Body Weight)"", ""brainwt\n\n(Brain Weight)"")) # pairs(litters) gives a scatterplot matrix with less adequate labeling mice1.lm <- lm(brainwt ~ lsize, data = litters) # Regress on lsize mice2.lm <- lm(brainwt ~ bodywt, data = litters) #Regress on bodywt mice12.lm <- lm(brainwt ~ lsize + bodywt, data = litters) # Regress on lsize & bodywt summary(mice1.lm)$coef # Similarly for other coefficients. # results are consistent with the biological concept of brain sparing pause() hat(model.matrix(mice12.lm)) # hat diagonal pause() plot(lm.influence(mice12.lm)$hat, residuals(mice12.lm)) print(""Diagnostics - Example 6.3"") mice12.lm <- lm(brainwt ~ bodywt+lsize, data=litters) oldpar <-par(mfrow = c(1,2)) bx <- mice12.lm$coef[2]; bz <- mice12.lm$coef[3] res <- residuals(mice12.lm) plot(litters$bodywt, bx*litters$bodywt+res, xlab=""Body weight"", ylab=""Component + Residual"") panel.smooth(litters$bodywt, bx*litters$bodywt+res) # Overlay plot(litters$lsize, bz*litters$lsize+res, xlab=""Litter size"", ylab=""Component + Residual"") panel.smooth(litters$lsize, bz*litters$lsize+res) par(oldpar)"
"DAAG-Lottario","DAAG","Lottario","Ontario Lottery Data",39,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/Lottario.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/Lottario.html","Lottario R Documentation   Ontario Lottery Data   Description  
The data frame Lottario  is a summary of 122 weekly draws of an Ontario lottery, beginning in November, 1978. Each draw consists of 7 numbered balls, drawn without replacement from an urn consisting of balls numbered from 1 through 39.    Usage   Lottario   Format  
This data frame contains the following columns:    Number
the integers from 1 to 39, representing the numbered balls   Frequency
the number of occurrences of each numbered ball     Source  
The Ontario Lottery Corporation    References  
Bellhouse, D.R. (1982). Fair is fair: new rules for Canadian lotteries. Canadian Public Policy - Analyse de Politiques 8: 311-320.    Examples   order(Lottario$Frequency)[33:39] # the 7 most frequently chosen numbers"
"DAAG-lung","DAAG","lung","Cape Fur Seal Lung Measurements",30,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/lung.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/lung.html","lung R Documentation   Cape Fur Seal Lung Measurements   Description  
The lung vector consists of weight measurements of lungs taken from 30 Cape Fur Seals that died as an unintended consequence of commercial fishing.    Usage   lung"
"DAAG-Manitoba.lakes","DAAG","Manitoba.lakes","The Nine Largest Lakes in Manitoba",9,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/Manitoba.lakes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/Manitoba.lakes.html","Manitoba.lakes R Documentation   The Nine Largest Lakes in Manitoba   Description  
The Manitoba.lakes data frame has 9 rows and 2 columns. The areas and elevations of the nine largest lakes in Manitoba, Canada. The geography of Manitoba (a relatively flat province) can be divided crudely into three main areas: a very flat prairie in the south which is at a relatively high elevation, a middle region consisting of mainly of forest and Precambrian rock, and a northern region which drains more rapidly into Hudson Bay. All water in Manitoba, which does not evaporate, eventually drains into Hudson Bay.   Usage   Manitoba.lakes   Format  
This data frame contains the following columns:    elevation
a numeric vector consisting of the elevations of the lakes (in meters)   area
a numeric vector consisting of the areas of the lakes (in square kilometers)     Source  
The CANSIM data base at Statistics Canada.    Examples    plot(Manitoba.lakes) plot(Manitoba.lakes[-1,])"
"DAAG-measles","DAAG","measles","Deaths in London from measles",311,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/measles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/measles.html","measles R Documentation   Deaths in London from measles   Description  
Deaths in London from measles: 1629 – 1939, with gaps.    Usage   data(measles)   Format  
The format is: Time-Series [1:311] from 1629 to 1939: 42 2 3 80 21 33 27 12 NA NA ...    Source  
Guy, W. A. 1882. Two hundred and fifty years of small pox in London. Journal of the Royal Statistical Society 399-443.   
Stocks, P. 1942. Measles and whooping cough during the dispersal of 1939-1940. Journal of the Royal Statistical Society 105:259-291.    References  
Lancaster, H. O. 1990. Expectations of Life. Springer."
"DAAG-medExpenses","DAAG","medExpenses","Family Medical Expenses",33,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/medExpenses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/medExpenses.html","medExpenses R Documentation   Family Medical Expenses   Description  
The medExpenses data frame contains average weekly medical expenses including drugs for 33 families randomly sampled from a community of 600 families which contained 2700 individuals. These data were collected in the 1970's at an unknown location.    Usage   medExpenses   Format   familysize
number of individuals in a family   expenses
average weekly cost for medical expenses per family member     Examples    with(medExpenses, weighted.mean(expenses, familysize))"
"DAAG-mifem","DAAG","mifem","Mortality Outcomes for Females Suffering Myocardial Infarction",1295,10,1,0,8,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/mifem.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/mifem.html","mifem R Documentation   Mortality Outcomes for Females Suffering Myocardial Infarction   Description  
The mifem data frame has 1295 rows and 10 columns. This is the female subset of the 'monica' data frame    Usage   mifem   Format  
This data frame contains the following columns:    outcome
mortality outcome, a factor with levels live , dead   age
age at onset   yronset
year of onset   premi
previous myocardial infarction event, a factor with levels y , n , nk not known   smstat
smoking status, a factor with levels c current, x ex-smoker, n non-smoker, nk not known   diabetes
a factor with levels y , n , nk not known   highbp
high blood pressure, a factor with levels  y , n , nk not known   hichol
high cholesterol, a factor with levels  y , n nk not known   angina
a factor with levels y ,  n , nk not known   stroke
a factor with levels  y , n , nk not known     Source  
Newcastle (Australia) centre of the Monica project; see the web site http://www.ktl.fi/monica    Examples    print(""CART - Example 10.7"") summary(mifem) pause() require(rpart) mifem.rpart <- rpart(outcome ~ ., data = mifem, cp = 0.0025) plotcp(mifem.rpart) printcp(mifem.rpart) pause() mifemb.rpart <- prune(mifem.rpart, cp=0.006) print(mifemb.rpart)"
"DAAG-mignonette","DAAG","mignonette","Darwin's Wild Mignonette Data",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/mignonette.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/mignonette.html","mignonette R Documentation   Darwin's Wild Mignonette Data   Description  
Data which compare the heights of crossed plants with self-fertilized plants. Plants were paired within the pots in which they were grown, with one on one side and one on the other.    Usage   mignonette   Format  
This data frame contains the following columns:    cross
heights of the crossed plants   self
heights of the self-fertilized plants     Source  
Darwin, Charles. 1877. The Effects of Cross and Self Fertilisation in the Vegetable Kingdom. Appleton and Company, New York.    Examples    print(""Is Pairing Helpful? - Example 4.3.1"") attach(mignonette) plot(cross ~ self, pch=rep(c(4,1), c(3,12))); abline(0,1) abline(mean(cross-self), 1, lty=2) detach(mignonette)"
"DAAG-milk","DAAG","milk","Milk Sweetness Study",17,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/milk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/milk.html","milk R Documentation   Milk Sweetness Study   Description  
The milk data frame has 17 rows and 2 columns. Each of 17 panelists compared two milk samples for sweetness.   Usage   milk   Format  
This data frame contains the following columns:    four
a numeric vector consisting of the assessments for four units of additive   one
a numeric vector while the is the assessment for one unit of additive     Source  
J.H. Maindonald    Examples    print(""Rug Plot - Example 1.8.1"") xyrange <- range(milk) plot(four ~ one, data = milk, xlim = xyrange, ylim = xyrange, pch = 16) rug(milk$one) rug(milk$four, side = 2) abline(0, 1)"
"DAAG-modelcars","DAAG","modelcars","Model Car Data",12,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/modelcars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/modelcars.html","modelcars R Documentation   Model Car Data   Description  
The modelcars data frame has 12 rows and 2 columns. The data are for an experiment in which a model car was released three times at each of four different distances up a 20 degree ramp. The experimenter recorded distances traveled from the bottom of the ramp across a concrete floor.   Usage   modelcars   Format  
This data frame contains the following columns:    distance.traveled
a numeric vector consisting of the lengths traveled (in cm)   starting.point
a numeric vector consisting of the distance of the starting point from the top of the ramp (in cm)     Source  
W.J. Braun    Examples    plot(modelcars) modelcars.lm <- lm(distance.traveled ~ starting.point, data=modelcars) aov(modelcars.lm) pause() print(""Response Curves - Example 4.6"") attach(modelcars) stripchart(distance.traveled ~ starting.point, vertical=TRUE, pch=15, xlab = ""Distance up ramp"", ylab=""Distance traveled"") detach(modelcars)"
"DAAG-monica","DAAG","monica","WHO Monica Data",6367,12,3,0,10,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/monica.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/monica.html","monica R Documentation   WHO Monica Data   Description  
The monica data frame has 6357 rows and 12 columns. Note that mifem is the female subset of this data frame.    Usage   monica   Format  
This data frame contains the following columns:    outcome
mortality outcome, a factor with levels live , dead   age
age at onset   sex
m = male, f = female   hosp
y = hospitalized, n = not hospitalized   yronset
year of onset   premi
previous myocardial infarction event, a factor with levels y , n , nk not known   smstat
smoking status, a factor with levels c current, x ex-smoker, n non-smoker, nk not known   diabetes
a factor with levels y , n , nk not known   highbp
high blood pressure, a factor with levels  y , n , nk not known   hichol
high cholesterol, a factor with levels  y , n nk not known   angina
a factor with levels y ,  n , nk not known   stroke
a factor with levels  y , n , nk not known     Source  
Newcastle (Australia) centre of the Monica project; see the web site http://www.ktl.fi/monica    Examples    print(""CART - Example 10.7"") summary(monica) pause() require(rpart) monica.rpart <- rpart(outcome ~ ., data = monica, cp = 0.0025) plotcp(monica.rpart) printcp(monica.rpart) pause() monicab.rpart <- prune(monica.rpart, cp=0.006) print(monicab.rpart)"
"DAAG-moths","DAAG","moths","Moths Data",41,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/moths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/moths.html","moths R Documentation   Moths Data   Description  
The moths data frame has 41 rows and 4 columns. These data are from a study of the effect of habitat on the densities of two species of moth (A and P). Transects were set across the search area. Within transects, sections were identified according to habitat type.    Usage   moths   Format  
This data frame contains the following columns:    meters
length of transect   A
number of type A moths found   P
number of type P moths found   habitat
a factor with levels  Bank ,  Disturbed ,  Lowerside ,  NEsoak ,  NWsoak ,  SEsoak ,  SWsoak ,  Upperside     Source  
Sharyn Wragg, formerly of Australian National University    Examples    print(""Quasi Poisson Regression - Example 8.3"") rbind(table(moths[,4]), sapply(split(moths[,-4], moths$habitat), apply,2, sum)) A.glm <- glm(formula = A ~ log(meters) + factor(habitat), family = quasipoisson, data = moths) summary(A.glm) # Note the huge standard errors moths$habitat <- relevel(moths$habitat, ref=""Lowerside"") A.glm <- glm(A ~ habitat + log(meters), family=quasipoisson, data=moths) summary(A.glm)$coef ## Consider as another possibility A2.glm <- glm(formula = A ~ sqrt(meters) + factor(habitat), family = quasipoisson(link=sqrt), data = moths) summary(A2.glm)"
"DAAG-nassCDS","DAAG","nassCDS","Airbag and other influences on accident fatalities",26217,15,7,3,5,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nassCDS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nassCDS.html","nassCDS R Documentation   Airbag and other influences on accident fatalities   Description  
US data, for 1997-2002, from police-reported car crashes in which there is a harmful event (people or property), and from which at least one vehicle was towed. Data are restricted to front-seat occupants, include only a subset of the variables recorded, and are restricted in other ways also.   Usage   nassCDS   Format  
A data frame with 26217 observations on the following 15 variables.    dvcat
ordered factor with levels (estimated impact speeds) 1-9km/h , 10-24 , 25-39 , 40-54 ,  55+     weight
Observation weights, albeit of uncertain accuracy, designed to account for varying sampling probabilities.   dead
factor with levels alive dead   airbag
a factor with levels none airbag   seatbelt
a factor with levels none belted   frontal
a numeric vector; 0 = non-frontal, 1=frontal impact   sex
a factor with levels f m   ageOFocc
age of occupant in years   yearacc
year of accident   yearVeh
Year of model of vehicle; a numeric vector   abcat
Did one or more (driver or passenger) airbag(s) deploy? This factor has levels deploy nodeploy   unavail   occRole
a factor with levels driver pass   deploy
a numeric vector: 0 if an airbag was unavailable or did not deploy; 1 if one or more bags deployed.   injSeverity
a numeric vector; 0:none, 1:possible injury, 2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death   caseid
character, created by pasting together the populations sampling unit, the case number, and the vehicle number. Within each year, use this to uniquely identify the vehicle.      Details  
Data collection used a multi-stage probabilistic sampling scheme. The observation weight, called national inflation factor ( national ) in the data from NASS, is the inverse of an estimate of the selection probability. These data include a subset of the variables from the NASS dataset. Variables that are coded here as factors are coded as numeric values in that dataset.    Source  
http://www.stat.colostate.edu/~meyer/airbags.htm \  ftp://ftp.nhtsa.dot.gov/nass/    
See also\  http://www.maths.anu.edu.au/~johnm/datasets/airbags     References  
Meyer, M.C. and Finney, T. (2005): Who wants airbags? . Chance 18:3-16.   
Farmer, C.H. 2006. Another look at Meyer and Finney's ‘Who wants airbags?’ . Chance 19:15-22.   
Meyer, M.C. 2006. Commentary on ""Another look at Meyer and Finney's ‘Who wants airbags?’ . Chance 19:23-24.   
For analyses based on the alternative FARS (Fatal Accident Recording System) data, and associated commentary, see:   
Cummings, P; McKnight, B, 2010. Accounting for vehicle, crash, and occupant characteristics in traffic crash studies. Injury Prevention 16: 363-366. [The relatively definitive analyses in this paper use a matched cohort design,   
Olson, CM; Cummings, P, Rivara, FP, 2006. Association of first- and second-generation air bags with front occupant death in car crashes: a matched cohort study. Am J Epidemiol 164:161-169. [The relatively definitive analyses in this paper use a matched cohort design, using data taken from the FARS (Fatal Accident Recording System) database.]   
Braver, ER; Shardell, M; Teoh, ER, 2010. How have changes in air bag designs affected frontal crash mortality? Ann Epidemiol 20:499-510.   
The web page http://www-fars.nhtsa.dot.gov/Main/index.aspx has a menu-based interface into the FARS (Fatality Analysis Recording System) data. The FARS database aims to include every accident in which there was at least one fatality.    Examples    data(nassCDS) xtabs(weight ~ dead + airbag, data=nassCDS) xtabs(weight ~ dead + airbag + seatbelt + dvcat, data=nassCDS) tab <- xtabs(weight ~ dead + abcat, data=nassCDS, subset=dvcat==""25-39""&frontal==0)[, c(3,1,2)] round(tab[2, ]/apply(tab,2,sum)*100,2)"
"DAAG-nasshead","DAAG","nasshead","Documentation of names of columns in nass9702cor",56,3,0,3,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nasshead.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nasshead.html","nasshead R Documentation   Documentation of names of columns in nass9702cor   Description  
SASname and longname are from the SAS XPT file nass9702cor.XPT that is available from the webite noted below. The name shortname is the name used in the data frame  nass9702cor , not included in this package, but available from my website that is noted below. It is also used in  nassCDS , for columns that nassCDS includes.    Usage   data(nasshead)   Format  
A data frame with 56 observations on the following 3 variables.    shortname
a character vector   SASname
a character vector   longname
a character vector     Details  
For full details of the coding of values in columns of  nass9702cor , consult one of the SAS format files that can be obtained by following the instructions on Dr Meyer's web site that is noted below.    Source  
http://www.stat.colostate.edu/~meyer/airbags.htm \  ftp://ftp.nhtsa.dot.gov/nass/ \ Click, e.g., on 1997 and then on SASformats. See also  http://www.maths.anu.edu.au/~johnm/datasets/airbags     References  
Meyer, M.C. and Finney, T. (2005): Who wants airbags? . Chance 18:3-16.   
Farmer, C.H. 2006. Another look at Meyer and Finney's 'Who wants airbags?' . Chance 19:15-22.   
Meyer, M.C. 2006. Commentary on ""Another look at Meyer and Finney's ‘Who wants airbags?’"" . Chance 19:23-24.    Examples    data(nasshead)"
"DAAG-nihills","DAAG","nihills","Record times for Northern Ireland mountain running events",23,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nihills.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nihills.html","nihills R Documentation   Record times for Northern Ireland mountain running events   Description  
Data were from the 2007 calendar for the Northern Ireland Mountain Running Association.    Usage   data(nihills)   Format  
A data frame with 23 observations on the following 4 variables.    dist
distances in miles   climb
amount of climb in feet   time
record time in hours for males   timef
record time in hours for females     Details  
These data make an interesting comparison with the dataset  hills2000 in the DAAG package.   Source  
For more recent information, see  http://www.nimra.org.uk/index.php/fixtures/     Examples    data(nihills) lm(formula = log(time) ~ log(dist) + log(climb), data = nihills) lm(formula = log(time) ~ log(dist) + log(climb/dist), data = nihills)"
"DAAG-nsw74demo","DAAG","nsw74demo","Labour Training Evaluation Data",445,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nsw74demo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nsw74demo.html","nsw74demo R Documentation   Labour Training Evaluation Data   Description  
This data frame contains 445 rows and 10 columns. These data are from an investigation of the effect of training on changes, between 1974-1975 and 1978, in the earnings of individuals who had experienced employment difficulties Data are for the male experimental control and treatment groups.    Usage   nsw74demo   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = PSID, 1 = NSW).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Source  
http://www.columbia.edu/~rd247/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620."
"DAAG-nsw74psid1","DAAG","nsw74psid1","Labour Training Evaluation Data",2675,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nsw74psid1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nsw74psid1.html","nsw74psid1 R Documentation   Labour Training Evaluation Data   Description  
This data frame contains 2675 rows and 10 columns. These data are pertinent to an investigation of the way that earnings changed, between 1974-1975 and 1978, in the absence of training. Data for the experimental treatment group (NSW) were combined with control data results from the Panel Study of Income Dynamics (PSID) study.   Usage   nsw74psid1   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = PSID, 1 = NSW).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Source  
http://www.columbia.edu/~rd247/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.    Examples    print(""Interpretation of Regression Coefficients - Example 6.6"") nsw74psid1.lm <- lm(re78~ trt+ (age + educ + re74 + re75) + (black + hisp + marr + nodeg), data = nsw74psid1) summary(nsw74psid1.lm)$coef options(digits=4) sapply(nsw74psid1[, c(2,3,8,9,10)], quantile, prob=c(.25,.5,.75,.95,1)) attach(nsw74psid1) sapply(nsw74psid1[trt==1, c(2,3,8,9,10)], quantile, prob=c(.25,.5,.75,.95,1)) pause() here <- age <= 40 & re74<=5000 & re75 <= 5000 & re78 < 30000 nsw74psidA <- nsw74psid1[here, ] detach(nsw74psid1) table(nsw74psidA$trt) pause() A1.lm <- lm(re78 ~ trt + (age + educ + re74 + re75) + (black + hisp + marr + nodeg), data = nsw74psidA) summary(A1.lm)$coef pause() A2.lm <- lm(re78 ~ trt + (age + educ + re74 + re75) * (black + hisp + marr + nodeg), data = nsw74psidA) anova(A1.lm, A2.lm)"
"DAAG-nsw74psid3","DAAG","nsw74psid3","Labour Training Evaluation Data",313,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nsw74psid3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nsw74psid3.html","nsw74psid3 R Documentation   Labour Training Evaluation Data   Description  
These data are pertinent to an investigation of the way that earnings changed, between 1974-1975 and 1978, in the absence of training. The data frame combines data for the experimental treatment group (NSW, 185 observations), using as control data results from the PSID (Panel Study of Income Dynamics) study (128 observations). The latter were chosen to mimic the characteristics of the NSW training and control groups. These are a subset of the nsw74psid1 data.    Usage   nsw74psid3   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = PSID, 1 = NSW)    age
age (in years)   educ
years of education   black
(0 = not black, 1 = black)   hisp
(0 = not hispanic, 1 = hispanic)   marr
(0 = not married, 1 = married)   nodeg
(0 = completed high school, 1 = dropout)   re74
real earnings in 1974   re75
real earnings in 1975   re78
real earnings in 1978     Source  
http://www.columbia.edu/~rd247/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.    Examples    print(""Contingency Tables - Example 4.4"") table(nsw74psid3$trt, nsw74psid3$nodeg) chisq.test(table(nsw74psid3$trt,nsw74psid3$nodeg))"
"DAAG-nsw74psidA","DAAG","nsw74psidA","A Subset of the nsw74psid1 Data Set",252,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nsw74psidA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nsw74psidA.html","nsw74psidA R Documentation   A Subset of the nsw74psid1 Data Set   Description  
The nsw74psidA data frame has 252 rows and 10 columns. See nsw74psid1 for more information.    Usage   nsw74psidA   Format  
This data frame contains the following columns:    trt
a numeric vector   age
a numeric vector   educ
a numeric vector   black
a numeric vector   hisp
a numeric vector   marr
a numeric vector   nodeg
a numeric vector   re74
a numeric vector   re75
a numeric vector   re78
a numeric vector     Details  
This data set was obtained using:   
here <- age <= 40 & re74<=5000 & re75 <= 5000 & re78 < 30000    
nsw74psidA <- nsw74psid1[here, ]     Examples    table(nsw74psidA$trt) A1.lm <- lm(re78 ~ trt + (age + educ + re74 + re75) + (black + hisp + marr + nodeg), data = nsw74psidA) summary(A1.lm)$coef discA.glm <- glm(formula = trt ~ age + educ + black + hisp + marr + nodeg + re74 + re75, family = binomial, data = nsw74psidA) A.scores <- predict(discA.glm) options(digits=4) overlap <- A.scores > -3.5 & A.scores < 3.8 A.lm <- lm(re78 ~ trt + A.scores, data=nsw74psidA, subset = overlap) summary(A.lm)$coef"
"DAAG-nswdemo","DAAG","nswdemo","Labour Training Evaluation Data",722,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nswdemo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nswdemo.html","nswdemo R Documentation   Labour Training Evaluation Data   Description  
The nswdemo data frame contains 722 rows and 10 columns. These data are pertinent to an investigation of the way that earnings changed, between 1974-1975 and 1978, for an experimental treatment who were given job training as compared with a control group who did not receive such training.   
The psid1 data set is an alternative non-experimental ""control"" group. psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 . Note also the cps1 , cps2 and cps3  datasets ( DAAGxtras ) that have been proposed as non-experimental controls.    Usage   data(nswdemo)   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Source  
http://www.nber.org/~rdehejia/nswdata.html     References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. 2005,""Does Matching overcome. LaLonde?s critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364.    See Also  
psid1 , psid2 , psid3"
"DAAG-nswpsid1","DAAG","nswpsid1","Labour Training Evaluation Data",2787,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/nswpsid1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/nswpsid1.html","nswpsid1 R Documentation   Labour Training Evaluation Data   Description  
This data frame contains 2787 rows and 10 columns. These data are pertinent to an investigation of the way that earnings changed, between 1974-1975 and 1978, in the absence of training. Data for the experimental treatment group in nswdemo are combined with the  psid1 control data from the Panel Study of Income Dynamics (PSID) study.    Usage   psid1   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 . nswpsid1 combines data for the experimental treatment group in nswdemo with the psid1 control data from the Panel Study of Income Dynamics (PSID) study.    Source  
http://www.nber.org/~rdehejia/nswdata.html     References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. ""Does Matching overcome. LaLonde?s critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-oddbooks","DAAG","oddbooks","Measurements on 12 books",12,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/oddbooks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/oddbooks.html","oddbooks R Documentation   Measurements on 12 books   Description  
Data giving thickness (mm), height (cm), width (cm) and weight (g), of 12 books. Books were selected so that thickness decreased as page area increased    Usage   data(oddbooks)   Format  
A data frame with 12 observations on the following 4 variables.    thick
a numeric vector   height
a numeric vector   breadth
a numeric vector   weight
a numeric vector     Source  
JM took books from his library.    Examples    data(oddbooks) str(oddbooks) plot(oddbooks)"
"DAAG-orings","DAAG","orings","Challenger O-rings Data",23,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/orings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/orings.html","orings R Documentation   Challenger O-rings Data   Description  
Record of the number and type of O-ring failures prior to the tragic Challenger mission in January, 1986.    Usage   orings   Format  
This data frame contains the following columns:    Temperature
O-ring temperature for each test firing or actual launch of the shuttle rocket engine   Erosion
Number of erosion incidents   Blowby
Number of blowby incidents   Total
Total number of incidents     Source  
Presidential Commission on the Space Shuttle Challenger Accident, Vol. 1, 1986: 129-131.   References  
Tufte, E. R. 1997. Visual Explanations. Graphics Press, Cheshire, Connecticut, U.S.A.    Examples    oldpar <- par(mfrow=c(1,2)) plot(Total~Temperature, data = orings[c(1,2,4,11,13,18),]) # the # observations included in the pre-launch charts plot(Total~Temperature, data = orings) par(oldpar)"
"DAAG-ozone","DAAG","ozone","Ozone Data",45,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/ozone.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/ozone.html","ozone R Documentation   Ozone Data   Description  
Monthly provisional mean total ozone (in Dobson units) at Halley Bay (approximately corrected to Bass-Paur).    Usage   ozone   Format  
This data frame contains the following columns:    Year
the year   Aug
August mean total ozone   Sep
September mean total ozone   Oct
October mean total ozone   Nov
November mean total ozone   Dec
December mean total ozone   Jan
January mean total ozone   Feb
February mean total ozone   Mar
March mean total ozone   Apr
April mean total ozone   Annual
Yearly mean total ozone     Source  
Shanklin, J. (2001) Ozone at Halley, Rothera and Vernadsky/Faraday.  
http://www.antarctica.ac.uk/met/jds/ozone/data/zoz5699.dat    References  
Christie, M. (2000) The Ozone Layer: a Philosophy of Science Perspective. Cambridge University Press.    Examples    AnnualOzone <- ts(ozone$Annual, start=1956) plot(AnnualOzone)"
"DAAG-pair65","DAAG","pair65","Heated Elastic Bands",9,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/pair65.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/pair65.html","pair65 R Documentation   Heated Elastic Bands   Description  
The pair65 data frame has 9 rows and 2 columns. Eighteen elastic bands were divided into nine pairs, with bands of similar stretchiness placed in the same pair. One member of each pair was placed in hot water (60-65 degrees C) for four minutes, while the other was left at ambient temperature. After a wait of about ten minutes, the amounts of stretch, under a 1.35 kg weight, were recorded.    Usage   pair65   Format  
This data frame contains the following columns:    heated
a numeric vector giving the stretch lengths for the heated bands   ambient
a numeric vector giving the stretch lengths for the unheated bands     Source  
J.H. Maindonald    Examples    mean(pair65$heated - pair65$ambient) sd(pair65$heated - pair65$ambient)"
"DAAG-possum","DAAG","possum","Possum Measurements",104,14,2,0,2,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/possum.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/possum.html","possum R Documentation   Possum Measurements   Description  
The possum data frame consists of nine morphometric measurements on each of 104 mountain brushtail possums, trapped at seven sites from Southern Victoria to central Queensland.    Usage   possum   Format  
This data frame contains the following columns:    case
observation number   site
one of seven locations where possums were trapped   Pop
a factor which classifies the sites as  Vic Victoria,  other New South Wales or Queensland   sex
a factor with levels  f female,  m male   age
age   hdlngth
head length   skullw
skull width   totlngth
total length   taill
tail length   footlgth
foot length   earconch
ear conch length   eye
distance from medial canthus to lateral canthus of right eye   chest
chest girth (in cm)   belly
belly girth (in cm)     Source  
Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458.   Examples    boxplot(earconch~sex, data=possum) pause() sex <- as.integer(possum$sex) oldpar <- par(oma=c(2,4,5,4)) pairs(possum[, c(9:11)], pch=c(0,2:7), col=c(""red"",""blue""), labels=c(""tail\nlength"",""foot\nlength"",""ear conch\nlength"")) chh <- par()$cxy[2]; xleg <- 0.05; yleg <- 1.04 oldpar <- par(xpd=TRUE) legend(xleg, yleg, c(""Cambarville"", ""Bellbird"", ""Whian Whian "", ""Byrangery"", ""Conondale "",""Allyn River"", ""Bulburin""), pch=c(0,2:7), x.intersp=1, y.intersp=0.75, cex=0.8, xjust=0, bty=""n"", ncol=4) text(x=0.2, y=yleg - 2.25*chh, ""female"", col=""red"", cex=0.8, bty=""n"") text(x=0.75, y=yleg - 2.25*chh, ""male"", col=""blue"", cex=0.8, bty=""n"") par(oldpar) pause() sapply(possum[,6:14], function(x)max(x,na.rm=TRUE)/min(x,na.rm=TRUE)) pause() here <- na.omit(possum$footlgth) possum.prc <- princomp(possum[here, 6:14]) pause() plot(possum.prc$scores[,1] ~ possum.prc$scores[,2], col=c(""red"",""blue"")[as.numeric(possum$sex[here])], pch=c(0,2:7)[possum$site[here]], xlab = ""PC1"", ylab = ""PC2"") # NB: We have abbreviated the axis titles chh <- par()$cxy[2]; xleg <- -15; yleg <- 20.5 oldpar <- par(xpd=TRUE) legend(xleg, yleg, c(""Cambarville"", ""Bellbird"", ""Whian Whian "", ""Byrangery"", ""Conondale "",""Allyn River"", ""Bulburin""), pch=c(0,2:7), x.intersp=1, y.intersp=0.75, cex=0.8, xjust=0, bty=""n"", ncol=4) text(x=-9, y=yleg - 2.25*chh, ""female"", col=""red"", cex=0.8, bty=""n"") summary(possum.prc, loadings=TRUE, digits=2) par(oldpar) pause() require(MASS) here <- !is.na(possum$footlgth) possum.lda <- lda(site ~ hdlngth+skullw+totlngth+ taill+footlgth+ earconch+eye+chest+belly, data=possum, subset=here) options(digits=4) possum.lda$svd # Examine the singular values plot(possum.lda, dimen=3) # Scatterplot matrix - scores on 1st 3 canonical variates (Figure 11.4) possum.lda"
"DAAG-possumsites","DAAG","possumsites","Possum Sites",7,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/possumsites.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/possumsites.html","possumsites R Documentation   Possum Sites   Description  
The possumsites data frame consists of Longitudes, Latitudes, and altitudes for the seven sites from Southern Victoria to central Queensland where the possum observations were made.    Usage   possumsites   Format  
This data frame contains the following columns:    Longitude
a numeric vector   Latitude
a numeric vector   altitude
in meters     Source  
Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458.   Examples    require(oz) oz(sections=c(3:5, 11:16)) attach(possumsites) points(Longitude, Latitude, pch=16, col=2) chw <- par()$cxy[1] chh <- par()$cxy[2] posval <- c(2,4,2,2,4,2,2) text(Longitude+(3-posval)*chw/4, Latitude, row.names(possumsites), pos=posval)"
"DAAG-poxetc","DAAG","poxetc","Deaths from various causes, in London from 1629 till 1881, with gaps",253,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/poxetc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/poxetc.html","poxetc R Documentation   Deaths from various causes, in London from 1629 till 1881, with gaps   Description  
Deaths from ""flux"" or smallpox, measles, all causes, and ratios of the the first two categories to total deaths.    Usage   data(poxetc)   Format  
This is a multiple time series consisting of 5 series:  fpox , measles , all , fpox2all , measles2all .    Source  
Guy, W. A. 1882. Two hundred and fifty years of small pox in London. Journal of the Royal Statistical Society 399-443.    References  
Lancaster, H. O. 1990. Expectations of Life. Springer.    Examples    data(poxetc) str(poxetc) plot(poxetc)"
"DAAG-primates","DAAG","primates","Primate Body and Brain Weights",5,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/primates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/primates.html","primates R Documentation   Primate Body and Brain Weights   Description  
A subset of Animals data frame from the MASS library. It contains the average body and brain measurements of five primates.    Usage   primates   Format  
This data frame contains the following columns:    Bodywt
a numeric vector consisting of the body weights (in kg) of five different primates   Brainwt
a numeric vector consisting of the corresponding brain weights (in g)     Source  
P. J. Rousseeuw and A. M. Leroy (1987) Robust Regression and Outlier Detection. Wiley, p. 57.    Examples    attach(primates) plot(x=Bodywt, y=Brainwt, pch=16, xlab=""Body weight (kg)"", ylab=""Brain weight (g)"", xlim=c(5,300), ylim=c(0,1500)) chw <- par()$cxy[1] chh <- par()$cxy[2] text(x=Bodywt+chw, y=Brainwt+c(-.1,0,0,.1,0)*chh, labels=row.names(primates), adj=0) detach(primates)"
"DAAG-progression","DAAG","progression","Progression of Record times for track races, 1912 - 2008",227,4,0,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/progression.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/progression.html","progression R Documentation   Progression of Record times for track races, 1912 - 2008   Description  
Progression in world record times for track and road races.   Usage   data(progression)   Format  
A data frame with 227 observations on the following 4 columns.    year
Year that time was first recorded   Distance
distance in kilometers   Time
time in minutes   race
character; descriptor for event (100m, mile, ...)     Details  
Record times for men's track events, from 1912 onwards. The series starts with times that were recognized as record times in 1912, where available.    Source  
Links to sources for the data are at   
http://en.wikipedia.org/wiki/Athletics_world_record     Examples    data(progression) plot(log(Time) ~ log(Distance), data=progression) xyplot(log(Time) ~ log(Distance), data=progression, type=c(""p"",""r"")) xyplot(log(Time) ~ log(Distance), data=progression, type=c(""p"",""smooth"")) res <- resid(lm(log(Time) ~ log(Distance), data=progression)) plot(res ~ log(Distance), data=progression, ylab=""Residuals from regression line on log scales"")"
"DAAG-psid1","DAAG","psid1","Labour Training Evaluation Data",2490,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/psid1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/psid1.html","psid1 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   psid1   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html     References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. ""Does Matching overcome. LaLonde?s critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-psid2","DAAG","psid2","Labour Training Evaluation Data",253,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/psid2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/psid2.html","psid2 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   psid2   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. ""Does Matching overcome. LaLonde?s critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-psid3","DAAG","psid3","Labour Training Evaluation Data",128,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/psid3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/psid3.html","psid3 R Documentation   Labour Training Evaluation Data   Description  
A non-experimental ""control"" group, used in various studies of the effect of a labor training program, alternative to the experimental control group in nswdemo .    Usage   psid3   Format  
This data frame contains the following columns:    trt
a numeric vector identifying the study in which the subjects were enrolled (0 = Control, 1 = treated).   age
age (in years).   educ
years of education.   black
(0 = not black, 1 = black).   hisp
(0 = not hispanic, 1 = hispanic).   marr
(0 = not married, 1 = married).   nodeg
(0 = completed high school, 1 = dropout).   re74
real earnings in 1974.   re75
real earnings in 1975.   re78
real earnings in 1978.     Details  
The cps1 and psid1 data sets are two non-experimental ""control"" groups, alternative to that in nswdemo , used in investigating whether use of such a non-experimental control group can be satisfactory. cps2 and cps3 are subsets of cps1 , designed to be better matched to the experimental data than cps1 . Similary psid2 and psid3 are subsets of psid1 , designed to be better matched to the experimental data than  psid1 .    Source  
http://www.nber.org/~rdehejia/nswdata.html    References  
Dehejia, R.H. and Wahba, S. 1999. Causal effects in non-experimental studies: re-evaluating the evaluation of training programs. Journal of the American Statistical Association 94: 1053-1062.   
Lalonde, R. 1986. Evaluating the economic evaluations of training programs. American Economic Review 76: 604-620.   
Smith, J. A. and Todd, P.E. ""Does Matching overcome. LaLonde?s critique of nonexperimental estimators"", Journal of Econometrics 125: 305-353.   
Dehejia, R.H. 2005. Practical propensity score matching: a reply to Smith and Todd. Journal of Econometrics 125: 355-364."
"DAAG-races2000","DAAG","races2000","Scottish Hill Races Data - 2000",77,5,0,1,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/races2000.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/races2000.html","races2000 R Documentation   Scottish Hill Races Data - 2000   Description  
The record times in 2000 for 77 Scottish long distance races. We believe the data are, for the most part, trustworthy. However, the dist variable for Caerketton (record 58) seems to have been variously recorded as 1.5 mi and 2.5 mi.   Usage   races2000   Format  
This data frame contains the following columns:    dist
distance, in miles (on the map)   climb
total height gained during the route, in feet   time
record time in hours   timef
record time in hours for females   type
a factor, with levels indicating type of race, i.e. hill, marathon, relay, uphill or other     Source  
The Scottish Running Resource, http://www.hillrunning.co.uk    Examples    pairs(races2000[,-5])"
"DAAG-rainforest","DAAG","rainforest","Rainforest Data",65,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/rainforest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/rainforest.html","rainforest R Documentation   Rainforest Data   Description  
The rainforest data frame has 65 rows and 7 columns.    Usage   rainforest   Format  
This data frame contains the following columns:    dbh
a numeric vector   wood
a numeric vector   bark
a numeric vector   root
a numeric vector   rootsk
a numeric vector   branch
a numeric vector   species
a factor with levels  Acacia mabellae ,  C. fraseri ,  Acmena smithii ,  B. myrtifolia     Source  
J. Ash, Australian National University    References  
Ash, J. and Helman, C. (1990) Floristics and vegetation biomass of a forest catchment, Kioloa, south coastal N.S.W. Cunninghamia, 2: 167-182.    Examples    table(rainforest$species)"
"DAAG-rareplants","DAAG","rareplants","Rare and Endangered Plant Species",4,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/rareplants.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/rareplants.html","rareplants R Documentation   Rare and Endangered Plant Species   Description  
These data were taken from species lists for South Australia, Victoria and Tasmania. Species were classified as CC, CR, RC and RR, with C denoting common and R denoting rare. The first code relates to South Australia and Victoria, and the second to Tasmania. They were further classified by habitat according to the Victorian register, where D = dry only, W = wet only, and WD = wet or dry.    Usage   rareplants   Format  
The format is: chr ""rareplants""    Source  
Jasmyn Lynch, Department of Botany and Zoology at Australian National University    Examples    chisq.test(rareplants)"
"DAAG-rice","DAAG","rice","Genetically Modified and Wild Type Rice Data",72,7,2,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/rice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/rice.html","rice R Documentation   Genetically Modified and Wild Type Rice Data   Description  
The rice data frame has 72 rows and 7 columns. The data are from an experiment that compared wild type (wt) and genetically modified rice plants (ANU843), each with three different chemical treatments (F10, NH4Cl, and NH4NO3).   Usage   rice   Format  
This data frame contains the following columns:    PlantNo
a numeric vector   Block
a numeric vector   RootDryMass
a numeric vector   ShootDryMass
a numeric vector   trt
a factor with levels  F10 ,  NH4Cl ,  NH4NO3 ,  F10 +ANU843 ,  NH4Cl +ANU843 ,  NH4NO3 +ANU843   fert
a factor with levels  F10   NH4Cl   NH4NO3   variety
a factor with levels  wt   ANU843     Source  
Perrine, F.M., Prayitno, J., Weinman, J.J., Dazzo, F.B. and Rolfe, B. 2001. Rhizobium plasmids are involved in the inhibition or stimulation of rice growth and development. Australian Journal of Plant Physiology 28: 923-927.    Examples    print(""One and Two-Way Comparisons - Example 4.5"") attach(rice) oldpar <- par(las = 2) stripchart(ShootDryMass ~ trt, pch=1, cex=1, xlab=""Level of factor 1"") detach(rice) pause() rice.aov <- aov(ShootDryMass ~ trt, data=rice); anova(rice.aov) anova(rice.aov) pause() summary.lm(rice.aov)$coef pause() rice$trt <- relevel(rice$trt, ref=""NH4Cl"") # Set NH4Cl as the baseline fac1 <- factor(sapply(strsplit(as.character(rice$trt),"" \\+""), function(x)x[1])) anu843 <- sapply(strsplit(as.character(rice$trt), ""\\+""), function(x)c(""wt"",""ANU843"")[length(x)]) anu843 <- factor(anu843, levels=c(""wt"", ""ANU843"")) attach(rice) interaction.plot(fac1, anu843, ShootDryMass) detach(rice) par(oldpar)"
"DAAG-rockArt","DAAG","rockArt","Pacific Rock Art features",103,641,624,13,0,0,628,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/rockArt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/rockArt.html","rockArt R Documentation   Pacific Rock Art features   Description  
Data characterise rock art at 103 sites in the Pacific.    Usage   rockArt   Format  
A data frame with 103 observations on the following 641 variables.    Site.No.
a numeric vector   Site.Name
a character vector   Site.Code
a character vector   District
a character vector   Island
a character vector   Country
a character vector   Technique
a character vector   Engtech
a character vector   red
a numeric vector   black
a numeric vector   yellow
a numeric vector   white
a numeric vector   green
a numeric vector   red.blk
a numeric vector   red.wh
a numeric vector   red.yell
a numeric vector   r.w.y
a numeric vector   black.white
a numeric vector   blue
a numeric vector   Geology
a character vector   Topography
a character vector   Location
a character vector   Proxhab.km.
a character vector   Proxcoast.km.
a numeric vector   Maxheight.m.
a numeric vector   Language
a character vector   No.motif
a character vector   Ca1
a numeric vector   Ca2
a numeric vector   Ca3
a numeric vector   Ca4
a numeric vector   Cb5
a numeric vector   Cb6
a numeric vector   Cc7
a numeric vector   Cc8
a numeric vector   Cc9
a numeric vector   Cc10
a numeric vector   Cc11
a numeric vector   Cc12
a numeric vector   Cc13
a numeric vector   Cc14
a numeric vector   Cc15
a numeric vector   Cc16
a numeric vector   Cc17
a numeric vector   Cc18
a numeric vector   Cc19
a numeric vector   Cc20
a numeric vector   Cd21
a numeric vector   Cd22
a numeric vector   Cd23
a numeric vector   Cd24
a numeric vector   Cd25
a numeric vector   Cd26
a numeric vector   Cd27
a numeric vector   Ce28
a numeric vector   Ce29
a numeric vector   Cf30
a numeric vector   Cf31
a numeric vector   Cf32
a numeric vector   Cf33
a numeric vector   Cf34
a numeric vector   Cf35
a numeric vector   Cf36
a numeric vector   Cf37
a numeric vector   Cf38
a numeric vector   Cg39
a numeric vector   Cg40
a numeric vector   Ch41
a numeric vector   Ch42
a numeric vector   Ci43
a numeric vector   Ci44
a numeric vector   Cj45
a numeric vector   Ck46
a numeric vector   Ck47
a numeric vector   Cl48
a numeric vector   Cm49
a numeric vector   Cm50
a numeric vector   Cm51
a numeric vector   Cm52
a numeric vector   Cm53
a numeric vector   Cm54
a numeric vector   Cm55
a numeric vector   Cm56
a numeric vector   Cm57
a numeric vector   Cm58
a numeric vector   Cn59
a numeric vector   Cn60
a numeric vector   Cn61
a numeric vector   Cn62
a numeric vector   Cn63
a numeric vector   Cn64
a numeric vector   Cn65
a numeric vector   Cn66
a numeric vector   Cn67
a numeric vector   Cn68
a numeric vector   Cn69
a numeric vector   Cn70
a numeric vector   Cn71
a numeric vector   Co72
a numeric vector   Co73
a numeric vector   Co74
a numeric vector   Co75
a numeric vector   Co76
a numeric vector   Co77
a numeric vector   Co78
a numeric vector   Co79
a numeric vector   Cp80
a numeric vector   Cq81
a numeric vector   Cq82
a numeric vector   Cq83
a numeric vector   Cq84
a numeric vector   Cq85
a numeric vector   Cq86
a numeric vector   Cq87
a numeric vector   Cq88
a numeric vector   Cq89
a numeric vector   Cq90
a numeric vector   Cq91
a numeric vector   Cq92
a numeric vector   Cq93
a numeric vector   Cq94
a numeric vector   Cq95
a numeric vector   Cq96
a numeric vector   Cq97
a numeric vector   Cr98
a numeric vector   Cr99
a numeric vector   Cr100
a numeric vector   Cr101
a numeric vector   Cs102
a numeric vector   Cs103
a numeric vector   Cs104
a numeric vector   Cs105
a numeric vector   Cs106
a numeric vector   Ct107
a numeric vector   C108
a numeric vector   C109
a numeric vector   C110
a numeric vector   C111
a numeric vector   SSa1
a numeric vector   SSd2
a numeric vector   SSd3
a numeric vector   SSd4
a numeric vector   SSd5
a numeric vector   SSd6
a numeric vector   SSd7
a numeric vector   SSd8
a numeric vector   SSf9
a numeric vector   SSg10
a numeric vector   SSj11
a numeric vector   SSj12
a numeric vector   SSj13
a numeric vector   SSl14
a numeric vector   SSm15
a numeric vector   SSm16
a numeric vector   SSn17
a numeric vector   SSn18
a numeric vector   SSn19
a numeric vector   SSn20
a numeric vector   SSn21
a numeric vector   SSn22
a numeric vector   SSn23
a numeric vector   SSn24
a numeric vector   SSn25
a numeric vector   SSn26
a numeric vector   SSn27
a numeric vector   SSn28
a numeric vector   SSn29
a numeric vector   SSn30
a numeric vector   SSn31
a numeric vector   SSn32
a numeric vector   SSn33
a numeric vector   SSn34
a numeric vector   SSn35
a numeric vector   SSo36
a numeric vector   SSo37
a numeric vector   SSp38
a numeric vector   SSq39
a numeric vector   SSq40
a numeric vector   SSt41
a numeric vector   SSu42
a numeric vector   Oa1
a numeric vector   Oc2
a numeric vector   Od3
a numeric vector   Od4
a numeric vector   Oe5
a numeric vector   Of6
a numeric vector   Of7
a numeric vector   Of8
a numeric vector   Of9
a numeric vector   Og10
a numeric vector   Og11
a numeric vector   Og12
a numeric vector   Og13
a numeric vector   Og14
a numeric vector   Og15
a numeric vector   Oi16
a numeric vector   Om17
a numeric vector   Om18
a numeric vector   Om19
a numeric vector   Om20
a numeric vector   Om21
a numeric vector   On22
a numeric vector   On23
a numeric vector   On24
a numeric vector   Oq25
a numeric vector   Oq26
a numeric vector   Oq27
a numeric vector   .u28
a numeric vector   Ov29
a numeric vector   Ov30
a numeric vector   O31
a numeric vector   O32
a numeric vector   O33
a numeric vector   Sa1
a numeric vector   Sb2
a numeric vector   Sb3
a numeric vector   Sd4
a numeric vector   Sd5
a numeric vector   Sd6
a numeric vector   Sd7
a numeric vector   Se8
a numeric vector   Si9
a numeric vector   Sm10
a numeric vector   Sm11
a numeric vector   S12
a numeric vector   S13
a numeric vector   Sx14
a numeric vector   Sx15
a numeric vector   Sx16
a numeric vector   Sx17
a numeric vector   Sy18
a numeric vector   Sz19
a numeric vector   S20
a numeric vector   S21
a numeric vector   S22
a numeric vector   S23
a numeric vector   S24
a numeric vector   S25
a numeric vector   SCd1
a numeric vector   SCd2
a numeric vector   SCd3
a numeric vector   SCd4
a numeric vector   SCd5
a numeric vector   SCd6
a numeric vector   SCd7
a numeric vector   SCm8
a numeric vector   SCn9
a numeric vector   SCn10
a numeric vector   SCw11
a numeric vector   SCx12
a numeric vector   SCx13
a numeric vector   SCx14
a numeric vector   SCx15
a numeric vector   SCx16
a numeric vector   SCy17
a numeric vector   SCy18
a numeric vector   SC19
a numeric vector   SC20
a numeric vector   SC21
a numeric vector   SC22
a numeric vector   SC23
a numeric vector   SC24
a numeric vector   SC25
a numeric vector   SC26
a numeric vector   SRd1
a numeric vector   SRd2
a numeric vector   SRd3
a numeric vector   SRd4
a numeric vector   SRf5
a numeric vector   SRf6
a numeric vector   SRf7
a numeric vector   SRj8
a numeric vector   SR9
a numeric vector   SR10
a numeric vector   Bd1
a numeric vector   Bn2
a numeric vector   Bn3
a numeric vector   Bn4
a numeric vector   Bt5
a numeric vector   Bx6
a numeric vector   Ha1
a numeric vector   Hg2
a numeric vector   Hn3
a numeric vector   Hq4
a numeric vector   Hq5
a numeric vector   TDd1
a numeric vector   TDf2
a numeric vector   TDj3
a numeric vector   TDn4
a numeric vector   TDq5
a numeric vector   TD6
a numeric vector   TD7
a numeric vector   TD8
a numeric vector   TD9
a numeric vector   Dc1
a numeric vector   Dg2
a numeric vector   Dh3
a numeric vector   Dk4
a numeric vector   Dm5
a numeric vector   Dm6
a numeric vector   D7
a numeric vector   D8
a numeric vector   D9
a numeric vector   D10
a numeric vector   D11
a numeric vector   D12
a numeric vector   D13
a numeric vector   Ta1
a numeric vector   Tc2
a numeric vector   Tc3
a numeric vector   Tc4
a numeric vector   Td5
a numeric vector   Tf6
a numeric vector   Tf7
a numeric vector   Tg8
a numeric vector   Th9
a numeric vector   To10
a numeric vector   T11
a numeric vector   T12
a numeric vector   T13
a numeric vector   T14
a numeric vector   T15
a numeric vector   T16
a numeric vector   CNg1
a numeric vector   CN2
a numeric vector   CN3
a numeric vector   CN4
a numeric vector   CN5
a numeric vector   CN6
a numeric vector   CN7
a numeric vector   CN8
a numeric vector   Ld1
a numeric vector   Lf2
a numeric vector   Lg3
a numeric vector   Lp4
a numeric vector   L5
a numeric vector   L6
a numeric vector   L7
a numeric vector   L8
a numeric vector   L9
a numeric vector   L10
a numeric vector   L11
a numeric vector   LS1
a numeric vector   LS2
a numeric vector   LL1
a numeric vector   LL2
a numeric vector   LL3
a numeric vector   LL4
a numeric vector   LL5
a numeric vector   EGd1
a numeric vector   EGf2
a numeric vector   CCd1
a numeric vector   CCn2
a numeric vector   CCn3
a numeric vector   EMc1
a numeric vector   EMd2
a numeric vector   EMd3
a numeric vector   EMf4
a numeric vector   EMf5
a numeric vector   EMn6
a numeric vector   EMx7
a numeric vector   EM8
a numeric vector   EM9
a numeric vector   EM10
a numeric vector   EM11
a numeric vector   EM12
a numeric vector   TE1
a numeric vector   TE2
a numeric vector   TE3
a numeric vector   TE4
a numeric vector   TE5
a numeric vector   BWe1
a numeric vector   BWn2
a numeric vector   BWn3
a numeric vector   TS1
a numeric vector   TS2
a numeric vector   TS3
a numeric vector   TS4
a numeric vector   TS5
a numeric vector   TS6
a numeric vector   TS7
a numeric vector   TS8
a numeric vector   TS9
a numeric vector   Pg1
a numeric vector   Pg2
a numeric vector   Pg3
a numeric vector   DUaa1
a numeric vector   DUw2
a numeric vector   DU3
a numeric vector   CP1
a numeric vector   CP2
a numeric vector   CP3
a numeric vector   CP4
a numeric vector   CP5
a numeric vector   CP6
a numeric vector   CP7
a numeric vector   CP8
a numeric vector   CP9
a numeric vector   CP10
a numeric vector   CP11
a numeric vector   CP12
a numeric vector   STd1
a numeric vector   STd2
a numeric vector   STd3
a numeric vector   STg4
a numeric vector   STaa5
a numeric vector   STaa6
a numeric vector   STaa7
a numeric vector   STaa8
a numeric vector   ST9
a numeric vector   ST10
a numeric vector   ST11
a numeric vector   ST12
a numeric vector   Wd1
a numeric vector   Wd2
a numeric vector   Wd3
a numeric vector   Wd4
a numeric vector   Wn5
a numeric vector   Waa6
a numeric vector   Waa7
a numeric vector   W8
a numeric vector   W9
a numeric vector   W10
a numeric vector   W11
a numeric vector   W12
a numeric vector   W13
a numeric vector   Zd1
a numeric vector   Zd2
a numeric vector   Zn3
a numeric vector   Zw4
a numeric vector   Zw5
a numeric vector   Zaa6
a numeric vector   Z7
a numeric vector   Z8
a numeric vector   Z9
a numeric vector   Z10
a numeric vector   Z11
a numeric vector   Z12
a numeric vector   CLd1
a numeric vector   CLd2
a numeric vector   CLd3
a numeric vector   CLd4
a numeric vector   CLd5
a numeric vector   CLd6
a numeric vector   CLd7
a numeric vector   CLd8
a numeric vector   CLd9
a numeric vector   CLd10
a numeric vector   CLd11
a numeric vector   CLd12
a numeric vector   CLd13
a numeric vector   CLd14
a numeric vector   CLd15
a numeric vector   CLd16
a numeric vector   CLd17
a numeric vector   CLd18
a numeric vector   CLd19
a numeric vector   CLd20
a numeric vector   CLd21
a numeric vector   CLd22
a numeric vector   CLd23
a numeric vector   CLd24
a numeric vector   CLd25
a numeric vector   CLd26
a numeric vector   CLd27
a numeric vector   CLd28
a numeric vector   CLd29
a numeric vector   CLd30
a numeric vector   CLd31
a numeric vector   CLd32
a numeric vector   CLd33
a numeric vector   CLd34
a numeric vector   CLd35
a numeric vector   CLd36
a numeric vector   CLd37
a numeric vector   CLd38
a numeric vector   CLn39
a numeric vector   CLn40
a numeric vector   CLn41
a numeric vector   CLn42
a numeric vector   CLn43
a numeric vector   CLn44
a numeric vector   CLn45
a numeric vector   CLn46
a numeric vector   CLn47
a numeric vector   CLn48
a numeric vector   CLw49
a numeric vector   CL50
a numeric vector   CL51
a numeric vector   CL52
a numeric vector   CL53
a numeric vector   CL54
a numeric vector   CL55
a numeric vector   CL56
a numeric vector   CL57
a numeric vector   CL58
a numeric vector   CL59
a numeric vector   Xd1
a numeric vector   Xd2
a numeric vector   Xd3
a numeric vector   Xd4
a numeric vector   Xd5
a numeric vector   Xd6
a numeric vector   Xd7
a numeric vector   Xd8
a numeric vector   Xd9
a numeric vector   Xd10
a numeric vector   Xd11
a numeric vector   Xd12
a numeric vector   Xd13
a numeric vector   Xf14
a numeric vector   Xk15
a numeric vector   Xn16
a numeric vector   Xn17
a numeric vector   Xn18
a numeric vector   Xn19
a numeric vector   Xn20
a numeric vector   Xn21
a numeric vector   Xn22
a numeric vector   Xn23
a numeric vector   Xn24
a numeric vector   Xn25
a numeric vector   Xn26
a numeric vector   Xn27
a numeric vector   Xn28
a numeric vector   Xn29
a numeric vector   Xn30
a numeric vector   Xn31
a numeric vector   Xn32
a numeric vector   Xp33
a numeric vector   Xp34
a numeric vector   Xp35
a numeric vector   Xq36
a numeric vector   Xq37
a numeric vector   Xq38
a numeric vector   X39
a numeric vector   X40
a numeric vector   X41
a numeric vector   X42
a numeric vector   X43
a numeric vector   X44
a numeric vector   X45
a numeric vector   X46
a numeric vector   X47
a numeric vector   X48
a numeric vector   X49
a numeric vector   X50
a numeric vector   Qd1
a numeric vector   Qe2
a numeric vector   Qe3
a numeric vector   Qh4
a numeric vector   Qh5
a numeric vector   Qh6
a numeric vector   Qh7
a numeric vector   Qh8
a numeric vector   Qh9
a numeric vector   Qn10
a numeric vector   Qn11
a numeric vector   Qt12
a numeric vector   Q13
a numeric vector   Q14
a numeric vector   Q15
a numeric vector   Q16
a numeric vector   Q17
a numeric vector   Q18
a numeric vector   Q19
a numeric vector   Q20
a numeric vector   Q21
a numeric vector   Q22
a numeric vector   TZd1
a numeric vector   TZf2
a numeric vector   TZh3
a numeric vector   TZ4
a numeric vector   CRd1
a numeric vector   CR2
a numeric vector   CR3
a numeric vector   EUd1
a numeric vector   EUd2
a numeric vector   EUg3
a numeric vector   EUm4
a numeric vector   EUw5
a numeric vector   EU6
a numeric vector   Ud1
a numeric vector   Ud2
a numeric vector   Ud3
a numeric vector   Uaa4
a numeric vector   U5
a numeric vector   Vd1
a numeric vector   V2
a numeric vector   V3
a numeric vector   V4
a numeric vector   V5
a numeric vector   LWE1
a numeric vector   LWE2
a numeric vector   Ad1
a numeric vector   Al2
a numeric vector   Am3
a numeric vector   An4
a numeric vector   Aw5
a numeric vector   Aaa6
a numeric vector   A7
a numeric vector   A8
a numeric vector   A9
a numeric vector   EVd1
a numeric vector   EVg2
a numeric vector   TK1
a numeric vector   ECL1
a numeric vector   EFe1
a numeric vector   EFm2
a numeric vector   EFm3
a numeric vector   EF4
a numeric vector   LPo1
a numeric vector   LPq2
a numeric vector   LP3
a numeric vector   LP4
a numeric vector   LP5
a numeric vector   PT1
a numeric vector   CSC
a numeric vector   CSR
a numeric vector   CCRC
a numeric vector   SA
a numeric vector   Anthrop
a numeric vector   Turtle
a numeric vector   Boat
a numeric vector   Canoe
a numeric vector   Hand
a numeric vector   Foot
a numeric vector   Lizard
a numeric vector   Crocodile
a numeric vector   Jellyfish
a numeric vector   Bird
a numeric vector   Anthrobird
a numeric vector   Axe
a numeric vector   Marine
a numeric vector   Face
a numeric vector   Zoo1
a numeric vector   Zoo2
a numeric vector   Zoo3
a numeric vector   Zoo4
a numeric vector   Zoo5
a numeric vector   Zoo6
a numeric vector     Details  
Note the vignette rockArt .    Source  
Meredith Wilson: Picturing Pacific Pre-History (PhD thesis), 2002, Australian National University.    References  
Meredith Wilson: Rethinking regional analyses of Western Pacific rock-art. Records of the Australian Museum , Supplement 29: 173-186.    Examples    data(rockArt) rockart.dist <- dist(x = as.matrix(rockArt[, 28:641]), method = ""binary"") sum(rockart.dist==1)/length(rockart.dist) plot(density(rockart.dist, to = 1)) rockart.cmd <- cmdscale(rockart.dist) tab <- table(rockArt$District) district <- as.character(rockArt$District) district[!(rockArt$District %in% names(tab)[tab>5])] <- ""other"" ## Not run: xyplot(rockart.cmd[,2] ~ rockart.cmd[,1], groups=district, auto.key=list(columns=5), par.settings=list(superpose.symbol=list(pch=16))) library(MASS) ## For sammon, need to avoid zero distances omit <- c(47, 54, 60, 63, 92) rockart.dist <- dist(x = as.matrix(rockArt[-omit, 28:641]), method = ""binary"") rockart.cmd <- cmdscale(rockart.dist) rockart.sam <- sammon(rockart.dist, rockart.cmd) xyplot(rockart.sam$points[,2] ~ rockart.sam$points[,1], groups=district[-omit], auto.key=list(columns=5), par.settings=list(superpose.symbol=list(pch=16))) ## Notice the very different appearance of the Sammon plot ## End(Not run)"
"DAAG-roller","DAAG","roller","Lawn Roller Data",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/roller.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/roller.html","roller R Documentation   Lawn Roller Data   Description  
The roller data frame has 10 rows and 2 columns. Different weights of roller were rolled over different parts of a lawn, and the depression was recorded.    Usage   roller   Format  
This data frame contains the following columns:    weight
a numeric vector consisting of the roller weights   depression
the depth of the depression made in the grass under the roller     Source  
Stewart, K.M., Van Toor, R.F., Crosbie, S.F. 1988. Control of grass grub (Coleoptera: Scarabaeidae) with rollers of different design. N.Z. Journal of Experimental Agriculture 16: 141-150.    Examples    plot(roller) roller.lm <- lm(depression ~ weight, data = roller) plot(roller.lm, which = 4)"
"DAAG-science","DAAG","science","School Science Survey Data",1385,7,3,0,6,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/science.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/science.html","science R Documentation   School Science Survey Data   Description  
The science data frame has 1385 rows and 7 columns.   
The data are on attitudes to science, from a survey where there were results from 20 classes in private schools and 46 classes in public schools.    Usage   science   Format  
This data frame contains the following columns:    State
a factor with levels  ACT Australian Capital Territory,  NSW New South Wales   PrivPub
a factor with levels  private school,  public school   school
a factor, coded to identify the school   class
a factor, coded to identify the class   sex
a factor with levels  f , m   like
a summary score based on two of the questions, on a scale from 1 (dislike) to 12 (like)   Class
a factor with levels corresponding to each class     Source  
Francine Adams, Rosemary Martin and Murali Nayadu, Australian National University    Examples    classmeans <- with(science, aggregate(like, by=list(PrivPub, Class), mean)) names(classmeans) <- c(""PrivPub"",""Class"",""like"") dim(classmeans) attach(classmeans) boxplot(split(like, PrivPub), ylab = ""Class average of attitude to science score"", boxwex = 0.4) rug(like[PrivPub == ""private""], side = 2) rug(like[PrivPub == ""public""], side = 4) detach(classmeans) if(require(lme4, quietly=TRUE)) { science.lmer <- lmer(like ~ sex + PrivPub + (1 | school) + (1 | school:class), data = science, na.action=na.exclude) summary(science.lmer) science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class), data = science, na.action=na.exclude) summary(science1.lmer) ranf <- ranef(obj = science1.lmer, drop=TRUE)[[""school:class""]] flist <- science1.lmer@flist[[""school:class""]] privpub <- science[match(names(ranf), flist), ""PrivPub""] num <- unclass(table(flist)); numlabs <- pretty(num) ## Plot effect estimates vs numbers plot(sqrt(num), ranf, xaxt=""n"", pch=c(1,3)[as.numeric(privpub)], xlab=""# in class (square root scale)"", ylab=""Estimate of class effect"") lines(lowess(sqrt(num[privpub==""private""]), ranf[privpub==""private""], f=1.1), lty=2) lines(lowess(sqrt(num[privpub==""public""]), ranf[privpub==""public""], f=1.1), lty=3) axis(1, at=sqrt(numlabs), labels=paste(numlabs)) }"
"DAAG-seedrates","DAAG","seedrates","Barley Seeding Rate Data",5,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/seedrates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/seedrates.html","seedrates R Documentation   Barley Seeding Rate Data   Description  
The seedrates data frame has 5 rows and 2 columns on the effect of seeding rate of barley on yield.    Usage   seedrates   Format  
This data frame contains the following columns:    rate
the seeding rate   grain
the number of grain per head of barley     Source  
McLeod, C.C. 1982. Effect of rates of seeding on barley grown for grain. New Zealand Journal of Agriculture 10: 133-136.   References  
Maindonald J H 1992. Statistical design, analysis and presentation issues. New Zealand Journal of Agricultural Research 35: 121-141.   Examples    plot(grain~rate,data=seedrates,xlim=c(50,180),ylim=c(15.5,22),axes=FALSE) new.df<-data.frame(rate=(2:8)*25) seedrates.lm1<-lm(grain~rate,data=seedrates) seedrates.lm2<-lm(grain~rate+I(rate^2),data=seedrates) hat1<-predict(seedrates.lm1,newdata=new.df,interval=""confidence"") hat2<-predict(seedrates.lm2,newdata=new.df,interval=""confidence"") axis(1,at=new.df$rate); axis(2); box() z1<-spline(new.df$rate, hat1[,""fit""]); z2<-spline(new.df$rate, hat2[,""fit""]) rate<-new.df$rate; lines(z1$x,z1$y) lines(spline(rate,hat1[,""lwr""]),lty=1,col=3) lines(spline(rate,hat1[,""upr""]),lty=1,col=3) lines(z2$x,z2$y,lty=4) lines(spline(rate,hat2[,""lwr""]),lty=4,col=3) lines(spline(rate,hat2[,""upr""]),lty=4,col=3)"
"DAAG-socsupport","DAAG","socsupport","Social Support Data",95,20,3,0,8,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/socsupport.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/socsupport.html","socsupport R Documentation   Social Support Data   Description  
Data from a survey on social and other kinds of support.    Usage   socsupport   Format  
This data frame contains the following columns:    gender
a factor with levels  female , male   age
age, in years, with levels  18-20 , 21-24 , 25-30 , 31-40 , 40+   country
a factor with levels australia , other   marital
a factor with levels married ,  other , single   livewith
a factor with levels alone , friends , other , parents , partner , residences   employment
a factor with levels  employed fulltime , employed part-time , govt assistance , other , parental support   firstyr
a factor with levels first year , other   enrolment
a factor with levels  full-time , part-time , <NA>   emotional
summary of 5 questions on emotional support availability   emotionalsat
summary of 5 questions on emotional support satisfaction   tangible
summary of 4 questions on availability of tangible support   tangiblesat
summary of 4 questions on satisfaction with tangible support   affect
summary of 3 questions on availability of affectionate support sources   affectsat
summary of 3 questions on satisfaction with affectionate support sources   psi
summary of 3 questions on availability of positive social interaction   psisat
summary of 3 questions on satisfaction with positive social interaction   esupport
summary of 4 questions on extent of emotional support sources   psupport
summary of 4 questions on extent of practical support sources   supsources
summary of 4 questions on extent of social support sources (formerly, socsupport)   BDI
Score on the Beck depression index (summary of 21 questions)     Source  
Melissa Manning, Psychology, Australian National University    Examples    attach(socsupport) not.na <- apply(socsupport[,9:19], 1, function(x)!any(is.na(x))) ss.pr1 <- princomp(as.matrix(socsupport[not.na, 9:19]), cor=TRUE) pairs(ss.pr1$scores[,1:3]) sort(-ss.pr1$scores[,1]) # Minus the largest value appears first pause() not.na[36] <- FALSE ss.pr <- princomp(as.matrix(socsupport[not.na, 9:19]), cor=TRUE) summary(ss.pr) # Examine the contribution of the components pause() # We now regress BDI on the first six principal components: ss.lm <- lm(BDI[not.na] ~ ss.pr$scores[, 1:6], data=socsupport) summary(ss.lm)$coef pause() ss.pr$loadings[,1] plot(BDI[not.na] ~ ss.pr$scores[ ,1], col=as.numeric(gender), pch=as.numeric(gender), xlab =""1st principal component"", ylab=""BDI"") topleft <- par()$usr[c(1,4)] legend(topleft[1], topleft[2], col=1:2, pch=1:2, legend=levels(gender))"
"DAAG-softbacks","DAAG","softbacks","Measurements on a Selection of Paperback Books",8,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/softbacks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/softbacks.html","softbacks R Documentation   Measurements on a Selection of Paperback Books   Description  
This is a subset of the allbacks data frame which gives measurements on the volume and weight of 8 paperback books.    Usage   softbacks   Format  
This data frame contains the following columns:    volume
a numeric vector giving the book volumes in cubic centimeters   weight
a numeric vector giving the weights in grams     Source  
The bookshelf of J. H. Maindonald.    Examples    print(""Outliers in Simple Regression - Example 5.2"") paperback.lm <- lm(weight ~ volume, data=softbacks) summary(paperback.lm) plot(paperback.lm)"
"DAAG-sorption","DAAG","sorption","sorption data set",192,14,0,0,5,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/sorption.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/sorption.html","sorption R Documentation   sorption data set   Description  
Concentration-time measurements on different varieties of apples under methyl bromide injection.    Usage   data(sorption)   Format  
A data frame with 192 observations on the following 14 variables.    m5
a numeric vector   m10
a numeric vector   m30
a numeric vector   m60
a numeric vector   m90
a numeric vector   m120
a numeric vector   ct
concentration-time   Cultivar
a factor with levels Pacific Rose BRAEBURN Fuji GRANNY Gala ROYAL Red Delicious Splendour   Dose
injected dose of methyl bromide   rep
replicate number, within Cultivar and year   year
a factor with levels 1988 1989 1998 1999   year.rep
a factor with levels 1988:1 1988:2 1988:3 1989:1 1989:2 1998:1 1998:2 1998:3 1999:1 1999:2   gp
a factor with levels BRAEBURN1 BRAEBURN2 Fuji1 Fuji10 Fuji2 Fuji6 Fuji7 Fuji8 Fuji9 GRANNY1 GRANNY2 Gala4 Gala5 Pacific Rose10 Pacific Rose6 Pacific Rose7 Pacific Rose8 Pacific Rose9 ROYAL1 ROYAL2 Red Del10 Red Del9 Red Delicious1 Red Delicious2 Red Delicious3 Red Delicious4 Red Delicious5 Red Delicious6 Red Delicious7 Red Delicious8 Splendour4 Splendour5   inyear
a factor with levels 1 2 3 4 5 6"
"DAAG-SP500close","DAAG","SP500close","Closing Numbers for S and P 500 Index",2780,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/SP500close.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/SP500close.html","SP500close R Documentation   Closing Numbers for S and P 500 Index   Description  
Closing numbers for S and P 500 Index, Jan. 1, 1990 through early 2000.   Usage   SP500close   Source  
Derived from SP500 in the MASS library.    Examples    ts.plot(SP500close)"
"DAAG-SP500W90","DAAG","SP500W90","Closing Numbers for S and P 500 Index - First 100 Days of 1990",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/SP500W90.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/SP500W90.html","SP500W90 R Documentation   Closing Numbers for S and P 500 Index - First 100 Days of 1990   Description  
Closing numbers for S and P 500 Index, Jan. 1, 1990 through early 2000.   Usage   SP500W90   Source  
Derived from SP500 in the MASS library.    Examples    ts.plot(SP500W90)"
"DAAG-spam7","DAAG","spam7","Spam E-mail Data",4601,7,1,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/spam7.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/spam7.html","spam7 R Documentation   Spam E-mail Data   Description  
The data consist of 4601 email items, of which 1813 items were identified as spam.    Usage   spam7   Format  
This data frame contains the following columns:    crl.tot
total length of words in capitals   dollar
number of occurrences of the \$ symbol   bang
number of occurrences of the ! symbol   money
number of occurrences of the word ‘money’   n000
number of occurrences of the string ‘000’   make
number of occurrences of the word ‘make’   yesno
outcome variable, a factor with levels  n not spam,  y spam     Source  
George Forman, Hewlett-Packard Laboratories   
These data are available from the University of California at Irvine Repository of Machine Learning Databases and Domain Theories. The address is: http://www.ics.uci.edu/~Here    Examples    require(rpart) spam.rpart <- rpart(formula = yesno ~ crl.tot + dollar + bang + money + n000 + make, data=spam7) plot(spam.rpart) text(spam.rpart)"
"DAAG-stVincent","DAAG","stVincent","Averages by block of yields for the St. Vincent Corn data",324,8,0,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/stVincent.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/stVincent.html","stVincent R Documentation   Averages by block of yields for the St. Vincent Corn data   Description  
These data frames have yield averages by blocks (parcels).    Usage   stVincent   Format  
A data frame with 324 observations on 8 variables.    code
a numeric vector   island
a numeric vector   id
a numeric vector   site
a factor with 8 levels.   block
a factor with levels I II III IV   plot
a numeric vector   trt
a factor consisting of 12 levels   harvwt
a numeric vector; the average yield     Source  
Andrews DF; Herzberg AM, 1985. Data. A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag. (pp. 339-353)"
"DAAG-sugar","DAAG","sugar","Sugar Data",12,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/sugar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/sugar.html","sugar R Documentation   Sugar Data   Description  
The sugar data frame has 12 rows and 2 columns. They are from an experiment that compared an unmodified wild type plant with three different genetically modified forms. The measurements are weights of sugar that were obtained by breaking down the cellulose.   Usage   sugar   Format  
This data frame contains the following columns:    weight
weight, in mg   trt
a factor with levels  Control i.e. unmodified Wild form, A Modified 1,  B Modified 2,  C Modified 3     Source  
Anonymous    Examples    sugar.aov <- aov(weight ~ trt, data=sugar) fitted.values(sugar.aov) summary.lm(sugar.aov) sugar.aov <- aov(formula = weight ~ trt, data = sugar) summary.lm(sugar.aov)"
"DAAG-tinting","DAAG","tinting","Car Window Tinting Experiment Data",182,9,3,0,4,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/tinting.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/tinting.html","tinting R Documentation   Car Window Tinting Experiment Data   Description  
These data are from an experiment that aimed to model the effects of the tinting of car windows on visual performance. The authors were mainly interested in effects on side window vision, and hence in visual recognition tasks that would be performed when looking through side windows.    Usage   tinting   Format  
This data frame contains the following columns:    case
observation number   id
subject identifier code (1-26)   age
age (in years)   sex
a factor with levels  f female,  m male   tint
an ordered factor with levels representing degree of tinting: no < lo < hi   target
a factor with levels  locon : low contrast,  hicon : high contrast   it
the inspection time, the time required to perform a simple discrimination task (in milliseconds)   csoa
critical stimulus onset asynchrony, the time to recognize an alphanumeric target (in milliseconds)   agegp
a factor with levels  younger , 21-27,  older , 70-78     Details  
Visual light transmittance (VLT) levels were 100% (tint=none), 81.3% (tint=lo), and 35.1% (tint=hi). Based on these and other data, Burns et al. argue that road safety may be compromised if the front side windows of cars are tinted to 35    Source  
Burns, N.R., Nettlebeck, T., White, M. and Willson, J., 1999. Effects of car window tinting on visual performance: a comparison of younger and older drivers. Ergonomics 42: 428-443.    Examples    levels(tinting$agegp) <- capstring(levels(tinting$agegp)) xyplot(csoa ~ it | sex * agegp, data=tinting) # Simple use of xyplot() pause() xyplot(csoa ~ it|sex*agegp, data=tinting, panel=panel.superpose, groups=target) pause() xyplot(csoa ~ it|sex*agegp, data=tinting, panel=panel.superpose, col=1:2, groups=target, key=list(x=0.14, y=0.84, points=list(pch=rep(1,2), col=1:2), text=list(levels(tinting$target), col=1:2), border=TRUE)) pause() xyplot(csoa ~ it|sex*agegp, data=tinting, panel=panel.superpose, groups=tint, type=c(""p"",""smooth""), span=0.8, col=1:3, key=list(x=0.14, y=0.84, points=list(pch=rep(1,2), col=1:3), text=list(levels(tinting$tint), col=1:3), border=TRUE))"
"DAAG-tomato","DAAG","tomato","Root weights of tomato plants exposed to 4 different treatments",24,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/tomato.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/tomato.html","tomato R Documentation   Root weights of tomato plants exposed to 4 different treatments   Description  
The tomato data frame has 24 rows and 2 columns. They are from an experiment that exposed tomato plants to four different 'nutrients'.    Usage   data(tomato)   Format  
This data frame contains the following columns:    weight
weight, in g   trt
a factor with levels  water only ,  conc nutrient ,  2-4-D + conc nutrient ,  3x conc nutrient     Source  
Dr Ron Balham, Victoria University of Wellington NZ, sometime in 1971 - 1976.    Examples    tomato.aov <- aov(log(weight) ~ trt, data=tomato) fitted.values(tomato.aov) summary.lm(tomato.aov) tomato.aov <- aov(formula = weight ~ trt, data = tomato) summary.lm(tomato.aov)"
"DAAG-toycars","DAAG","toycars","Toy Cars Data",27,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/toycars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/toycars.html","toycars R Documentation   Toy Cars Data   Description  
The toycars data frame has 27 rows and 3 columns. Observations are on the distance traveled by one of three different toy cars on a smooth surface, starting from rest at the top of a 16 inch long ramp tilted at varying angles.    Usage   toycars   Format  
This data frame contains the following columns:    angle
tilt of ramp, in degrees   distance
distance traveled, in meters   car
a numeric code (1 = first car, 2 = second car, 3 = third car)     Examples    toycars.lm <- lm(distance ~ angle + factor(car), data=toycars) summary(toycars.lm)"
"DAAG-vince111b","DAAG","vince111b","Averages by block of corn yields, for treatment 111 only",36,8,0,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/vince111b.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/vince111b.html","vince111b R Documentation   Averages by block of corn yields, for treatment 111 only   Description  
These data frames have averages by blocks (parcels) for the treatment  111 .    Usage   vince111b   Format  
A data frame with 36 observations on 8 variables.    site
a factor with levels AGSV CASV CPSV   LPSV MPSV OOSV OTSV SSSV UISV     parcel
a factor with levels I II III IV   code
a numeric vector   island
a numeric vector   id
a numeric vector   plot
a numeric vector   trt
a numeric vector   harvwt
a numeric vector     Source  
Andrews DF; Herzberg AM, 1985. Data. A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag. (pp. 339-353)"
"DAAG-vlt","DAAG","vlt","Video Lottery Terminal Data",345,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/vlt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/vlt.html","vlt R Documentation   Video Lottery Terminal Data   Description  
Data on objects appearing in three windows on a video lottery terminal, together with the prize payout (usually 0). Observations were taken on two successive days in late 1994 at a hotel lounge north of Winnipeg, Manitoba. Each observation cost 25 cents (Canadian). The game played was ‘Double Diamond’.    Usage   vlt   Format  
This data frame contains the following columns:    window1
object appearing in the first window.   window2
object appearing in the second window.   window3
object appearing in the third window.   prize
cash prize awarded (in Canadian dollars).   night
1, if observation was taken on day 1; 2, if observation was taken on day 2.     Details  
At each play, each of three windows shows one of 7 possible objects. Apparently, the three windows are independent of each other, and the objects should appear with equal probability across the three windows. The objects are coded as follows: blank (0), single bar (1), double bar (2), triple bar (3), double diamond (5), cherries (6), and the numeral ""7"" (7).  
Prizes (in quarters) are awarded according to the following scheme: 800 (5-5-5), 80 (7-7-7), 40 (3-3-3), 25 (2-2-2), 10 (1-1-1), 10 (6-6-6), 5 (2 ""6""'s), 2 (1 ""6"") and 5 (any combination of ""1"", ""2"" and ""3""). In addition, a ""5"" doubles any winning combination, e.g. (5-3-3) pays 80 and (5-3-5) pays 160.    Source  
Braun, W. J. (1995) An illustration of bootstrapping using video lottery terminal data. Journal of Statistics Education http://www.amstat.org/publications/jse/v3n2/datasets.braun.html    Examples    vlt.stk <- stack(vlt[,1:3]) table(vlt.stk)"
"DAAG-wages1833","DAAG","wages1833","Wages of Lancashire Cotton Factory Workers in 1833",51,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/wages1833.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/wages1833.html","wages1833 R Documentation   Wages of Lancashire Cotton Factory Workers in 1833   Description  
The wages1833 data frame gives the wages of Lancashire cotton factory workers in 1833.   Usage   wages1833   Format  
This data frame contains the following columns:    age
age in years   mnum
number of male workers   mwage
average wage of male workers   fnum
number of female workers   fwage
average wage of female workers     Source  
Boot, H.M. 1995. How Skilled Were the Lancashire Cotton Factory Workers in 1833? Economic History Review 48: 283-303.    Examples    attach(wages1833) plot(mwage~age,ylim=range(c(mwage,fwage[fwage>0]))) points(fwage[fwage>0]~age[fwage>0],pch=15,col=""red"") lines(lowess(age,mwage)) lines(lowess(age[fwage>0],fwage[fwage>0]),col=""red"")"
"DAAG-whoops","DAAG","whoops","Deaths from whooping cough, in London",142,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/whoops.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/whoops.html","whoops R Documentation   Deaths from whooping cough, in London   Description  
Deaths from whooping cough, in London from 1740 to 1881.   Usage   data(whoops)   Format  
This is a multiple time series consisting of 3 series:  wcough , ratio , and alldeaths .    Source  
Guy, W. A. 1882. Two hundred and fifty years of small pox in London. Journal of the Royal Statistical Society 399-443.    References  
Lancaster, H. O. 1990. Expectations of Life. Springer.    Examples    data(whoops) str(whoops) plot(whoops)"
"DAAG-worldRecords","DAAG","worldRecords","Record times for track and road races, at August 9th 2006",40,5,1,1,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/DAAG/worldRecords.csv","https://vincentarelbundock.github.io/Rdatasets/doc/DAAG/worldRecords.html","worldRecords R Documentation   Record times for track and road races, at August 9th 2006   Description  
Record times for track and road races, at August 9th 2006   Usage   data(worldRecords)   Format  
A data frame with 40 observations on the following 9 variables.    Distance
distance in kilometers   roadORtrack
a factor with levels road track   Place
place; a character vector   Time
time in minutes   Date
a Date     Details  
For further details, and some additional details, see the web site that is the source of the data.    Source  
http://www.gbrathletics.com/wrec.htm     Examples    data(worldRecords) xyplot(log(Time) ~ log(Distance), groups=roadORtrack, data=worldRecords) xyplot(log(Time) ~ log(Distance), groups=roadORtrack, data=worldRecords, type=c(""p"",""r"")) xyplot(log(Time) ~ log(Distance), groups=roadORtrack, data=worldRecords, type=c(""p"",""smooth""))"
"datasets-ability.cov","datasets","ability.cov","Ability and Intelligence Tests",6,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/ability.cov.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/ability.cov.html","ability.cov R Documentation   Ability and Intelligence Tests   Description  
Six tests were given to 112 individuals. The covariance matrix is given in this object.    Usage   ability.cov   Details  
The tests are described as    general:
a non-verbal measure of general intelligence using Cattell's culture-fair test.   picture:
a picture-completion test   blocks:
block design   maze:
mazes   reading:
reading comprehension   vocab:
vocabulary    
Bartholomew gives both covariance and correlation matrices, but these are inconsistent. Neither are in the original paper.    Source  
Bartholomew, D. J. (1987).  Latent Variable Analysis and Factor Analysis . Griffin.   
Bartholomew, D. J. and Knott, M. (1990).  Latent Variable Analysis and Factor Analysis . Second Edition, Arnold.    References  
Smith, G. A. and Stanley G. (1983). Clocking g : relating intelligence and measures of timed performance.  Intelligence , 7 , 353–368. doi: 10.1016/0160-2896(83)90010-7 .    Examples    require(stats) (ability.FA <- factanal(factors = 1, covmat = ability.cov)) update(ability.FA, factors = 2) ## The signs of factors and hence the signs of correlations are ## arbitrary with promax rotation. update(ability.FA, factors = 2, rotation = ""promax"")"
"datasets-airmiles","datasets","airmiles","Passenger Miles on Commercial US Airlines, 1937-1960",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/airmiles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/airmiles.html","airmiles R Documentation   Passenger Miles on Commercial US Airlines, 1937–1960   Description  
The revenue passenger miles flown by commercial airlines in the United States for each year from 1937 to 1960.    Usage   airmiles   Format  
A time series of 24 observations; yearly, 1937–1960.    Source  
F.A.A. Statistical Handbook of Aviation.   References  
Brown, R. G. (1963)  Smoothing, Forecasting and Prediction of Discrete Time Series . Prentice-Hall.    Examples    require(graphics) plot(airmiles, main = ""airmiles data"", xlab = ""Passenger-miles flown by U.S. commercial airlines"", col = 4)"
"datasets-AirPassengers","datasets","AirPassengers","Monthly Airline Passenger Numbers 1949-1960",144,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/AirPassengers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/AirPassengers.html","AirPassengers R Documentation   Monthly Airline Passenger Numbers 1949-1960   Description  
The classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.    Usage   AirPassengers   Format  
A monthly time series, in thousands.    Source  
Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976)  Time Series Analysis, Forecasting and Control.  Third Edition. Holden-Day. Series G.    Examples    ## Not run: ## These are quite slow and so not run by example(AirPassengers) ## The classic 'airline model', by full ML (fit <- arima(log10(AirPassengers), c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12))) update(fit, method = ""CSS"") update(fit, x = window(log10(AirPassengers), start = 1954)) pred <- predict(fit, n.ahead = 24) tl <- pred$pred - 1.96 * pred$se tu <- pred$pred + 1.96 * pred$se ts.plot(AirPassengers, 10^tl, 10^tu, log = ""y"", lty = c(1, 2, 2)) ## full ML fit is the same if the series is reversed, CSS fit is not ap0 <- rev(log10(AirPassengers)) attributes(ap0) <- attributes(AirPassengers) arima(ap0, c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12)) arima(ap0, c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 12), method = ""CSS"") ## Structural Time Series ap <- log10(AirPassengers) - 2 (fit <- StructTS(ap, type = ""BSM"")) par(mfrow = c(1, 2)) plot(cbind(ap, fitted(fit)), plot.type = ""single"") plot(cbind(ap, tsSmooth(fit)), plot.type = ""single"") ## End(Not run)"
"datasets-airquality","datasets","airquality","New York Air Quality Measurements",153,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/airquality.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/airquality.html","airquality R Documentation   New York Air Quality Measurements   Description  
Daily air quality measurements in New York, May to September 1973.    Usage   airquality   Format  
A data frame with 153 observations on 6 variables.   
  [,1] Ozone  numeric Ozone (ppb)
  [,2] Solar.R numeric Solar R (lang)
  [,3] Wind  numeric Wind (mph)
  [,4] Temp  numeric Temperature (degrees F)
  [,5] Month  numeric Month (1--12)
  [,6] Day  numeric Day of month (1--31)    Details  
Daily readings of the following air quality values for May 1, 1973 (a Tuesday) to September 30, 1973.   

Ozone : Mean ozone in parts per billion from 1300 to 1500 hours at Roosevelt Island   
Solar.R : Solar radiation in Langleys in the frequency band 4000–7700 Angstroms from 0800 to 1200 hours at Central Park   
Wind : Average wind speed in miles per hour at 0700 and 1000 hours at LaGuardia Airport   
Temp : Maximum daily temperature in degrees Fahrenheit at La Guardia Airport.      Source  
The data were obtained from the New York State Department of Conservation (ozone data) and the National Weather Service (meteorological data).    References  
Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A. (1983)  Graphical Methods for Data Analysis . Belmont, CA: Wadsworth.    Examples    require(graphics) pairs(airquality, panel = panel.smooth, main = ""airquality data"")"
"datasets-anscombe","datasets","anscombe","Anscombe's Quartet of 'Identical' Simple Linear Regressions",11,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/anscombe.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/anscombe.html","anscombe R Documentation   Anscombe's Quartet of ‘Identical’ Simple Linear Regressions   Description  
Four x - y datasets which have the same traditional statistical properties (mean, variance, correlation, regression line, etc.), yet are quite different.    Usage   anscombe   Format  
A data frame with 11 observations on 8 variables.   
 x1 == x2 == x3 the integers 4:14, specially arranged
 x4 values 8 and 19
 y1, y2, y3, y4 numbers in (3, 12.5) with mean 7.5 and sdev 2.03   Source  
Tufte, Edward R. (1989).  The Visual Display of Quantitative Information , 13–14. Graphics Press.    References  
Anscombe, Francis J. (1973). Graphs in statistical analysis.  The American Statistician , 27 , 17–21. doi: 10.2307/2682899 .    Examples    require(stats); require(graphics) summary(anscombe) ##-- now some ""magic"" to do the 4 regressions in a loop: ff <- y ~ x mods <- setNames(as.list(1:4), paste0(""lm"", 1:4)) for(i in 1:4) { ff[2:3] <- lapply(paste0(c(""y"",""x""), i), as.name) ## or ff[[2]] <- as.name(paste0(""y"", i)) ## ff[[3]] <- as.name(paste0(""x"", i)) mods[[i]] <- lmi <- lm(ff, data = anscombe) print(anova(lmi)) } ## See how close they are (numerically!) sapply(mods, coef) lapply(mods, function(fm) coef(summary(fm))) ## Now, do what you should have done in the first place: PLOTS op <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma = c(0, 0, 2, 0)) for(i in 1:4) { ff[2:3] <- lapply(paste0(c(""y"",""x""), i), as.name) plot(ff, data = anscombe, col = ""red"", pch = 21, bg = ""orange"", cex = 1.2, xlim = c(3, 19), ylim = c(3, 13)) abline(mods[[i]], col = ""blue"") } mtext(""Anscombe's 4 Regression data sets"", outer = TRUE, cex = 1.5) par(op)"
"datasets-attenu","datasets","attenu","The Joyner-Boore Attenuation Data",182,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/attenu.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/attenu.html","attenu R Documentation   The Joyner–Boore Attenuation Data   Description  
This data gives peak accelerations measured at various observation stations for 23 earthquakes in California. The data have been used by various workers to estimate the attenuating affect of distance on ground acceleration.    Usage   attenu   Format  
A data frame with 182 observations on 5 variables.   
 [,1] event numeric Event Number
 [,2] mag numeric Moment Magnitude
 [,3] station factor Station Number
 [,4] dist numeric Station-hypocenter distance (km)
 [,5] accel numeric Peak acceleration (g)   Source  
Joyner, W.B., D.M. Boore and R.D. Porcella (1981). Peak horizontal acceleration and velocity from strong-motion records including records from the 1979 Imperial Valley, California earthquake. USGS Open File report 81-365. Menlo Park, Ca.    References  
Boore, D. M. and Joyner, W. B.(1982). The empirical prediction of ground motion,  Bulletin of the Seismological Society of America , 72 , S269–S268.   
Bolt, B. A. and Abrahamson, N. A. (1982). New attenuation relations for peak and expected accelerations of strong ground motion.  Bulletin of the Seismological Society of America , 72 , 2307–2321.   
Bolt B. A. and Abrahamson, N. A. (1983). Reply to W. B. Joyner & D. M. Boore's “Comments on: New attenuation relations for peak and expected accelerations for peak and expected accelerations of strong ground motion”,  Bulletin of the Seismological Society of America , 73 , 1481–1483.   
Brillinger, D. R. and Preisler, H. K. (1984). An exploratory analysis of the Joyner-Boore attenuation data,  Bulletin of the Seismological Society of America , 74 , 1441–1449.   
Brillinger, D. R. and Preisler, H. K. (1984).  Further analysis of the Joyner-Boore attenuation data . Manuscript.    Examples    require(graphics) ## check the data class of the variables sapply(attenu, data.class) summary(attenu) pairs(attenu, main = ""attenu data"") coplot(accel ~ dist | as.factor(event), data = attenu, show.given = FALSE) coplot(log(accel) ~ log(dist) | as.factor(event), data = attenu, panel = panel.smooth, show.given = FALSE)"
"datasets-attitude","datasets","attitude","The Chatterjee-Price Attitude Data",30,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/attitude.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/attitude.html","attitude R Documentation   The Chatterjee–Price Attitude Data   Description  
From a survey of the clerical employees of a large financial organization, the data are aggregated from the questionnaires of the approximately 35 employees for each of 30 (randomly selected) departments. The numbers give the percent proportion of favourable responses to seven questions in each department.   Usage   attitude   Format  
A data frame with 30 observations on 7 variables. The first column are the short names from the reference, the second one the variable names in the data frame:   
 Y rating numeric Overall rating
 X[1] complaints numeric Handling of employee complaints
 X[2] privileges numeric Does not allow special privileges
 X[3] learning numeric Opportunity to learn
 X[4] raises numeric Raises based on performance
 X[5] critical numeric Too critical
 X[6] advancel numeric Advancement   Source  
Chatterjee, S. and Price, B. (1977)  Regression Analysis by Example . New York: Wiley. (Section 3.7, p.68ff of 2nd ed.(1991).)    Examples    require(stats); require(graphics) pairs(attitude, main = ""attitude data"") summary(attitude) summary(fm1 <- lm(rating ~ ., data = attitude)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0), mar = c(4.1, 4.1, 2.1, 1.1)) plot(fm1) summary(fm2 <- lm(rating ~ complaints, data = attitude)) plot(fm2) par(opar)"
"datasets-austres","datasets","austres","Quarterly Time Series of the Number of Australian Residents",89,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/austres.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/austres.html","austres R Documentation    Quarterly Time Series of the Number of Australian Residents    Description  
Numbers (in thousands) of Australian residents measured quarterly from March 1971 to March 1994. The object is of class ""ts"" .    Usage   austres   Source  
P. J. Brockwell and R. A. Davis (1996)  Introduction to Time Series and Forecasting.  Springer"
"datasets-BJsales","datasets","BJsales","Sales Data with Leading Indicator",150,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/BJsales.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/BJsales.html","BJsales R Documentation   Sales Data with Leading Indicator   Description  
The sales time series BJsales and leading indicator  BJsales.lead each contain 150 observations. The objects are of class ""ts"" .    Usage    BJsales BJsales.lead    Source  
The data are given in Box & Jenkins (1976). Obtained from the Time Series Data Library at  https://robjhyndman.com/TSDL/     References  
G. E. P. Box and G. M. Jenkins (1976):  Time Series Analysis, Forecasting and Control , Holden-Day, San Francisco, p. 537.   
P. J. Brockwell and R. A. Davis (1991):  Time Series: Theory and Methods , Second edition, Springer Verlag, NY, pp. 414."
"datasets-BOD","datasets","BOD","Biochemical Oxygen Demand",6,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/BOD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/BOD.html","BOD R Documentation   Biochemical Oxygen Demand   Description  
The BOD data frame has 6 rows and 2 columns giving the biochemical oxygen demand versus time in an evaluation of water quality.    Usage   BOD   Format  
This data frame contains the following columns:    Time  
A numeric vector giving the time of the measurement (days).    demand  
A numeric vector giving the biochemical oxygen demand (mg/l).      Source  
Bates, D.M. and Watts, D.G. (1988),  Nonlinear Regression Analysis and Its Applications , Wiley, Appendix A1.4.   
Originally from Marske (1967), Biochemical Oxygen Demand Data Interpretation Using Sum of Squares Surface  M.Sc. Thesis, University of Wisconsin – Madison.    Examples    require(stats) # simplest form of fitting a first-order model to these data fm1 <- nls(demand ~ A*(1-exp(-exp(lrc)*Time)), data = BOD, start = c(A = 20, lrc = log(.35))) coef(fm1) fm1 # using the plinear algorithm (trace o/p differs by platform) ## IGNORE_RDIFF_BEGIN fm2 <- nls(demand ~ (1-exp(-exp(lrc)*Time)), data = BOD, start = c(lrc = log(.35)), algorithm = ""plinear"", trace = TRUE) ## IGNORE_RDIFF_END # using a self-starting model fm3 <- nls(demand ~ SSasympOrig(Time, A, lrc), data = BOD) summary(fm3)"
"datasets-cars","datasets","cars","Speed and Stopping Distances of Cars",50,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/cars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/cars.html","cars R Documentation   Speed and Stopping Distances of Cars   Description  
The data give the speed of cars and the distances taken to stop. Note that the data were recorded in the 1920s.    Usage   cars   Format  
A data frame with 50 observations on 2 variables.   
 [,1] speed numeric Speed (mph)
 [,2] dist numeric Stopping distance (ft)    Source  
Ezekiel, M. (1930)  Methods of Correlation Analysis . Wiley.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(stats); require(graphics) plot(cars, xlab = ""Speed (mph)"", ylab = ""Stopping distance (ft)"", las = 1) lines(lowess(cars$speed, cars$dist, f = 2/3, iter = 3), col = ""red"") title(main = ""cars data"") plot(cars, xlab = ""Speed (mph)"", ylab = ""Stopping distance (ft)"", las = 1, log = ""xy"") title(main = ""cars data (logarithmic scales)"") lines(lowess(cars$speed, cars$dist, f = 2/3, iter = 3), col = ""red"") summary(fm1 <- lm(log(dist) ~ log(speed), data = cars)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0), mar = c(4.1, 4.1, 2.1, 1.1)) plot(fm1) par(opar) ## An example of polynomial regression plot(cars, xlab = ""Speed (mph)"", ylab = ""Stopping distance (ft)"", las = 1, xlim = c(0, 25)) d <- seq(0, 25, length.out = 200) for(degree in 1:4) { fm <- lm(dist ~ poly(speed, degree), data = cars) assign(paste(""cars"", degree, sep = "".""), fm) lines(d, predict(fm, data.frame(speed = d)), col = degree) } anova(cars.1, cars.2, cars.3, cars.4)"
"datasets-ChickWeight","datasets","ChickWeight","Weight versus age of chicks on different diets",578,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/ChickWeight.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/ChickWeight.html","ChickWeight R Documentation   Weight versus age of chicks on different diets   Description  
The ChickWeight data frame has 578 rows and 4 columns from an experiment on the effect of diet on early growth of chicks.    Usage   ChickWeight   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    weight  
a numeric vector giving the body weight of the chick (gm).    Time  
a numeric vector giving the number of days since birth when the measurement was made.    Chick  
an ordered factor with levels  18 < ... < 48  giving a unique identifier for the chick. The ordering of the levels groups chicks on the same diet together and orders them according to their final weight (lightest to heaviest) within diet.    Diet  
a factor with levels 1, ..., 4 indicating which experimental diet the chick received.      Details  
The body weights of the chicks were measured at birth and every second day thereafter until day 20. They were also measured on day 21. There were four groups on chicks on different protein diets.   
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Crowder, M. and Hand, D. (1990), Analysis of Repeated Measures , Chapman and Hall (example 5.3)   
Hand, D. and Crowder, M. (1996), Practical Longitudinal Data Analysis , Chapman and Hall (table A.2)   
Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS , Springer.    See Also  
SSlogis for models fitted to this dataset.    Examples    require(graphics) coplot(weight ~ Time | Chick, data = ChickWeight, type = ""b"", show.given = FALSE)"
"datasets-chickwts","datasets","chickwts","Chicken Weights by Feed Type",71,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/chickwts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/chickwts.html","chickwts R Documentation   Chicken Weights by Feed Type   Description  
An experiment was conducted to measure and compare the effectiveness of various feed supplements on the growth rate of chickens.    Usage   chickwts   Format  
A data frame with 71 observations on the following 2 variables.    weight
a numeric variable giving the chick weight.   feed
a factor giving the feed type.     Details  
Newly hatched chicks were randomly allocated into six groups, and each group was given a different feed supplement. Their weights in grams after six weeks are given along with feed types.    Source  
Anonymous (1948)  Biometrika , 35 , 214.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(stats); require(graphics) boxplot(weight ~ feed, data = chickwts, col = ""lightgray"", varwidth = TRUE, notch = TRUE, main = ""chickwt data"", ylab = ""Weight at six weeks (gm)"") anova(fm1 <- lm(weight ~ feed, data = chickwts)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0), mar = c(4.1, 4.1, 2.1, 1.1)) plot(fm1) par(opar)"
"datasets-CO2","datasets","CO2","Carbon Dioxide Uptake in Grass Plants",84,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/CO2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/CO2.html","CO2 R Documentation   Carbon Dioxide Uptake in Grass Plants   Description  
The CO2 data frame has 84 rows and 5 columns of data from an experiment on the cold tolerance of the grass species  Echinochloa crus-galli .    Usage   CO2   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    Plant  
an ordered factor with levels  Qn1 < Qn2 < Qn3 < ... < Mc1  giving a unique identifier for each plant.    Type  
a factor with levels  Quebec   Mississippi  giving the origin of the plant    Treatment  
a factor with levels  nonchilled   chilled     conc  
a numeric vector of ambient carbon dioxide concentrations (mL/L).    uptake  
a numeric vector of carbon dioxide uptake rates ( umol/m^2 sec).      Details  
The CO2 uptake of six plants from Quebec and six plants from Mississippi was measured at several levels of ambient  CO2 concentration. Half the plants of each type were chilled overnight before the experiment was conducted.   
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Potvin, C., Lechowicz, M. J. and Tardif, S. (1990) “The statistical analysis of ecophysiological response curves obtained from experiments involving repeated measures”, Ecology ,  71 , 1389–1400.   
Pinheiro, J. C. and Bates, D. M. (2000)  Mixed-effects Models in S and S-PLUS , Springer.    Examples    require(stats); require(graphics) coplot(uptake ~ conc | Plant, data = CO2, show.given = FALSE, type = ""b"") ## fit the data for the first plant fm1 <- nls(uptake ~ SSasymp(conc, Asym, lrc, c0), data = CO2, subset = Plant == ""Qn1"") summary(fm1) ## fit each plant separately fmlist <- list() for (pp in levels(CO2$Plant)) { fmlist[[pp]] <- nls(uptake ~ SSasymp(conc, Asym, lrc, c0), data = CO2, subset = Plant == pp) } ## check the coefficients by plant print(sapply(fmlist, coef), digits = 3)"
"datasets-co2","datasets","co2","Mauna Loa Atmospheric CO2 Concentration",468,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/co2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/co2.html","co2 R Documentation   Mauna Loa Atmospheric CO2 Concentration   Description  
Atmospheric concentrations of CO 2 are expressed in parts per million (ppm) and reported in the preliminary 1997 SIO manometric mole fraction scale.    Usage   co2   Format  
A time series of 468 observations; monthly from 1959 to 1997.    Details  
The values for February, March and April of 1964 were missing and have been obtained by interpolating linearly between the values for January and May of 1964.    Source  
Keeling, C. D. and Whorf, T. P., Scripps Institution of Oceanography (SIO), University of California, La Jolla, California USA 92093-0220.   
https://scrippsco2.ucsd.edu/data/atmospheric_co2/ .   
Note that the data are subject to revision (based on recalibration of standard gases) by the Scripps institute, and hence may not agree exactly with the data provided by R .    References  
Cleveland, W. S. (1993)  Visualizing Data . New Jersey: Summit Press.    Examples    require(graphics) plot(co2, ylab = expression(""Atmospheric concentration of CO""[2]), las = 1) title(main = ""co2 data set"")"
"datasets-crimtab","datasets","crimtab","Student's 3000 Criminals Data",924,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/crimtab.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/crimtab.html","crimtab R Documentation   Student's 3000 Criminals Data   Description  
Data of 3000 male criminals over 20 years old undergoing their sentences in the chief prisons of England and Wales.    Usage   crimtab   Format  
A table object of integer counts, of dimension  42 * 22 with a total count, sum(crimtab) of 3000.   
The 42 rownames ( ""9.4"" , ""9.5"" , ...) correspond to midpoints of intervals of finger lengths whereas the 22 column names ( colnames ) ( ""142.24"" , ""144.78"" , ...) correspond to (body) heights of 3000 criminals, see also below.    Details  
Student is the pseudonym of William Sealy Gosset. In his 1908 paper he wrote (on page 13) at the beginning of section VI entitled Practical Test of the forgoing Equations :   
“Before I had succeeded in solving my problem analytically, I had endeavoured to do so empirically. The material used was a correlation table containing the height and left middle finger measurements of 3000 criminals, from a paper by W. R. MacDonell ( Biometrika , Vol. I., p. 219). The measurements were written out on 3000 pieces of cardboard, which were then very thoroughly shuffled and drawn at random. As each card was drawn its numbers were written down in a book, which thus contains the measurements of 3000 criminals in a random order. Finally, each consecutive set of 4 was taken as a sample—750 in all—and the mean, standard deviation, and correlation of each sample determined. The difference between the mean of each sample and the mean of the population was then divided by the standard deviation of the sample, giving us the z of Section III.”   
The table is in fact page 216 and not page 219 in MacDonell(1902). In the MacDonell table, the middle finger lengths were given in mm and the heights in feet/inches intervals, they are both converted into cm here. The midpoints of intervals were used, e.g., where MacDonell has 4' 7''9/16 -- 8''9/16 , we have 142.24 which is 2.54*56 = 2.54*( 4' 8'' ).   
MacDonell credited the source of data (page 178) as follows:  The data on which the memoir is based were obtained, through the kindness of Dr Garson, from the Central Metric Office, New Scotland Yard...  He pointed out on page 179 that : The forms were drawn at random from the mass on the office shelves; we are therefore dealing with a random sampling.     Source  
https://pbil.univ-lyon1.fr/R/donnees/criminals1902.txt  thanks to Jean R. Lobry and Anne-Béatrice Dufour.    References  
Garson, J.G. (1900). The metric system of identification of criminals, as used in in Great Britain and Ireland.  The Journal of the Anthropological Institute of Great Britain and Ireland , 30 , 161–198. doi: 10.2307/2842627 .   
MacDonell, W.R. (1902). On criminal anthropometry and the identification of criminals.  Biometrika , 1 (2), 177–227. doi: 10.2307/2331487 .   
Student (1908). The probable error of a mean.  Biometrika , 6 , 1–25. doi: 10.2307/2331554 .    Examples    require(stats) dim(crimtab) utils::str(crimtab) ## for nicer printing: local({cT <- crimtab colnames(cT) <- substring(colnames(cT), 2, 3) print(cT, zero.print = "" "") }) ## Repeat Student's experiment: # 1) Reconstitute 3000 raw data for heights in inches and rounded to # nearest integer as in Student's paper: (heIn <- round(as.numeric(colnames(crimtab)) / 2.54)) d.hei <- data.frame(height = rep(heIn, colSums(crimtab))) # 2) shuffle the data: set.seed(1) d.hei <- d.hei[sample(1:3000), , drop = FALSE] # 3) Make 750 samples each of size 4: d.hei$sample <- as.factor(rep(1:750, each = 4)) # 4) Compute the means and standard deviations (n) for the 750 samples: h.mean <- with(d.hei, tapply(height, sample, FUN = mean)) h.sd <- with(d.hei, tapply(height, sample, FUN = sd)) * sqrt(3/4) # 5) Compute the difference between the mean of each sample and # the mean of the population and then divide by the # standard deviation of the sample: zobs <- (h.mean - mean(d.hei[,""height""]))/h.sd # 6) Replace infinite values by +/- 6 as in Student's paper: zobs[infZ <- is.infinite(zobs)] # none of them zobs[infZ] <- 6 * sign(zobs[infZ]) # 7) Plot the distribution: require(grDevices); require(graphics) hist(x = zobs, probability = TRUE, xlab = ""Student's z"", col = grey(0.8), border = grey(0.5), main = ""Distribution of Student's z score for 'crimtab' data"")"
"datasets-discoveries","datasets","discoveries","Yearly Numbers of Important Discoveries",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/discoveries.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/discoveries.html","discoveries R Documentation   Yearly Numbers of Important Discoveries   Description  
The numbers of “great” inventions and scientific discoveries in each year from 1860 to 1959.    Usage   discoveries   Format  
A time series of 100 values.   Source  
The World Almanac and Book of Facts, 1975 Edition, pages 315–318.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(graphics) plot(discoveries, ylab = ""Number of important discoveries"", las = 1) title(main = ""discoveries data set"")"
"datasets-DNase","datasets","DNase","Elisa assay of DNase",176,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/DNase.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/DNase.html","DNase R Documentation   Elisa assay of DNase   Description  
The DNase data frame has 176 rows and 3 columns of data obtained during development of an ELISA assay for the recombinant protein DNase in rat serum.    Usage   DNase   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    Run  
an ordered factor with levels 10 < ... < 3  indicating the assay run.    conc  
a numeric vector giving the known concentration of the protein.    density  
a numeric vector giving the measured optical density (dimensionless) in the assay. Duplicate optical density measurements were obtained.      Details  
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Davidian, M. and Giltinan, D. M. (1995)  Nonlinear Models for Repeated Measurement Data , Chapman & Hall (section 5.2.4, p. 134)   
Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS , Springer.    Examples    require(stats); require(graphics) coplot(density ~ conc | Run, data = DNase, show.given = FALSE, type = ""b"") coplot(density ~ log(conc) | Run, data = DNase, show.given = FALSE, type = ""b"") ## fit a representative run fm1 <- nls(density ~ SSlogis( log(conc), Asym, xmid, scal ), data = DNase, subset = Run == 1) ## compare with a four-parameter logistic fm2 <- nls(density ~ SSfpl( log(conc), A, B, xmid, scal ), data = DNase, subset = Run == 1) summary(fm2) anova(fm1, fm2)"
"datasets-esoph","datasets","esoph","Smoking, Alcohol and (O)esophageal Cancer",88,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/esoph.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/esoph.html","esoph R Documentation   Smoking, Alcohol and (O)esophageal Cancer   Description  
Data from a case-control study of (o)esophageal cancer in Ille-et-Vilaine, France.    Usage   esoph   Format  
A data frame with records for 88 age/alcohol/tobacco combinations.   
 [,1] ""agegp"" Age group 1 25--34 years
  2 35--44
  3 45--54
  4 55--64
  5 65--74
  6 75+
 [,2] ""alcgp"" Alcohol consumption 1 0--39 gm/day
  2 40--79
  3 80--119
  4 120+
 [,3] ""tobgp"" Tobacco consumption 1 0-- 9 gm/day
  2 10--19
  3 20--29
  4 30+
 [,4] ""ncases"" Number of cases
 [,5] ""ncontrols"" Number of controls     Author(s)  
Thomas Lumley   Source  
Breslow, N. E. and Day, N. E. (1980)  Statistical Methods in Cancer Research. Volume 1: The Analysis of Case-Control Studies. IARC Lyon / Oxford University Press.    Examples    require(stats) require(graphics) # for mosaicplot summary(esoph) ## effects of alcohol, tobacco and interaction, age-adjusted model1 <- glm(cbind(ncases, ncontrols) ~ agegp + tobgp * alcgp, data = esoph, family = binomial()) anova(model1) ## Try a linear effect of alcohol and tobacco model2 <- glm(cbind(ncases, ncontrols) ~ agegp + unclass(tobgp) + unclass(alcgp), data = esoph, family = binomial()) summary(model2) ## Re-arrange data for a mosaic plot ttt <- table(esoph$agegp, esoph$alcgp, esoph$tobgp) o <- with(esoph, order(tobgp, alcgp, agegp)) ttt[ttt == 1] <- esoph$ncases[o] tt1 <- table(esoph$agegp, esoph$alcgp, esoph$tobgp) tt1[tt1 == 1] <- esoph$ncontrols[o] tt <- array(c(ttt, tt1), c(dim(ttt),2), c(dimnames(ttt), list(c(""Cancer"", ""control"")))) mosaicplot(tt, main = ""esoph data set"", color = TRUE)"
"datasets-euro","datasets","euro","Conversion Rates of Euro Currencies",11,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/euro.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/euro.html","euro R Documentation   Conversion Rates of Euro Currencies   Description  
Conversion rates between the various Euro currencies.   Usage    euro euro.cross    Format  
euro is a named vector of length 11, euro.cross a matrix of size 11 by 11, with dimnames.    Details  
The data set euro contains the value of 1 Euro in all currencies participating in the European monetary union (Austrian Schilling ATS, Belgian Franc BEF, German Mark DEM, Spanish Peseta ESP, Finnish Markka FIM, French Franc FRF, Irish Punt IEP, Italian Lira ITL, Luxembourg Franc LUF, Dutch Guilder NLG and Portuguese Escudo PTE). These conversion rates were fixed by the European Union on December 31, 1998. To convert old prices to Euro prices, divide by the respective rate and round to 2 digits.   
The data set euro.cross contains conversion rates between the various Euro currencies, i.e., the result of  outer(1 / euro, euro) .    Examples    cbind(euro) ## These relations hold: euro == signif(euro, 6) # [6 digit precision in Euro's definition] all(euro.cross == outer(1/euro, euro)) ## Convert 20 Euro to Belgian Franc 20 * euro[""BEF""] ## Convert 20 Austrian Schilling to Euro 20 / euro[""ATS""] ## Convert 20 Spanish Pesetas to Italian Lira 20 * euro.cross[""ESP"", ""ITL""] require(graphics) dotchart(euro, main = ""euro data: 1 Euro in currency unit"") dotchart(1/euro, main = ""euro data: 1 currency unit in Euros"") dotchart(log(euro, 10), main = ""euro data: log10(1 Euro in currency unit)"")"
"datasets-EuStockMarkets","datasets","EuStockMarkets","Daily Closing Prices of Major European Stock Indices, 1991-1998",1860,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/EuStockMarkets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/EuStockMarkets.html","EuStockMarkets R Documentation    Daily Closing Prices of Major European Stock Indices, 1991–1998    Description  
Contains the daily closing prices of major European stock indices: Germany DAX (Ibis), Switzerland SMI, France CAC, and UK FTSE. The data are sampled in business time, i.e., weekends and holidays are omitted.    Usage    EuStockMarkets    Format  
A multivariate time series with 1860 observations on 4 variables. The object is of class ""mts"" .    Source  
The data were kindly provided by Erste Bank AG, Vienna, Austria."
"datasets-faithful","datasets","faithful","Old Faithful Geyser Data",272,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/faithful.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/faithful.html","faithful R Documentation   Old Faithful Geyser Data   Description  
Waiting time between eruptions and the duration of the eruption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA.    Usage   faithful   Format  
A data frame with 272 observations on 2 variables.   
 [,1] eruptions numeric Eruption time in mins
 [,2] waiting numeric Waiting time to next eruption (in mins)
    Details  
A closer look at faithful$eruptions reveals that these are heavily rounded times originally in seconds, where multiples of 5 are more frequent than expected under non-human measurement. For a better version of the eruption times, see the example below.   
There are many versions of this dataset around: Azzalini and Bowman (1990) use a more complete version.    Source  
W. Härdle.   References  
Härdle, W. (1991).  Smoothing Techniques with Implementation in S . New York: Springer.   
Azzalini, A. and Bowman, A. W. (1990). A look at some data on the Old Faithful geyser.  Applied Statistics , 39 , 357–365. doi: 10.2307/2347385 .    See Also  
geyser in package MASS for the Azzalini–Bowman version.    Examples    require(stats); require(graphics) f.tit <- ""faithful data: Eruptions of Old Faithful"" ne60 <- round(e60 <- 60 * faithful$eruptions) all.equal(e60, ne60) # relative diff. ~ 1/10000 table(zapsmall(abs(e60 - ne60))) # 0, 0.02 or 0.04 faithful$better.eruptions <- ne60 / 60 te <- table(ne60) te[te >= 4] # (too) many multiples of 5 ! plot(names(te), te, type = ""h"", main = f.tit, xlab = ""Eruption time (sec)"") plot(faithful[, -3], main = f.tit, xlab = ""Eruption time (min)"", ylab = ""Waiting time to next eruption (min)"") lines(lowess(faithful$eruptions, faithful$waiting, f = 2/3, iter = 3), col = ""red"")"
"datasets-Formaldehyde","datasets","Formaldehyde","Determination of Formaldehyde",6,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Formaldehyde.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Formaldehyde.html","Formaldehyde R Documentation   Determination of Formaldehyde   Description  
These data are from a chemical experiment to prepare a standard curve for the determination of formaldehyde by the addition of chromatropic acid and concentrated sulphuric acid and the reading of the resulting purple color on a spectrophotometer.    Usage   Formaldehyde   Format  
A data frame with 6 observations on 2 variables.   
 [,1] carb numeric Carbohydrate (ml)
 [,2] optden numeric Optical Density    Source  
Bennett, N. A. and N. L. Franklin (1954)  Statistical Analysis in Chemistry and the Chemical Industry . New York: Wiley.    References  
McNeil, D. R. (1977) Interactive Data Analysis.  New York: Wiley.    Examples    require(stats); require(graphics) plot(optden ~ carb, data = Formaldehyde, xlab = ""Carbohydrate (ml)"", ylab = ""Optical Density"", main = ""Formaldehyde data"", col = 4, las = 1) abline(fm1 <- lm(optden ~ carb, data = Formaldehyde)) summary(fm1) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0)) plot(fm1) par(opar)"
"datasets-freeny","datasets","freeny","Freeny's Revenue Data",39,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/freeny.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/freeny.html","freeny R Documentation   Freeny's Revenue Data   Description  
Freeny's data on quarterly revenue and explanatory variables.    Usage    freeny freeny.x freeny.y    Format  
There are three ‘freeny’ data sets.   
freeny.y is a time series with 39 observations on quarterly revenue from (1962,2Q) to (1971,4Q).   
freeny.x is a matrix of explanatory variables. The columns are freeny.y lagged 1 quarter, price index, income level, and market potential.   
Finally, freeny is a data frame with variables y ,  lag.quarterly.revenue , price.index , income.level , and market.potential obtained from the above two data objects.    Source  
A. E. Freeny (1977)  A Portable Linear Regression Package with Test Programs . Bell Laboratories memorandum.    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole.    Examples    require(stats); require(graphics) summary(freeny) pairs(freeny, main = ""freeny data"") # gives warning: freeny$y has class ""ts"" summary(fm1 <- lm(y ~ ., data = freeny)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0), mar = c(4.1, 4.1, 2.1, 1.1)) plot(fm1) par(opar)"
"datasets-HairEyeColor","datasets","HairEyeColor","Hair and Eye Color of Statistics Students",32,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/HairEyeColor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/HairEyeColor.html","HairEyeColor R Documentation   Hair and Eye Color of Statistics Students   Description  
Distribution of hair and eye color and sex in 592 statistics students.    Usage   HairEyeColor   Format  
A 3-dimensional array resulting from cross-tabulating 592 observations on 3 variables. The variables and their levels are as follows:   
 No Name Levels
 1 Hair Black, Brown, Red, Blond
 2 Eye Brown, Blue, Hazel, Green
 3 Sex Male, Female    Details  
The Hair x Eye table comes from a survey of students at the University of Delaware reported by Snee (1974). The split by  Sex was added by Friendly (1992a) for didactic purposes.   
This data set is useful for illustrating various techniques for the analysis of contingency tables, such as the standard chi-squared test or, more generally, log-linear modelling, and graphical methods such as mosaic plots, sieve diagrams or association plots.    Source  
http://www.datavis.ca/sas/vcd/catdata/haireye.sas    
Snee (1974) gives the two-way table aggregated over Sex . The  Sex split of the ‘Brown hair, Brown eye’ cell was changed to agree with that used by Friendly (2000).    References  
Snee, R. D. (1974). Graphical display of two-way contingency tables.  The American Statistician , 28 , 9–12. doi: 10.2307/2683520 .   
Friendly, M. (1992a). Graphical methods for categorical data.  SAS User Group International Conference Proceedings , 17 , 190–200.  http://datavis.ca/papers/sugi/sugi17.pdf    
Friendly, M. (1992b). Mosaic displays for loglinear models.  Proceedings of the Statistical Graphics Section , American Statistical Association, pp. 61–68.  http://www.datavis.ca/papers/asa92.html    
Friendly, M. (2000).  Visualizing Categorical Data . SAS Institute, ISBN 1-58025-660-0.    See Also  
chisq.test ,  loglin ,  mosaicplot     Examples    require(graphics) ## Full mosaic mosaicplot(HairEyeColor) ## Aggregate over sex (as in Snee's original data) x <- apply(HairEyeColor, c(1, 2), sum) x mosaicplot(x, main = ""Relation between hair and eye color"")"
"datasets-Harman23.cor","datasets","Harman23.cor","Harman Example 2.3",8,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Harman23.cor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Harman23.cor.html","Harman23.cor R Documentation   Harman Example 2.3   Description  
A correlation matrix of eight physical measurements on 305 girls between ages seven and seventeen.    Usage   Harman23.cor   Source  
Harman, H. H. (1976)  Modern Factor Analysis , Third Edition Revised, University of Chicago Press, Table 2.3.    Examples    require(stats) (Harman23.FA <- factanal(factors = 1, covmat = Harman23.cor)) for(factors in 2:4) print(update(Harman23.FA, factors = factors))"
"datasets-Harman74.cor","datasets","Harman74.cor","Harman Example 7.4",24,26,0,0,0,0,26,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Harman74.cor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Harman74.cor.html","Harman74.cor R Documentation   Harman Example 7.4   Description  
A correlation matrix of 24 psychological tests given to 145 seventh and eight-grade children in a Chicago suburb by Holzinger and Swineford.    Usage   Harman74.cor   Source  
Harman, H. H. (1976)  Modern Factor Analysis , Third Edition Revised, University of Chicago Press, Table 7.4.    Examples    require(stats) (Harman74.FA <- factanal(factors = 1, covmat = Harman74.cor)) for(factors in 2:5) print(update(Harman74.FA, factors = factors)) Harman74.FA <- factanal(factors = 5, covmat = Harman74.cor, rotation = ""promax"") print(Harman74.FA$loadings, sort = TRUE)"
"datasets-Indometh","datasets","Indometh","Pharmacokinetics of Indomethacin",66,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Indometh.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Indometh.html","Indometh R Documentation   Pharmacokinetics of Indomethacin   Description  
The Indometh data frame has 66 rows and 3 columns of data on the pharmacokinetics of indometacin (or, older spelling, ‘indomethacin’).    Usage   Indometh   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    Subject  
an ordered factor with containing the subject codes. The ordering is according to increasing maximum response.    time  
a numeric vector of times at which blood samples were drawn (hr).    conc  
a numeric vector of plasma concentrations of indometacin (mcg/ml).      Details  
Each of the six subjects were given an intravenous injection of indometacin.   
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Kwan, Breault, Umbenhauer, McMahon and Duggan (1976) Kinetics of Indomethacin absorption, elimination, and enterohepatic circulation in man.  Journal of Pharmacokinetics and Biopharmaceutics 4 , 255–280.   
Davidian, M. and Giltinan, D. M. (1995)  Nonlinear Models for Repeated Measurement Data , Chapman & Hall (section 5.2.4, p. 129)   
Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS , Springer.    See Also  
SSbiexp for models fitted to this dataset."
"datasets-infert","datasets","infert","Infertility after Spontaneous and Induced Abortion",248,8,1,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/infert.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/infert.html","infert R Documentation   Infertility after Spontaneous and Induced Abortion   Description  
This is a matched case-control study dating from before the availability of conditional logistic regression.    Usage   infert   Format  
 1. Education 0 = 0-5 years
   1 = 6-11 years
   2 = 12+ years
 2. age age in years of case
 3. parity count
 4. number of prior 0 = 0
  induced abortions 1 = 1
   2 = 2 or more
 5. case status 1 = case
   0 = control
 6. number of prior 0 = 0
  spontaneous abortions 1 = 1
   2 = 2 or more
 7. matched set number 1-83
 8. stratum number 1-63   Note  
One case with two prior spontaneous abortions and two prior induced abortions is omitted.    Source  
Trichopoulos et al (1976)  Br. J. of Obst. and Gynaec. 83 , 645–650.    Examples    require(stats) model1 <- glm(case ~ spontaneous+induced, data = infert, family = binomial()) summary(model1) ## adjusted for other potential confounders: summary(model2 <- glm(case ~ age+parity+education+spontaneous+induced, data = infert, family = binomial())) ## Really should be analysed by conditional logistic regression ## which is in the survival package if(require(survival)){ model3 <- clogit(case ~ spontaneous+induced+strata(stratum), data = infert) print(summary(model3)) detach() # survival (conflicts) }"
"datasets-InsectSprays","datasets","InsectSprays","Effectiveness of Insect Sprays",72,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/InsectSprays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/InsectSprays.html","InsectSprays R Documentation   Effectiveness of Insect Sprays   Description  
The counts of insects in agricultural experimental units treated with different insecticides.    Usage   InsectSprays   Format  
A data frame with 72 observations on 2 variables.   
 [,1] count numeric Insect count
 [,2] spray factor The type of spray    Source  
Beall, G., (1942) The Transformation of data from entomological field experiments,  Biometrika , 29 , 243–262.    References  
McNeil, D. (1977) Interactive Data Analysis . New York: Wiley.    Examples    require(stats); require(graphics) boxplot(count ~ spray, data = InsectSprays, xlab = ""Type of spray"", ylab = ""Insect count"", main = ""InsectSprays data"", varwidth = TRUE, col = ""lightgray"") fm1 <- aov(count ~ spray, data = InsectSprays) summary(fm1) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0)) plot(fm1) fm2 <- aov(sqrt(count) ~ spray, data = InsectSprays) summary(fm2) plot(fm2) par(opar)"
"datasets-iris","datasets","iris","Edgar Anderson's Iris Data",150,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/iris.html","iris R Documentation   Edgar Anderson's Iris Data   Description  
This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa ,  versicolor , and virginica .    Usage    iris iris3    Format  
iris is a data frame with 150 cases (rows) and 5 variables (columns) named Sepal.Length , Sepal.Width ,  Petal.Length , Petal.Width , and Species .   
iris3 gives the same data arranged as a 3-dimensional array of size 50 by 4 by 3, as represented by S-PLUS. The first dimension gives the case number within the species subsample, the second the measurements with names Sepal L. , Sepal W. ,  Petal L. , and Petal W. , and the third the species.    Source  
Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems.  Annals of Eugenics ,  7 , Part II, 179–188.   
The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula,  Bulletin of the American Iris Society ,  59 , 2–5.    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole. (has iris3 as iris .)    See Also  
matplot some examples of which use  iris .    Examples    dni3 <- dimnames(iris3) ii <- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4, dimnames = list(NULL, sub("" L."","".Length"", sub("" W."","".Width"", dni3[[2]])))), Species = gl(3, 50, labels = sub(""S"", ""s"", sub(""V"", ""v"", dni3[[3]])))) all.equal(ii, iris) # TRUE"
"datasets-iris3","datasets","iris3","Edgar Anderson's Iris Data",50,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/iris3.html","iris R Documentation   Edgar Anderson's Iris Data   Description  
This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa ,  versicolor , and virginica .    Usage    iris iris3    Format  
iris is a data frame with 150 cases (rows) and 5 variables (columns) named Sepal.Length , Sepal.Width ,  Petal.Length , Petal.Width , and Species .   
iris3 gives the same data arranged as a 3-dimensional array of size 50 by 4 by 3, as represented by S-PLUS. The first dimension gives the case number within the species subsample, the second the measurements with names Sepal L. , Sepal W. ,  Petal L. , and Petal W. , and the third the species.    Source  
Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems.  Annals of Eugenics ,  7 , Part II, 179–188.   
The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula,  Bulletin of the American Iris Society ,  59 , 2–5.    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole. (has iris3 as iris .)    See Also  
matplot some examples of which use  iris .    Examples    dni3 <- dimnames(iris3) ii <- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4, dimnames = list(NULL, sub("" L."","".Length"", sub("" W."","".Width"", dni3[[2]])))), Species = gl(3, 50, labels = sub(""S"", ""s"", sub(""V"", ""v"", dni3[[3]])))) all.equal(ii, iris) # TRUE"
"datasets-islands","datasets","islands","Areas of the World's Major Landmasses",48,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/islands.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/islands.html","islands R Documentation   Areas of the World's Major Landmasses   Description  
The areas in thousands of square miles of the landmasses which exceed 10,000 square miles.    Usage   islands   Format  
A named vector of length 48.   Source  
The World Almanac and Book of Facts, 1975, page 406.   References  
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(graphics) dotchart(log(islands, 10), main = ""islands data: log10(area) (log10(sq. miles))"") dotchart(log(islands[order(islands)], 10), main = ""islands data: log10(area) (log10(sq. miles))"")"
"datasets-JohnsonJohnson","datasets","JohnsonJohnson","Quarterly Earnings per Johnson & Johnson Share",84,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/JohnsonJohnson.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/JohnsonJohnson.html","JohnsonJohnson R Documentation   Quarterly Earnings per Johnson & Johnson Share   Description  
Quarterly earnings (dollars) per Johnson & Johnson share 1960–80.    Usage   JohnsonJohnson   Format  
A quarterly time series    Source  
Shumway, R. H. and Stoffer, D. S. (2000)  Time Series Analysis and its Applications . Second Edition. Springer. Example 1.1.    Examples    require(stats); require(graphics) JJ <- log10(JohnsonJohnson) plot(JJ) ## This example gives a possible-non-convergence warning on some ## platforms, but does seem to converge on x86 Linux and Windows. (fit <- StructTS(JJ, type = ""BSM"")) tsdiag(fit) sm <- tsSmooth(fit) plot(cbind(JJ, sm[, 1], sm[, 3]-0.5), plot.type = ""single"", col = c(""black"", ""green"", ""blue"")) abline(h = -0.5, col = ""grey60"") monthplot(fit)"
"datasets-LakeHuron","datasets","LakeHuron","Level of Lake Huron 1875-1972",98,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/LakeHuron.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/LakeHuron.html","LakeHuron R Documentation   Level of Lake Huron 1875–1972   Description  
Annual measurements of the level, in feet, of Lake Huron 1875–1972.    Usage   LakeHuron   Format  
A time series of length 98.    Source  
Brockwell, P. J. and Davis, R. A. (1991).  Time Series and Forecasting Methods . Second edition. Springer, New York. Series A, page 555.   
Brockwell, P. J. and Davis, R. A. (1996).  Introduction to Time Series and Forecasting . Springer, New York. Sections 5.1 and 7.6."
"datasets-lh","datasets","lh","Luteinizing Hormone in Blood Samples",48,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/lh.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/lh.html","lh R Documentation    Luteinizing Hormone in Blood Samples    Description  
A regular time series giving the luteinizing hormone in blood samples at 10 mins intervals from a human female, 48 samples.    Usage   lh   Source  
P.J. Diggle (1990)  Time Series: A Biostatistical Introduction.  Oxford, table A.1, series 3"
"datasets-LifeCycleSavings","datasets","LifeCycleSavings","Intercountry Life-Cycle Savings Data",50,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/LifeCycleSavings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/LifeCycleSavings.html","LifeCycleSavings R Documentation   Intercountry Life-Cycle Savings Data   Description  
Data on the savings ratio 1960–1970.    Usage   LifeCycleSavings   Format  
A data frame with 50 observations on 5 variables.   
 [,1] sr numeric aggregate personal savings
 [,2] pop15 numeric % of population under 15
 [,3] pop75 numeric % of population over 75
 [,4] dpi numeric real per-capita disposable income
 [,5] ddpi numeric % growth rate of dpi    Details  
Under the life-cycle savings hypothesis as developed by Franco Modigliani, the savings ratio (aggregate personal saving divided by disposable income) is explained by per-capita disposable income, the percentage rate of change in per-capita disposable income, and two demographic variables: the percentage of population less than 15 years old and the percentage of the population over 75 years old. The data are averaged over the decade 1960–1970 to remove the business cycle or other short-term fluctuations.    Source  
The data were obtained from Belsley, Kuh and Welsch (1980). They in turn obtained the data from Sterling (1977).    References  
Sterling, Arnie (1977) Unpublished BS Thesis. Massachusetts Institute of Technology.   
Belsley, D. A., Kuh. E. and Welsch, R. E. (1980)  Regression Diagnostics . New York: Wiley.    Examples    require(stats); require(graphics) pairs(LifeCycleSavings, panel = panel.smooth, main = ""LifeCycleSavings data"") fm1 <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings) summary(fm1)"
"datasets-Loblolly","datasets","Loblolly","Growth of Loblolly pine trees",84,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Loblolly.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Loblolly.html","Loblolly R Documentation   Growth of Loblolly pine trees   Description  
The Loblolly data frame has 84 rows and 3 columns of records of the growth of Loblolly pine trees.    Usage   Loblolly   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    height  
a numeric vector of tree heights (ft).    age  
a numeric vector of tree ages (yr).    Seed  
an ordered factor indicating the seed source for the tree. The ordering is according to increasing maximum height.      Details  
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Kung, F. H. (1986), Fitting logistic growth curve with predetermined carrying capacity, in Proceedings of the Statistical Computing Section, American Statistical Association , 340–343.   
Pinheiro, J. C. and Bates, D. M. (2000)  Mixed-effects Models in S and S-PLUS , Springer.    Examples    require(stats); require(graphics) plot(height ~ age, data = Loblolly, subset = Seed == 329, xlab = ""Tree age (yr)"", las = 1, ylab = ""Tree height (ft)"", main = ""Loblolly data and fitted curve (Seed 329 only)"") fm1 <- nls(height ~ SSasymp(age, Asym, R0, lrc), data = Loblolly, subset = Seed == 329) age <- seq(0, 30, length.out = 101) lines(age, predict(fm1, list(age = age)))"
"datasets-longley","datasets","longley","Longley's Economic Regression Data",16,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/longley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/longley.html","longley R Documentation   Longley's Economic Regression Data   Description  
A macroeconomic data set which provides a well-known example for a highly collinear regression.    Usage   longley   Format  
A data frame with 7 economical variables, observed yearly from 1947 to 1962 ( n=16 ).    GNP.deflator
GNP implicit price deflator ( 1954=100 )   GNP
Gross National Product.   Unemployed
number of unemployed.   Armed.Forces
number of people in the armed forces.   Population
‘noninstitutionalized’ population  ≥ 14 years of age.   Year
the year (time).   Employed
number of people employed.    
The regression lm(Employed ~ .) is known to be highly collinear.    Source  
J. W. Longley (1967) An appraisal of least-squares programs from the point of view of the user.  Journal of the American Statistical Association 62 , 819–841.    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole.    Examples    require(stats); require(graphics) ## give the data set in the form it is used in S-PLUS: longley.x <- data.matrix(longley[, 1:6]) longley.y <- longley[, ""Employed""] pairs(longley, main = ""longley data"") summary(fm1 <- lm(Employed ~ ., data = longley)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0), mar = c(4.1, 4.1, 2.1, 1.1)) plot(fm1) par(opar)"
"datasets-lynx","datasets","lynx","Annual Canadian Lynx trappings 1821-1934",114,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/lynx.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/lynx.html","lynx R Documentation   Annual Canadian Lynx trappings 1821–1934   Description  
Annual numbers of lynx trappings for 1821–1934 in Canada. Taken from Brockwell & Davis (1991), this appears to be the series considered by Campbell & Walker (1977).    Usage   lynx   Source  
Brockwell, P. J. and Davis, R. A. (1991).  Time Series and Forecasting Methods . Second edition. Springer. Series G (page 557).    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988).  The New S Language . Wadsworth & Brooks/Cole.   
Campbell, M. J. and Walker, A. M. (1977). A Survey of statistical work on the Mackenzie River series of annual Canadian lynx trappings for the years 1821–1934 and a new analysis.  Journal of the Royal Statistical Society series A , 140 , 411–431. doi: 10.2307/2345277 ."
"datasets-morley","datasets","morley","Michelson Speed of Light Data",100,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/morley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/morley.html","morley R Documentation   Michelson Speed of Light Data   Description  
A classical data of Michelson (but not this one with Morley) on measurements done in 1879 on the speed of light. The data consists of five experiments, each consisting of 20 consecutive ‘runs’. The response is the speed of light measurement, suitably coded (km/sec, with 299000 subtracted).    Usage    morley    Format  
A data frame with 100 observations on the following 3 variables.    Expt
The experiment number, from 1 to 5.   Run
The run number within each experiment.   Speed
Speed-of-light measurement.     Details  
The data is here viewed as a randomized block experiment with ‘experiment’ and ‘run’ as the factors. ‘run’ may also be considered a quantitative variate to account for linear (or polynomial) changes in the measurement over the course of a single experiment.    Note  
This is the same dataset as michelson in package  MASS .    Source  
A. J. Weekes (1986)  A Genstat Primer . London: Edward Arnold.   
S. M. Stigler (1977) Do robust estimators work with real data?  Annals of Statistics 5 , 1055–1098. (See Table 6.)   
A. A. Michelson (1882) Experimental determination of the velocity of light made at the United States Naval Academy, Annapolis.  Astronomic Papers 1 135–8. U.S. Nautical Almanac Office. (See Table 24.)    Examples    require(stats); require(graphics) michelson <- transform(morley, Expt = factor(Expt), Run = factor(Run)) xtabs(~ Expt + Run, data = michelson) # 5 x 20 balanced (two-way) plot(Speed ~ Expt, data = michelson, main = ""Speed of Light Data"", xlab = ""Experiment No."") fm <- aov(Speed ~ Run + Expt, data = michelson) summary(fm) fm0 <- update(fm, . ~ . - Run) anova(fm0, fm)"
"datasets-mtcars","datasets","mtcars","Motor Trend Car Road Tests",32,11,2,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/mtcars.html","mtcars R Documentation   Motor Trend Car Road Tests   Description  
The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).    Usage   mtcars   Format  
A data frame with 32 observations on 11 (numeric) variables.   
 [, 1] mpg Miles/(US) gallon
 [, 2] cyl Number of cylinders
 [, 3] disp Displacement (cu.in.)
 [, 4] hp Gross horsepower
 [, 5] drat Rear axle ratio
 [, 6] wt Weight (1000 lbs)
 [, 7] qsec 1/4 mile time
 [, 8] vs Engine (0 = V-shaped, 1 = straight)
 [, 9] am Transmission (0 = automatic, 1 = manual)
 [,10] gear Number of forward gears
 [,11] carb Number of carburetors    Note  
Henderson and Velleman (1981) comment in a footnote to Table 1: ‘Hocking [original transcriber]'s noncrucial coding of the Mazda's rotary engine as a straight six-cylinder engine and the Porsche's flat engine as a V engine, as well as the inclusion of the diesel Mercedes 240D, have been retained to enable direct comparisons to be made with previous analyses.’    Source  
Henderson and Velleman (1981), Building multiple regression models interactively.  Biometrics , 37 , 391–411.    Examples    require(graphics) pairs(mtcars, main = ""mtcars data"", gap = 1/4) coplot(mpg ~ disp | as.factor(cyl), data = mtcars, panel = panel.smooth, rows = 1) ## possibly more meaningful, e.g., for summary() or bivariate plots: mtcars2 <- within(mtcars, { vs <- factor(vs, labels = c(""V"", ""S"")) am <- factor(am, labels = c(""automatic"", ""manual"")) cyl <- ordered(cyl) gear <- ordered(gear) carb <- ordered(carb) }) summary(mtcars2)"
"datasets-nhtemp","datasets","nhtemp","Average Yearly Temperatures in New Haven",60,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/nhtemp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/nhtemp.html","nhtemp R Documentation   Average Yearly Temperatures in New Haven   Description  
The mean annual temperature in degrees Fahrenheit in New Haven, Connecticut, from 1912 to 1971.    Usage   nhtemp   Format  
A time series of 60 observations.   Source  
Vaux, J. E. and Brinker, N. B. (1972)  Cycles , 1972 , 117–121.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(stats); require(graphics) plot(nhtemp, main = ""nhtemp data"", ylab = ""Mean annual temperature in New Haven, CT (deg. F)"")"
"datasets-Nile","datasets","Nile","Flow of the River Nile",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Nile.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Nile.html","Nile R Documentation   Flow of the River Nile   Description  
Measurements of the annual flow of the river Nile at Aswan (formerly  Assuan ), 1871–1970, in 10^8 m^3 , “with apparent changepoint near 1898” (Cobb(1978), Table 1, p.249).    Usage   Nile   Format  
A time series of length 100.    Source  
Durbin, J. and Koopman, S. J. (2001).  Time Series Analysis by State Space Methods . Oxford University Press.  http://www.ssfpack.com/DKbook.html     References  
Balke, N. S. (1993). Detecting level shifts in time series.  Journal of Business and Economic Statistics , 11 , 81–92. doi: 10.2307/1391308 .   
Cobb, G. W. (1978). The problem of the Nile: conditional solution to a change-point problem.  Biometrika 65 , 243–51. doi: 10.2307/2335202 .    Examples    require(stats); require(graphics) par(mfrow = c(2, 2)) plot(Nile) acf(Nile) pacf(Nile) ar(Nile) # selects order 2 cpgram(ar(Nile)$resid) par(mfrow = c(1, 1)) arima(Nile, c(2, 0, 0)) ## Now consider missing values, following Durbin & Koopman NileNA <- Nile NileNA[c(21:40, 61:80)] <- NA arima(NileNA, c(2, 0, 0)) plot(NileNA) pred <- predict(arima(window(NileNA, 1871, 1890), c(2, 0, 0)), n.ahead = 20) lines(pred$pred, lty = 3, col = ""red"") lines(pred$pred + 2*pred$se, lty = 2, col = ""blue"") lines(pred$pred - 2*pred$se, lty = 2, col = ""blue"") pred <- predict(arima(window(NileNA, 1871, 1930), c(2, 0, 0)), n.ahead = 20) lines(pred$pred, lty = 3, col = ""red"") lines(pred$pred + 2*pred$se, lty = 2, col = ""blue"") lines(pred$pred - 2*pred$se, lty = 2, col = ""blue"") ## Structural time series models par(mfrow = c(3, 1)) plot(Nile) ## local level model (fit <- StructTS(Nile, type = ""level"")) lines(fitted(fit), lty = 2) # contemporaneous smoothing lines(tsSmooth(fit), lty = 2, col = 4) # fixed-interval smoothing plot(residuals(fit)); abline(h = 0, lty = 3) ## local trend model (fit2 <- StructTS(Nile, type = ""trend"")) ## constant trend fitted pred <- predict(fit, n.ahead = 30) ## with 50% confidence interval ts.plot(Nile, pred$pred, pred$pred + 0.67*pred$se, pred$pred -0.67*pred$se) ## Now consider missing values plot(NileNA) (fit3 <- StructTS(NileNA, type = ""level"")) lines(fitted(fit3), lty = 2) lines(tsSmooth(fit3), lty = 3) plot(residuals(fit3)); abline(h = 0, lty = 3)"
"datasets-nottem","datasets","nottem","Average Monthly Temperatures at Nottingham, 1920-1939",240,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/nottem.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/nottem.html","nottem R Documentation    Average Monthly Temperatures at Nottingham, 1920–1939    Description  
A time series object containing average air temperatures at Nottingham Castle in degrees Fahrenheit for 20 years.    Usage   nottem   Source  
Anderson, O. D. (1976)  Time Series Analysis and Forecasting: The Box-Jenkins approach.  Butterworths. Series R.    Examples    require(stats); require(graphics) nott <- window(nottem, end = c(1936,12)) fit <- arima(nott, order = c(1,0,0), list(order = c(2,1,0), period = 12)) nott.fore <- predict(fit, n.ahead = 36) ts.plot(nott, nott.fore$pred, nott.fore$pred+2*nott.fore$se, nott.fore$pred-2*nott.fore$se, gpars = list(col = c(1,1,4,4)))"
"datasets-npk","datasets","npk","Classical N, P, K Factorial Experiment",24,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/npk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/npk.html","npk R Documentation    Classical N, P, K Factorial Experiment    Description  
A classical N, P, K (nitrogen, phosphate, potassium) factorial experiment on the growth of peas conducted on 6 blocks. Each half of a fractional factorial design confounding the NPK interaction was used on 3 of the plots.    Usage    npk    Format  
The npk data frame has 24 rows and 5 columns:    block  
which block (label 1 to 6).    N  
indicator (0/1) for the application of nitrogen.    P  
indicator (0/1) for the application of phosphate.    K  
indicator (0/1) for the application of potassium.    yield  
Yield of peas, in pounds/plot (the plots were (1/70) acre).      Source  
Imperial College, London, M.Sc. exercise sheet.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    options(contrasts = c(""contr.sum"", ""contr.poly"")) npk.aov <- aov(yield ~ block + N*P*K, npk) npk.aov summary(npk.aov) coef(npk.aov) options(contrasts = c(""contr.treatment"", ""contr.poly"")) npk.aov1 <- aov(yield ~ block + N + K, data = npk) summary.lm(npk.aov1) se.contrast(npk.aov1, list(N==""0"", N==""1""), data = npk) model.tables(npk.aov1, type = ""means"", se = TRUE)"
"datasets-occupationalStatus","datasets","occupationalStatus","Occupational Status of Fathers and their Sons",64,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/occupationalStatus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/occupationalStatus.html","occupationalStatus R Documentation   Occupational Status of Fathers and their Sons   Description  
Cross-classification of a sample of British males according to each subject's occupational status and his father's occupational status.    Usage   occupationalStatus   Format  
A table of counts, with classifying factors  origin (father's occupational status; levels 1:8 ) and destination (son's occupational status; levels 1:8 ).    Source  
Goodman, L. A. (1979) Simple Models for the Analysis of Association in Cross-Classifications having Ordered Categories.  J. Am. Stat. Assoc. , 74 (367), 537–552.   
The data set has been in package gnm and been provided by the package authors.    Examples    require(stats); require(graphics) plot(occupationalStatus) ## Fit a uniform association model separating diagonal effects Diag <- as.factor(diag(1:8)) Rscore <- scale(as.numeric(row(occupationalStatus)), scale = FALSE) Cscore <- scale(as.numeric(col(occupationalStatus)), scale = FALSE) modUnif <- glm(Freq ~ origin + destination + Diag + Rscore:Cscore, family = poisson, data = occupationalStatus) summary(modUnif) plot(modUnif) # 4 plots, with warning about h_ii ~= 1"
"datasets-Orange","datasets","Orange","Growth of Orange Trees",35,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Orange.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Orange.html","Orange R Documentation   Growth of Orange Trees   Description  
The Orange data frame has 35 rows and 3 columns of records of the growth of orange trees.    Usage   Orange   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    Tree  
an ordered factor indicating the tree on which the measurement is made. The ordering is according to increasing maximum diameter.    age  
a numeric vector giving the age of the tree (days since 1968/12/31)    circumference  
a numeric vector of trunk circumferences (mm). This is probably “circumference at breast height”, a standard measurement in forestry.      Details  
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Draper, N. R. and Smith, H. (1998), Applied Regression Analysis (3rd ed) , Wiley (exercise 24.N).   
Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS , Springer.    Examples    require(stats); require(graphics) coplot(circumference ~ age | Tree, data = Orange, show.given = FALSE) fm1 <- nls(circumference ~ SSlogis(age, Asym, xmid, scal), data = Orange, subset = Tree == 3) plot(circumference ~ age, data = Orange, subset = Tree == 3, xlab = ""Tree age (days since 1968/12/31)"", ylab = ""Tree circumference (mm)"", las = 1, main = ""Orange tree data and fitted model (Tree 3 only)"") age <- seq(0, 1600, length.out = 101) lines(age, predict(fm1, list(age = age)))"
"datasets-OrchardSprays","datasets","OrchardSprays","Potency of Orchard Sprays",64,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/OrchardSprays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/OrchardSprays.html","OrchardSprays R Documentation   Potency of Orchard Sprays   Description  
An experiment was conducted to assess the potency of various constituents of orchard sprays in repelling honeybees, using a Latin square design.    Usage   OrchardSprays   Format  
A data frame with 64 observations on 4 variables.   
 [,1] rowpos numeric Row of the design
 [,2] colpos numeric Column of the design
 [,3] treatment factor Treatment level
 [,4] decrease numeric Response    Details  
Individual cells of dry comb were filled with measured amounts of lime sulphur emulsion in sucrose solution. Seven different concentrations of lime sulphur ranging from a concentration of 1/100 to 1/1,562,500 in successive factors of 1/5 were used as well as a solution containing no lime sulphur.   
The responses for the different solutions were obtained by releasing 100 bees into the chamber for two hours, and then measuring the decrease in volume of the solutions in the various cells.   
An 8 x 8 Latin square design was used and the treatments were coded as follows:   
 A highest level of lime sulphur
 B next highest level of lime sulphur
 .
 .
 .
 G lowest level of lime sulphur
 H no lime sulphur    Source  
Finney, D. J. (1947)  Probit Analysis . Cambridge.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(graphics) pairs(OrchardSprays, main = ""OrchardSprays data"")"
"datasets-PlantGrowth","datasets","PlantGrowth","Results from an Experiment on Plant Growth",30,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/PlantGrowth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/PlantGrowth.html","PlantGrowth R Documentation   Results from an Experiment on Plant Growth   Description  
Results from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment conditions.    Usage   PlantGrowth   Format  
A data frame of 30 cases on 2 variables.   
 [, 1] weight numeric
 [, 2] group factor   
The levels of group are ‘ctrl’, ‘trt1’, and ‘trt2’.    Source  
Dobson, A. J. (1983)  An Introduction to Statistical Modelling . London: Chapman and Hall.    Examples    ## One factor ANOVA example from Dobson's book, cf. Table 7.4: require(stats); require(graphics) boxplot(weight ~ group, data = PlantGrowth, main = ""PlantGrowth data"", ylab = ""Dried weight of plants"", col = ""lightgray"", notch = TRUE, varwidth = TRUE) anova(lm(weight ~ group, data = PlantGrowth))"
"datasets-precip","datasets","precip","Annual Precipitation in US Cities",70,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/precip.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/precip.html","precip R Documentation   Annual Precipitation in US Cities   Description  
The average amount of precipitation (rainfall) in inches for each of 70 United States (and Puerto Rico) cities.    Usage   precip   Format  
A named vector of length 70.    Note  
The dataset version up to Nov.16, 2016 had a typo in ""Cincinnati"" 's name. The examples show how to recreate that version.    Source  
Statistical Abstracts of the United States, 1975.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(graphics) dotchart(precip[order(precip)], main = ""precip data"") title(sub = ""Average annual precipitation (in.)"") ## Old (""wrong"") version of dataset (just name change): precip.O <- local({ p <- precip; names(p)[names(p) == ""Cincinnati""] <- ""Cincinati"" ; p }) stopifnot(all(precip == precip.O), match(""Cincinnati"", names(precip)) == 46, identical(names(precip)[-46], names(precip.O)[-46]))"
"datasets-presidents","datasets","presidents","Quarterly Approval Ratings of US Presidents",120,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/presidents.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/presidents.html","presidents R Documentation   Quarterly Approval Ratings of US Presidents   Description  
The (approximately) quarterly approval rating for the President of the United States from the first quarter of 1945 to the last quarter of 1974.    Usage   presidents   Format  
A time series of 120 values.    Details  
The data are actually a fudged version of the approval ratings. See McNeil's book for details.    Source  
The Gallup Organisation.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(stats); require(graphics) plot(presidents, las = 1, ylab = ""Approval rating (%)"", main = ""presidents data"")"
"datasets-pressure","datasets","pressure","Vapor Pressure of Mercury as a Function of Temperature",19,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/pressure.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/pressure.html","pressure R Documentation   Vapor Pressure of Mercury as a Function of Temperature   Description  
Data on the relation between temperature in degrees Celsius and vapor pressure of mercury in millimeters (of mercury).    Usage   pressure   Format  
A data frame with 19 observations on 2 variables.   
 [, 1] temperature numeric temperature (deg C)
 [, 2] pressure numeric pressure (mm)    Source  
Weast, R. C., ed. (1973)  Handbook of Chemistry and Physics . CRC Press.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(graphics) plot(pressure, xlab = ""Temperature (deg C)"", ylab = ""Pressure (mm of Hg)"", main = ""pressure data: Vapor Pressure of Mercury"") plot(pressure, xlab = ""Temperature (deg C)"", log = ""y"", ylab = ""Pressure (mm of Hg)"", main = ""pressure data: Vapor Pressure of Mercury"")"
"datasets-Puromycin","datasets","Puromycin","Reaction Velocity of an Enzymatic Reaction",23,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Puromycin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Puromycin.html","Puromycin R Documentation   Reaction Velocity of an Enzymatic Reaction   Description  
The Puromycin data frame has 23 rows and 3 columns of the reaction velocity versus substrate concentration in an enzymatic reaction involving untreated cells or cells treated with Puromycin.    Usage   Puromycin   Format  
This data frame contains the following columns:    conc  
a numeric vector of substrate concentrations (ppm)    rate  
a numeric vector of instantaneous reaction rates (counts/min/min)    state  
a factor with levels  treated   untreated       Details  
Data on the velocity of an enzymatic reaction were obtained by Treloar (1974). The number of counts per minute of radioactive product from the reaction was measured as a function of substrate concentration in parts per million (ppm) and from these counts the initial rate (or velocity) of the reaction was calculated (counts/min/min). The experiment was conducted once with the enzyme treated with Puromycin, and once with the enzyme untreated.    Source  
Bates, D.M. and Watts, D.G. (1988),  Nonlinear Regression Analysis and Its Applications , Wiley, Appendix A1.3.   
Treloar, M. A. (1974), Effects of Puromycin on Galactosyltransferase in Golgi Membranes , M.Sc. Thesis, U. of Toronto.    See Also  
SSmicmen for other models fitted to this dataset.    Examples    require(stats); require(graphics) plot(rate ~ conc, data = Puromycin, las = 1, xlab = ""Substrate concentration (ppm)"", ylab = ""Reaction velocity (counts/min/min)"", pch = as.integer(Puromycin$state), col = as.integer(Puromycin$state), main = ""Puromycin data and fitted Michaelis-Menten curves"") ## simplest form of fitting the Michaelis-Menten model to these data fm1 <- nls(rate ~ Vm * conc/(K + conc), data = Puromycin, subset = state == ""treated"", start = c(Vm = 200, K = 0.05)) fm2 <- nls(rate ~ Vm * conc/(K + conc), data = Puromycin, subset = state == ""untreated"", start = c(Vm = 160, K = 0.05)) summary(fm1) summary(fm2) ## add fitted lines to the plot conc <- seq(0, 1.2, length.out = 101) lines(conc, predict(fm1, list(conc = conc)), lty = 1, col = 1) lines(conc, predict(fm2, list(conc = conc)), lty = 2, col = 2) legend(0.8, 120, levels(Puromycin$state), col = 1:2, lty = 1:2, pch = 1:2) ## using partial linearity fm3 <- nls(rate ~ conc/(K + conc), data = Puromycin, subset = state == ""treated"", start = c(K = 0.05), algorithm = ""plinear"")"
"datasets-quakes","datasets","quakes","Locations of Earthquakes off Fiji",1000,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/quakes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/quakes.html","quakes R Documentation   Locations of Earthquakes off Fiji   Description  
The data set give the locations of 1000 seismic events of MB > 4.0. The events occurred in a cube near Fiji since 1964.    Usage   quakes   Format  
A data frame with 1000 observations on 5 variables.   
 [,1] lat numeric Latitude of event
 [,2] long numeric Longitude
 [,3] depth numeric Depth (km)
 [,4] mag numeric Richter Magnitude
 [,5] stations numeric Number of stations reporting    Details  
There are two clear planes of seismic activity. One is a major plate junction; the other is the Tonga trench off New Zealand. These data constitute a subsample from a larger dataset of containing 5000 observations.    Source  
This is one of the Harvard PRIM-H project data sets. They in turn obtained it from Dr. John Woodhouse, Dept. of Geophysics, Harvard University.    Examples    require(graphics) pairs(quakes, main = ""Fiji Earthquakes, N = 1000"", cex.main = 1.2, pch = ""."")"
"datasets-randu","datasets","randu","Random Numbers from Congruential Generator RANDU",400,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/randu.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/randu.html","randu R Documentation   Random Numbers from Congruential Generator RANDU   Description  
400 triples of successive random numbers were taken from the VAX FORTRAN function RANDU running under VMS 1.5.    Usage   randu   Format  
A data frame with 400 observations on 3 variables named x ,  y and z which give the first, second and third random number in the triple.    Details  
In three dimensional displays it is evident that the triples fall on 15 parallel planes in 3-space. This can be shown theoretically to be true for all triples from the RANDU generator.   
These particular 400 triples start 5 apart in the sequence, that is they are ((U[5i+1], U[5i+2], U[5i+3]), i= 0, ..., 399), and they are rounded to 6 decimal places.   
Under VMS versions 2.0 and higher, this problem has been fixed.    Source  
David Donoho    Examples    ## We could re-generate the dataset by the following R code seed <- as.double(1) RANDU <- function() { seed <<- ((2^16 + 3) * seed) %% (2^31) seed/(2^31) } for(i in 1:400) { U <- c(RANDU(), RANDU(), RANDU(), RANDU(), RANDU()) print(round(U[1:3], 6)) }"
"datasets-rivers","datasets","rivers","Lengths of Major North American Rivers",141,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/rivers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/rivers.html","rivers R Documentation   Lengths of Major North American Rivers   Description  
This data set gives the lengths (in miles) of 141 “major” rivers in North America, as compiled by the US Geological Survey.    Usage   rivers   Format  
A vector containing 141 observations.   Source  
World Almanac and Book of Facts, 1975, page 406.   References  
McNeil, D. R. (1977) Interactive Data Analysis . New York: Wiley."
"datasets-rock","datasets","rock","Measurements on Petroleum Rock Samples",48,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/rock.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/rock.html","rock R Documentation   Measurements on Petroleum Rock Samples   Description  
Measurements on 48 rock samples from a petroleum reservoir.   Usage   rock   Format  
A data frame with 48 rows and 4 numeric columns.   
 [,1] area area of pores space, in pixels out of 256 by 256
 [,2] peri perimeter in pixels
 [,3] shape perimeter/sqrt(area)
 [,4] perm permeability in milli-Darcies    Details  
Twelve core samples from petroleum reservoirs were sampled by 4 cross-sections. Each core sample was measured for permeability, and each cross-section has total area of pores, total perimeter of pores, and shape.    Source  
Data from BP Research, image analysis by Ronit Katz, U. Oxford."
"datasets-Seatbelts","datasets","Seatbelts","Road Casualties in Great Britain 1969-84",192,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Seatbelts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Seatbelts.html","UKDriverDeaths R Documentation    Road Casualties in Great Britain 1969–84    Description  
UKDriverDeaths is a time series giving the monthly totals of car drivers in Great Britain killed or seriously injured Jan 1969 to Dec 1984. Compulsory wearing of seat belts was introduced on 31 Jan 1983.   
Seatbelts is more information on the same problem.    Usage    UKDriverDeaths Seatbelts    Format  
Seatbelts is a multiple time series, with columns    DriversKilled
car drivers killed.   drivers
same as UKDriverDeaths .   front
front-seat passengers killed or seriously injured.   rear
rear-seat passengers killed or seriously injured.   kms
distance driven.   PetrolPrice
petrol price.   VanKilled
number of van (‘light goods vehicle’) drivers.   law
0/1: was the law in effect that month?     Source  
Harvey, A.C. (1989).  Forecasting, Structural Time Series Models and the Kalman Filter . Cambridge University Press, pp. 519–523.   
Durbin, J. and Koopman, S. J. (2001).  Time Series Analysis by State Space Methods . Oxford University Press.  http://www.ssfpack.com/dkbook/     References  
Harvey, A. C. and Durbin, J. (1986). The effects of seat belt legislation on British road casualties: A case study in structural time series modelling.  Journal of the Royal Statistical Society series A, 149 , 187–227. doi: 10.2307/2981553 .    Examples    require(stats); require(graphics) ## work with pre-seatbelt period to identify a model, use logs work <- window(log10(UKDriverDeaths), end = 1982+11/12) par(mfrow = c(3, 1)) plot(work); acf(work); pacf(work) par(mfrow = c(1, 1)) (fit <- arima(work, c(1, 0, 0), seasonal = list(order = c(1, 0, 0)))) z <- predict(fit, n.ahead = 24) ts.plot(log10(UKDriverDeaths), z$pred, z$pred+2*z$se, z$pred-2*z$se, lty = c(1, 3, 2, 2), col = c(""black"", ""red"", ""blue"", ""blue"")) ## now see the effect of the explanatory variables X <- Seatbelts[, c(""kms"", ""PetrolPrice"", ""law"")] X[, 1] <- log10(X[, 1]) - 4 arima(log10(Seatbelts[, ""drivers""]), c(1, 0, 0), seasonal = list(order = c(1, 0, 0)), xreg = X)"
"datasets-sleep","datasets","sleep","Student's Sleep Data",20,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sleep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/sleep.html","sleep R Documentation   Student's Sleep Data   Description  
Data which show the effect of two soporific drugs (increase in hours of sleep compared to control) on 10 patients.    Usage   sleep   Format  
A data frame with 20 observations on 3 variables.   
 [, 1] extra numeric increase in hours of sleep
 [, 2] group factor drug given
 [, 3] ID factor patient ID    Details  
The group variable name may be misleading about the data: They represent measurements on 10 persons, not in groups.    Source  
Cushny, A. R. and Peebles, A. R. (1905) The action of optical isomers: II hyoscines.  The Journal of Physiology 32 , 501–510.   
Student (1908) The probable error of the mean.  Biometrika , 6 , 20.    References  
Scheffé, Henry (1959)  The Analysis of Variance . New York, NY: Wiley.    Examples    require(stats) ## Student's paired t-test with(sleep, t.test(extra[group == 1], extra[group == 2], paired = TRUE)) ## The sleep *prolongations* sleep1 <- with(sleep, extra[group == 2] - extra[group == 1]) summary(sleep1) stripchart(sleep1, method = ""stack"", xlab = ""hours"", main = ""Sleep prolongation (n = 10)"") boxplot(sleep1, horizontal = TRUE, add = TRUE, at = .6, pars = list(boxwex = 0.5, staplewex = 0.25))"
"datasets-stackloss","datasets","stackloss","Brownlee's Stack Loss Plant Data",21,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/stackloss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/stackloss.html","stackloss R Documentation   Brownlee's Stack Loss Plant Data   Description  
Operational data of a plant for the oxidation of ammonia to nitric acid.    Usage    stackloss stack.x stack.loss    Format  
stackloss is a data frame with 21 observations on 4 variables.   
 [,1] Air Flow  Flow of cooling air
 [,2] Water Temp Cooling Water Inlet Temperature
 [,3]  Acid Conc. Concentration of acid [per 1000, minus 500]
 [,4]  stack.loss Stack loss
   
For compatibility with S-PLUS, the data sets stack.x , a matrix with the first three (independent) variables of the data frame, and  stack.loss , the numeric vector giving the fourth (dependent) variable, are provided as well.    Details  
“Obtained from 21 days of operation of a plant for the oxidation of ammonia (NH 3 ) to nitric acid (HNO 3 ). The nitric oxides produced are absorbed in a countercurrent absorption tower”. (Brownlee, cited by Dodge, slightly reformatted by MM.)   
Air Flow represents the rate of operation of the plant.  Water Temp is the temperature of cooling water circulated through coils in the absorption tower.  Acid Conc. is the concentration of the acid circulating, minus 50, times 10: that is, 89 corresponds to 58.9 per cent acid.  stack.loss (the dependent variable) is 10 times the percentage of the ingoing ammonia to the plant that escapes from the absorption column unabsorbed; that is, an (inverse) measure of the over-all efficiency of the plant.    Source  
Brownlee, K. A. (1960, 2nd ed. 1965)  Statistical Theory and Methodology in Science and Engineering . New York: Wiley. pp. 491–500.    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole.   
Dodge, Y. (1996) The guinea pig of multiple regression. In:  Robust Statistics, Data Analysis, and Computer Intensive Methods; In Honor of Peter Huber's 60th Birthday , 1996,  Lecture Notes in Statistics 109 , Springer-Verlag, New York.    Examples    require(stats) summary(lm.stack <- lm(stack.loss ~ stack.x))"
"datasets-sunspot.month","datasets","sunspot.month","Monthly Sunspot Data, from 1749 to ""Present""",3177,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sunspot.month.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/sunspot.month.html","sunspot.month R Documentation   Monthly Sunspot Data, from 1749 to ""Present""   Description  
Monthly numbers of sunspots, as from the World Data Center, aka SIDC. This is the version of the data that will occasionally be updated when new counts become available.    Usage    sunspot.month    Format  
The univariate time series sunspot.year and  sunspot.month contain 289 and 2988 observations, respectively. The objects are of class ""ts"" .    Author(s)  
R    Source  
WDC-SILSO, Solar Influences Data Analysis Center (SIDC), Royal Observatory of Belgium, Av. Circulaire, 3, B-1180 BRUSSELS Currently at http://www.sidc.be/silso/datafiles     See Also  
sunspot.month is a longer version of sunspots ; the latter runs until 1983 and is kept fixed (for reproducibility as example dataset).    Examples    require(stats); require(graphics) ## Compare the monthly series plot (sunspot.month, main=""sunspot.month & sunspots [package'datasets']"", col=2) lines(sunspots) # -> faint differences where they overlap ## Now look at the difference : all(tsp(sunspots) [c(1,3)] == tsp(sunspot.month)[c(1,3)]) ## Start & Periodicity are the same n1 <- length(sunspots) table(eq <- sunspots == sunspot.month[1:n1]) #> 132 are different ! i <- which(!eq) rug(time(eq)[i]) s1 <- sunspots[i] ; s2 <- sunspot.month[i] cbind(i = i, time = time(sunspots)[i], sunspots = s1, ss.month = s2, perc.diff = round(100*2*abs(s1-s2)/(s1+s2), 1)) ## How to recreate the ""old"" sunspot.month (R <= 3.0.3): .sunspot.diff <- cbind( i = c(1202L, 1256L, 1258L, 1301L, 1407L, 1429L, 1452L, 1455L, 1663L, 2151L, 2329L, 2498L, 2594L, 2694L, 2819L), res10 = c(1L, 1L, 1L, -1L, -1L, -1L, 1L, -1L, 1L, 1L, 1L, 1L, 1L, 20L, 1L)) ssm0 <- sunspot.month[1:2988] with(as.data.frame(.sunspot.diff), ssm0[i] <<- ssm0[i] - res10/10) sunspot.month.0 <- ts(ssm0, start = 1749, frequency = 12)"
"datasets-sunspot.year","datasets","sunspot.year","Yearly Sunspot Data, 1700-1988",289,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sunspot.year.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/sunspot.year.html","sunspot.year R Documentation   Yearly Sunspot Data, 1700–1988   Description  
Yearly numbers of sunspots from 1700 to 1988 (rounded to one digit).   
Note that monthly numbers are available as  sunspot.month , though starting slightly later.    Usage    sunspot.year    Format  
The univariate time series sunspot.year contains 289 observations, and is of class ""ts"" .    Source  
H. Tong (1996)  Non-Linear Time Series . Clarendon Press, Oxford, p. 471.    See Also  
For monthly sunspot numbers, see sunspot.month  and sunspots .   
Regularly updated yearly sunspot numbers are available from WDC-SILSO, Royal Observatory of Belgium, at  http://www.sidc.be/silso/datafiles     Examples    utils::str(sm <- sunspots)# the monthly version we keep unchanged utils::str(sy <- sunspot.year) ## The common time interval (t1 <- c(max(start(sm), start(sy)), 1)) # Jan 1749 (t2 <- c(min( end(sm)[1],end(sy)[1]), 12)) # Dec 1983 s.m <- window(sm, start=t1, end=t2) s.y <- window(sy, start=t1, end=t2[1]) # {irrelevant warning} stopifnot(length(s.y) * 12 == length(s.m), ## The yearly series *is* close to the averages of the monthly one: all.equal(s.y, aggregate(s.m, FUN = mean), tolerance = 0.0020)) ## NOTE: Strangely, correctly weighting the number of days per month ## (using 28.25 for February) is *not* closer than the simple mean: ndays <- c(31, 28.25, rep(c(31,30, 31,30, 31), 2)) all.equal(s.y, aggregate(s.m, FUN = mean)) # 0.0013 all.equal(s.y, aggregate(s.m, FUN = weighted.mean, w = ndays)) # 0.0017"
"datasets-sunspots","datasets","sunspots","Monthly Sunspot Numbers, 1749-1983",2820,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sunspots.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/sunspots.html","sunspots R Documentation   Monthly Sunspot Numbers, 1749–1983   Description  
Monthly mean relative sunspot numbers from 1749 to 1983. Collected at Swiss Federal Observatory, Zurich until 1960, then Tokyo Astronomical Observatory.    Usage   sunspots   Format  
A time series of monthly data from 1749 to 1983.    Source  
Andrews, D. F. and Herzberg, A. M. (1985)  Data: A Collection of Problems from Many Fields for the Student and Research Worker . New York: Springer-Verlag.    See Also  
sunspot.month has a longer (and a bit different) series,  sunspot.year is a much shorter one. See there for getting more current sunspot numbers.    Examples    require(graphics) plot(sunspots, main = ""sunspots data"", xlab = ""Year"", ylab = ""Monthly sunspot numbers"")"
"datasets-swiss","datasets","swiss","Swiss Fertility and Socioeconomic Indicators (1888) Data",47,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/swiss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/swiss.html","swiss R Documentation   Swiss Fertility and Socioeconomic Indicators (1888) Data   Description  
Standardized fertility measure and socio-economic indicators for each of 47 French-speaking provinces of Switzerland at about 1888.    Usage   swiss   Format  
A data frame with 47 observations on 6 variables, each of which is in percent, i.e., in [0, 100] .   
 [,1] Fertility Ig , ‘common standardized fertility measure’
 [,2] Agriculture % of males involved in agriculture as occupation
 [,3] Examination % draftees receiving highest mark on army examination
 [,4] Education % education beyond primary school for draftees.
 [,5] Catholic % ‘catholic’ (as opposed to ‘protestant’).
 [,6] Infant.Mortality live births who live less than 1 year.   
All variables but ‘Fertility’ give proportions of the population.    Details  
(paraphrasing Mosteller and Tukey):   
Switzerland, in 1888, was entering a period known as the  demographic transition ; i.e., its fertility was beginning to fall from the high level typical of underdeveloped countries.   
The data collected are for 47 French-speaking “provinces” at about 1888.   
Here, all variables are scaled to [0, 100] , where in the original, all but ""Catholic"" were scaled to [0, 1] .    Note  
Files for all 182 districts in 1888 and other years have been available at  https://opr.princeton.edu/archive/pefp/switz.aspx .   
They state that variables Examination and Education  are averages for 1887, 1888 and 1889.    Source  
Project “16P5”, pages 549–551 in   
Mosteller, F. and Tukey, J. W. (1977)  Data Analysis and Regression: A Second Course in Statistics . Addison-Wesley, Reading Mass.   
indicating their source as “Data used by permission of Franice van de Walle. Office of Population Research, Princeton University, 1976. Unpublished data assembled under NICHD contract number No 1-HD-O-2077.”    References  
Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)  The New S Language . Wadsworth & Brooks/Cole.    Examples    require(stats); require(graphics) pairs(swiss, panel = panel.smooth, main = ""swiss data"", col = 3 + (swiss$Catholic > 50)) summary(lm(Fertility ~ . , data = swiss))"
"datasets-Theoph","datasets","Theoph","Pharmacokinetics of Theophylline",132,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Theoph.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Theoph.html","Theoph R Documentation   Pharmacokinetics of Theophylline   Description  
The Theoph data frame has 132 rows and 5 columns of data from an experiment on the pharmacokinetics of theophylline.   Usage   Theoph   Format  
An object of class  c(""nfnGroupedData"", ""nfGroupedData"", ""groupedData"", ""data.frame"")  containing the following columns:    Subject  
an ordered factor with levels 1 , ..., 12  identifying the subject on whom the observation was made. The ordering is by increasing maximum concentration of theophylline observed.    Wt  
weight of the subject (kg).    Dose  
dose of theophylline administered orally to the subject (mg/kg).    Time  
time since drug administration when the sample was drawn (hr).    conc  
theophylline concentration in the sample (mg/L).      Details  
Boeckmann, Sheiner and Beal (1994) report data from a study by Dr. Robert Upton of the kinetics of the anti-asthmatic drug theophylline. Twelve subjects were given oral doses of theophylline then serum concentrations were measured at 11 time points over the next 25 hours.   
These data are analyzed in Davidian and Giltinan (1995) and Pinheiro and Bates (2000) using a two-compartment open pharmacokinetic model, for which a self-starting model function, SSfol , is available.   
This dataset was originally part of package nlme , and that has methods (including for [ , as.data.frame , plot and  print ) for its grouped-data classes.    Source  
Boeckmann, A. J., Sheiner, L. B. and Beal, S. L. (1994), NONMEM Users Guide: Part V , NONMEM Project Group, University of California, San Francisco.   
Davidian, M. and Giltinan, D. M. (1995)  Nonlinear Models for Repeated Measurement Data , Chapman & Hall (section 5.5, p. 145 and section 6.6, p. 176)   
Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS , Springer (Appendix A.29)    See Also  
SSfol   Examples    require(stats); require(graphics) coplot(conc ~ Time | Subject, data = Theoph, show.given = FALSE) Theoph.4 <- subset(Theoph, Subject == 4) fm1 <- nls(conc ~ SSfol(Dose, Time, lKe, lKa, lCl), data = Theoph.4) summary(fm1) plot(conc ~ Time, data = Theoph.4, xlab = ""Time since drug administration (hr)"", ylab = ""Theophylline concentration (mg/L)"", main = ""Observed concentrations and fitted model"", sub = ""Theophylline data - Subject 4 only"", las = 1, col = 4) xvals <- seq(0, par(""usr"")[2], length.out = 55) lines(xvals, predict(fm1, newdata = list(Time = xvals)), col = 4)"
"datasets-Titanic","datasets","Titanic","Survival of passengers on the Titanic",32,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/Titanic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/Titanic.html","Titanic R Documentation   Survival of passengers on the Titanic   Description  
This data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner ‘Titanic’, summarized according to economic status (class), sex, age and survival.    Usage   Titanic   Format  
A 4-dimensional array resulting from cross-tabulating 2201 observations on 4 variables. The variables and their levels are as follows:   
 No Name Levels
 1 Class 1st, 2nd, 3rd, Crew
 2 Sex Male, Female
 3 Age Child, Adult
 4 Survived No, Yes    Details  
The sinking of the Titanic is a famous event, and new books are still being published about it. Many well-known facts—from the proportions of first-class passengers to the ‘women and children first’ policy, and the fact that that policy was not entirely successful in saving the women and children in the third class—are reflected in the survival rates for various classes of passenger.   
These data were originally collected by the British Board of Trade in their investigation of the sinking. Note that there is not complete agreement among primary sources as to the exact numbers on board, rescued, or lost.   
Due in particular to the very successful film ‘Titanic’, the last years saw a rise in public interest in the Titanic. Very detailed data about the passengers is now available on the Internet, at sites such as Encyclopedia Titanica  ( https://www.encyclopedia-titanica.org/ ).    Source  
Dawson, Robert J. MacG. (1995), The ‘Unusual Episode’ Data Revisited.  Journal of Statistics Education , 3 . doi: 10.1080/10691898.1995.11910499 .   
The source provides a data set recording class, sex, age, and survival status for each person on board of the Titanic, and is based on data originally collected by the British Board of Trade and reprinted in:   
British Board of Trade (1990),  Report on the Loss of the ‘Titanic’ (S.S.) . British Board of Trade Inquiry Report (reprint). Gloucester, UK: Allan Sutton Publishing.    Examples    require(graphics) mosaicplot(Titanic, main = ""Survival on the Titanic"") ## Higher survival rates in children? apply(Titanic, c(3, 4), sum) ## Higher survival rates in females? apply(Titanic, c(2, 4), sum) ## Use loglm() in package 'MASS' for further analysis ..."
"datasets-ToothGrowth","datasets","ToothGrowth","The Effect of Vitamin C on Tooth Growth in Guinea Pigs",60,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/ToothGrowth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/ToothGrowth.html","ToothGrowth R Documentation   The Effect of Vitamin C on Tooth Growth in Guinea Pigs   Description  
The response is the length of odontoblasts (cells responsible for tooth growth) in 60 guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice or ascorbic acid (a form of vitamin C and coded as VC ).    Usage   ToothGrowth   Format  
A data frame with 60 observations on 3 variables.   
 [,1] len numeric Tooth length
 [,2] supp factor Supplement type (VC or OJ).
 [,3] dose numeric Dose in milligrams/day    Source  
C. I. Bliss (1952).  The Statistics of Bioassay . Academic Press.    References  
McNeil, D. R. (1977).  Interactive Data Analysis . New York: Wiley.   
Crampton, E. W. (1947). The growth of the odontoblast of the incisor teeth as a criterion of vitamin C intake of the guinea pig.  The Journal of Nutrition , 33 (5), 491–504. doi: 10.1093/jn/33.5.491 .    Examples    require(graphics) coplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth, xlab = ""ToothGrowth data: length vs dose, given type of supplement"")"
"datasets-treering","datasets","treering","Yearly Treering Data, -6000-1979",7980,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/treering.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/treering.html","treering R Documentation    Yearly Treering Data, -6000–1979    Description  
Contains normalized tree-ring widths in dimensionless units.    Usage    treering    Format  
A univariate time series with 7981 observations. The object is of class ""ts"" .   
Each tree ring corresponds to one year.    Details  
The data were recorded by Donald A. Graybill, 1980, from Gt Basin Bristlecone Pine 2805M, 3726-11810 in Methuselah Walk, California.    Source  
Time Series Data Library:  https://robjhyndman.com/TSDL/ , series ‘ CA535.DAT ’    References  
For some photos of Methuselah Walk see  https://web.archive.org/web/20110523225828/http://www.ltrr.arizona.edu/~hallman/sitephotos/meth.html"
"datasets-trees","datasets","trees","Diameter, Height and Volume for Black Cherry Trees",31,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/trees.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/trees.html","trees R Documentation   Diameter, Height and Volume for Black Cherry Trees   Description  
This data set provides measurements of the diameter, height and volume of timber in 31 felled black cherry trees. Note that the diameter (in inches) is erroneously labelled Girth in the data. It is measured at 4 ft 6 in above the ground.    Usage   trees   Format  
A data frame with 31 observations on 3 variables.   
  [,1] Girth numeric  Tree diameter (rather than girth, actually) in inches
  [,2] Height numeric  Height in ft
  [,3] Volume numeric  Volume of timber in cubic ft   Source  
Ryan, T. A., Joiner, B. L. and Ryan, B. F. (1976)  The Minitab Student Handbook . Duxbury Press.    References  
Atkinson, A. C. (1985)  Plots, Transformations and Regression . Oxford University Press.    Examples    require(stats); require(graphics) pairs(trees, panel = panel.smooth, main = ""trees data"") plot(Volume ~ Girth, data = trees, log = ""xy"") coplot(log(Volume) ~ log(Girth) | Height, data = trees, panel = panel.smooth) summary(fm1 <- lm(log(Volume) ~ log(Girth), data = trees)) summary(fm2 <- update(fm1, ~ . + log(Height), data = trees)) step(fm2) ## i.e., Volume ~= c * Height * Girth^2 seems reasonable"
"datasets-UCBAdmissions","datasets","UCBAdmissions","Student Admissions at UC Berkeley",24,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/UCBAdmissions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/UCBAdmissions.html","UCBAdmissions R Documentation   Student Admissions at UC Berkeley   Description  
Aggregate data on applicants to graduate school at Berkeley for the six largest departments in 1973 classified by admission and sex.    Usage   UCBAdmissions   Format  
A 3-dimensional array resulting from cross-tabulating 4526 observations on 3 variables. The variables and their levels are as follows:   
 No Name Levels
 1 Admit Admitted, Rejected
 2 Gender Male, Female
 3 Dept A, B, C, D, E, F    Details  
This data set is frequently used for illustrating Simpson's paradox, see Bickel et al (1975). At issue is whether the data show evidence of sex bias in admission practices. There were 2691 male applicants, of whom 1198 (44.5%) were admitted, compared with 1835 female applicants of whom 557 (30.4%) were admitted. This gives a sample odds ratio of 1.83, indicating that males were almost twice as likely to be admitted. In fact, graphical methods (as in the example below) or log-linear modelling show that the apparent association between admission and sex stems from differences in the tendency of males and females to apply to the individual departments (females used to apply  more to departments with higher rejection rates).   
This data set can also be used for illustrating methods for graphical display of categorical data, such as the general-purpose mosaicplot or the fourfoldplot for 2-by-2-by- k tables.    References  
Bickel, P. J., Hammel, E. A., and O'Connell, J. W. (1975). Sex bias in graduate admissions: Data from Berkeley.  Science , 187 , 398–403. doi: 10.1126/science.187.4175.398 .  https://www.jstor.org/stable/1739581 .    Examples    require(graphics) ## Data aggregated over departments apply(UCBAdmissions, c(1, 2), sum) mosaicplot(apply(UCBAdmissions, c(1, 2), sum), main = ""Student admissions at UC Berkeley"") ## Data for individual departments opar <- par(mfrow = c(2, 3), oma = c(0, 0, 2, 0)) for(i in 1:6) mosaicplot(UCBAdmissions[,,i], xlab = ""Admit"", ylab = ""Sex"", main = paste(""Department"", LETTERS[i])) mtext(expression(bold(""Student admissions at UC Berkeley"")), outer = TRUE, cex = 1.5) par(opar)"
"datasets-UKDriverDeaths","datasets","UKDriverDeaths","Road Casualties in Great Britain 1969-84",192,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/UKDriverDeaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/UKDriverDeaths.html","UKDriverDeaths R Documentation    Road Casualties in Great Britain 1969–84    Description  
UKDriverDeaths is a time series giving the monthly totals of car drivers in Great Britain killed or seriously injured Jan 1969 to Dec 1984. Compulsory wearing of seat belts was introduced on 31 Jan 1983.   
Seatbelts is more information on the same problem.    Usage    UKDriverDeaths Seatbelts    Format  
Seatbelts is a multiple time series, with columns    DriversKilled
car drivers killed.   drivers
same as UKDriverDeaths .   front
front-seat passengers killed or seriously injured.   rear
rear-seat passengers killed or seriously injured.   kms
distance driven.   PetrolPrice
petrol price.   VanKilled
number of van (‘light goods vehicle’) drivers.   law
0/1: was the law in effect that month?     Source  
Harvey, A.C. (1989).  Forecasting, Structural Time Series Models and the Kalman Filter . Cambridge University Press, pp. 519–523.   
Durbin, J. and Koopman, S. J. (2001).  Time Series Analysis by State Space Methods . Oxford University Press.  http://www.ssfpack.com/dkbook/     References  
Harvey, A. C. and Durbin, J. (1986). The effects of seat belt legislation on British road casualties: A case study in structural time series modelling.  Journal of the Royal Statistical Society series A, 149 , 187–227. doi: 10.2307/2981553 .    Examples    require(stats); require(graphics) ## work with pre-seatbelt period to identify a model, use logs work <- window(log10(UKDriverDeaths), end = 1982+11/12) par(mfrow = c(3, 1)) plot(work); acf(work); pacf(work) par(mfrow = c(1, 1)) (fit <- arima(work, c(1, 0, 0), seasonal = list(order = c(1, 0, 0)))) z <- predict(fit, n.ahead = 24) ts.plot(log10(UKDriverDeaths), z$pred, z$pred+2*z$se, z$pred-2*z$se, lty = c(1, 3, 2, 2), col = c(""black"", ""red"", ""blue"", ""blue"")) ## now see the effect of the explanatory variables X <- Seatbelts[, c(""kms"", ""PetrolPrice"", ""law"")] X[, 1] <- log10(X[, 1]) - 4 arima(log10(Seatbelts[, ""drivers""]), c(1, 0, 0), seasonal = list(order = c(1, 0, 0)), xreg = X)"
"datasets-UKgas","datasets","UKgas","UK Quarterly Gas Consumption",108,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/UKgas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/UKgas.html","UKgas R Documentation   UK Quarterly Gas Consumption   Description  
Quarterly UK gas consumption from 1960Q1 to 1986Q4, in millions of therms.    Usage   UKgas   Format  
A quarterly time series of length 108.    Source  
Durbin, J. and Koopman, S. J. (2001) Time Series Analysis by State Space Methods. Oxford University Press.  http://www.ssfpack.com/dkbook/     Examples    ## maybe str(UKgas) ; plot(UKgas) ..."
"datasets-USAccDeaths","datasets","USAccDeaths","Accidental Deaths in the US 1973-1978",72,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USAccDeaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/USAccDeaths.html","USAccDeaths R Documentation    Accidental Deaths in the US 1973–1978    Description  
A time series giving the monthly totals of accidental deaths in the USA. The values for the first six months of 1979 are 7798 7406 8363 8460 9217 9316.    Usage   USAccDeaths   Source  
P. J. Brockwell and R. A. Davis (1991)  Time Series: Theory and Methods.  Springer, New York."
"datasets-USArrests","datasets","USArrests","Violent Crime Rates by US State",50,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/USArrests.html","USArrests R Documentation   Violent Crime Rates by US State   Description  
This data set contains statistics, in arrests per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973. Also given is the percent of the population living in urban areas.    Usage   USArrests   Format  
A data frame with 50 observations on 4 variables.   
 [,1] Murder numeric Murder arrests (per 100,000)
 [,2] Assault numeric Assault arrests (per 100,000)
 [,3] UrbanPop numeric Percent urban population
 [,4] Rape numeric Rape arrests (per 100,000)    Note  
USArrests contains the data as in McNeil's monograph. For the  UrbanPop percentages, a review of the table (No. 21) in the Statistical Abstracts 1975 reveals a transcription error for Maryland (and that McNeil used the same “round to even” rule that R 's  round() uses), as found by Daniel S Coven (Arizona).   
See the example below on how to correct the error and improve accuracy for the ‘<n>.5’ percentages.    Source  
World Almanac and Book of facts 1975. (Crime rates).   
Statistical Abstracts of the United States 1975, p.20, (Urban rates), possibly available as  https://books.google.ch/books?id=zl9qAAAAMAAJ&pg=PA20 .    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    See Also  
The state data sets.   Examples    summary(USArrests) require(graphics) pairs(USArrests, panel = panel.smooth, main = ""USArrests data"") ## Difference between 'USArrests' and its correction USArrests[""Maryland"", ""UrbanPop""] # 67 -- the transcription error UA.C <- USArrests UA.C[""Maryland"", ""UrbanPop""] <- 76.6 ## also +/- 0.5 to restore the original <n>.5 percentages s5u <- c(""Colorado"", ""Florida"", ""Mississippi"", ""Wyoming"") s5d <- c(""Nebraska"", ""Pennsylvania"") UA.C[s5u, ""UrbanPop""] <- UA.C[s5u, ""UrbanPop""] + 0.5 UA.C[s5d, ""UrbanPop""] <- UA.C[s5d, ""UrbanPop""] - 0.5 ## ==> UA.C is now a *C*orrected version of USArrests"
"datasets-USJudgeRatings","datasets","USJudgeRatings","Lawyers' Ratings of State Judges in the US Superior Court",43,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USJudgeRatings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/USJudgeRatings.html","USJudgeRatings R Documentation   Lawyers' Ratings of State Judges in the US Superior Court   Description  
Lawyers' ratings of state judges in the US Superior Court.    Usage   USJudgeRatings   Format  
A data frame containing 43 observations on 12 numeric variables.   
 [,1] CONT Number of contacts of lawyer with judge.
 [,2] INTG Judicial integrity.
 [,3] DMNR Demeanor.
 [,4] DILG Diligence.
 [,5] CFMG Case flow managing.
 [,6] DECI Prompt decisions.
 [,7] PREP Preparation for trial.
 [,8] FAMI Familiarity with law.
 [,9] ORAL Sound oral rulings.
 [,10] WRIT Sound written rulings.
 [,11] PHYS Physical ability.
 [,12] RTEN Worthy of retention.    Source  
New Haven Register, 14 January, 1977 (from John Hartigan).    Examples    require(graphics) pairs(USJudgeRatings, main = ""USJudgeRatings data"")"
"datasets-USPersonalExpenditure","datasets","USPersonalExpenditure","Personal Expenditure Data",5,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USPersonalExpenditure.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/USPersonalExpenditure.html","USPersonalExpenditure R Documentation   Personal Expenditure Data   Description  
This data set consists of United States personal expenditures (in billions of dollars) in the categories; food and tobacco, household operation, medical and health, personal care, and private education for the years 1940, 1945, 1950, 1955 and 1960.    Usage   USPersonalExpenditure   Format  
A matrix with 5 rows and 5 columns.   Source  
The World Almanac and Book of Facts, 1962, page 756.   References  
Tukey, J. W. (1977)  Exploratory Data Analysis . Addison-Wesley.   
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(stats) # for medpolish USPersonalExpenditure medpolish(log10(USPersonalExpenditure))"
"datasets-uspop","datasets","uspop","Populations Recorded by the US Census",19,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/uspop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/uspop.html","uspop R Documentation   Populations Recorded by the US Census   Description  
This data set gives the population of the United States (in millions) as recorded by the decennial census for the period 1790–1970.    Usage   uspop   Format  
A time series of 19 values.   Source  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(graphics) plot(uspop, log = ""y"", main = ""uspop data"", xlab = ""Year"", ylab = ""U.S. Population (millions)"")"
"datasets-VADeaths","datasets","VADeaths","Death Rates in Virginia (1940)",5,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/VADeaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/VADeaths.html","VADeaths R Documentation   Death Rates in Virginia (1940)   Description  
Death rates per 1000 in Virginia in 1940.    Usage   VADeaths   Format  
A matrix with 5 rows and 4 columns.   Details  
The death rates are measured per 1000 population per year. They are cross-classified by age group (rows) and population group (columns). The age groups are: 50–54, 55–59, 60–64, 65–69, 70–74 and the population groups are Rural/Male, Rural/Female, Urban/Male and Urban/Female.   
This provides a rather nice 3-way analysis of variance example.    Source  
Molyneaux, L., Gilliam, S. K., and Florant, L. C.(1947) Differences in Virginia death rates by color, sex, age, and rural or urban residence.  American Sociological Review , 12 , 525–535.    References  
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(stats); require(graphics) n <- length(dr <- c(VADeaths)) nam <- names(VADeaths) d.VAD <- data.frame( Drate = dr, age = rep(ordered(rownames(VADeaths)), length.out = n), gender = gl(2, 5, n, labels = c(""M"", ""F"")), site = gl(2, 10, labels = c(""rural"", ""urban""))) coplot(Drate ~ as.numeric(age) | gender * site, data = d.VAD, panel = panel.smooth, xlab = ""VADeaths data - Given: gender"") summary(aov.VAD <- aov(Drate ~ .^2, data = d.VAD)) opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0)) plot(aov.VAD) par(opar)"
"datasets-volcano","datasets","volcano","Topographic Information on Auckland's Maunga Whau Volcano",87,61,0,0,0,0,61,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/volcano.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/volcano.html","volcano R Documentation   Topographic Information on Auckland's Maunga Whau Volcano   Description  
Maunga Whau (Mt Eden) is one of about 50 volcanos in the Auckland volcanic field. This data set gives topographic information for Maunga Whau on a 10m by 10m grid.    Usage   volcano   Format  
A matrix with 87 rows and 61 columns, rows corresponding to grid lines running east to west and columns to grid lines running south to north.   Source  
Digitized from a topographic map by Ross Ihaka. These data should not be regarded as accurate.    See Also  
filled.contour for a nice plot.   Examples    require(grDevices); require(graphics) filled.contour(volcano, color.palette = terrain.colors, asp = 1) title(main = ""volcano data: filled contour map"")"
"datasets-warpbreaks","datasets","warpbreaks","The Number of Breaks in Yarn during Weaving",54,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/warpbreaks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/warpbreaks.html","warpbreaks R Documentation   The Number of Breaks in Yarn during Weaving   Description  
This data set gives the number of warp breaks per loom, where a loom corresponds to a fixed length of yarn.    Usage   warpbreaks   Format  
A data frame with 54 observations on 3 variables.   
  [,1] breaks  numeric The number of breaks
  [,2] wool  factor The type of wool (A or B)
  [,3] tension factor The level of tension (L, M, H)   
There are measurements on 9 looms for each of the six types of warp ( AL , AM , AH , BL , BM , BH ).    Source  
Tippett, L. H. C. (1950)  Technological Applications of Statistics . Wiley. Page 106.    References  
Tukey, J. W. (1977)  Exploratory Data Analysis . Addison-Wesley.   
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    See Also  
xtabs for ways to display these data as a table.    Examples    require(stats); require(graphics) summary(warpbreaks) opar <- par(mfrow = c(1, 2), oma = c(0, 0, 1.1, 0)) plot(breaks ~ tension, data = warpbreaks, col = ""lightgray"", varwidth = TRUE, subset = wool == ""A"", main = ""Wool A"") plot(breaks ~ tension, data = warpbreaks, col = ""lightgray"", varwidth = TRUE, subset = wool == ""B"", main = ""Wool B"") mtext(""warpbreaks data"", side = 3, outer = TRUE) par(opar) summary(fm1 <- lm(breaks ~ wool*tension, data = warpbreaks)) anova(fm1)"
"datasets-women","datasets","women","Average Heights and Weights for American Women",15,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/women.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/women.html","women R Documentation   Average Heights and Weights for American Women   Description  
This data set gives the average heights and weights for American women aged 30–39.    Usage   women   Format  
A data frame with 15 observations on 2 variables.   
  [,1]  height  numeric Height (in)
  [,2]  weight  numeric Weight (lbs)    Details  
The data set appears to have been taken from the American Society of Actuaries Build and Blood Pressure Study for some (unknown to us) earlier year.   
The World Almanac notes: “The figures represent weights in ordinary indoor clothing and shoes, and heights with shoes”.    Source  
The World Almanac and Book of Facts, 1975.   References  
McNeil, D. R. (1977)  Interactive Data Analysis . Wiley.    Examples    require(graphics) plot(women, xlab = ""Height (in)"", ylab = ""Weight (lb)"", main = ""women data: American women aged 30-39"")"
"datasets-WorldPhones","datasets","WorldPhones","The World's Telephones",7,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/WorldPhones.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/WorldPhones.html","WorldPhones R Documentation   The World's Telephones   Description  
The number of telephones in various regions of the world (in thousands).    Usage   WorldPhones   Format  
A matrix with 7 rows and 8 columns. The columns of the matrix give the figures for a given region, and the rows the figures for a year.   
The regions are: North America, Europe, Asia, South America, Oceania, Africa, Central America.   
The years are: 1951, 1956, 1957, 1958, 1959, 1960, 1961.    Source  
AT&T (1961) The World's Telephones .    References  
McNeil, D. R. (1977)  Interactive Data Analysis . New York: Wiley.    Examples    require(graphics) matplot(rownames(WorldPhones), WorldPhones, type = ""b"", log = ""y"", xlab = ""Year"", ylab = ""Number of telephones (1000's)"") legend(1951.5, 80000, colnames(WorldPhones), col = 1:6, lty = 1:5, pch = rep(21, 7)) title(main = ""World phones data: log scale for response"")"
"datasets-WWWusage","datasets","WWWusage","Internet Usage per Minute",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/WWWusage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/datasets/WWWusage.html","WWWusage R Documentation   Internet Usage per Minute   Description  
A time series of the numbers of users connected to the Internet through a server every minute.    Usage   WWWusage   Format  
A time series of length 100.    Source  
Durbin, J. and Koopman, S. J. (2001) Time Series Analysis by State Space Methods. Oxford University Press.  http://www.ssfpack.com/dkbook/     References  
Makridakis, S., Wheelwright, S. C. and Hyndman, R. J. (1998)  Forecasting: Methods and Applications. Wiley.    Examples    require(graphics) work <- diff(WWWusage) par(mfrow = c(2, 1)); plot(WWWusage); plot(work) ## Not run: require(stats) aics <- matrix(, 6, 6, dimnames = list(p = 0:5, q = 0:5)) for(q in 1:5) aics[1, 1+q] <- arima(WWWusage, c(0, 1, q), optim.control = list(maxit = 500))$aic for(p in 1:5) for(q in 0:5) aics[1+p, 1+q] <- arima(WWWusage, c(p, 1, q), optim.control = list(maxit = 500))$aic round(aics - min(aics, na.rm = TRUE), 2) ## End(Not run)"
"dplyr-band_instruments","dplyr","band_instruments","Band membership",3,2,1,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/band_instruments.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/band_instruments.html","band_members R Documentation   Band membership   Description  
These data sets describe band members of the Beatles and Rolling Stones. They are toy data sets that can be displayed in their entirety on a slide (e.g. to demonstrate a join).    Usage    band_members band_instruments band_instruments2    Format  
Each is a tibble with two variables and three observations    Details  
band_instruments and band_instruments2 contain the same data but use different column names for the first column of the data set.  band_instruments uses name , which matches the name of the key column of  band_members ; band_instruments2 uses artist , which does not.    Examples    band_members band_instruments band_instruments2"
"dplyr-band_instruments2","dplyr","band_instruments2","Band membership",3,2,1,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/band_instruments2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/band_instruments2.html","band_members R Documentation   Band membership   Description  
These data sets describe band members of the Beatles and Rolling Stones. They are toy data sets that can be displayed in their entirety on a slide (e.g. to demonstrate a join).    Usage    band_members band_instruments band_instruments2    Format  
Each is a tibble with two variables and three observations    Details  
band_instruments and band_instruments2 contain the same data but use different column names for the first column of the data set.  band_instruments uses name , which matches the name of the key column of  band_members ; band_instruments2 uses artist , which does not.    Examples    band_members band_instruments band_instruments2"
"dplyr-band_members","dplyr","band_members","Band membership",3,2,1,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/band_members.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/band_members.html","band_members R Documentation   Band membership   Description  
These data sets describe band members of the Beatles and Rolling Stones. They are toy data sets that can be displayed in their entirety on a slide (e.g. to demonstrate a join).    Usage    band_members band_instruments band_instruments2    Format  
Each is a tibble with two variables and three observations    Details  
band_instruments and band_instruments2 contain the same data but use different column names for the first column of the data set.  band_instruments uses name , which matches the name of the key column of  band_members ; band_instruments2 uses artist , which does not.    Examples    band_members band_instruments band_instruments2"
"dplyr-starwars","dplyr","starwars","Starwars characters",87,11,1,8,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/starwars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/starwars.html","Toggle navigation             Rdatasets   1.0.0      
 
  Available datasets    
                 
 
 
  Page not found (404)    Content not found. Please use links in the navbar.   
    Contents          
 
Developed by Vincent Arel-Bundock.    
 
Site built with pkgdown 1.6.1."
"dplyr-storms","dplyr","storms","Storm tracks data",10010,13,0,2,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dplyr/storms.html","storms R Documentation   Storm tracks data   Description  
This data is a subset of the NOAA Atlantic hurricane database best track data, https://www.nhc.noaa.gov/data/#hurdat . The data includes the positions and attributes of 198 tropical storms, measured every six hours during the lifetime of a storm.    Usage    storms    Format  
A tibble with 10,010 observations and 13 variables:    name
Storm Name   year,month,day
Date of report   hour
Hour of report (in UTC)   lat,long
Location of storm center   status
Storm classification (Tropical Depression, Tropical Storm, or Hurricane)   category
Saffir-Simpson storm category (estimated from wind speed. -1 = Tropical Depression, 0 = Tropical Storm)   wind
storm's maximum sustained wind speed (in knots)   pressure
Air pressure at the storm's center (in millibars)   ts_diameter
Diameter of the area experiencing tropical storm strength winds (34 knots or above)   hu_diameter
Diameter of the area experiencing hurricane strength winds (64 knots or above)     See Also  
The script to create the storms data set: https://github.com/tidyverse/dplyr/blob/master/data-raw/storms.R     Examples    storms"
"dragracer-rpdr_contep","dragracer","rpdr_contep","RuPaul's Drag Race Episode-Contestant Data",2096,11,6,3,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/dragracer/rpdr_contep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dragracer/rpdr_contep.html","rpdr_contep R Documentation   RuPaul's Drag Race Episode-Contestant Data   Description  
These are episode-contestant-level data for RuPaul's Drag Race for all available seasons (currently through Season 12). For a given season, observations mostly decrease with each episode. Data include all sorts of information.    Usage    rpdr_contep    Format  
A data frame with 1,888 observations on the following 11 variables.    season
a character vector for the season   rank
a numeric vector for the final rank of the contestant   contestant
a character vector for the contestant's name   missc
a dummy variable indicating if the contestant was Miss Congeniality   episode
a numeric vector for the episode number   outcome
a character vector for the outcome for the queen after the main challenge   eliminated
a character vector (0,1) for if the queen was eliminated/removed from the competition after the episode   participant
a character vector (0,1) for if the queen was a participant in the show   minichalw
a character vector (0,1) if the queen won a mini-challenge that episode. NOTE: this is a work in progress. For now, I encourage getting the mini-challenge data from one of the other data sets.   finale
a numeric vector for if the episode was the finale   penultimate
a numeric vector for if the episode was the penultimate before the finale. Applicable to seasons 6, 7, and 8."
"dragracer-rpdr_contestants","dragracer","rpdr_contestants","RuPaul's Drag Race Contestant Data",170,5,0,3,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/dragracer/rpdr_contestants.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dragracer/rpdr_contestants.html","rpdr_contestants R Documentation   RuPaul's Drag Race Contestant Data   Description  
These are contestant-level data for RuPaul's Drag Race for all available seasons (currently through Season 12). Data include all sorts of information.    Usage    rpdr_contestants    Format  
A data frame with 157 observations on the following 5 variables.    season
a character vector for season   contestant
a character vector for contestant's name, by season   age
a numeric vector for the respondent's purported age as of filming   dob
a date vector for the contestant's purported date of birth   hometown
a character vector for hometown.     Details  
Note: Cynthia Lee Fontaine, Shangela, Eureka O'Hara, and Vanessa Vanjie Mateo will appear in this data set twice."
"dragracer-rpdr_ep","dragracer","rpdr_ep","RuPaul's Drag Race Episode Data",175,22,3,17,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/dragracer/rpdr_ep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/dragracer/rpdr_ep.html","rpdr_ep R Documentation   RuPaul's Drag Race Episode Data   Description  
These are episode-level data for RuPaul's Drag Race for all available seasons (currently through Season 12). Data include all sorts of information.    Usage    rpdr_ep    Format  
A data frame with 159 observations on the following 22 variables.    season
a character vector for season   episode
a numeric vector for the episode number   airdate
a date for the episode air date   special
Is the episode a special (e.g. a reunited or clip show)   finale
Is the episode the finale   nickname
Name of the episode   runwaytheme
a character vector for runway theme, where applicable/available   numqueens
a numeric vector for number of queens at the start of the episode   minic
a character vector describing the mini-challenge   minicw1
a character vector for a mini-challenge winner   minicw2
a character vector for a second mini-challenge winner, where applicable   minicw3
a character vector for a second mini-challenge winner, where applicable   bottom1
a character vector for queen in the bottom 2 of that episode   bottom2
a character vector for queen in the bottom 2 of that episode   bottom3
a character vector for the third queen in the bottom of that episode. Thanks, Season 11.   bottom4
a character vector for the fourth queen in the bottom of that episode. Thanks, Season 11.   bottom5
a character vector for the fifth queen in the bottom of that episode. Thanks, Season 11.   bottom6
a character vector for the sixth queen in the bottom of that episode. Thanks, Season 11.   lipsyncartist
a character vector for the lip-sync artist   lipsyncsong
a character vector for the lip-sync artist's song   eliminated1
a character vector for the queen eliminated after the lip-sync   eliminated2
a character vector for the queen eliminated after the lip-sync, if there was a double-sashay that episode."
"drc-acidiq","drc","acidiq","Acifluorfen and diquat tested on Lemna minor.",180,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/acidiq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/acidiq.html","acidiq R Documentation   Acifluorfen and diquat tested on Lemna minor.   Description  
Data from an experiment where the chemicals acifluorfen and diquat tested on Lemna minor. The dataset has 7 mixtures used in 8 dilutions with three replicates and 12 common controls, in total 180 observations.    Usage   data(acidiq)   Format  
A data frame with 180 observations on the following 3 variables.    dose
a numeric vector of dose values   pct
a numeric vector denoting the grouping according to the mixtures percentages   rgr
a numeric vector of response values (relative growth rates)     Details  
The dataset is analysed in Soerensen et al (2007). Hewlett's symmetric model seems appropriate for this dataset.   Source  
The dataset is kindly provided by Nina Cedergreen, Department of Agricultural Sciences, Royal Veterinary and Agricultural University, Denmark.    References  
Soerensen, H. and Cedergreen, N. and Skovgaard, I. M. and Streibig, J. C. (2007) An isobole-based statistical model and test for synergism/antagonism in binary mixture toxicity experiments, Environmental and Ecological Statistics , 14 , 383–397.    Examples    ## Fitting the model with freely varying ED50 values ## Ooops: Box-Cox transformation is needed acidiq.free <- drm(rgr ~ dose, pct, data = acidiq, fct = LL.4(), pmodels = list(~factor(pct), ~1, ~1, ~factor(pct) - 1)) ## Lack-of-fit test modelFit(acidiq.free) summary(acidiq.free) ## Plotting isobole structure isobole(acidiq.free, xlim = c(0, 400), ylim = c(0, 450)) ## Fitting the concentration addition model acidiq.ca <- mixture(acidiq.free, model = ""CA"") ## Comparing to model with freely varying e parameter anova(acidiq.ca, acidiq.free) # rejected ## Plotting isobole based on concentration addition -- poor fit isobole(acidiq.free, acidiq.ca, xlim = c(0, 420), ylim = c(0, 450)) # poor fit ## Fitting the Hewlett model acidiq.hew <- mixture(acidiq.free, model = ""Hewlett"") ## Comparing to model with freely varying e parameter anova(acidiq.free, acidiq.hew) # accepted summary(acidiq.hew) ## Plotting isobole based on the Hewlett model isobole(acidiq.free, acidiq.hew, xlim = c(0, 400), ylim = c(0, 450)) # good fit"
"drc-algae","drc","algae","Volume of algae as function of increasing concentrations of a herbicide",14,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/algae.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/algae.html","algae R Documentation   Volume of algae as function of increasing concentrations of a herbicide   Description  
Dataset from an experiment exploring the effect of increasing concentrations of a herbicide on the volume of the treated algae.    Usage   data(algae)   Format  
A data frame with 14 observations on the following 2 variables.    conc
a numeric vector of concentrations.   vol
a numeric vector of response values, that is relative change in volume.     Details  
This datasets requires a cubic root transformation in order to stabilise the variance.    Source  
Meister, R. and van den Brink, P. (2000)  The Analysis of Laboratory Toxicity Experiments , Chapter 4 in Statistics in Ecotoxicology , Editor: T. Sparks, New York: John Wiley \& Sons, (pp. 114–116).   Examples    algae.m1 <- drm(vol~conc, data=algae, fct=LL.3()) summary(algae.m1) algae.m2 <- boxcox(algae.m1) summary(algae.m2)"
"drc-auxins","drc","auxins","Effect of technical grade and commercially formulated auxin herbicides",150,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/auxins.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/auxins.html","auxins R Documentation   Effect of technical grade and commercially formulated auxin herbicides   Description  
MCPA, 2,4-D, mecorprop and dichorlprop were applied either as technical grades materials (h = 1, 2, 3, 4) or as commercial formulations (herb = 5, 6, 7, 8). Each experimental unit consisted of five 1-week old seedlings grown together in a pot of nutrient solution during 14 days.   Usage   data(auxins)   Format  
A data frame with 150 observations on the following 5 variables.    r
a numeric vector   h
a numeric vector   w
a numeric vector   y
a numeric vector   dose
a numeric vector     Details  
Data are parts of a larger joint action experiment with various herbicides.   
The eight herbicide preparations are naturally grouped into four pairs: (1, 5), (2, 6), (3, 7), and (4, 8), and in each pair of herbicides should have the same active ingredients but different formulation constituents, which were assumed to be biologically inert. The data consist of the 150 observations y of dry weights, each observation being the weight of five plants grown in the same pot. All the eight herbicide preparations have essentially the same mode of action in the plant; they all act like the plant auxins, which are plant regulators that affect cell enlongation an other essential metabolic pathways. One of the objects of the experiment was to test if the response functions were identical except for a multiplicative factor in the dose. This is a necessary, but not a sufficient, condition for a similar mode of action for the herbicides.   Source  
Streibig, J. C. (1987). Joint action of root-absorbed mixtures of auxin herbicides in Sinapis alba L. and barley (Hordeum vulgare L.) Weed Research , 27 , 337–347.    References  
Rudemo, M., Ruppert, D., and Streibig, J. C. (1989). Random-Effect Models in Nonlinear Regression with Applications to Bioassay.  Biometrics , 45 , 349–362.    Examples    ## Fitting model with varying lower limits auxins.m1 <- boxcox(drm(y ~ dose, h, pmodels = data.frame(h, h, 1, h), fct = LL.4(), data = auxins), method = ""anova"") ## Fitting model with common lower limit auxins.m2 <- boxcox(drm(y ~ dose, h, pmodels = data.frame(h, 1, 1, h), fct = LL.4(), data = auxins), method = ""anova"") ## Comparing the two models anova(auxins.m2, auxins.m1)"
"drc-chickweed","drc","chickweed","Germination of common chickweed (_Stellaria media_)",35,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/chickweed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/chickweed.html","chickweed R Documentation    Germination of common chickweed ( Stellaria media )    Description  
Germination data from tests of chickweed seeds from chlorsulfuron resistant and sensitive biotypes    Usage   data(chickweed)   Format  
A data frame with 35 observations on the following 3 variables.    start
a numeric vector of left endpoints of the monitoring intervals   end
a numeric vector of right endpoints of the monitoring intervals   count
a numeric vector of the number of seeds germinated in the interval between start and end   time
a numeric vector of the non-zero left endpoints of the monitoring intervals (often used for recording in practice)     Details  
The germination tests of chickweed seeds from chlorsulfuron resistant and sensitive biotypes in central Zealand were done in petri dishes (diameter: 9.0cm) in a dark growth cabinet at a temperature of 5 degrees Celsius. The seeds were incubated for 24 hours in a 0.3% solution of potassium nitrate in order to imbibe seeds prior to the test. A total of 200 seeds were placed on filter plate. After initialization of the tests, the number of germinated seeds was recorded and removed at 34 consecutive inspection times. Definition of a germinated seed was the breakthrough of the seed testa by the radicle.  
Chickweed is known to have dormant seeds and therefore we would not expect 100% germination. It means that the upper limit of the proportion germinated has to be incorporated as a parameter into a model, which adequately reflects the experimental design as well as any expectations about the resulting outcome.    Source  
Data are kindly provided by Lisa Borggaard (formerly at the Faculty of Life Sciences, University of Copenhagen).    References  
Ritz, C., Pipper, C. B. and Streibig, J. C. (2013) Analysis of germination data from agricultural experiments, Europ. J. Agronomy , 45 , 1–6.   Examples    ## Incorrect analysis using a logistic regression model ## (treating event times as binomial data) ## The argument ""type"" specifies that binomial data are supplied chickweed.m0a <- drm(count/200 ~ time, weights = rep(200, 34), data = chickweed0, fct = LL.3(), type = ""binomial"") summary(chickweed.m0a) # showing a summmary of the model fit (including parameter estimates) ## Incorrect analysis based on nonlinear regression ## LL.3() refers to the three-parameter log-logistic model ## As the argument ""type"" is not specified it is assumed that the data type ## is continuous and nonlinear regression based on least squares estimation is carried out chickweed.m0b <- drm(count/200 ~ time, data = chickweed0, fct = LL.3()) summary(chickweed.m0b) # showing a summmary of the model fit (including parameter estimates) ## How to re-arrange the data for fitting the event-time model ## (only for illustration of the steps needed for converting a dataset, ## but in this case not needed as both datasets are already provided in ""drc"") #chickweed <- data.frame(start = c(0, chickweed0$time), end = c(chickweed0$time, Inf)) #chickweed$count <- c(0, diff(chickweed0$count), 200 - tail(chickweed0$count, 1)) #head(chickweed) # showing top 6 lines of the dataset #tail(chickweed) # showing bottom 6 lines ## Fitting the event-time model (by specifying the argument type explicitly) chickweed.m1 <- drm(count~start+end, data = chickweed, fct = LL.3(), type = ""event"") summary(chickweed.m1) # showing a summmary of the model fit (including parameter estimates) ## Summary output with robust standard errors ## library(lmtest) ## library(sandwich) ## coeftest(chickweed.m1, vcov = sandwich) ## Calculating t10, t50, t90 for the distribution of viable seeds ED(chickweed.m1, c(10, 50, 90)) ## Plotting data and fitted regression curve plot(chickweed.m1, xlab = ""Time (hours)"", ylab = ""Proportion germinated"", xlim=c(0, 340), ylim=c(0, 0.25), log="""", lwd=2, cex=1.2) ## Adding the fitted curve obtained using nonlinear regression plot(chickweed.m0b, add = TRUE, lty = 2, xlim=c(0, 340), ylim=c(0, 0.25), log="""", lwd=2, cex=1.2) # Note: the event-time model has slightly better fit at the upper limit ## Enhancing the plot (to look like in the reference paper) abline(h = 0.20011, lty = 3, lwd = 2) text(-15, 0.21, ""Upper limit: d"", pos = 4, cex = 1.5) segments(0,0.1,196,0.1, lty = 3, lwd = 2) segments(196,0.1, 196, -0.1, lty = 3, lwd = 2) text(200, -0.004, expression(paste(""50% germination: "", t[50])), pos = 4, cex = 1.5) abline(a = 0.20011/2-0.20011*20.77/4, b = 0.20011*20.77/4/196, lty = 3, lwd = 2) #text(200, 0.1, expression(paste(""Slope: "", b*(-d/(4*t[50])))), pos = 4, cex = 1.5) text(200, 0.1, expression(""Slope: b"" %.% ""constant""), pos = 4, cex = 1.5) points(196, 0.1, cex = 2, pch = 0) ## Adding confidence intervals ## Predictions from the event-time model #coefVec <- coef(chickweed.m1) #names(coefVec) <- c(""b"",""d"",""e"") # #predFct <- function(tival) #{ # as.numeric(deltaMethod(coefVec, paste(""d/(1+exp(b*(log("",tival,"")-log(e))))""), # vcov(chickweed.m1))) #} #predFctv <- Vectorize(predFct, ""tival"") # #etpred <- t(predFctv(0:340)) #lines(0:340, etpred[,1]-1.96*etpred[,2], lty=1, lwd=2, col=""darkgray"") #lines(0:340, etpred[,1]+1.96*etpred[,2], lty=1, lwd=2, col=""darkgray"") # ### Predictions from the nonlinear regression model #nrpred <- predict(chickweed.m0b, data.frame(time=0:340), interval=""confidence"") #lines(0:340, nrpred[,2], lty=2, lwd=2, col=""darkgray"") #lines(0:340, nrpred[,3], lty=2, lwd=2, col=""darkgray"")"
"drc-chickweed0","drc","chickweed0","Germination of common chickweed (_Stellaria media_)",34,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/chickweed0.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/chickweed0.html","chickweed R Documentation    Germination of common chickweed ( Stellaria media )    Description  
Germination data from tests of chickweed seeds from chlorsulfuron resistant and sensitive biotypes    Usage   data(chickweed)   Format  
A data frame with 35 observations on the following 3 variables.    start
a numeric vector of left endpoints of the monitoring intervals   end
a numeric vector of right endpoints of the monitoring intervals   count
a numeric vector of the number of seeds germinated in the interval between start and end   time
a numeric vector of the non-zero left endpoints of the monitoring intervals (often used for recording in practice)     Details  
The germination tests of chickweed seeds from chlorsulfuron resistant and sensitive biotypes in central Zealand were done in petri dishes (diameter: 9.0cm) in a dark growth cabinet at a temperature of 5 degrees Celsius. The seeds were incubated for 24 hours in a 0.3% solution of potassium nitrate in order to imbibe seeds prior to the test. A total of 200 seeds were placed on filter plate. After initialization of the tests, the number of germinated seeds was recorded and removed at 34 consecutive inspection times. Definition of a germinated seed was the breakthrough of the seed testa by the radicle.  
Chickweed is known to have dormant seeds and therefore we would not expect 100% germination. It means that the upper limit of the proportion germinated has to be incorporated as a parameter into a model, which adequately reflects the experimental design as well as any expectations about the resulting outcome.    Source  
Data are kindly provided by Lisa Borggaard (formerly at the Faculty of Life Sciences, University of Copenhagen).    References  
Ritz, C., Pipper, C. B. and Streibig, J. C. (2013) Analysis of germination data from agricultural experiments, Europ. J. Agronomy , 45 , 1–6.   Examples    ## Incorrect analysis using a logistic regression model ## (treating event times as binomial data) ## The argument ""type"" specifies that binomial data are supplied chickweed.m0a <- drm(count/200 ~ time, weights = rep(200, 34), data = chickweed0, fct = LL.3(), type = ""binomial"") summary(chickweed.m0a) # showing a summmary of the model fit (including parameter estimates) ## Incorrect analysis based on nonlinear regression ## LL.3() refers to the three-parameter log-logistic model ## As the argument ""type"" is not specified it is assumed that the data type ## is continuous and nonlinear regression based on least squares estimation is carried out chickweed.m0b <- drm(count/200 ~ time, data = chickweed0, fct = LL.3()) summary(chickweed.m0b) # showing a summmary of the model fit (including parameter estimates) ## How to re-arrange the data for fitting the event-time model ## (only for illustration of the steps needed for converting a dataset, ## but in this case not needed as both datasets are already provided in ""drc"") #chickweed <- data.frame(start = c(0, chickweed0$time), end = c(chickweed0$time, Inf)) #chickweed$count <- c(0, diff(chickweed0$count), 200 - tail(chickweed0$count, 1)) #head(chickweed) # showing top 6 lines of the dataset #tail(chickweed) # showing bottom 6 lines ## Fitting the event-time model (by specifying the argument type explicitly) chickweed.m1 <- drm(count~start+end, data = chickweed, fct = LL.3(), type = ""event"") summary(chickweed.m1) # showing a summmary of the model fit (including parameter estimates) ## Summary output with robust standard errors ## library(lmtest) ## library(sandwich) ## coeftest(chickweed.m1, vcov = sandwich) ## Calculating t10, t50, t90 for the distribution of viable seeds ED(chickweed.m1, c(10, 50, 90)) ## Plotting data and fitted regression curve plot(chickweed.m1, xlab = ""Time (hours)"", ylab = ""Proportion germinated"", xlim=c(0, 340), ylim=c(0, 0.25), log="""", lwd=2, cex=1.2) ## Adding the fitted curve obtained using nonlinear regression plot(chickweed.m0b, add = TRUE, lty = 2, xlim=c(0, 340), ylim=c(0, 0.25), log="""", lwd=2, cex=1.2) # Note: the event-time model has slightly better fit at the upper limit ## Enhancing the plot (to look like in the reference paper) abline(h = 0.20011, lty = 3, lwd = 2) text(-15, 0.21, ""Upper limit: d"", pos = 4, cex = 1.5) segments(0,0.1,196,0.1, lty = 3, lwd = 2) segments(196,0.1, 196, -0.1, lty = 3, lwd = 2) text(200, -0.004, expression(paste(""50% germination: "", t[50])), pos = 4, cex = 1.5) abline(a = 0.20011/2-0.20011*20.77/4, b = 0.20011*20.77/4/196, lty = 3, lwd = 2) #text(200, 0.1, expression(paste(""Slope: "", b*(-d/(4*t[50])))), pos = 4, cex = 1.5) text(200, 0.1, expression(""Slope: b"" %.% ""constant""), pos = 4, cex = 1.5) points(196, 0.1, cex = 2, pch = 0) ## Adding confidence intervals ## Predictions from the event-time model #coefVec <- coef(chickweed.m1) #names(coefVec) <- c(""b"",""d"",""e"") # #predFct <- function(tival) #{ # as.numeric(deltaMethod(coefVec, paste(""d/(1+exp(b*(log("",tival,"")-log(e))))""), # vcov(chickweed.m1))) #} #predFctv <- Vectorize(predFct, ""tival"") # #etpred <- t(predFctv(0:340)) #lines(0:340, etpred[,1]-1.96*etpred[,2], lty=1, lwd=2, col=""darkgray"") #lines(0:340, etpred[,1]+1.96*etpred[,2], lty=1, lwd=2, col=""darkgray"") # ### Predictions from the nonlinear regression model #nrpred <- predict(chickweed.m0b, data.frame(time=0:340), interval=""confidence"") #lines(0:340, nrpred[,2], lty=2, lwd=2, col=""darkgray"") #lines(0:340, nrpred[,3], lty=2, lwd=2, col=""darkgray"")"
"drc-daphnids","drc","daphnids","Daphnia test",16,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/daphnids.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/daphnids.html","daphnids R Documentation   Daphnia test   Description  
The number of immobile daphnids –in contrast to mobile daphnids– out of a total of 20 daphnids was counted for several concentrations of a toxic substance.    Usage   data(daphnids)   Format  
A data frame with 16 observations on the following 4 variables.    dose
a numeric vector   no
a numeric vector   total
a numeric vector   time
a factor with levels 24h 48h     Details  
The same daphnids were counted at 24h and later again at 48h.    Source  
Nina Cedergreen, Faculty of Life Sciences, University of Copenhagen, Denmark.    Examples    ## Fitting a model with different parameters ## for different curves daphnids.m1 <- drm(no/total~dose, time, weights = total, data = daphnids, fct = LL.2(), type = ""binomial"") ## Goodness-of-fit test modelFit(daphnids.m1) ## Summary of the data summary(daphnids.m1) ## Fitting a model with a common intercept parameter daphnids.m2 <- drm(no/total~dose, time, weights = total, data = daphnids, fct = LL.2(), type = ""binomial"", pmodels = list(~1, ~time))"
"drc-decontaminants","drc","decontaminants","Performance of decontaminants used in the culturing of a micro-organism",128,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/decontaminants.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/decontaminants.html","decontaminants R Documentation    Performance of decontaminants used in the culturing of a micro-organism    Description  
The two decontaminants 1-hexadecylpyridium chloride and oxalic acid were used. Additionally there was a control group (coded as concentration 0 and only included under oxalic acid).    Usage   data(""decontaminants"")   Format  
A data frame with 128 observations on the following 3 variables.    conc
a numeric vector of percentage weight per volume   count
a numeric vector of numbers of M. bovis colonies at stationarity   group
a factor with levels hpc and oxalic of the decontaminants used     Details  
These data examplify Wadley's problem: counts where the maximum number is not known. The data were analyzed by Trajstman (1989) using a three-parameter logistic model and then re-analyzed by Morgan and Smith (1992) using a three-parameter Weibull type II model. In both cases the authors adjusted for overdispersion (in different ways).   
It seems that Morgan and Smith (1992) fitted separate models for the two decontaminants and using the control group for both model fits. In the example below a joint model is fitted where the control group is used once to determine a shared upper limit at concentration 0.    Source  
Trajstman, A. C. (1989) Indices for Comparing Decontaminants when Data Come from Dose-Response Survival and Contamination Experiments, Applied Statistics , 38 , 481–494.   References  
Morgan, B. J. T. and Smith, D. M. (1992) A Note on Wadley's Problem with Overdispersion, Applied Statistics , 41 , 349–354.    Examples    ## Wadley's problem using a three-parameter log-logistic model decon.LL.3.1 <- drm(count~conc, group, data = decontaminants, fct = LL.3(), type = ""Poisson"", pmodels = list(~group, ~1, ~group)) summary(decon.LL.3.1) plot(decon.LL.3.1) ## Same model fit in another parameterization (no intercepts) decon.LL.3.2 <- drm(count~conc, group, data = decontaminants, fct=LL.3(), type = ""Poisson"", pmodels = list(~group-1, ~1, ~group-1)) summary(decon.LL.3.2)"
"drc-deguelin","drc","deguelin","Deguelin applied to chrysanthemum aphis",6,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/deguelin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/deguelin.html","deguelin R Documentation   Deguelin applied to chrysanthemum aphis   Description  
Quantal assay data from an experiment where the insectide deguelin was applied to  Macrosiphoniella sanborni .    Usage   data(deguelin)   Format  
A data frame with 6 observations on the following 4 variables.    dose
a numeric vector of doses applied   log10dose
a numeric vector of logarithm-transformed doses   r
a numeric vector contained number of dead insects   n
a numeric vector contained the total number of insects     Details  
The log-logistic model provides an inadequate fit.   
The dataset is used in Nottingham and Birch (2000) to illustrate a semiparametric approach to dose-response modelling.    Source  
Morgan, B. J. T. (1992) Analysis of Quantal Response Data , London: Chapman \& Hall/CRC (Table 3.9, p. 117).    References  
Notttingham, Q. J. and Birch, J. B. (2000) A semiparametric approach to analysing dose-response data, Statist. Med. , 19 , 389–404.    Examples    ## Log-logistic fit deguelin.m1 <- drm(r/n~dose, weights=n, data=deguelin, fct=LL.2(), type=""binomial"") modelFit(deguelin.m1) summary(deguelin.m1) ## Loess fit deguelin.m2 <- loess(r/n~dose, data=deguelin, degree=1) ## Plot of data with fits superimposed plot(deguelin.m1, ylim=c(0.2,1)) lines(1:60, predict(deguelin.m2, newdata=data.frame(dose=1:60)), col = 2, lty = 2) lines(1:60, 0.95*predict(deguelin.m2, newdata=data.frame(dose=1:60))+0.05*predict(deguelin.m1, newdata=data.frame(dose=1:60), se = FALSE), col = 3, lty=3)"
"drc-earthworms","drc","earthworms","Earthworm toxicity test",35,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/earthworms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/earthworms.html","earthworms R Documentation   Earthworm toxicity test   Description  
The dataset was obtained from a toxicity test using earthworms, and it contains the number of earthworms remaining in a container that was contaminated with a toxic substance (not disclosed) at various doses; so the number of earthworms not migrating to the neighbouring uncontaminated container.    Usage   data(earthworms)   Format  
A data frame with 35 observations on the following 3 variables.    dose
a numeric vector of dose values   number
a numeric vector containing counts of remaining earthworms in the container   total
a numeric vector containing total number of earthworms put in the containers     Details  
At dose 0 around half of the earthworms is expected be in each of the two containers. Thus it is not appropriate to fit an ordinary logistic regression with log(dose) as explanatory variable to these data as it implies an upper limit of 1 at dose 0 and in fact this model does not utilise the observations at dose 0 (see the example section below).   Source  
The dataset is kindly provided by Nina Cedergreen, Faculty of Life Sciences, University of Copenhagen, Denmark.    Examples    ## Fitting a logistic regression model earthworms.m1 <- drm(number/total~dose, weights = total, data = earthworms, fct = LL.2(), type = ""binomial"") modelFit(earthworms.m1) # a crude goodness-of-fit test ## Fitting an extended logistic regression model ## where the upper limit is estimated earthworms.m2 <- drm(number/total~dose, weights = total, data = earthworms, fct = LL.3(), type = ""binomial"") modelFit(earthworms.m2) # goodness-of-fit test # improvement not visible in test!!! ## Comparing model1 and model2 ## (Can the first model be reduced to the second model?) anova(earthworms.m1, earthworms.m2)"
"drc-etmotc","drc","etmotc","Effect of erythromycin on mixed sewage microorganisms",57,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/etmotc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/etmotc.html","etmotc R Documentation   Effect of erythromycin on mixed sewage microorganisms   Description  
Relative growth rate in biomass of mixed sewage microorganisms (per hour) as a function of increasing concentrations of the antibiotic erythromycin (mg/l).    Usage   data(etmotc)   Format  
A data frame with 57 observations on the following 4 variables.    cell
a numeric vector   dose1
a numeric vector   pct1
a numeric vector   rgr1
a numeric vector     Details  
Data stem from an experiment investigating the effect of pharmaceuticals, that are used in human and veterinary medicine and that are being released into the aquatic environment through waste water or through manure used for fertilising agricultural land. The experiment constitutes a typical dose-response situation. The dose is concentration of the antibiotic erythromycin (mg/l), which is an antibiotic that can be used by persons or animals showing allergy to penicillin, and the measured response is the relative growth rate in biomass of mixed sewage microorganisms (per hour), measured as turbidity two hours after exposure by means of a spectrophotometer. The experiment was designed in such a way that eight replicates were assigned to the control (dose 0), but no replicates were assigned to the 7 non-zero doses. Further details are found in Christensen et al (2006).    Source  
Christensen, A. M. and Ingerslev, F. and Baun, A. 2006 Ecotoxicity of mixtures of antibiotics used in aquacultures, Environmental Toxicology and Chemistry , 25 , 2208–2215.    Examples    etmotc.m1<-drm(rgr1~dose1, data=etmotc[1:15,], fct=LL.4()) plot(etmotc.m1) modelFit(etmotc.m1) summary(etmotc.m1) etmotc.m2<-drm(rgr1~dose1, data=etmotc[1:15,], fct=W2.4()) plot(etmotc.m2, add = TRUE) modelFit(etmotc.m2) summary(etmotc.m2) etmotc.m3<-drm(rgr1~dose1, data=etmotc[1:15,], fct=W2.3()) plot(etmotc.m3, add = TRUE) modelFit(etmotc.m3) summary(etmotc.m3)"
"drc-finney71","drc","finney71","Example from Finney (1971)",6,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/finney71.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/finney71.html","finney71 R Documentation   Example from Finney (1971)   Description  
For each of six concentration of an insecticid the number of insects affected (out of the number of insects) was recorded.    Usage   data(finney71)   Format  
A data frame with 6 observations on the following 3 variables.    dose
a numeric vector   total
a numeric vector   affected
a numeric vector     Source  
Finney, D. J. (1971) Probit Analysis , Cambridge: Cambridge University Press.    Examples    ## Model with ED50 as a parameter finney71.m1 <- drm(affected/total ~ dose, weights = total, data = finney71, fct = LL.2(), type = ""binomial"") summary(finney71.m1) plot(finney71.m1, broken = TRUE, bp = 0.1, lwd = 2) ED(finney71.m1, c(10, 20, 50), interval = ""delta"", reference = ""control"") ## Model fitted with 'glm' #fitl.glm <- glm(cbind(affected, total-affected) ~ log(dose), #family=binomial(link = logit), data=finney71[finney71$dose != 0, ]) #summary(fitl.glm) # p-value almost agree for the b parameter # #xp <- dose.p(fitl.glm, p=c(0.50, 0.90, 0.95)) # from MASS #xp.ci <- xp + attr(xp, ""SE"") %*% matrix(qnorm(1 - 0.05/2)*c(-1,1), nrow=1) #zp.est <- exp(cbind(xp.ci[,1],xp,xp.ci[,2])) #dimnames(zp.est)[[2]] <- c(""zp.lcl"",""zp"",""zp.ucl"") #zp.est # not far from above results with 'ED' ## Model with log(ED50) as a parameter finney71.m2 <- drm(affected/total ~ dose, weights = total, data = finney71, fct = LL2.2(), type = ""binomial"") ## Confidence intervals based on back-transformation ## complete agreement with results based on 'glm' ED(finney71.m2, c(10, 20, 50), interval = ""fls"", reference = ""control"")"
"drc-G.aparine","drc","G.aparine","Herbicide applied to Galium aparine",240,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/G.aparine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/G.aparine.html","G.aparine R Documentation   Herbicide applied to Galium aparine   Description  
Small plants of Galium aparine , growing in pots in a green house, were sprayed with the technical grade phenmidipham herbicide either alone or in mixture with an ester of oleic acid. The plants were allowed to grow in the green house for 14 days after herbicide treatment. Then the dry matter was measured per pot.    Usage   data(G.aparine)   Format  
A data frame with 240 observations on the following 3 variables.    dose
a numeric vector of dose value (g/ha)   drymatter
a numeric vector of dry matter weights (mg/pot)   treatment
a numeric vector giving the grouping: 0: control, 1,2: herbicide formulations     Source  
Cabanne, F., Gaudry, J. C. and Streibig, J. C. (1999) Influence of alkyl oleates on efficacy of phenmedipham applied as an acetone:water solution on Galium aparine, Weed Research , 39 , 57–67.    Examples    ## Fitting a model with a common control (so a single upper limit: ""1"") G.aparine.m1 <- drm(drymatter ~ dose, treatment, data = G.aparine, pmodels = data.frame(treatment, treatment, 1, treatment), fct = LL.4()) ## Visual inspection of fit plot(G.aparine.m1, broken = TRUE) ## Lack of fit test modelFit(G.aparine.m1) ## Summary output summary(G.aparine.m1) ## Predicted values with se and confidence intervals #predict(G.aparine.m1, interval = ""confidence"") # long output ## Calculating the relative potency EDcomp(G.aparine.m1, c(50,50)) ## Showing the relative potency as a ## function of the response level relpot(G.aparine.m1) relpot(G.aparine.m1, interval = ""delta"") # appears constant! ## Response level in percent relpot(G.aparine.m1, scale = ""percent"") ## Fitting a reduced model (with a common slope parameter) G.aparine.m2 <- drm(drymatter ~ dose, treatment, data = G.aparine, pmodels = data.frame(1, treatment, 1, treatment), fct = LL.4()) anova(G.aparine.m2, G.aparine.m1) ## Showing the relative potency relpot(G.aparine.m2) ## Fitting the same model in a different parameterisation G.aparine.m3 <- drm(drymatter ~ dose, treatment, data = G.aparine, pmodels = data.frame(treatment, treatment, 1, treatment), fct = LL2.4()) EDcomp(G.aparine.m3, c(50, 50), logBase = exp(1))"
"drc-germination","drc","germination","Germination of three crops",192,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/germination.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/germination.html","germination R Documentation    Germination of three crops    Description  
Germination data were obtained from experiments involving the three species mungbean, rice, and wheat, which were opposed to different temperatures between 10 and 40 degrees Celsius. Experiments lasted at most 18 days.    Usage   data(germination)   Format  
A data frame with 192 observations on the following 5 variables.    temp
a numeric vector of temperatures that seeds were exposed to   species
a factor with levels mungbean rice wheat   start
a numeric vector of left endpoints of the monitoring intervals   end
a numeric vector of right endpoints of the monitoring intervals   germinated
a numeric vector giving the numbers of seeds germinated     Details  
For each of the three species mungbean, rice, and wheat, a total of 20 seeds were uniformly distributed on filter paper in a petri dish (diameter: 9.0cm) and then placed in dark climate cabinets with different temperatures (10, 16, 22, 28, 34, 40 degrees Celsius). Not all of the temperatures were applied to all species. The germinated seeds were counted and removed from the petri dish on a daily basis up to 18 days (or until all seeds had germinated). I   
n this experiment we also assume that the upper limit of the proportion germinated is a parameter that has to be estimated from the data. Moreover, we assume that different combinations of species and temperature may lead to different germination curves with respect to slope, time required for 50% germination, and upper limit.    References  
Ritz, C., Pipper, C. B. and Streibig, J. C. (2013) Analysis of germination data from agricultural experiments, Europ. J. Agronomy , 45 , 1–6.   See Also  
Analysis of a single germination curve is shown for chickweed .   Examples    ## Fitting two-parameter log-logistic curves to each combination of species and temperature ## (upper limit fixed at 1) ## Note: Rows 24 and 62 are omitted from the dataset (all mungbean seeds germinated ## and thus no right-censoring in this case) ## germLL.2 <- drm(germinated ~ start + end, species:factor(temp), ## data = germination[c(1:23, 25:61, 63:192), ], fct = LL.2(), type = ""event"") ## plot(germLL.2, ylim=c(0, 1.5), legendPos=c(2.5,1.5)) # plotting the fitted curves and the data ## summary(germLL.2) # showing the parameter estimates ## Fitting two-parameter log-logistic curves to each combination of species and temperature ## Note: the argument ""start"" may be used for providing sensible initial ## parameter values for estimation procedure (is needed occasionally) ## (initial values were obtained from the model fit germLL.2) ## Note also: the argument ""upper"" ensures that the upper limit cannot exceed 1 ## (however, no restrictions are imposed on the two remaining parameters ## (as indicated by an infinite value) ## germLL.3 <- drm(germinated~start+end, species:factor(temp), ## data = germination[c(1:23, 25:61, 63:192), ], fct = LL.3(), type = ""event"", ## start = c(coef(germLL.2)[1:13], rep(0.7,13), coef(germLL.2)[14:26]), ## upper = c(rep(Inf, 13), rep(1, 13), rep(Inf, 13))) ## Plotting the fitted curves and the data ## plot(germLL.3, ylim = c(0, 1.5), legendPos = c(2.5,1.5)) ## Showing the parameter estimates ## summary(germLL.3) ## Showing the parameter estimates with robust standard errors ## library(lmtest) ## coeftest(germLL.3, vcov = sandwich) ## Calculating t50 with associated standard errors ## ED(germLL.3, 50) ## Calculating t10, t20, t50 with 95% confidence intervals ## ED(germLL.3, c(10, 20, 50), interval = ""delta"") ## Comparing t50 between combinations by means of approximate t-tests ## compParm(germLL.3, ""e"", ""-"") ## Making plots of fitted regression curves for each species ## Plot for mungbean #plot(germLL.3, log="""", ylim=c(0, 1), xlim=c(0, 20), #level=c(""mungbean:10"", ""mungbean:16""), #lty=2:3, lwd = 1.5, #xlab=""Time (days)"", #ylab=""Proportion germinated"", #main=""Mungbean"", #legendPos=c(3, 1.05), legendText=c(expression(10*degree), expression(16*degree))) ## Plot for rice #plot(germLL.3, log="""", ylim=c(0, 1), xlim=c(0, 20), #level=c(""rice:16"", ""rice:22"", ""rice:28"", ""rice:34"", ""rice:40""), #lty=2:6, lwd = 1.5, #xlab=""Time (days)"", #ylab=""Proportion germinated"", #main=""Rice"", #pch=2:6, #legendPos=c(3, 1.05), legendText=c(expression(16*degree), expression(22*degree), #expression(28*degree), expression(34*degree), expression(40*degree))) ## Plot for wheat #plot(germLL.3, log="""", ylim=c(0, 1), xlim=c(0, 20), #level=c(""wheat:10"", ""wheat:16"", ""wheat:22"", ""wheat:28"", ""wheat:34"", ""wheat:40""), #lty=c(""dashed"",""dotted"",""dotdash"",""longdash"",""twodash"",""232A""), lwd = 1.5, #xlab=""Time (days)"", #ylab=""Proportion germinated"", #main=""Wheat"", #legendPos=c(3, 1.05), #legendText=c(expression(10*degree), expression(16*degree), expression(22*degree), #expression(28*degree), expression(34*degree), expression(40*degree)))"
"drc-glymet","drc","glymet","Glyphosate and metsulfuron-methyl tested on algae.",113,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/glymet.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/glymet.html","glymet R Documentation   Glyphosate and metsulfuron-methyl tested on algae.   Description  
The dataset has 7 mixtures, 8 dilutions, two replicates and 5 common control controls. Four observations are missing, giving a total of 113 observations.    Usage   data(glymet)   Format  
A data frame with 113 observations on the following 3 variables.    dose
a numeric vector of dose values   pct
a numeric vector denoting the grouping according to the mixtures percentages   rgr
a numeric vector of response values (relative growth rates)     Details  
The dataset is analysed in Soerensen et al (2007). The concentration addition model can be entertained for this dataset.    Source  
The dataset is kindly provided by Nina Cedergreen, Department of Agricultural Sciences, Royal Veterinary and Agricultural University, Denmark.    References  
Soerensen, H. and Cedergreen, N. and Skovgaard, I. M. and Streibig, J. C. (2007) An isobole-based statistical model and test for synergism/antagonism in binary mixture toxicity experiments, Environmental and Ecological Statistics , 14 , 383–397.    Examples    ## Fitting the model with freely varying ED50 values glymet.free <- drm(rgr~dose, pct, data = glymet, fct = LL.3(), pmodels = list(~factor(pct) , ~1, ~factor(pct))) ## Lack-of-fit test modelFit(glymet.free) # acceptable summary(glymet.free) ## Plotting isobole structure isobole(glymet.free, exchange=0.01) ## Fitting the concentration addition model glymet.ca <- mixture(glymet.free, model = ""CA"") ## Comparing to model with freely varying e parameter anova(glymet.ca, glymet.free) # borderline accepted ## Plotting isobole based on concentration addition isobole(glymet.free, glymet.ca, exchange = 0.01) # acceptable fit ## Fitting the Hewlett model glymet.hew <- mixture(glymet.free, model = ""Hewlett"") ### Comparing to model with freely varying e parameter anova(glymet.ca, glymet.hew) # borderline accepted # the Hewlett model offers no improvement over concentration addition ## Plotting isobole based on the Hewlett model isobole(glymet.free, glymet.hew, exchange = 0.01) # no improvement over concentration addition"
"drc-H.virescens","drc","H.virescens","Mortality of tobacco budworms",12,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/H.virescens.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/H.virescens.html","H.virescens R Documentation   Mortality of tobacco budworms   Description  
For three days, moths of the tobacco budworm ( Heliothis virescens ) were exposed to doses of the pyrethroid trans-cypermethrin.    Usage   data(H.virescens)   Format  
A data frame with 12 observations on the following 4 variables.    dose
a numeric vector of dose values ( μ g )   numdead
a numeric vector of dead or knocked-down moths   total
a numeric vector of total number of moths   sex
a factor with levels F M denoting a grouping according to sex     Details  
In Venables and Ripley (2002), these data are analysed using a logistic regression with base-2 logarithm of dose as explanatory variable.    Source  
Venables, W. N. and Ripley, B. D (2002) Modern Applied Statistics with S , New York: Springer (fourth edition).    Examples    ## Fitting dose-response model (log-logistic with common slope) Hv.m1 <- drm(numdead/total~dose, sex, weights = total, data = H.virescens, fct = LL.2(), pmodels = list(~ 1, ~ sex - 1), type = ""binomial"") summary(Hv.m1) ## Fitting the same model as in Venables and Riply (2002) Hv.m2 <- glm(cbind(numdead, total-numdead) ~ sex + I(log2(dose)) - 1, data = H.virescens, family = binomial) ## Comparing the fits logLik(Hv.m1) logLik(Hv.m2) ## Estimated ED values (matching those given in MASS) ED(Hv.m1, c(25, 50, 75))"
"drc-heartrate","drc","heartrate","Heart rate baroreflexes for rabbits",18,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/heartrate.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/heartrate.html","heartrate R Documentation   Heart rate baroreflexes for rabbits   Description  
The dataset contains measurements of mean arterial pressure (mmHG) and heart rate (b/min) for a baroreflex curve.    Usage   data(heartrate)   Format  
A data frame with 18 observations on the following 2 variables.    pressure
a numeric vector containing measurements of arterial pressure.   rate
a numeric vector containing measurements of heart rate.     Details  
The dataset is an example of an asymmetric dose-response curve, that is not easily handled using the log-logistic or Weibull models ( LL.4 , LL.5 , W1.4 and W2.4 ), whereas the baro5 model provides a nice fit.    Source  
Ricketts, J. H. and Head, G. A. (1999) A five-parameter logistic equation for investigating asymmetry of curvature in baroreflex studies, Am. J. Physiol. (Regulatory Integrative Comp. Physiol. 46) , 277 , 441–454.    Examples    ## Fitting the baro5 model heartrate.m1 <- drm(rate~pressure, data=heartrate, fct=baro5()) plot(heartrate.m1) coef(heartrate.m1) #Output: #b1:(Intercept) b2:(Intercept) c:(Intercept) d:(Intercept) e:(Intercept) # 11.07984 46.67492 150.33588 351.29613 75.59392 ## Inserting the estimated baro5 model function in deriv() baro5Derivative <- deriv(~ 150.33588 + ((351.29613 - 150.33588)/ (1 + (1/(1 + exp((2 * 11.07984 * 46.67492/(11.07984 + 46.67492)) * (log(x) - log(75.59392 ))))) * (exp(11.07984 * (log(x) - log(75.59392)))) + (1 - (1/(1 + exp((2 * 11.07984 * 46.67492/(11.07984 + 46.67492)) * (log(x) - log(75.59392 )))))) * (exp(46.67492 * (log(x) - log(75.59392 )))))), ""x"", function(x){}) ## Plotting the derivative #pressureVector <- 50:100 pressureVector <- seq(50, 100, length.out=300) derivativeVector <- attr(baro5Derivative(pressureVector), ""gradient"") plot(pressureVector, derivativeVector, type = ""l"") ## Finding the minimum pressureVector[which.min(derivativeVector)]"
"drc-leaflength","drc","leaflength","Leaf length of barley",42,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/leaflength.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/leaflength.html","leaflength R Documentation   Leaf length of barley   Description  
In an experiment barley was grown in a hydroponic solution with a herbicide.    Usage   data(leaflength)   Format  
A data frame with 42 observations on the following 2 variables.    Dose
a numeric vector   DW
a numeric vector     Details  
The dataset exhibits a large hormetical effect.    Source  
Nina Cedergreen, Royal Veterinary and Agricultural University, Denmark.    Examples    ## Fitting a hormesis model leaflength.crs4c1 <- drm(DW ~ Dose, data = leaflength, fct = CRS.4c()) plot(fitted(leaflength.crs4c1), residuals(leaflength.crs4c1)) leaflength.crs4c2 <- boxcox(drm(DW ~ Dose, data = leaflength, fct = CRS.4c()), method = ""anova"", plotit = FALSE) summary(leaflength.crs4c2) ## Plottinf fitted curve and original data plot(leaflength.crs4c2, broken = TRUE, conLevel = 0.001, type = ""all"", legend = FALSE, ylab = ""Produced leaf length (cm)"", xlab = ""Metsulfuron-methyl (mg/l)"", main = ""Hormesis: leaf length of barley"")"
"drc-lepidium","drc","lepidium","Dose-response profile of degradation of agrochemical using lepidium",42,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/lepidium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/lepidium.html","lepidium R Documentation   Dose-response profile of degradation of agrochemical using lepidium   Description  
Estimation of the degradation profile of an agrochemical based on soil samples at depth 0-10cm from a calibration experiment.    Usage   data(lepidium)   Format  
A data frame with 42 observations on the following 2 variables.    conc
a numeric vector of concentrations (g/ha)   weight
a numeric vector of plant weight (g) after 3 weeks' growth     Details  
It is an experiment with seven concentrations and six replicates per concentration. Lepidium  is rather robust as it only responds to high concentrations.    Source  
Racine-Poon, A. (1988) A Bayesian Approach to Nonlinear Calibration Problems, J. Am. Statist. Ass. , 83 , 650–656.    Examples    lepidium.m1 <- drm(weight~conc, data=lepidium, fct = LL.4()) modelFit(lepidium.m1) plot(lepidium.m1, type = ""all"", log = """")"
"drc-lettuce","drc","lettuce","Hormesis in lettuce plants",14,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/lettuce.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/lettuce.html","lettuce R Documentation   Hormesis in lettuce plants   Description  
Data are from an experiment where isobutylalcohol was dissolved in a nutrient solution in which lettuce ( Lactuca sativa ) plants were grown. The plant biomass of the shoot was determined af 21 days.    Usage   data(lettuce)   Format  
A data frame with 14 observations on the following 2 variables.    conc
a numeric vector of concentrations of isobutylalcohol (mg/l)   weight
a numeric vector of biomass of shoot (g)     Details  
The data set illustrates hormesis, presence of a subtoxic stimulus at low concentrations.    Source  
van Ewijk, P. H. and Hoekstra, J. A. (1993) Calculation of the EC50 and its Confidence Interval When Subtoxic Stimulus Is Present,  ECOTOXICOLOGY AND ENVIRONMENTAL SAFETY , 25 , 25–32.    References  
van Ewijk, P. H. and Hoekstra, J. A. (1994) Curvature Measures and Confidence Intervals for the Linear Logistic Model,  Appl. Statist. , 43 , 477–487.    Examples    ## Look at data lettuce ## Monotonous dose-response model lettuce.m1 <- drm(weight~conc, data=lettuce, fct=LL.3()) plot(lettuce.m1, broken = TRUE) ## Model fit in van Ewijk and Hoekstra (1994) lettuce.m2 <- drm(weight~conc, data=lettuce, fct=BC.4()) modelFit(lettuce.m2) plot(lettuce.m2, add = TRUE, broken = TRUE, type = ""none"", lty = 2) ## Hormesis effect only slightly significant summary(lettuce.m2) ## Hormesis effect highly significant ## compare with t-test for the ""f"" parameter in the summary output) anova(lettuce.m1, lettuce.m2)"
"drc-M.bahia","drc","M.bahia","Effect of an effluent on the growth of mysid shrimp",40,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/M.bahia.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/M.bahia.html","M.bahia R Documentation   Effect of an effluent on the growth of mysid shrimp   Description  
Juvenile mysid shrimp ( Mysidopsis bahia ) were exposed to up to 32% effluent in a 7-day survival and growth test. The average weight per treatment replicate of surviving organisms was measured.    Usage   data(M.bahia)   Format  
A data frame with 40 observations on the following 2 variables.    conc
a numeric vector of effluent concentrations (%)   dryweight
a numeric vector of average dry weights (mg)     Details  
The data are analysed in Bruce and Versteeg (1992) using a log-normal dose-response model (using the logarithm with base 10).   
At 32% there was complete mortality, and this justifies using a model where a lower asymptote of 0 is assumed.    Source  
Bruce, R. D. and Versteeg, D. J. (1992) A statistical procedure for modeling continuous toxicity data,  Environ. Toxicol. Chem. , 11 , 1485–1494.    Examples    M.bahia.m1 <- drm(dryweight~conc, data=M.bahia, fct=LN.3()) ## Variation increasing plot(fitted(M.bahia.m1), residuals(M.bahia.m1)) ## Using transform-both-sides approach M.bahia.m2 <- boxcox(M.bahia.m1, method = ""anova"") summary(M.bahia.m2) # logarithm transformation ## Variation roughly constant, but still not a great fit plot(fitted(M.bahia.m2), residuals(M.bahia.m2)) ## Visual comparison of fits plot(M.bahia.m1, type=""all"", broken=TRUE) plot(M.bahia.m2, add=TRUE, type=""none"", broken=TRUE, lty=2) ED(M.bahia.m2, c(10,20,50), ci=""fls"") ## A better fit M.bahia.m3 <- boxcox(update(M.bahia.m1, fct = LN.4()), method = ""anova"") #plot(fitted(M.bahia.m3), residuals(M.bahia.m3)) plot(M.bahia.m3, add=TRUE, type=""none"", broken=TRUE, lty=3, col=2) ED(M.bahia.m3, c(10,20,50), ci=""fls"")"
"drc-mecter","drc","mecter","Mechlorprop and terbythylazine tested on Lemna minor",102,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/mecter.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/mecter.html","mecter R Documentation   Mechlorprop and terbythylazine tested on Lemna minor   Description  
Data consist of 5 mixture, 6 dilutions, three replicates, and 12 common controls; in total 102 onservations.    Usage   data(mecter)   Format  
A data frame with 102 observations on the following 3 variables.    dose
a numeric vector of dose values   pct
a numeric vector denoting the grouping according to the mixtures percentages   rgr
a numeric vector of response values (relative growth rates)     Details  
The dataset is analysed in Soerensen et al (2007). The asymmetric Voelund model is appropriate, whereas the symmetric Hewlett model is not.    Source  
The dataset is kindly provided by Nina Cedergreen, Department of Agricultural Sciences, Royal Veterinary and Agricultural University, Denmark.    References  
Soerensen, H. and Cedergreen, N. and Skovgaard, I. M. and Streibig, J. C. (2007) An isobole-based statistical model and test for synergism/antagonism in binary mixture toxicity experiments, Environmental and Ecological Statistics , 14 , 383–397.    Examples    ## Fitting the model with freely varying ED50 values mecter.free <- drm(rgr ~ dose, pct, data = mecter, fct = LL.4(), pmodels = list(~1, ~1, ~1, ~factor(pct) - 1)) ## Lack-of-fit test modelFit(mecter.free) # not really acceptable summary(mecter.free) ## Plotting isobole structure isobole(mecter.free, exchange = 0.02) ## Fitting the concentration addition model mecter.ca <- mixture(mecter.free, model = ""CA"") ## Comparing to model with freely varying e parameter anova(mecter.ca, mecter.free) # rejected ## Plotting isobole based on concentration addition isobole(mecter.free, mecter.ca, exchange = 0.02) # poor fit ## Fitting the Hewlett model mecter.hew <- mixture(mecter.free, model = ""Hewlett"") ## Comparing to model with freely varying e parameter anova(mecter.hew, mecter.free) # rejected ## Plotting isobole based on the Hewlett model isobole(mecter.free, mecter.hew, exchange = 0.02) # poor fit ## Fitting the Voelund model mecter.voe<-mixture(mecter.free, model = ""Voelund"") ## Comparing to model with freely varying e parameter anova(mecter.voe, mecter.free) # accepted ## Plotting isobole based on the Voelund model isobole(mecter.free, mecter.voe, exchange = 0.02) # good fit"
"drc-metals","drc","metals","Data from heavy metal mixture experiments",543,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/metals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/metals.html","metals R Documentation    Data from heavy metal mixture experiments    Description  
Data are from a study of the response of the cyanobacterial self-luminescent metallothionein-based whole-cell biosensor Synechoccocus elongatus PCC 7942 pBG2120 to binary mixtures of 6 heavy metals (Zn, Cu, Cd, Ag, Co and Hg).    Usage   data(""metals"")   Format  
A data frame with 543 observations on the following 3 variables.    metal
a factor with levels Ag AgCd Cd Co CoAg CoCd Cu CuAg CuCd CuCo CuHg CuZn Hg HgCd HgCo Zn ZnAg ZnCd ZnCo ZnHg   conc
a numeric vector of concentrations   BIF
a numeric vector of luminescence induction factors     Details  
Data are from the study described by Martin-Betancor et al. (2015).    Source  
Martin-Betancor, K. and Ritz, C. and Fernandez-Pinas, F. and Leganes, F. and Rodea-Palomares, I. (2015) Defining an additivity framework for mixture research in inducible whole-cell biosensors,  Scientific Reports   17200 .   Examples    ## One example from the paper by Martin-Betancor et al (2015) ## Figure 2 ## Fitting a model for ""Zn"" Zn.lgau <- drm(BIF ~ conc, data = subset(metals, metal == ""Zn""), fct = lgaussian(), bcVal = 0, bcAdd = 10) ## Plotting data and fitted curve plot(Zn.lgau, log = """", type = ""all"", xlab = expression(paste(plain(""Zn"")^plain(""2+""), "" "", mu, """", plain(""M"")))) ## Calculating effective doses ED(Zn.lgau, 50, interval = ""delta"") ED(Zn.lgau, -50, interval = ""delta"", bound = FALSE) ED(Zn.lgau, 99.999,interval = ""delta"") # approx. for ED0 ## Fitting a model for ""Cu"" Cu.lgau <- drm(BIF ~ conc, data = subset(metals, metal == ""Cu""), fct = lgaussian()) ## Fitting a model for the mixture Cu-Zn CuZn.lgau <- drm(BIF ~ conc, data = subset(metals, metal == ""CuZn""), fct = lgaussian()) ## Calculating effects needed for the FA-CI plot CuZn.effects <- CIcompX(0.015, list(CuZn.lgau, Cu.lgau, Zn.lgau), c(-5, -10, -20, -30, -40, -50, -60, -70, -80, -90, -99, 99, 90, 80, 70, 60, 50, 40, 30, 20, 10)) ## Reproducing the FA-cI plot shown in Figure 5d plotFACI(CuZn.effects, ""ED"", ylim = c(0.8, 1.6), showPoints = TRUE)"
"drc-methionine","drc","methionine","Weight gain for different methionine sources",9,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/methionine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/methionine.html","methionine R Documentation   Weight gain for different methionine sources   Description  
Data consist of average body weight gain of chickens being treated with one of the two methionine sources DLM and HMTBA.    Usage   data(methionine)   Format  
A data frame with 9 observations on the following 3 variables:    product
a factor with levels control , DLM and MHA denoting the treatments   dose
a numeric vector of methionine dose   gain
a numeric vector of average body weight gain     Details  
The dataset contains a common control measurement for the two treatments. More examples using this dataset are found under AR.2 and MM.2 .    Source  
Kratzer. D. D. and Littell, R. C. (2006) Appropriate Statistical Methods to Compare Dose Responses of Methionine Sources, Poultry Science , 85 , 947–954.    Examples    ## Fitting model with constraint on one parameter met.ar.m1 <- drm(gain~dose, product, data = methionine, fct = AR.3(), pmodels = list(~1, ~factor(product), ~factor(product)), upperl = c(Inf, Inf, 1700, Inf, Inf)) plot(met.ar.m1, xlim=c(0,0.3), ylim=c(1450, 1800)) abline(h=1700, lty=1) summary(met.ar.m1)"
"drc-nasturtium","drc","nasturtium","Dose-response profile of degradation of agrochemical using nasturtium",42,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/nasturtium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/nasturtium.html","nasturtium R Documentation   Dose-response profile of degradation of agrochemical using nasturtium   Description  
Estimation of the degradation profile of an agrochemical based on soil samples at depth 0-10cm from a calibration experiment.    Usage   data(nasturtium)   Format  
A data frame with 42 observations on the following 2 variables.    conc
a numeric vector of concentrations (g/ha)   weight
a numeric vector of plant weight (mg) after 3 weeks' growth     Details  
It is an experiment with seven concentrations and six replicates per concentration. Nasturtium  is sensitive and its weight reduces noticeable at low concentrations.   
Racine-Poon (1988) suggests using a three-parameter log-logistic model.    Source  
Racine-Poon, A. (1988) A Bayesian Approach to Nonlinear Calibration Problems, J. Am. Statist. Ass. , 83 , 650–656.    Examples    nasturtium.m1 <- drm(weight~conc, data=nasturtium, fct = LL.3()) modelFit(nasturtium.m1) plot(nasturtium.m1, type = ""all"", log = """", xlab = ""Concentration (g/ha)"", ylab = ""Weight (mg)"")"
"drc-O.mykiss","drc","O.mykiss","Test data from a 21 day fish test",70,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/O.mykiss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/O.mykiss.html","O.mykiss R Documentation   Test data from a 21 day fish test   Description  
Test data from a 21 day fish test following the guidelines OECD GL204, using the test organism Rainbow trout Oncorhynchus mykiss .    Usage   data(O.mykiss)   Format  
A data frame with 70 observations on the following 2 variables.    conc
a numeric vector of concentrations (mg/l)   weight
a numeric vector of wet weights (g)     Details  
Weights are measured after 28 days.    Source  
Organisation for Economic Co-operation and Development (OECD) (2006)  CURRENT APPROACHES IN THE STATISTICAL ANALYSIS OF ECOTOXICITY DATA: A GUIDANCE TO APPLICATION - ANNEXES , Paris (p. 65).    References  
Organisation for Economic Co-operation and Development (OECD) (2006)  CURRENT APPROACHES IN THE STATISTICAL ANALYSIS OF ECOTOXICITY DATA: A GUIDANCE TO APPLICATION - ANNEXES , Paris (pp. 80–85).    Examples    head(O.mykiss) ## Fitting exponential model O.mykiss.m1 <- drm(weight ~ conc, data = O.mykiss, fct = EXD.2(), na.action = na.omit) modelFit(O.mykiss.m1) summary(O.mykiss.m1) ## Fitting same model with transform-both-sides approach O.mykiss.m2 <- boxcox(O.mykiss.m1 , method = ""anova"") summary(O.mykiss.m2) # no need for a transformation ## Plotting the fit plot(O.mykiss.m1, type = ""all"", xlim = c(0, 500), ylim = c(0,4), xlab = ""Concentration (mg/l)"", ylab = ""Weight (g)"", broken = TRUE)"
"drc-P.promelas","drc","P.promelas","Effect of sodium pentachlorophenate on growth of fathead minnow",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/P.promelas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/P.promelas.html","P.promelas R Documentation   Effect of sodium pentachlorophenate on growth of fathead minnow   Description  
Fathead minnows ( Pimephales promelas ) were exposed to sodium pentachlorophenate concentrations ranging from 32 to 512 micro g/L in a 7-day larval survival and growth test. The average dry weight was measured.    Usage   data(P.promelas)   Format  
A data frame with 24 observations on the following 2 variables.    conc
a numeric vector of sodium pentachlorophenate concentrations (micro g/L).   dryweight
a numeric vector dry weights (mg)     Details  
The data are analysed in Bruce and Versteeg (1992) using a log-normal dose-response model (using the logarithm with base 10).    Source  
Bruce, R. D. and Versteeg, D. J. (1992) A statistical procedure for modeling continuous toxicity data,  Environ. Toxicol. Chem. , 11 , 1485–1494.    Examples    ## Model with ED50 on log scale as parameter p.prom.m1<-drm(dryweight~conc, data=P.promelas, fct=LN.3()) plot(fitted(p.prom.m1), residuals(p.prom.m1)) plot(p.prom.m1, type=""all"", broken=TRUE, xlim=c(0,1000)) summary(p.prom.m1) ED(p.prom.m1, c(10,20,50), interval=""delta"") ## Model with ED50 as parameter p.prom.m2<-drm(dryweight~conc, data=P.promelas, fct=LN.3(loge=TRUE)) summary(p.prom.m2) ED(p.prom.m2, c(10,20,50), interval=""fls"")"
"drc-RScompetition","drc","RScompetition","Competition between two biotypes",49,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/RScompetition.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/RScompetition.html","RScompetition R Documentation   Competition between two biotypes   Description  
To assess the competitive ability between two biotypes of Lolium rigidum , one resistant to glyphosate and the other a sensitive wild type, the density of resistant and sensitive biotypes was counted after germination.    Usage   data(RScompetition)   Format  
A data frame with 49 observations on the following 3 variables.    z
a numeric vector with densities of the resistant biotype (plants/m2)   x
a numeric vector with densities of the sensitive biotype (plants/m2)   biomass
a numeric vector of biomass weight (g/plant)     Details  
A hyperbolic model (Jensen, 1993) is describing the data reasonably well.    Source  
The dataset is from Pedersen et al (2007).    References  
Jensen, J. E. (1993) Fitness of herbicide-resistant weed biotypes described by competition models, Proceedings of the 8th EWRS Symposium, 14-16 June, Braunschweig, Germany , 1 , 25–32.   
Pedersen, B. P. and Neve, P. and Andreasen, C. and Powles, S. (2007) Ecological fitness of a glyphosate resistant Lolium rigidum population: Growth and seed production along a competition gradient,  Basic and Applied Ecology , 8 , 258–268."
"drc-ryegrass","drc","ryegrass","Effect of ferulic acid on growth of ryegrass",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/ryegrass.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/ryegrass.html","ryegrass R Documentation   Effect of ferulic acid on growth of ryegrass   Description  
A single dose-response curve.    Usage   data(ryegrass)   Format  
A data frame with 24 observations on the following 2 variables.    rootl
a numeric vector of root lengths   conc
a numeric vector of concentrations of ferulic acid     Details  
The data are part of a study to investigate the joint action of phenolic acids on root growth inhibition of perennial ryegrass ( Lolium perenne L ).   
conc is the concentration of ferulic acid is in mM, and rootl is the root length of perennial ryegrass measured in cm.   Source  
Inderjit and J. C. Streibig, and M. Olofsdotter (2002) Joint action of phenolic acid mixtures and its significance in allelopathy research, Physiologia Plantarum , 114 , 422–428, 2002.    Examples    ## Displaying the data set ryegrass ## Fitting a four-parameter Weibull model (type 2) ryegrass.m1 <- drm(rootl ~ conc, data = ryegrass, fct = W2.4()) ## Displaying a summary of the model fit summary(ryegrass.m1) ## Plotting the fitted curve together with the original data plot(ryegrass.m1) ## Fitting a four-parameter Weibull model (type 1) ryegrass.m2 <- drm(rootl ~ conc, data = ryegrass, fct = W1.4()) plot(ryegrass.m2) ## Fitting a four-parameter log-logistic model ## with user-defined parameter names ryegrass.m3 <- drm(rootl ~ conc, data = ryegrass, fct = LL.4(names = c(""Slope"", ""Lower Limit"", ""Upper Limit"", ""ED50""))) summary(ryegrass.m3) ## Comparing log-logistic and Weibull models ## (Figure 2 in Ritz (2009)) ryegrass.m0 <- drm(rootl ~ conc, data = ryegrass, fct = LL.4()) ryegrass.m1 <- drm(rootl ~ conc, data = ryegrass, fct = W1.4()) ryegrass.m2 <- drm(rootl ~ conc, data = ryegrass, fct = W2.4()) plot(ryegrass.m0, broken=TRUE, xlab=""Dose (mM)"", ylab=""Root length (cm)"", lwd=2, cex=1.2, cex.axis=1.2, cex.lab=1.2) plot(ryegrass.m1, add=TRUE, broken=TRUE, lty=2, lwd=2) plot(ryegrass.m2, add=TRUE, broken=TRUE, lty=3, lwd=2) arrows(3, 7.5, 1.4, 7.5, 0.15, lwd=2) text(3,7.5, ""Weibull-2"", pos=4, cex=1.2) arrows(2.5, 0.9, 5.7, 0.9, 0.15, lwd=2) text(3,0.9, ""Weibull-1"", pos=2, cex=1.2)"
"drc-S.alba","drc","S.alba","Potency of two herbicides",68,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/S.alba.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/S.alba.html","S.alba R Documentation   Potency of two herbicides   Description  
Data are from an experiment, comparing the potency of the two herbicides glyphosate and bentazone in white mustard Sinapis alba .    Usage   data(S.alba)   Format  
A data frame with 68 observations on the following 3 variables.    Dose
a numeric vector containing the dose in g/ha.   Herbicide
a factor with levels Bentazone Glyphosate (the two herbicides applied).   DryMatter
a numeric vector containing the response (dry matter in g/pot).     Details  
The lower and upper limits for the two herbicides can be assumed identical, whereas slopes and ED50 values are different (in the log-logistic model).    Source  
Christensen, M. G. and Teicher, H. B., and Streibig, J. C. (2003) Linking fluorescence induction curve and biomass in herbicide screening, Pest Management Science ,  59 , 1303–1310.    See Also  
See the examples sections for drm and EDcomp .    Examples    ## Fitting a log-logistic model with ## common lower and upper limits S.alba.LL.4.1 <- drm(DryMatter~Dose, Herbicide, data=S.alba, fct = LL.4(), pmodels=data.frame(Herbicide,1,1,Herbicide)) summary(S.alba.LL.4.1) ## Applying the optimal transform-both-sides Box-Cox transformation ## (using the initial model fit) S.alba.LL.4.2 <- boxcox(S.alba.LL.4.1, method = ""anova"") summary(S.alba.LL.4.2) ## Plotting fitted regression curves together with the data plot(S.alba.LL.4.2)"
"drc-S.capricornutum","drc","S.capricornutum","Effect of cadmium on growth of green alga",18,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/S.capricornutum.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/S.capricornutum.html","S.capricornutum R Documentation   Effect of cadmium on growth of green alga   Description  
Green alga ( Selenastrum capricornutum ) was exposed to cadmium chloride concentrations ranging from 5 to 80 micro g/L in geometric progression in 4-day population growth test.    Usage   data(S.capricornutum)   Format  
A data frame with 18 observations on the following 2 variables.    conc
a numeric vector of cadmium chloride concentrations (micro g/L)   count
a numeric vector of algal counts (10000 x cells /ml)     Details  
The data are analysed in Bruce and Versteeg (1992) using a log-normal dose-response model (using the logarithm with base 10).    Source  
Bruce, R. D. and Versteeg, D. J. (1992) A statistical procedure for modeling continuous toxicity data,  Environ. Toxicol. Chem. , 11 , 1485–1494.    Examples    ## Fitting 3-parameter log-normal model s.cap.m1 <- drm(count ~ conc, data = S.capricornutum, fct = LN.3()) ## Residual plot plot(fitted(s.cap.m1), residuals(s.cap.m1)) ## Fitting model with transform-both-sides approach s.cap.m2 <- boxcox(s.cap.m1, method = ""anova"") summary(s.cap.m2) ## Residual plot after transformation (looks better) plot(fitted(s.cap.m2), residuals(s.cap.m2)) ## Calculating ED values on log scale ED(s.cap.m2, c(10, 20, 50), interval=""delta"") ## Fitting model with ED50 as parameter ## (for comparison) s.cap.m3 <- drm(count ~ conc, data = S.capricornutum, fct = LN.3(loge=TRUE)) s.cap.m4 <- boxcox(s.cap.m3, method = ""anova"") summary(s.cap.m4) ED(s.cap.m4, c(10, 20, 50), interval = ""fls"")"
"drc-secalonic","drc","secalonic","Root length measurements",7,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/secalonic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/secalonic.html","secalonic R Documentation   Root length measurements   Description  
Data stem from an experiment assessing the inhibitory effect of secalonic acids on plant growth.    Usage   data(secalonic)   Format  
A data frame with 7 observations on the following 2 variables:    dose
a numeric vector containing dose values (mM)   rootl
a numeric vector containing root lengths (cm)     Details  
For each dose the root length is an average three measurements.    Source  
Gong, X. and Zeng, R. and Luo, S. and Yong, C. and Zheng, Q. (2004) Two new secalonic acids from Aspergillus Japonicus and their allelopathic effects on higher plants,  Proceedings of International Symposium on Allelopathy Research and Application, 27-29 April, Shanshui, Guangdong, China (Editors: R. Zeng and S. Luo) , 209–217.   
Ritz, C (2009) Towards a unified approach to dose-response modeling in ecotoxicology  To appear in Environ Toxicol Chem .    Examples    ## Fitting a four-parameter log-logistic model secalonic.m1 <- drm(rootl ~ dose, data = secalonic, fct = LL.4()) summary(secalonic.m1) ## Fitting a three-parameter log-logistic model ## lower limit fixed at 0 secalonic.m2 <- drm(rootl ~ dose, data = secalonic, fct = LL.3()) summary(secalonic.m1) ## Comparing logistic and log-logistic models ## (Figure 1 in Ritz (2009)) secalonic.LL4 <- drm(rootl ~ dose, data = secalonic, fct = LL.4()) secalonic.L4 <- drm(rootl ~ dose, data = secalonic, fct = L.4()) plot(secalonic.LL4, broken=TRUE, ylim=c(0,7), xlab=""Dose (mM)"", ylab=""Root length (cm)"", cex=1.2, cex.axis=1.2, cex.lab=1.2, lwd=2) plot(secalonic.L4, broken=TRUE, ylim=c(0,7), add=TRUE, type=""none"", lty=2, lwd=2) abline(h=coef(secalonic.L4)[3], lty=3, lwd=2)"
"drc-selenium","drc","selenium","Data from toxicology experiments with selenium",25,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/selenium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/selenium.html","selenium R Documentation    Data from toxicology experiments with selenium    Description  
Comparison of toxicity of four types of selenium by means of dose-response analysis    Usage   data(selenium)   Format  
A data frame with 25 observations on the following 4 variables.    type
a numeric vector indicating the form of selenium applied   conc
a numeric vector of (total) selenium concentrations   total
a numeric vector containing the total number of flies   dead
a numeric vector containing the number of dead flies     Details  
The experiment is described in more details by Jeske et al. (2009).    Source  
Jeske, D. R., Xu, H. K., Blessinger, T., Jensen, P. and Trumble, J. (2009) Testing for the Equality of EC50 Values in the Presence of Unequal Slopes With Application to Toxicity of Selenium Types, Journal of Agricultural, Biological, and Environmental Statistics ,  14 , 469–483   Examples    ## Analysis similar to what is proposed in Jeske et al (2009) ## but simply using existing functionality in ""drc"" ## Fitting the two-parameter log-logistic model with unequal ED50 and slope sel.m1 <- drm(dead/total~conc, type, weights=total, data=selenium, fct=LL.2(), type=""binomial"") #sel.m1b <- drm(dead/total~conc, type, weights=total, data=selenium, fct=LN.2(), # type=""binomial"", start=c(1,1,1,1,50,50,50,50)) plot(sel.m1, ylim = c(0, 1.3)) summary(sel.m1) ## Testing for equality of slopes sel.m2 <- drm(dead/total~conc, type, weights=total, data=selenium, fct=LL.2(), type=""binomial"", pmodels=list(~1, ~factor(type)-1)) sel.m2b <- drm(dead/total~conc, type, weights=total, data=selenium, fct=LN.2(), type=""binomial"", pmodels=list(~1, ~factor(type)-1)) plot(sel.m2, ylim = c(0, 1.3)) summary(sel.m2) anova(sel.m2, sel.m1) # 48.654 #anova(sel.m2b, sel.m1b) # close to the value 48.46 reported in the paper ## Testing for equality of ED50 sel.m3<-drm(dead/total~conc, type, weights=total, data=selenium, fct=LL.2(), type=""binomial"", pmodels=list(~factor(type)-1, ~1)) #sel.m3b<-drm(dead/total~conc, type, weights=total, data=selenium, fct=LN.2(), # type=""binomial"", pmodels=list(~factor(type)-1, ~1), start=c(1,1,1,1,50)) plot(sel.m3, ylim = c(0, 1.3)) summary(sel.m3) anova(sel.m3, sel.m1) # 123.56 #anova(sel.m3b, sel.m1b) # not too far from the value 138.45 reported in the paper # (note that the estimation procedure is not exactly the same) # (and we use the log-logistic model instead of the log-normal model)"
"drc-spinach","drc","spinach","Inhibition of photosynthesis",105,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/spinach.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/spinach.html","spinach R Documentation   Inhibition of photosynthesis   Description  
Data from an experiment investigating the inhibition of photosynthesis in response to two synthetic photosystem II inhibitors, the herbicides diuron and bentazon. More specifically, the effect of oxygen consumption of thylakoid membranes (chloroplasts) from spinach was measured after incubation with the synthetic inhibitors in 5 assays, resulting in 5 dose-response curves.    Usage   data(spinach)   Format  
A data frame with 105 observations on the following four variables:    CURVE
a numeric vector specifying the assay or curve (a total of 5 independent assays where used in this experiment).   HERBICIDE
a character vector specifying the herbicide applied: bentazon or diuron.   DOSE
a numeric vector giving the herbicide concentration in muMol.   SLOPE
a numeric vector with the measured response: oxygen consumption of thylakoid membranes.     Details  
The experiment is described in more details by Streibig (1998).    Source  
Streibig, J. C. (1998) Joint action of natural and synthetic photosystem II inhibitors, Pesticide Science , 55 , 137–146.    Examples    ## Displaying the first rows in the dataset head(spinach) # displaying first 6 rows in the data set"
"drc-terbuthylazin","drc","terbuthylazin","The effect of terbuthylazin on growth rate",30,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/terbuthylazin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/terbuthylazin.html","terbuthylazin R Documentation   The effect of terbuthylazin on growth rate   Description  
Test on the effect of terbuthylazin on Lemna minor , performed on an aseptic culture according to the OECD-guidelines.   Usage   data(terbuthylazin)   Format  
A data frame with 30 observations on the following 2 variables.    dose
a numeric vector of dose values.   rgr
a numeric vector of relative growth rates.     Details  
Dose is  
μ l^{-1}  
and rgr is the relative growth rate of Lemna .   Source  
Cedergreen N. (2004). Unpublished bioassay data.    Examples    ## displaying first 6 rows of the data set head(terbuthylazin) ## Fitting log-logistic model terbuthylazin.m1 <- drm(rgr~dose, data = terbuthylazin, fct = LL.4()) summary(terbuthylazin.m1) ## Fitting log-logistic model ## with Box-Cox transformation terbuthylazin.m2 <- boxcox(terbuthylazin.m1, method = ""anova"") summary(terbuthylazin.m2)"
"drc-vinclozolin","drc","vinclozolin","Vinclozolin from AR in vitro assay",53,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/drc/vinclozolin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/drc/vinclozolin.html","vinclozolin R Documentation   Vinclozolin from AR in vitro assay   Description  
Dose-response experiment with vinclozolin in an AR reporter gene assay    Usage   data(vinclozolin)   Format  
A data frame with 53 observations on the following 3 variables.    exper
a factor with levels 10509 10821 10828 10904 11023 11106   conc
a numeric vector of concentrations of vinclozolin   effect
a numeric vector of luminescense effects     Details  
The basic dose-response experiment was repeated 6 times on different days. Chinese Hamster Ovary cells were exposed to various concentrations of vinclozolin for 22 hours and the resulting luminescense effects were recorded.   
Data are part of mixture experiment reported in Nellemann et al (2003).   Source  
Nellemann C., Dalgaard M., Lam H.R. and Vinggaard A.M. (2003) The combined effects of vinclozolin and procymidone do not deviate from expected additivity in vitro and in vivo , Toxicological Sciences , 71 , 251–262.    Examples    vinclozolin.m1 <- drm(effect~conc, exper, data=vinclozolin, fct = LL.3()) plot(vinclozolin.m1, xlim=c(0,50), ylim=c(0,2800), conLevel=1e-4) vinclozolin.m2 <- drm(effect~conc, data=vinclozolin, fct = LL.3()) plot(vinclozolin.m2, xlim=c(0,50), conLevel=1e-4, add=TRUE, type=""none"", col=""red"") ## Are the ED50 values indetical across experiments? vinclozolin.m3 <- update(vinclozolin.m1, pmodels=data.frame(exper, exper, 1)) anova(vinclozolin.m3, vinclozolin.m1) # No!"
"Ecdat-Accident","Ecdat","Accident","Ship Accidents",40,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Accident.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Accident.html","Accident R Documentation   Ship Accidents   Description  
a cross-section   
number of observations : 40    Usage   data(Accident)   Format  
A dataframe containing :    type
ship type, a factor with levels (A,B,C,D,E)   constr
year constructed, a factor with levels (C6064,C6569,C7074,C7579)   operate
year operated, a factor with levels (O6074,O7579)   months
measure of service amount   acc
accidents     Source  
McCullagh, P. and J. Nelder (1983) Generalized Linear Models , New York:Chapman and Hall.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F21.3.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-AccountantsAuditorsPct","Ecdat","AccountantsAuditorsPct","Accountants and Auditors in the US 1850-2016",31,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/AccountantsAuditorsPct.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/AccountantsAuditorsPct.html","AccountantsAuditorsPct R Documentation   Accountants and Auditors in the US 1850-2016   Description  
Accountants and auditors as a percent of the US labor force 1850 to 2016 updating the analysis in Wyatt and Hecker (2006).   Usage   data(AccountantsAuditorsPct)   Format  
a numeric vector of length 30 giving the percent of the US labor force in ""Accounting and Auditing"" each decade from 1850 to 2010 except for 1940 plus each year between 2011 and 2016.   Source  
This is based primarily on data extracted from the Integrated Public Use Microdata Series on 2018-09-01 with the computations documented in a vignette by this title in the Ecfun package.  
This updates the data on Accountants and Auditors in Wyatt and Hecker (2006). They relied primarily on data extracted from the Integrated Public Use Microdata Series . This follows the same methodology with two modifications:  
1. IPUMS provided no data for 1940. Wyatt and Hecker (2006) used Historical Statistics of the United States, Colonial Times to 1970, Bicentennial Edition, part 1 (U.S. Department of Commerce, Bureau of the Census, 1975) for 1910-1940. The current data set uses that source only for 1040.  
2. The IPUMS numbers showed an extreme jump from 1850 to 1860 followed by an even more extreme drop to 1870. The numbers in Sobek (2006) showed essentially the same behavior. Specifically, Sobek (2006) estimated the number of accountants and auditors in the US in those three years as 700, 1700, and 1200, and the labor force as 5277000, 8160800, and 12004200. These numbers give accountants and auditors as 0.013, 0.021, and 0.010 percent of the labor force, respectively for those three years. These numbers portray an incredible increase in the employment of accountants and auditors between 1850 and 1860 followed by a shocking decline the following decade. If, however, we swap the 1700 and 1200 between 1860 and 1870, the percentages become quite stable: 0.013, 0.015, and 0.014 percent, respectively.  
We use these latter numbers, even though the uncorrected numbers seem more consistent with the numbers obtained from IPUMS.   References  
Historical Statistics of the United States, Colonial Times to 1970, Bicentennial Edition, part 1 (U.S. Department of Commerce, Bureau of the Census, 1975)    
Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas, and Matthew Sobek (2018) IPUMS USA: Version 8.0 [dataset]. Minneapolis, MN: IPUMS .  
Matthew Sobek (2006) Chapter Ba. ""Labor Occupations"" in Susan B. Carter, ed.,  Historical Statistics of the United States, Cambridge U. Pr.    
Ian D. Wyatt and Daniel E. Hecker (2006)  ""Occupational changes during the 20th century"", Monthly Labor Review, March 2006, pp. 35-57     See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations   Examples    data(AccountantsAuditorsPct) plot(names(AccountantsAuditorsPct), AccountantsAuditorsPct, type='l', log='y', cex.axis=1.8) # for the version of this contributed to Wikimedia Commons"
"Ecdat-Airline","Ecdat","Airline","Cost for U.S. Airlines",90,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Airline.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Airline.html","Airline R Documentation   Cost for U.S. Airlines   Description  
a panel of 6 observations from 1970 to 1984   
number of observations : 90   
observation : production units   
country : United States    Usage   data(Airline)   Format  
A dataframe containing :    airline
airline   year
year   cost
total cost, in \$1,000   output
output, in revenue passenger miles, index number   pf
fuel price   lf
load factor, the average capacity utilization of the fleet     References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F7.1.    See Also  
Index.Source , Index.Economics ,  Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Airq","Ecdat","Airq","Air Quality for Californian Metropolitan Areas",30,6,1,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Airq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Airq.html","Airq R Documentation   Air Quality for Californian Metropolitan Areas   Description  
a cross-section from 1972   
number of observations : 30   
observation : regional   
country : United States    Usage   data(Airq)   Format  
A dataframe containing :    airq
indicator of air quality (the lower the better)   vala
value added of companies (in thousands of dollars)   rain
amount of rain (in inches)   coas
is it a coastal area ?   dens
population density (per square mile)   medi
average income per head (in US dollars)     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 4.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-bankingCrises","Ecdat","bankingCrises","Countries in Banking Crises",211,71,69,0,0,0,71,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/bankingCrises.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/bankingCrises.html","bankingCrises R Documentation    Countries in Banking Crises    Description  
A data.frame identifying which of 70 countries had a banking crisis each year 1800:2010. The first column is year . The remaining columns carry the names of the countries; those columns are 1 for years with banking crises and 0 otherwise.    Usage   data(bankingCrises)   Format  
A data.frame   Details  
This file was created using the following command:   
bankingCrises <- readFinancialCrisisFiles(FinancialCrisisFiles)    
HOWEVER: This function was in Ecfun 0.2-3 but was removed in 0.2-4. It used gdata::read.xls , and gdata  users were informed that gdata might be removed from CRAN, and any package that used it would also be removed. It seemed that the database that this function was designed to read may not have been updated, which suggested that it made sense to remove this function, because it there may not be any further need for it.  
This dataset is an update of a subset of the data used to create Figure 10.1. Capital Mobility and the Incidence of Banking Crises, All Countries, 1800-2008, Reinhart and Rogoff (2009, p. 156).   
The general upward trend visible in a plot of these data may be attributed to at least two different factors:  
(1) The gradual increase in the proportion of human labor that is monetized.  
(2) An increase in the general ability of cronies of those in power to gamble with other people's money in forming and bankrupting financial institutions. The marked feature of this plot is the virtual absence of banking crises during the period of the Bretton Woods agreement, 1944 to 1971. This period ended when US President Nixon in effect canceled the Bretton Woods agreement by taking the US off the silver standard.    Author(s)  
Spencer Graves   Source  
http://www.reinhartandrogoff.com     References  
Carmen M. Reinhart and Kenneth S. Rogoff (2009) This Time Is Different: Eight Centuries of Financial Folly, Princeton U. Pr.    Examples    data(bankingCrises) numberOfCrises <- rowSums(bankingCrises[-1], na.rm=TRUE) plot(bankingCrises$year, numberOfCrises, type='b') # Write to a file for Wikimedia Commons ## Not run: if(FALSE){ svg('bankingCrises.svg') plot(bankingCrises$year, numberOfCrises, type='b', cex.axis=2, las=1, xlab='', ylab='', bty='n', cex=0.5) abline(v=c(1945, 1971), lty='dashed', col='blue') text(1958, 14, 'Bretton Woods', srt=90, cex=2, col='blue') dev.off() } ## End(Not run)"
"Ecdat-Benefits","Ecdat","Benefits","Unemployment of Blue Collar Workers",4877,18,9,0,11,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Benefits.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Benefits.html","Benefits R Documentation   Unemployment of Blue Collar Workers   Description  
a cross-section from 1972   
number of observations : 4877   
observation : individuals   
country : United States    Usage   data(Benefits)   Format  
A time series containing :    stateur
state unemployment rate (in %)   statemb
state maximum benefit level   state
state of residence code   age
age in years   tenure
years of tenure in job lost   joblost  
a factor with levels (slack\_work,position\_abolished,seasonal\_job\_ended,other)    nwhite
non-white ?   school12
more than 12 years of school ?   sex
a factor with levels (male,female)   bluecol
blue collar worker ?   smsa
lives in SMSA ?   married
married ?   dkids
has kids ?   dykids
has young kids (0-5 yrs) ?   yrdispl 
year of job displacement (1982=1,..., 1991=10)    rr
replacement rate   head
is head of household ?   ui 
applied for (and received) UI benefits ?      Source  
McCall, B.P. (1995) “The impact of unemployment insurance benefit levels on recipiency”, Journal of Business and Economic Statistics , 13 , 189–198.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 7.   
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Bids","Ecdat","Bids","Bids Received By U.S. Firms",126,12,5,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Bids.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Bids.html","Bids R Documentation   Bids Received By U.S. Firms   Description  
a cross-section   
number of observations : 126   
observation : production units   
country : United States    Usage   data(Bids)   Format  
A dataframe containing :    docno
doc no.   weeks
weeks   numbids
count   takeover
delta (1 if taken over)   bidprem
bid Premium   insthold
institutional holdings   size
size measured in billions   leglrest
legal restructuring   rearest
real restructuring   finrest
financial restructuring   regulatn
regulation   whtknght
white knight     Source  
Jaggia, Sanjiv and Satish Thosar (1993) “Multiple Bids as a Consequence of Target Management Resistance”, Review of Quantitative Finance and Accounting , 447–457.   
Cameron, A.C. and Per Johansson (1997) “Count Data Regression Models using Series Expansions: with Applications”, Journal of Applied Econometrics , 12 , may, 203–223.    References  
Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 5.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-breaches","Ecdat","breaches","Cyber Security Breaches",1055,13,0,2,5,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/breaches.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/breaches.html","breaches R Documentation   Cyber Security Breaches   Description  
data.frame of cyber security breaches involving health care records of 500 or more humans reported to the U.S. Department of Health and Human Services (HHS) as of June 27, 2014.   Usage   data(breaches)   Format  
A data.frame with 1055 observations on the following 24 variables:    Number  
integer record number in the HHS data base   Name_of_Covered_Entity  
factor giving the name of the entity experiencing the breach   State  
Factor giving the 2-letter code of the state where the breach occurred. This has 52 levels for the 50 states plus the District of Columbia (DC) and Puerto Rico (PR).   Business_Associate_Involved  
Factor giving the name of a subcontractor (or blank) associated with the breach.   Individuals_Affected  
integer number of humans whose records were compromised in the breach. This is 500 or greater; U.S. law requires reports of breaches involving 500 or more records but not of breaches involving fewer.   Date_of_Breach  
character vector giving the date or date range of the breach. Recodes as Date s in breach_start  and breach_end .   Type_of_Breach  
factor with 29 levels giving the type of breach (e.g., ""Theft"" vs. ""Unauthorized Access/Disclosure"", etc.)    Location_of_Breached_Information 
factor with 41 levels coding the location from which the breach occurred (e.g., ""Paper"", ""Laptop"", etc.)    Date_Posted_or_Updated  
Date the information was posted to the HHS data base or last updated.   Summary  
character vector of a summary of the incident.   breach_start  
Date of the start of the incident = first date given in  Date_of_Breach above.    
breach_end   Date of the end of the incident or NA if only one date is given in Date_of_Breach above. year   integer giving the year of the breach   Details  
The data primarily consists of breaches that occurred from 2010 through early 2014 when the extract was taken. However, a few breaches are recorded including 1 from 1997, 8 from 2002-2007, 13 from 2008 and 56 from 2009. The numbers of breaches from 2010 - 2014 are 211, 229, 227, 254 and 56, respectively. (A chi-square test for equality of the counts from 2010 through 2013 is 4.11, which with 3 degrees of freedom has a significance probability of 0.25. Thus, even though the lowest number is the first and the largest count is the last, the apparent trend is not statistically significant under the usual assumption of independent Poisson trials.)  
The following corrections were made to the file:  
 Number Name of Covered Entity  Corrections

45 Wyoming Department of Health Cause of breach was missing. Added ""Unauthorized
Access / Disclosure"" per smartbrief.com/03/29/10
 55 Reliant Rehabilitation Hospital North  Cause of breach was missing. Added ""Unauthorized
Houston Access / Disclosure"" per Dissent. ""Two Breaches
  Involving Unauthorized Access Lead to Notification.""
 www.phiprivacy.net/two-breaches-involving-unauthorized-access-lead-to-notification ; approximately 2010-04-20. This web page has since been removed, apparently without having been captured by archive.net.]
123 Aetna Cause of breach was missing. Added Improper
  disposal per   Aetna.com/news/newsReleases/2010/0630  
157 Mayo Clinic Cause of breach was missing. Added Unauthorized
 Access/Disclosure per Anderson, Howard. ""Mayo Fires
  ""Employees in 2 Incidents: Both Involved
 Unauthorized Access to Records.""
  Data Breach Today. N.p., 4 Oct. 2010
 341 Saint Barnabas MedicL Center Misspelled ""Saint Barnabas Medical Center""
347 Americar Health Medicare Misspelled ""American Health Medicare""
 484 Lake Granbury Medicl Ceter Misspelled ""Lake Granbury Medical Center""
782 See list of Practices under Item 9 Replaced name as ""Cogent Healthcare, Inc."" checked
  from XML and web documents 
805 Dermatology Associates of Tallahassee Had 00/00/0000 on breach date. This was crossed
  check to determine that it was Sept 4, 2013 with 916 records
 815 Santa Clara Valley Medical Center Mistype breach year as 09/14/2913 corrected as 09/14/2013
 961 Valley View Hosptial Association Misspelled ""Valley View Hospital Association""
1034 Bio-Reference Laboratories, Inc. Date changed from 00/00/000 to 2/02/2014 as
  subsequently determined.
    Author(s)  
Spencer Graves   Source  
U.S. Department of Health and Human Services: Health Information Privacy: Breaches Affecting 500 or More Individuals     See Also  
HHSCyberSecurityBreaches for a version of these data downloaded more recently. This newer version includes changes in reporting and in the variables included in the data.frame .   Examples    data(breaches) quantile(breaches$Individuals_Affected) # confirm that the smallest number is 500 # -- and the largest is 4.9e6 # ... and there are no NAs dDays <- with(breaches, breach_end - breach_start) quantile(dDays, na.rm=TRUE) # confirm that breach_end is NA or is later than # breach_start"
"Ecdat-BudgetFood","Ecdat","BudgetFood","Budget Share of Food for Spanish Households",23972,6,1,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/BudgetFood.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/BudgetFood.html","BudgetFood R Documentation   Budget Share of Food for Spanish Households   Description  
a cross-section from 1980   
number of observations : 23972   
observation : households   
country : Spain    Usage   data(BudgetFood)   Format  
A dataframe containing :    wfood
percentage of total expenditure which the household has spent on food   totexp
total expenditure of the household   age
age of reference person in the household   size
size of the household   town  
size of the town where the household is placed categorized into 5 groups: 1 for small towns, 5 for big ones    sex
sex of reference person (man,woman)     Source  
Delgado, A. and Juan Mora (1998) “Testing non–nested semiparametric models : an application to Engel curves specification”, Journal of Applied Econometrics , 13(2) , 145–162.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-BudgetItaly","Ecdat","BudgetItaly","Budget Shares for Italian Households",1729,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/BudgetItaly.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/BudgetItaly.html","BudgetItaly R Documentation   Budget Shares for Italian Households   Description  
a cross-section from 1973 to 1992   
number of observations : 1729   
observation : households   
country : Italy    Usage   data(BudgetItaly)   Format  
A dataframe containing :    wfood
food share   whouse
housing and fuels share   wmisc
miscellaneous share   pfood
food price   phouse
housing and fuels price   pmisc
miscellaneous price   totexp
total expenditure   year
year   income
income   size
household size   pct
cellule weight     Source  
Bollino, Carlo Andrea, Frederico Perali and Nicola Rossi (2000) “Linear household technologies”, Journal of Applied Econometrics , 15(3) , 253–274.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-BudgetUK","Ecdat","BudgetUK","Budget Shares of British Households",1519,10,1,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/BudgetUK.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/BudgetUK.html","BudgetUK R Documentation   Budget Shares of British Households   Description  
a cross-section from 1980 to 1982   
number of observations : 1519   
observation : households   
country : United Kingdom    Usage   data(BudgetUK)   Format  
A dataframe containing :    wfood
budget share for food expenditure   wfuel
budget share for fuel expenditure   wcloth  
budget share for clothing expenditure    walc  
budget share for alcohol expenditure    wtrans  
budget share for transport expenditure    wother  
budget share for other good expenditure    totexp  
total household expenditure (rounded to the nearest 10 UK pounds sterling)    income  
total net household income (rounded to the nearest 10 UK pounds sterling)    age
age of household head   children
number of children     Source  
Blundell, Richard, Alan Duncan and Krishna Pendakur (1998) “Semiparametric estimation and consumer demand”, Journal of Applied Econometrics , 13(5) , 435–462.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Bwages","Ecdat","Bwages","Wages in Belgium",1472,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Bwages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Bwages.html","Bwages R Documentation   Wages in Belgium   Description  
a cross-section from 1994   
number of observations : 1472   
observation : individuals   
country : Belgium    Usage   data(Bwages)   Format  
A dataframe containing :    wage
gross hourly wage rate in euro   educ
education level from 1 [low] to 5 [high]   exper
years of experience   sex
a factor with levels (males,female)     Source  
European Community Household Panel.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 3.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Capm","Ecdat","Capm","Stock Market Data",516,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Capm.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Capm.html","Capm R Documentation   Stock Market Data   Description  
monthly observations from 1960–01 to 2002–12   
number of observations : 516    Usage   data(Capm)   Format  
A time series containing :    rfood
excess returns food industry   rdur
excess returns durables industry   rcon
excess returns construction industry   rmrf
excess returns market portfolio   rf
risk-free return     Source  
most of the above data are from Kenneth French's data library at http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html .    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Car","Ecdat","Car","Stated Preferences for Car Choice",4654,70,13,0,13,0,57,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Car.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Car.html","Car R Documentation   Stated Preferences for Car Choice   Description  
a cross-section   
number of observations : 4654   
observation : individuals   
country : United States    Usage   data(Car)   Format  
A dataframe containing :    choice  
choice of a vehicle among 6 propositions    college
college education ?   hsg2
size of household greater than 2 ?   coml5
commute lower than 5 miles a day ?   typez  
body type, one of regcar (regular car), sportuv (sport utility vehicle), sportcar , stwagon (station wagon), truck , van , for each proposition z from 1 to 6    fuelz  
fuel for proposition z, one of gasoline , methanol , cng (compressed natural gas), electric .    pricez  
price of vehicle divided by the logarithm of income    rangez  
hundreds of miles vehicle can travel between refuelings/rechargings    accz  
acceleration, tens of seconds required to reach 30 mph from stop    speedz
highest attainable speed in hundreds of mph   pollutionz
tailpipe emissions as fraction of those for new gas vehicle   sizez
0 for a mini, 1 for a subcompact, 2 for a compact and 3 for a mid–size or large vehicle   spacez
fraction of luggage space in comparable new gas vehicle   costz
cost per mile of travel (tens of cents) : home recharging for electric vehicle, station refueling otherwise   stationz
fraction of stations that can refuel/recharge vehicle     Source  
McFadden, Daniel and Kenneth Train (2000) “Mixed MNL models for discrete response”, Journal of Applied Econometrics , 15(5) , 447–470.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Caschool","Ecdat","Caschool","The California Test Score Data Set",420,17,1,0,3,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Caschool.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Caschool.html","Caschool R Documentation   The California Test Score Data Set   Description  
a cross-section from 1998-1999   
number of observations : 420   
observation : schools   
country : United States    Usage   data(Caschool)   Format  
A dataframe containing :    distcod
district code   county
county   district
district   grspan
grade span of district   enrltot
total enrollment   teachers
number of teachers   calwpct
percent qualifying for CalWORKS   mealpct
percent qualifying for reduced-price lunch   computer
number of computers   testscr  
average test score (read.scr+math.scr)/2     compstu
computer per student   expnstu
expenditure per student   str
student teacher ratio   avginc
district average income   elpct
percent of English learners   readscr
average reading score   mathscr
average math score     Source  
California Department of Education https://www.cde.ca.gov .    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 4–7.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Catsup","Ecdat","Catsup","Choice of Brand for Catsup",2798,14,8,0,1,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Catsup.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Catsup.html","Catsup R Documentation   Choice of Brand for Catsup   Description  
a cross-section   
number of observations : 2798   
observation : individuals   
country : United States    Usage   data(Catsup)   Format  
A dataframe containing :    id
individuals identifiers   choice  
one of heinz41 , heinz32 , heinz28 , hunts32     disp.z
is there a display for brand z ?   feat.z  
is there a newspaper feature advertisement for brand z ?    price.z
price of brand z     Source  
Jain, Dipak C., Naufel J. Vilcassim and Pradeep K. Chintagunta (1994) “A random–coefficients logit brand–choice model applied to panel data”, Journal of Business and Economics Statistics , 12(3) , 317.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Ketchup ,  Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Cigar","Ecdat","Cigar","Cigarette Consumption",1380,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Cigar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Cigar.html","Cigar R Documentation   Cigarette Consumption   Description  
a panel of 46 observations from 1963 to 1992   
number of observations : 1380   
observation : regional   
country : United States    Usage   data(Cigar)   Format  
A dataframe containing :    state
state abbreviation   year
the year   price
price per pack of cigarettes   pop
population   pop16
population above the age of 16   cpi
consumer price index (1983=100)   ndi
per capita disposable income   sales
cigarette sales in packs per capita   pimin
minimum price in adjoining states per pack of cigarettes     Source  
Baltagi, B.H. and D. Levin (1992) “Cigarette taxation: raising revenues and reducing consumption”, Structural Changes and Economic Dynamics , 3 , 321–335.   
Baltagi, B.H., J.M. Griffin and W. Xiong (2000) “To pool or not to pool: homogeneous versus heterogeneous estimators applied to cigarette demand”, Review of Economics and Statistics , 82 , 117–126.    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Cigarette","Ecdat","Cigarette","The Cigarette Consumption Panel Data Set",528,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Cigarette.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Cigarette.html","Cigarette R Documentation   The Cigarette Consumption Panel Data Set   Description  
a panel of 48 observations from 1985 to 1995   
number of observations : 528   
observation : regional   
country : United States    Usage   data(Cigarette)   Format  
A dataframe containing :    state
state   year
year   cpi
consumer price index   pop
state population   packpc
number of packs per capita   income
state personal income (total, nominal)   tax
average state, federal, and average local excise taxes for fiscal year   avgprs
average price during fiscal year, including sales taxes   taxs
average excise taxes for fiscal year, including sales taxes     Source  
Professor Jonathan Gruber, MIT.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 10.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Clothing","Ecdat","Clothing","Sales Data of Men's Fashion Stores",400,13,0,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Clothing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Clothing.html","Clothing R Documentation   Sales Data of Men's Fashion Stores   Description  
a cross-section from 1990   
number of observations : 400   
observation : production units   
country : Netherland    Usage   data(Clothing)   Format  
A dataframe containing :    tsales
annual sales in Dutch guilders   sales
sales per square meter   margin
gross-profit-margin   nown
number of owners (managers)   nfull
number of full-timers   npart
number of part-timers   naux
number of helpers (temporary workers)   hoursw
total number of hours worked   hourspw
number of hours worked per worker   inv1
investment in shop-premises   inv2
investment in automation.   ssize  
sales floor space of the store (in m$^2$).    start
year start of business     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 3.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Computers","Ecdat","Computers","Prices of Personal Computers",6259,10,3,0,3,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Computers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Computers.html","Computers R Documentation   Prices of Personal Computers   Description  
a cross-section from 1993 to 1995   
number of observations : 6259   
observation : goods   
country : United States    Usage   data(Computers)   Format  
A dataframe containing :    price
price in US dollars of 486 PCs   speed
clock speed in MHz   hd
size of hard drive in MB   ram
size of Ram in in MB   screen
size of screen in inches   cd
is a CD-ROM present ?   multi
is a multimedia kit (speakers, sound card) included ?   premium
is the manufacturer was a ""premium"" firm (IBM, COMPAQ) ?   ads
number of 486 price listings for each month   trend
time trend indicating month starting from January of 1993 to November of 1995.     Source  
Stengos, T. and E. Zacharias (2005) “Intertemporal pricing and price discrimination : a semiparametric hedonic analysis of the personal computer market”, Journal of Applied Econometrics , forthcoming .    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Consumption","Ecdat","Consumption","Quarterly Data on Consumption and Expenditure",200,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Consumption.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Consumption.html","Consumption R Documentation   Quarterly Data on Consumption and Expenditure   Description  
quarterly observations from 1947-1 to 1996-4   
number of observations : 200   
observation : country   
country : Canada    Usage   data(Consumption)   Format  
A time series containing :    yd
personal disposable income, 1986 dollars   ce
personal consumption expenditure, 1986 dollars     References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 1, 3, 4, 6, 9, 10, 14 and 15.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-coolingFromNuclearWar","Ecdat","coolingFromNuclearWar","Global cooling from a nuclear war",4,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/coolingFromNuclearWar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/coolingFromNuclearWar.html","coolingFromNuclearWar R Documentation   Global cooling from a nuclear war   Description  
Average surface temperature changes world wide and in the Northern Hemisphere 3 and 10 years after the injections of 5, 50 and 150 Tg (teragrams = millions of metric tons) of smoke into the upper troposphere, per Robock, Oman, and Stenchikov (2007).   
These numbers are relative to the average for 1925-1975, which explains why the numbers are positive with smoke = 0.   Usage   data(coolingFromNuclearWar)   Format  
A dataframe containing :    smoke
teragrams = millions of metric tons   dC3g, dC10g, dC3n, dC10n  
average change in surface temperature 3 and 10 years after injection of smoke into the upper troposphere globally ( g ) or in the Northern Hemisphere ( n ) in degrees Celsius.      Source  
Alan Robock, Luke Oman, and Georgiy L. Stenchikov (2007) Nuclear winter revisited with a modern climate model and current nuclear arsenals: Still catastrophic consequences, Journal of Geophysical Research , 112    Examples    data(coolingFromNuclearWar) matplot(coolingFromNuclearWar[, 'smoke'], coolingFromNuclearWar[, 2:5], type='l') (linFit <- lm(cbind(dC3g, dC10g, dC3n, dC10n)~smoke, coolingFromNuclearWar)) # total change dC <- as.matrix(coolingFromNuclearWar[, 2:5] - rep(unlist(coolingFromNuclearWar[1, -1]), e=4)) (linFit0 <- lm(dC~smoke, coolingFromNuclearWar)) summary(linFit0)"
"Ecdat-CPSch3","Ecdat","CPSch3","Earnings from the Current Population Survey",11130,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/CPSch3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/CPSch3.html","CPSch3 R Documentation   Earnings from the Current Population Survey   Description  
a cross-section from 1998   
number of observations : 11130   
observation : individuals   
country : United States    Usage   data(CPSch3)   Format  
A dataframe containing :    year
survey year   ahe
average hourly earnings   sex
a factor with levels (male,female)     Source  
Bureau of labor statistics, U.S. Department of Labor https://www.bls.gov .    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 3.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Cracker","Ecdat","Cracker","Choice of Brand for Crackers",3292,14,8,0,1,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Cracker.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Cracker.html","Cracker R Documentation   Choice of Brand for Crackers   Description  
a cross-section   
number of observations : 3292   
observation : individuals   
country : United States    Usage   data(Cracker)   Format  
A dataframe containing :    id
individuals identifiers   choice  
one of sunshine , kleebler , nabisco , private     disp.z
is there a display for brand z ?   feat.z
is there a newspaper feature advertisement for brand z ?   price.z
price of brand z     Source  
Jain, Dipak C., Naufel J. Vilcassim and Pradeep K. Chintagunta (1994) “A random–coefficients logit brand–choice model applied to panel data”, Journal of Business and Economics Statistics , 12(3) , 317.   
Paap, R. and Philip Hans Frances (2000) “A dynamic multinomial probit model for brand choices with different short–run effects of marketing mix variables”, Journal of Applied Econometrics , 15(6) , 717–744.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-CRANpackages","Ecdat","CRANpackages","Growth of CRAN",29,4,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/CRANpackages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/CRANpackages.html","CRANpackages R Documentation   Growth of CRAN   Description  
Data casually collected on the number of packages on the Comprehensive R Archive Network (CRAN) at different dates.   
NOTE: This could change in the future. See Details below.   Usage    data(CRANpackages)    Format  
A data.frame containing:    Version  
an ordered factor of the R version number primarily in use at the time. This was taken from archives of the major releases at  https://svn.r-project.org/R/branches/R-1-3-patches/tests/internet.Rout.save , ...  https://svn.r-project.org/R/branches/R-3-1-branch/tests/internet.Rout.save     Date  
an object of class Date giving the date on which the count of the number of CRAN packages was determined.    Packages  
an integer number of packages on the CRAN mirror checked on the indicated Date .    Source  
A factor giving the source (person) who collected the data.      Details  
This seems to provide the most widely available source for data on the growth of CRAN, manually recorded by John Fox and Spencer Graves. For a discussion of these and related data, see Fox (2009).   
For more detail, see the CRAN packages data on GitHub maintained by Hadley Wickham. This contains the description file of every package uploaded to CRAN prior to the date of Hadley's most recent update. The current maintainer of the Ecdat and Ecfun packages would consider contributions along the following lines:  
1. It might be nice to have a more complete dataset or datasets showing CRAN growth. This might include code fitting multiple models and predicting future growth with error bounds computed using Bayesian Model Averaging. These model fits might make an interesting addition to the examples in this help file. With a little more effort, it might make an interesting note for R Journal . Functions written to fit those models might be added to the Ecfun package.  
2. It might be nice to have a function in Ecfun to download the CRAN packages  data from GitHub and convert it to a format suitable for updating this dataset.  
The current maintainer for Ecdat and Ecfun (Spencer Graves) might be willing to accept code and documentation for this but is not ready to do it himself at the present time.   Source  
John Fox, ""Aspects of the Social Organization and Trajectory of the R Project"", R Journal , 1(2), Dec. 2009, 5-13.  https://journal.r-project.org/archive/2009-2/RJournal_2009-2_Fox.pdf , accessed 2014-04-13.    Examples    plot(Packages~Date, CRANpackages, log='y') # almost exponential growth"
"Ecdat-Crime","Ecdat","Crime","Crime in North Carolina",630,24,1,0,2,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Crime.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Crime.html","Crime R Documentation   Crime in North Carolina   Description  
a panel of 90 observations from 1981 to 1987   
number of observations : 630   
observation : regional   
country : United States    Usage   data(Crime)   Format  
A dataframe containing :    county
county identifier   year
year from 1981 to 1987   crmrte
crimes committed per person   prbarr
'probability' of arrest   prbconv
'probability' of conviction   prbpris
'probability' of prison sentence   avgsen
average sentence, days   polpc
police per capita   density
hundreds of people per square mile   taxpc
tax revenue per capita   region
one of 'other', 'west' or 'central'   smsa
'yes' or 'no' if in SMSA   pctmin
percentage minority in 1980   wcon
weekly wage in construction   wtuc  
weekly wage in trns, util, commun    wtrd  
weekly wage in whole sales and retail trade    wfir  
weekly wage in finance, insurance and real estate    wser
weekly wage in service industry   wmfg
weekly wage in manufacturing   wfed
weekly wage of federal employees   wsta
weekly wage of state employees   wloc  
weekly wage of local governments employees   mix
offense mix: face-to-face/other   pctymle
percentage of young males     Note  
Thanks to Yungfong ""Frank"" Tang for identifying an error in the description of ""density"", previously documented erroneously as only ""people per square mile"".   Source  
Cornwell, C. and W.N. Trumbull (1994) “Estimating the economic model of crime with panel data”, Review of Economics and Statistics , 76 , 360–366.   
Baltagi, B. H. (2006) “Estimating an economic model of crime using panel data from North Carolina”, Journal of Applied Econometrics , 21(4), May/June 2006, pp. 543-547.  
See also: CRIME4.DES and Baltagi in JAE Data Archive .    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series , Crime"
"Ecdat-CRSPday","Ecdat","CRSPday","Daily Returns from the CRSP Database",2528,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/CRSPday.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/CRSPday.html","CRSPday R Documentation   Daily Returns from the CRSP Database   Description  
daily observations from 1969-1-03 to 1998-12-31   
number of observations : 2528   
observation : production units   
country : United States    Usage   data(CRSPday)   Format  
A dataframe containing :    year
the year   month
the month   day
the day   ge
the return for General Electric, PERMNO 12060   ibm
the return for IBM, PERMNO 12490   mobil  
the return for Mobil Corporation, PERMNO 15966    crsp
the return for the CRSP value-weighted index, including dividends     Source  
Center for Research in Security Prices, Graduate School of Business, University of Chicago, 725 South Wells - Suite 800, Chicago, Illinois 60607, http://www.crsp.org .    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 7, 9 and 15.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-CRSPmon","Ecdat","CRSPmon","Monthly Returns from the CRSP Database",360,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/CRSPmon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/CRSPmon.html","CRSPmon R Documentation   Monthly Returns from the CRSP Database   Description  
monthly observations from 1969-1 to 1998-12   
number of observations : 360   
observation : production units   
country : United States    Usage   data(CRSPmon)   Format  
A time series containing :    ge
the return for General Electric, PERMNO 12060   ibm
the return for IBM, PERMNO 12490   mobil  
the return for Mobil Corporation, PERMNO 15966    crsp 
the return for the CRSP value-weighted index, including dividends      Source  
Center for Research in Security Prices, Graduate School of Business, University of Chicago, 725 South Wells - Suite 800, Chicago, Illinois 60607, http://www.crsp.org .    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 13.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Diamond","Ecdat","Diamond","Pricing the C's of Diamond Stones",308,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Diamond.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Diamond.html","Diamond R Documentation   Pricing the C's of Diamond Stones   Description  
a cross-section from 2000   
number of observations : 308   
observation : goods   
country : Singapore    Usage   data(Diamond)   Format  
A dataframe containing :    carat
weight of diamond stones in carat unit   colour
a factor with levels (D,E,F,G,H,I)   clarity  
a factor with levels ( IF,VVS1,VVS2,VS1,VS2 )    certification  
certification body, a factor with levels (  GIA , IGI , HRD )    price
price in Singapore \$     Source  
Chu, Singfat (2001) “Pricing the C's of Diamond Stones”, Journal of Statistics Education , 9(2) .    References  
Journal of Statistics Education's data archive : http://jse.amstat.org/jse_data_archive.htm .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-DM","Ecdat","DM","DM Dollar Exchange Rate",778,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/DM.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/DM.html","DM R Documentation   DM Dollar Exchange Rate   Description  
weekly observations from 1975 to 1989   
number of observations : 778   
observation : country   
country : Germany    Usage   data(DM)   Format  
A dataframe containing :    date  
the date of the observation (19850104 is January, 4, 1985)    s  
the ask price of the dollar in units of DM in the spot market on Friday of the current week    f  
the ask price of the dollar in units of DM in the 30-day forward market on Friday of the current week    s30  
the bid price of the dollar in units of DM in the spot market on the delivery date on a current forward contract      Source  
Bekaert, G. and R. Hodrick (1993) “On biases in the measurement of foreign exchange risk premiums”, Journal of International Money and Finance , 12 , 115-138.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 6, 438-443.    See Also  
Pound , Yen , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Doctor","Ecdat","Doctor","Number of Doctor Visits",485,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Doctor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Doctor.html","Doctor R Documentation   Number of Doctor Visits   Description  
a cross-section from 1986   
number of observations : 485   
observation : individuals   
country : United States    Usage   data(Doctor)   Format  
A dataframe containing :    doctor
the number of doctor visits   children
the number of children in the household   access
is a measure of access to health care   health
a measure of health status (larger positive numbers are associated with poorer health)     Source  
Gurmu, Shiferaw (1997) “Semiparametric estimation of hurdle regression models with an application to medicaid utilization”, Journal of Applied Econometrics , 12(3) , 225-242.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 11.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
DoctorContacts , DoctorAUS , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-DoctorAUS","Ecdat","DoctorAUS","Doctor Visits in Australia",5190,15,1,0,2,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/DoctorAUS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/DoctorAUS.html","DoctorAUS R Documentation   Doctor Visits in Australia   Description  
a cross-section from 1977–1978   
number of observations : 5190   
observation : individuals   
country : Australia    Usage   data(DoctorAUS)   Format  
A dataframe containing :    sex
sex   age
age   income  
annual income in tens of thousands of dollars    insurance  
insurance contract ( medlevy : medibanl levy , levyplus : private health insurance, freepoor : government insurance due to low income, freerepa : government insurance due to old age disability or veteran status    illness
number of illness in past 2 weeks   actdays  
number of days of reduced activity in past 2 weeks due to illness or injury    hscore  
general health score using Goldberg's method (from 0 to 12)    chcond  
chronic condition ( np : no problem, la : limiting activity, nla : not limiting activity)    doctorco  
number of consultations with a doctor or specialist in the past 2 weeks    nondocco 
number of consultations with non-doctor health professionals (chemist, optician, physiotherapist, social worker, district community nurse, chiropodist or chiropractor) in the past 2 weeks    hospadmi 
number of admissions to a hospital, psychiatric hospital, nursing or convalescent home in the past 12 months (up to 5 or more admissions which is coded as 5)    hospdays  
number of nights in a hospital, etc. during most recent admission: taken, where appropriate, as the mid-point of the intervals 1, 2, 3, 4, 5, 6, 7, 8-14, 15-30, 31-60, 61-79 with 80 or more admissions coded as 80. If no admission in past 12 months then equals zero.    medecine  
total number of prescribed and nonprescribed medications used in past 2 days    prescrib 
total number of prescribed medications used in past 2 days    nonpresc  
total number of nonprescribed medications used in past 2 days      Source  
Cameron, A.C. and P.K. Trivedi (1986) “Econometric Models Based on Count Data: Comparisons and Applications of Some Estimators and Tests”, Journal of Applied Econometrics , 1 , 29-54..    References  
Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 3.    See Also  
Doctor , DoctorContacts , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-DoctorContacts","Ecdat","DoctorContacts","Contacts With Medical Doctor",20186,15,5,0,2,4,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/DoctorContacts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/DoctorContacts.html","DoctorContacts R Documentation   Contacts With Medical Doctor   Description  
a cross-section from 1977–1978   
number of observations : 20186    Usage   data(DoctorContacts)   Format  
A time series containing :    mdu  
number of outpatient visits to a medical doctor    lc  
log(coinsrate+1) where coinsurance rate is 0 to 100    idp
individual deductible plan ?   lpi  
log (annual participation incentive payment) or 0 if no payment   fmde  
log (max(medical deductible expenditure)) if IDP =1 and MDE >1 or 0 otherwise    physlim
physical limitation ?   ndisease
number of chronic diseases   health  
self–rate health (excellent,good,fair,poor)    linc
log of annual family income (in \$)   lfam
log of family size   educdec
years of schooling of household head   age
exact age   sex
sex (male,female)   child
age less than 18 ?   black
is household head black ?     Source  
Deb, P. and P.K. Trivedi (2002) “The Structure of Demand for Medical Care: Latent Class versus Two-Part Models”, Journal of Health Economics , 21 , 601–625.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 553–556 and 565.    See Also  
Doctor , MedExp ,  DoctorAUS , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Earnings","Ecdat","Earnings","Earnings for Three Age Groups",4266,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Earnings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Earnings.html","Earnings R Documentation   Earnings for Three Age Groups   Description  
a cross-section from 1988-1989   
number of observations : 4266   
observation : individuals   
country : United States    Usage   data(Earnings)   Format  
A dataframe containing :    age  
age groups, a factor with levels (g1,g2,g3)     y  
average annual earnings, in 1982 US dollars      Source  
Mills, Jeffery A. and Sourushe Zandvakili (1997) “Statistical Inference via Bootstrapping for Measures of Inequality”, Journal of Applied Econometrics , 12(2) , pp. 133-150.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 5 and 7.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Electricity","Ecdat","Electricity","Cost Function for Electricity Producers",158,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Electricity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Electricity.html","Electricity R Documentation   Cost Function for Electricity Producers   Description  
a cross-section from 1970 to 1970   
number of observations : 158   
observation : production units   
country : United States    Usage   data(Electricity)   Format  
A dataframe containing :    cost
total cost   q
total output   pl
wage rate   sl
cost share for labor   pk
capital price index   sk
cost share for capital   pf
fuel price   sf
cost share for fuel     Source  
Christensen, L. and W. H. Greene (1976) “Economies of scale in U.S. electric power generation”, Journal of Political Economy , 84 , 655-676.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , chapter 4, 317-320.   
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 1, 76-84.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Fair","Ecdat","Fair","Extramarital Affairs Data",601,9,2,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Fair.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Fair.html","Fair R Documentation   Extramarital Affairs Data   Description  
a cross-section   
number of observations : 601   
observation : individuals   
country : United States    Usage   data(Fair)   Format  
A dataframe containing :    sex
a factor with levels (male,female)   age
age   ym
number of years married   child
children ? a factor   religious  
how religious, from 1 (anti) to 5 (very)    education
education   occupation  
occupation, from 1 to 7, according to Hollingshead's classification (reverse numbering)    rate  
self rating of marriage, from 1 (very unhappy) to 5 (very happy)    nbaffairs
number of affairs in past year     Source  
Fair, R. (1977) “A note on the computation of the tobit estimator”, Econometrica , 45 , 1723-1727.   
http://fairmodel.econ.yale.edu/rayfair/pdf/1978A200.PDF .    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F22.2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Fatality","Ecdat","Fatality","Drunk Driving Laws and Traffic Deaths",336,10,2,0,2,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Fatality.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Fatality.html","Fatality R Documentation   Drunk Driving Laws and Traffic Deaths   Description  
a panel of 48 observations from 1982 to 1988   
number of observations : 336   
observation : regional   
country : United States    Usage   data(Fatality)   Format  
A dataframe containing :    state
state ID code   year
year   mrall
traffic fatality rate (deaths per 10000)   beertax
tax on case of beer   mlda
minimum legal drinking age   jaild
mandatory jail sentence ?   comserd
mandatory community service ?   vmiles
average miles per driver   unrate
unemployment rate   perinc
per capita personal income     Source  
Pr. Christopher J. Ruhm, Department of Economics, University of North Carolina.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 8.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Fishing","Ecdat","Fishing","Choice of Fishing Mode",1182,12,0,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Fishing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Fishing.html","Fishing R Documentation   Choice of Fishing Mode   Description  
a cross-section   
number of observations : 1182   
observation : individuals   
country : United States    Usage   data(Fishing)   Format  
A dataframe containing :    mode
recreation mode choice, on of : beach, pier, boat and charter   price
price for chosen alternative   catch
catch rate for chosen alternative   pbeach
price for beach mode   ppier
price for pier mode   pboat
price for private boat mode   pcharter
price for charter boat mode   cbeach
catch rate for beach mode   cpier
catch rate for pier mode   cboat
catch rate for private boat mode   ccharter
catch rate for charter boat mode   income
monthly income     Source  
Herriges, J. A. and C. L. Kling (1999) “Nonlinear Income Effects in Random Utility Models”, Review of Economics and Statistics , 81 , 62-72.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 463–466, 486 and 491–495.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Forward","Ecdat","Forward","Exchange Rates of US Dollar Against Other Currencies",276,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Forward.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Forward.html","Forward R Documentation    Exchange Rates of US Dollar Against Other Currencies    Description  
monthly observations from 1979–01 to 2001–12   
number of observations : 276    Usage   data(Forward)   Format  
A time series containing :    usdbp
exchange rate USD/British Pound Sterling   usdeuro
exchange rate US D/Euro   eurobp
exchange rate Euro/Pound   usdbp1
1 month forward rate USD/Pound   usdeuro1
1 month forward rate USD/Euro   eurobp1
1 month forward rate Euro/Pound   usdbp3
3 month forward rate USD/Pound   usdeuro3
month forward rate USD/Euro   eurobp3
month forward rate Euro/Pound     Source  
Datastream    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 4.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-FriendFoe","Ecdat","FriendFoe","Data from the Television Game Show Friend Or Foe ?",227,13,7,0,8,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/FriendFoe.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/FriendFoe.html","FriendFoe R Documentation    Data from the Television Game Show Friend Or Foe ?   Description  
a cross-section from 2002–03   
number of observations : 227   
observation : individuals   
country : United States    Usage   data(FriendFoe)   Format  
A dataframe containing :    sex
contestant's sex   white
is contestant white ?   age
contestant's age in years   play  
contestant's choice : a factor with levels ""foe"" and ""friend"". If both players play ""friend"", they share the trust box, if both play ""foe"", both players receive zero prize, if one of them play ""foe"" and the other one ""friend"", the ""foe"" player receive the entire trust box and the ""friend"" player nothing    round  
round in which contestant is eliminated, a factor with levels (""1"",""2"",""3"")    season  
season show, a factor with levels (""1"",""2"")    cash
the amount of cash in the trust box   sex1
partner's sex   white1
is partner white ?   age1
partner's age in years   play1  
partner's choice : a factor with levels ""foe"" and ""friend""    win
money won by contestant   win1
money won by partner     Source  
Kalist, David E. (2004) “Data from the Television Game Show ""Friend or Foe?""”, Journal of Statistics Education , 12(3) .    References  
Journal of Statistics Education's data archive : http://jse.amstat.org/jse_data_archive.htm .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Garch","Ecdat","Garch","Daily Observations on Exchange Rates of the US Dollar Against Other Currencies",1867,8,0,1,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Garch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Garch.html","Garch R Documentation   Daily Observations on Exchange Rates of the US Dollar Against Other Currencies   Description  
daily observations from 1980–01 to 1987–05–21   
number of observations : 1867   
observation : country   
country : World    Usage   data(Garch)   Format  
A dataframe containing :    date  
date of observation ( yymmdd )    day
day of the week (a factor)   dm  
exchange rate Dollar/Deutsch Mark    ddm
dm-dm(-1)   bp  
exchange rate of Dollar/British Pound    cd  
exchange rate of Dollar/Canadian Dollar    dy  
exchange rate of Dollar/Yen    sf  
exchange rate of Dollar/Swiss Franc      References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 8.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Gasoline","Ecdat","Gasoline","Gasoline Consumption",342,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Gasoline.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Gasoline.html","Gasoline R Documentation   Gasoline Consumption   Description  
a panel of 18 observations from 1960 to 1978   
number of observations : 342   
observation : country   
country : OECD    Usage   data(Gasoline)   Format  
A dataframe containing :    country
a factor with 18 levels   year
the year   lgaspcar
logarithm of motor gasoline consumption per auto   lincomep
logarithm of real per-capita income   lrpmg
logarithm of real motor gasoline price   lcarpcap
logarithm of the stock of cars per capita     Source  
Baltagi, B.H. and Y.J. Griggin (1983) “Gasoline demand in the OECD: an application of pooling and testing procedures”, European Economic Review , 22 .    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Griliches","Ecdat","Griliches","Wage Data",758,20,6,0,6,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Griliches.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Griliches.html","Griliches R Documentation   Wage Data   Description  
a cross-section from 1980   
number of observations : 758   
observation : individuals   
country : United States    Usage   data(Griliches)   Format  
A dataframe containing :    rns
residency in the southern states (first observation) ?   rns80
same variable for 1980   mrt
married (first observation) ?   mrt80
same variable for 1980   smsa
residency in metropolitan areas (first observation) ?   smsa80
same variable for 1980   med
mother's education in years   iq
IQ score   kww
score on the “knowledge of the world of work” test   year
year of the observation   age
age (first observation)   age80
same variable for 1980   school
completed years of schooling (first observation)   school80
same variable for 1980   expr
experience in years (first observation)   expr80
same variable for 1980   tenure
tenure in years (first observation)   tenure80
same variable for 1980   lw
log wage (first observation)   lw80
same variable for 1980     Source  
Blackburn, M. and Neumark D. (1992) “Unobserved ability, efficiency wages, and interindustry wage differentials”, Quarterly Journal of Economics , 107 , 1421-1436.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 3, 250-256.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Grunfeld","Ecdat","Grunfeld","Grunfeld Investment Data",200,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Grunfeld.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Grunfeld.html","Grunfeld R Documentation   Grunfeld Investment Data   Description  
a panel of 20 annual observations from 1935 to 1954 on each of 10 firms.  
number of observations : 200   
observation : production units   
country : United States    Usage   data(Grunfeld)   Format  
A dataframe containing :    firm
observation   year
date   inv
gross Investment   value
value of the firm   capital
stock of plant and equipment     Details  
There are several versions of these data.  
GrunfeldGreene is ""A data frame containing 20 annual observations on 3 variables for 5 firms."" That dataset reportedly contains errors but is maintained in that way to avoid breaking the code of others who use it. That help file also provides a link to the corrected version.  
See also for a version with only 5 firms .   Source  
Moody's Industrial Manual, Survey of Current Business.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, Table F13.1.   
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  GrunfeldGreene ,  
Index.Time.Series"
"Ecdat-HC","Ecdat","HC","Heating and Cooling System Choice in Newly Built Houses in California",250,18,0,0,1,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/HC.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/HC.html","HC R Documentation   Heating and Cooling System Choice in Newly Built Houses in California   Description  
a cross-section   
number of observations : 250   
observation : households   
country : California    Usage   data(HC)   Format  
A dataframe containing :    depvar  
heating system, one of gcc (gas central heat with cooling), ecc (electric central resistance heat with cooling), erc (electric room resistance heat with cooling), hpc (electric heat pump which provides cooling also), gc (gas central heat without cooling, ec (electric central resistance heat without cooling), er (electric room resistance heat without cooling)    ich.z  
installation cost of the heating portion of the system    icca
installation cost for cooling   och.z
operating cost for the heating portion of the system   occa
operating cost for cooling   income
annual income of the household     References  
Kenneth Train's home page : http://elsa.berkeley.edu/~train/ .    See Also  
Heating , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Hdma","Ecdat","Hdma","The Boston HMDA Data Set",2381,13,7,0,6,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Hdma.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Hdma.html","Hmda R Documentation   The Boston HMDA Data Set   Description  
a cross-section from 1997-1998   
number of observations : 2381  observation : individuals  country : United States   
In package version 0.2-9 and earlier this dataset was called Hdma .    Usage   data(Hmda)   Format  
A dataframe containing :    dir
debt payments to total income ratio   hir
housing expenses to income ratio   lvr  
ratio of size of loan to assessed value of property    ccs  
consumer credit score from 1 to 6 (a low value being a good score)   mcs  
mortgage credit score from 1 to 4 (a low value being a good score)   pbcr
public bad credit record ?   dmi
denied mortgage insurance ?   self
self employed ?   single
is the applicant single ?   uria  
1989 Massachusetts unemployment rate in the applicant's industry    condominium  
is unit a condominium ? (was called comdominiom in version 0.2-9 and earlier versions of the package)    black
is the applicant black ?   deny
mortgage application denied ?     Source  
Federal Reserve Bank of Boston.   
Munnell, Alicia H., Geoffrey M.B. Tootell, Lynne E. Browne and James McEneaney (1996) “Mortgage lending in Boston: Interpreting HMDA data”, American Economic Review , 25-53.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 9.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Heating","Ecdat","Heating","Heating System Choice in California Houses",900,21,0,0,2,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Heating.html","Heating R Documentation   Heating System Choice in California Houses   Description  
a cross-section   
number of observations : 900   
observation : households   
country : California    Usage   data(Heating)   Format  
A dataframe containing :    idcase
id   depvar  
heating system, one of gc (gas central), gr (gas room), ec (electric central), er (electric room), hp (heat pump)    ic.z  
installation cost for heating system z (defined for the 5 heating systems)    oc.z  
annual operating cost for heating system z (defined for the 5 heating systems)    pb.z  
ratio oc.z/ic.z     income
annual income of the household   agehed
age of the household head   rooms
numbers of rooms in the house     References  
Kenneth Train's home page : https://eml.berkeley.edu/~train/ .    See Also  
HC , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Hedonic","Ecdat","Hedonic","Hedonic Prices of Census Tracts in Boston",506,15,1,0,1,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Hedonic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Hedonic.html","Hedonic R Documentation   Hedonic Prices of Census Tracts in Boston   Description  
a cross-section   
number of observations : 506   
observation : regional   
country : United States    Usage   data(Hedonic)   Format  
A dataframe containing :    mv
median value of owner–occupied homes   crim
crime rate   zn
proportion of 25,000 square feet residential lots   indus
proportion of nonretail business acres   chas
is the tract bounds the Charles River ?   nox
annual average nitrogen oxide concentration in parts per hundred million   rm
average number of rooms   age
proportion of owner units built prior to 1940   dis
weighted distances to five employment centers in the Boston area   rad
index of accessibility to radial highways   tax
full value property tax rate (\$/\$10,000)   ptratio
pupil/teacher ratio   blacks
proportion of blacks in the population   lstat
proportion of population that is lower status   townid
town identifier     Source  
Harrison, D. and D.L. Rubinfeld (1978) “Hedonic housing prices and the demand for clean air”, Journal of Environmental Economics Ans Management , 5 , 81–102.   
Belsley, D.A., E. Kuh and R. E. Welsch (1980) Regression diagnostics: identifying influential data and sources of collinearity , John Wiley, New–York.    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-HHSCyberSecurityBreaches","Ecdat","HHSCyberSecurityBreaches","Cybersecurity breaches reported to the US Department of Health and Human Services",1151,9,1,2,4,1,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/HHSCyberSecurityBreaches.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/HHSCyberSecurityBreaches.html","HHSCyberSecurityBreaches R Documentation    Cybersecurity breaches reported to the US Department of Health and Human Services   Description  
Since October 2009 organizations in the U.S. that store data on human health are required to report any incident that compromises the confidentiality of 500 or more patients / human subjects ( 45 C.F.R. 164.408 ) These reports are publicly available. HHSCyberSecurityBreaches was downloaded from the Office for Civil Rights of the U.S. Department of Health and Human Services, 2015-02-26     Usage   data(HHSCyberSecurityBreaches)   Format  
A dataframe containing 1151 observations of 9 variables:    Name.of.Covered.Entity  
A character vector identifying the organization involved in the breach.   State  
A factor giving the two-letter abbreviation of the US state or territory where the breach occurred. This has 52 levels for the 50 states plus the District of Columbia (DC) and Puerto Rico (PR).   Covered.Entity.Type  
A factor giving the organization type of the covered entity with levels ""Business Associate"", ""Health Plan"", ""Healthcare Clearing House"", and ""Healthcare Provider""   Individuals.Affected  
An integer giving the number of humans whose records were compromised in the breach. This is 500 or greater; U.S. law requires reports of breaches involving 500 or more records but not of breaches involving fewer.   Breach.Submission.Date  
Date when the breach was reported.   Type.of.Breach  
A factor giving one of 29 different combinations of 7 different breach types, separated by "", "": ""Hacking/IT Incident"", ""Improper Disposal"", ""Loss"", ""Other"", ""Theft"", ""Unauthorized Access/Disclosure"", and ""Unknown""    Location.of.Breached.Information 
A factor giving one of 47 different combinations of 8 different location categories: ""Desktop Computer"", ""Electronic Medical Record"", ""Email"", ""Laptop"", ""Network Server"", ""Other"", ""Other Portable Electronic Device"", ""Paper/Films""    Business.Associate.Present  
Logical = ( Covered.Entity.Type  == ""Business Associate"")    Web.Description  
A character vector giving a narrative description of the incident.     Details  
This contains the breach report data downloaded 2015-02-26 from the US Health and Human Services. This catalogs reports starting 2009-10-21. Earlier downloads included a few breaches prior to 2009 when the law was enacted (inconsistently reported), and a date for breach occurrence in addition to the date of the report.  
The following corrections were made to the file:   

UCLA Health System, breach date 11/4/2011, had cover entity added as ""Healthcare Provider""   
Wyoming Department of Health, breach date 3/2/2010 had breach type changed to ""Unauthorized Access / Disclosure""   
Computer Program and Systems, Inc. (CPSI), breach date 3/30/2010 had breach type changed to ""Unauthorized Access / Disclosure""  
Aetna, breach date 7/27/2010 had breach type changed to ""Improper Disposal' (see explanation below), breach date 5/24/2010 name changed to City of Charlotte, NC (Health Plan) and state changed to NC   
Mercer, breach date 7/30/2010 state changed to MI   
Not applicable, breach date 11/2/2011 name changed to Northridge Hospital Medical Center and state changed to CA   
na , breach date 4/4/2011 name changed to Brian J Daniels DDS, Paul R Daniels DDS, and state changed to AZ   
NA , breach date 5/27/2011 name changed to and Spartanburg Regional Healthcare System state changed to SC   
NA , breach date 7/4/2011 name changed to Yanz Dental Corporation and state changed to CA      Source  
""Breaches Affecting 500 or More Individuals"" downloaded from the Office for Civil Rights of the U.S. Department of Health and Human Services, 2015-02-26     See Also  
breaches for an earlier download of these data. The exact reporting requirements and even the number and definitions of variables included in the data.frame have changed.   Examples    ## ## 1. mean(Individuals.Affected) ## mean(HHSCyberSecurityBreaches$Individuals.Affected) ## ## 2. Basic Breach Types ## tb <- as.character(HHSCyberSecurityBreaches$Type.of.Breach) tb. <- strsplit(tb, ', ') table(unlist(tb.)) # 8 levels, but two are the same apart from # a trailing blank. ## ## 3. Location.of.Breached.Information ## lb <- as.character(HHSCyberSecurityBreaches[[ 'Location.of.Breached.Information']]) table(lb) lb. <- strsplit(lb, ', ') table(unlist(lb.)) # 8 levels table(sapply(lb., length)) # 1 2 3 4 5 6 7 8 #1007 119 13 8 1 1 1 1 # all 8 levels together observed once # There are 256 = 2^8 possible combinations # of which 47 actually occur in these data."
"Ecdat-HI","Ecdat","HI","Health Insurance and Hours Worked By Wives",22272,13,4,0,7,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/HI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/HI.html","HI R Documentation   Health Insurance and Hours Worked By Wives   Description  
a cross-section from 1993   
number of observations : 22272   
observation : individuals   
country : United States    Usage   data(HI)   Format  
A dataframe containing :    whrswk
hours worked per week by wife   hhi
wife covered by husband's HI ?   whi
wife has HI thru her job ?   hhi2
husband has HI thru own job ?   education
a factor with levels, ""<9years"", ""9-11years"", ""12years"", ""13-15years"", ""16years"", "">16years""   race
one of white, black, other   hispanic
Hispanic ?   experience
years of potential work experience   kidslt6
number of kids under age of 6   kids618
number of kids 6–18 years old   husby
husband's income in thousands of dollars   region  
one of other , northcentral , south , west     wght
sampling weight     Source  
Olson, Craig A. (1998) “A comparison of parametric and semiparametric estimates of the effect of spousal health insurance coverage on weekly hours worked by wives”, Journal of Applied Econometrics , 13(5) , September–October, 543–565.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Hmda","Ecdat","Hmda","The Boston HMDA Data Set",2381,13,7,0,6,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Hmda.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Hmda.html","Hmda R Documentation   The Boston HMDA Data Set   Description  
a cross-section from 1997-1998   
number of observations : 2381  observation : individuals  country : United States   
In package version 0.2-9 and earlier this dataset was called Hdma .    Usage   data(Hmda)   Format  
A dataframe containing :    dir
debt payments to total income ratio   hir
housing expenses to income ratio   lvr  
ratio of size of loan to assessed value of property    ccs  
consumer credit score from 1 to 6 (a low value being a good score)   mcs  
mortgage credit score from 1 to 4 (a low value being a good score)   pbcr
public bad credit record ?   dmi
denied mortgage insurance ?   self
self employed ?   single
is the applicant single ?   uria  
1989 Massachusetts unemployment rate in the applicant's industry    condominium  
is unit a condominium ? (was called comdominiom in version 0.2-9 and earlier versions of the package)    black
is the applicant black ?   deny
mortgage application denied ?     Source  
Federal Reserve Bank of Boston.   
Munnell, Alicia H., Geoffrey M.B. Tootell, Lynne E. Browne and James McEneaney (1996) “Mortgage lending in Boston: Interpreting HMDA data”, American Economic Review , 25-53.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 9.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Housing","Ecdat","Housing","Sales Prices of Houses in the City of Windsor",546,12,6,0,6,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Housing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Housing.html","Housing R Documentation   Sales Prices of Houses in the City of Windsor   Description  
a cross-section from 1987   
number of observations : 546   
observation : goods   
country : Canada    Usage   data(Housing)   Format  
A dataframe containing :    price
sale price of a house   lotsize
the lot size of a property in square feet   bedrooms
number of bedrooms   bathrms
number of full bathrooms   stories
number of stories excluding basement   driveway
does the house has a driveway ?   recroom
does the house has a recreational room ?   fullbase
does the house has a full finished basement ?   gashw
does the house uses gas for hot water heating ?   airco
does the house has central air conditioning ?   garagepl
number of garage places   prefarea
is the house located in the preferred neighbourhood of the city ?     Source  
Anglin, P.M. and R. Gencay (1996) “Semiparametric estimation of a hedonic price function”, Journal of Applied Econometrics , 11(6) , 633-648.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 3.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Hstarts","Ecdat","Hstarts","Housing Starts",168,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Hstarts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Hstarts.html","Hstarts R Documentation   Housing Starts   Description  
quarterly observations from 1960-1 to 2001-4   
number of observations : 168   
observation : country   
country : Canada    Usage   data(Hstarts)   Format  
A time series containing :    hs
the log of urban housing starts in Canada, not seasonally adjusted, CANSIM series J6001, converted to quarterly    hssa
the log of urban housing starts in Canada, seasonally adjusted, CANSIM series J9001, converted to quarterly. Observations prior to 1966:1 are missing      References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 13.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Icecream","Ecdat","Icecream","Ice Cream Consumption",30,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Icecream.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Icecream.html","Icecream R Documentation   Ice Cream Consumption   Description  
four–weekly observations from 1951–03–18 to 1953–07–11   
number of observations : 30   
observation : country   
country : United States    Usage   data(Icecream)   Format  
A time series containing :    cons
consumption of ice cream per head (in pints);   income
average family income per week (in US Dollars);   price
price of ice cream (per pint);   temp
average temperature (in Fahrenheit);     Source  
Hildreth, C. and J. Lu (1960) Demand relations with autocorrelated disturbances , Technical Bulletin No 2765, Michigan State University.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 4.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-incidents.byCountryYr","Ecdat","incidents.byCountryYr","Global Terrorism Database yearly summaries",206,46,0,0,0,0,46,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/incidents.byCountryYr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/incidents.byCountryYr.html","terrorism R Documentation    Global Terrorism Database yearly summaries    Description  
The Global Terrorism Database (GTD) ""is a database of incidents of terrorism from 1970 onward"". Through 2015, this database contains information on 141,966 incidents.  
terrorism provides a few summary statistics along with an ordered  factor methodology , which Pape et al.  insisted is necessary, because an increase of over 70 percent in suicide terrorism between 2007 and 2013 is best explained by a methodology change in GTD that occurred on 2011-11-01; Pape's own Suicide Attack Database showed a 19 percent decrease over the same period.   Usage    data(terrorism) data(incidents.byCountryYr) data(nkill.byCountryYr)    Format  
incidents.byCountryYr and nkill.byCountryYr are matrices giving the numbers of incidents and numbers of deaths by year and by location of the event for 206 countries (rows) and for all years between 1970 and 2016 (columns) except for 1993, for which the entries are all NA, because the raw data previously collected was lost (though the total for that year is available in the data.frame  terrorism ).  
NOTES:  
1. For nkill.byCountryYr and for terrorism[c('nkill', 'nkill.us')] , NAs in GTD were treated as 0. Thus the actual number of deaths were likely higher, unless this was more than offset by incidents being classified as terrorism, when they should not have been.  
2. incidents.byCountryYr and nkill.byCountryYr are NA for 1993, because the GTD data for that year were lost.  
terrorism is a data.frame  containing the following:   year
integer year, 1970:2016.   methodology  
an ordered factor giving the methodology / organization responsible for the data collection for most of the given year. The Pinkerton Global Intelligence Service ( PGIS ) managed data collection from 1970-01-01 to 1997-12-31. The Center for Terrorism and Intelligence Studies ( CETIS ) managed the project from 1998-01-01 to 2008-03-31. The Institute for the Study of Violent Groups ( ISVG ) carried the project from 2008-04-01 to 2011-10-31. The National Consortium for the Study of Terrorism and Responses to Terrorism ( START ) has managed data collection since 2011-11-01. For this variable, partial years are ignored, so methodology = CEDIS for 1998:2007, ISVG for 2008:2011, and START for 2012:2014.   method  
a character vector consisting of the first character of the levels of methodology :  
c('p', 'c', 'i', 's')    incidents  
integer number of incidents identified each year.  
NOTE: sum(terrorism[[""incidents""]]) = 146920 = 141966 in the GTD database plus 4954 for 1993, for which the incident-level data were lost.   incidents.us  
integer number of incidents identified each year with country_txt = ""United States"".   suicide  
integer number of incidents classified as ""suicide"" by GTD variable suicide = 1. For 2007, this is 359, the number reported by Pape et al. For 2013, it is 624, which is 5 more than the 619 mentioned by Pape et al. Without checking with the SMART project administrators, one might suspect that 5 more suicide incidents from 2013 were found after the data Pape et al. analyzed but before the data used for this analysis.   suicide.us  
Number of suicide incidents by year with country_txt = ""United States"".   nkill  
number of confirmed fatalities for incidents in the given year, including attackers = sum(nkill, na.rm=TRUE) in the GTD incident data.  
NOTE: nkill in the GTD incident data includes both perpetrators and victims when both are available. It includes one when only one is available and is NA when neither is available. However, in most cases, we might expect that the more spectacular and lethal incidents would likely be more accurately reported. To the extent that this is true, it means that when numbers are missing, they are usually zero or small. This further suggests that the summary numbers recorded here probably represent a slight but not substantive undercount.   nkill.us  
number of U.S. citizens who died as a result of incidents for that year = sum(nkill.us, na.rm=TRUE) in the GTD incident data.  
NOTES:  
1. This is subject to the same likely modest undercount discussed with nkill .)   
2. These are U.S. citizens killed regardless of location. This explains at least part of the discrepancies between  terrorism[, 'nkill.us'] and nkill.byCountryYr['United States', ] .    nwound  
number of people wounded. (This is subject to the same likely modest undercount discussed with nkill .)    nwound.us  
Number of U.S. citizens wounded in terrorist incidents for that year = sum(nwound.us, na.rm=TRUE) in the GTD incident data. (This is subject to the same likely modest undercount discussed with nkill .)    pNA.nkill, pNA.nkill.us, pNA.nwound, pNA.nwound.us  
proportion of observations by year with missing values. These numbers are higher for the early data than more recent numbers. This is particularly true for nkill.us  and nwound.us , which exceed 90 percent for most of the period with methodology = PGIS , prior to 1998.   worldPopulation, USpopulation  
Estimated de facto population in thousands living in the world and in the US as of 1 July of the year indicated, according to the Population Division of the Department of Economic and Social Affairs of the United Nations; see ""Sources"" below.   worldDeathRate, USdeathRate  
Crude death rate  (deaths per 1,000 population) worldwide and in the US, according to the World Bank; see ""Sources"" below. This World Bank data set includes USdeathRate for each year from 1900 to 2014.  
The worldDeathRate numbers here were read manually from a plot on that web page, except for the the number for 2015, which was estimated as a reduction of 0.73 percent from 2014, which was the average rate of decline (ratio of two successive years) for 1990 to 2014. The same method was used to estimate the USdeathRate for 2015 as the same as for 2014.  
NOTE: USdeathRate is to two significant digits only, unlike worldDeathRate , which has four significant digits.   worldDeaths, USdeaths  
number of deaths by year in the world and US   
worldDeaths = worldPopulation * worldDeathRate .  
USdeaths were computed by summing across age groups in ""Deaths_5x1.txt"" for the United States, downloaded from https://www.mortality.org/cgi-bin/hmd/country.php?cntr=USA&level=1 from the Human Mortality Database; see sources below.   kill.pmp, kill.pmp.us  
terrorism deaths per million population worldwide and in the US =  
0.001 * nkill / worldPopulation     pkill, pkill.us  
terrorism deaths as a proportion of total deaths worldwide and in the US   
pkill = nkill / worldDeaths   
pkill.us = nkill.us / USdeaths      Details  
As noted with the ""description"" above, Pape et al. noted that the GTD reported an increase in suicide terrorism of over 70 percent between 2007 and 2013, while their Suicide Attack Database  showed a 19 percent decrease over the same period. Pape et al. insisted that the most likely explanation for this difference is the change in the organization responsible for managing that data collection from ISVG to START .  
If the issue is restricted to how incidents are classified as ""suicide terrorism"", this concern does not affect the other variables in this summary.  
However, if it also impacts what incidents are classified as ""terrorism"", it suggests larger problems.   Author(s)  
Spencer Graves   Source  
National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2017). Global Terrorism Database [Data file]. Retrieved from https://start.umd.edu/gtd [accessed 2018-04-08].  
See also the Global Terrorism Database maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START, 2015), https://www.start.umd.edu/gtd .  
The world and US population figures came from ""Total Population - Both Sexes"", World Population Prospects 2015, published by the Population Division of the Department of Economic and Social Affairs of the United Nations accessed 2016-09-05 (at a web link that has since changed: No longer at https://esa.un.org/unpd/wpp/Download/Standard/Population , as it was when the data current used here was downloaded, 2016-09-05. Fortunately, as of 2020-02-09, such data seem to be available at https://population.un.org/wpp/Download/Standard/Population/ .  
Human Mortality Database. University of California, Berkeley (USA), and Max Planck Institute for Demographic Research (Germany).     References  
Robert Pape, Keven Ruby, Vincent Bauer and Gentry Jenkins, ""How to fix the flaws in the Global Terrorism Database and why it matters"" , The Washington Post , August 11, 2014 (accessed 2016-01-09).   Examples    data(terrorism) ## ## plot deaths per million population ## plot(kill.pmp~year, terrorism, pch=method, type='b') plot(kill.pmp.us~year, terrorism, pch=method, type='b', log='y', las=1) # terrorism as parts per 10,000 # of all deaths plot(pkill*1e4~year, terrorism, pch=method, type='b', las=1) plot(pkill.us*1e4~year, terrorism, pch=method, type='b', log='y', las=1) # plot number of incidents, number killed, # and proportion NA plot(incidents~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method, log='y') plot(pNA.nkill.us~year, terrorism, type='b', pch=method) abline(v=1997.5, lty='dotted', col='red') ## ## by country by year ## data(incidents.byCountryYr) data(nkill.byCountryYr) yr <- as.integer(colnames( incidents.byCountryYr)) str(maxDeaths <- apply(nkill.byCountryYr, 1, max) ) str(omax <- order(maxDeaths, decreasing=TRUE)) head(maxDeaths[omax], 8) tolower(substring( names(maxDeaths[omax[1:8]]), 1, 2)) pch. <- c('i', 'g', 'f', 'l', 's', 'c', 'u', 'p') cols <- 1:4 matplot(yr, sqrt(t( nkill.byCountryYr[omax[1:8], ])), type='b', pch=pch., axes=FALSE, ylab='(square root scale) ', xlab='', col=cols, main='number of terrorism deaths\nby country') axis(1) (max.nk <- max(nkill.byCountryYr[omax[1:8], ])) i.nk <- c(1, 100, 1000, 3000, 5000, 7000, 10000) cbind(i.nk, sqrt(i.nk)) axis(2, sqrt(i.nk), i.nk, las=1) ip <- paste(pch., names(maxDeaths[omax[1:8]])) legend('topleft', ip, cex=.55, col=cols, text.col=cols)"
"Ecdat-incomeInequality","Ecdat","incomeInequality","Income Inequality in the US",66,22,0,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/incomeInequality.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/incomeInequality.html","incomeInequality R Documentation   Income Inequality in the US   Description  
Data on quantiles of the distributions of family incomes in the United States. This combines three data sources:   
(1) US Census Table F-1 for the central quantiles   
(2) Piketty and Saez for the 95th and higher quantiles   
(3) Gross Domestic Product and implicit price deflators from Measuring Worth. (NOTE: The Measuring Worth Web site, https://MeasuringWorth.com , often gives security warnings. The desired data still seems to be available and not corrupted, however.)    Usage   data(incomeInequality)   Format  
A data.frame containing:    Year
numeric year 1947:2012   Number.thousands 
number of families in the US   quintile1, quintile2, median, quintile3, quintile4, p95  
quintile1, quintile2, quintile3, quintile4, and p95 are the indicated quantiles of the distribution of family income from US Census Table F-1. The media is computed as the geometric mean of quintile2 and quintile3. This is accurate to the extent that the lognormal distribution adequately approximates the central 20 percent of the income distribution, which it should for most practical purposes.    P90, P95, P99, P99.5, P99.9, P99.99  
The indicated quantiles of family income per Piketty and Saez    realGDP.M, GDP.Deflator, PopulationK, realGDPperCap  
real GDP in millions, GDP implicit price deflators, US population in thousands, and real GDP per capita, according to  MeasuringWorth.com . (NOTE: The web address for this, https://MeasuringWorth.com , seems to be functional but may not be maintained to current internet security standards. It is therefore given here as text rather than a hot link.)   P95IRSvsCensus  
ratio of the estimates of the 95th percentile of distributions of family income from the Piketty and Saez analysis of data from the Internal Revenue Service (IRS) and from the US Census Bureau.   
The IRS has ranged between 72 and 98 percent of the Census Bureau figures for the 95th percentile of the distribution, with this ratio averaging around 75 percent since the late 1980s. However, this systematic bias is modest relative to the differences between the different quantiles of interest in this combined dataset.    personsPerFamily  
average number of persons per family using the number of families from US Census Table F-1 and the population from MeasuringWorth. (Note: The web site for Measuring Worth, https://MeasuringWorth.com , often gives security warnings. It still seems to work. It seems that the web site is not maintained to current internet security standards.)   realGDPperFamily  
personsPerFamily * realGDPperCap     mean.median  
ratio of realGDPperFamily to the median. This is a measure of skewness and income inequality.      Details  
For details on how this data.frame was created, see ""F1.PikettySaez.R"" in  system.file('scripts', package='fda') . This provides links for files to download and R commands to read those files and convert them into an updated version of incomeInequality . This is a reasonable thing to do if it is more than 2 years since max(incomeInequality$year) . All data are in constant 2012 dollars.    Author(s)  
Spencer Graves   Source  
United States Census Bureau, Table F-1. Income Limits for Each Fifth and Top 5 Percent of Families, All Races,  https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-inequality.html , accessed 2016-12-09.   
Thomas Piketty and Emmanuel Saez (2003) ""Income Inequality in the United States, 1913-1998"", Quarterly Journal of Economics, 118(1) 1-39, https://eml.berkeley.edu/~saez/ , update accessed February 28, 2014.   
Louis Johnston and Samuel H. Williamson (2011) ""What Was the U.S. GDP Then?"" MeasuringWorth. (Note: Their web address, https://www.measuringworth.org/usgdp , often gives security warnings. The desired data still seems to be available there. However, it seems that the site is not maintained to current internet security standards. The data used in the current USGDPpresidents data set was extracted February 28, 2014.)    Examples    ## ## Rato of IRS to census estimates for the 95th percentile ## data(incomeInequality) plot(P95IRSvsCensus~Year, incomeInequality, type='b') # starts ~0.74, trends rapidly up to ~0.97, # then drifts back to ~0.75 abline(h=0.75) abline(v=1989) # check sum(is.na(incomeInequality$P95IRSvsCensus)) # The Census data runs to 2011; Pikety and Saez runs to 2010. quantile(incomeInequality$P95IRSvsCensus, na.rm=TRUE) # 0.72 ... 0.98 ## ## Persons per Family ## plot(personsPerFamily~Year, incomeInequality, type='b') quantile(incomeInequality$personsPerFamily) # ranges from 3.72 to 4.01 with median 3.84 # -- almost 4 ## ## GDP per family ## plot(realGDPperFamily~Year, incomeInequality, type='b', log='y') ## ## Plot the mean then the first quintile, then the median, ## 99th, 99.9th and 99.99th percentiles ## plotCols <- c(21, 3, 5, 11, 13:14) kcols <- length(plotCols) plotColors <- c(1:6, 8:13)[1:kcols] # omit 7=yellow plotLty <- 1:kcols matplot(incomeInequality$Year, incomeInequality[plotCols]/1000, log='y', type='l', col=plotColors, lty=plotLty) #*** Growth broadly shared 1947 - 1970, then began diverging #*** The divergence has been most pronounced among the top 1% #*** and especially the top 0.01% ## ## Growth rate by quantile 1947-1970 and 1970 - present ## keyYears <- c(1947, 1970, 2010) (iYears <- which(is.element(incomeInequality$Year, keyYears))) (dYears <- diff(keyYears)) kk <- length(keyYears) (lblYrs <- paste(keyYears[-kk], keyYears[-1], sep='-')) (growth <- sapply(incomeInequality[iYears,], function(x, labels=lblYrs){ dxi <- exp(diff(log(x))) names(dxi) <- labels dxi } )) # as percent (gr <- round(100*(growth-1), 1)) # The average annual income (realGDPperFamily) doubled between # 1970 and 2010 (increased by 101 percent), while the median household # income increased only 23 percent. ## ## Income lost by each quantile 1970-2010 ## relative to the broadly shared growth 1947-1970 ## (lostGrowth <- (growth[, 'realGDPperFamily']-growth[, plotCols])) # 1947-1970: The median gained 20% relative to the mean, # while the top 1% lost ground # 1970-2010: The median lost 79%, the 99th percentile lost 29%, # while the top 0.1% gained (lostIncome <- (lostGrowth[2, ] * incomeInequality[iYears[2], plotCols])) # The median family lost $39,000 per year in income # relative to what they would have with the same economic growth # broadly shared as during 1947-1970. # That's slightly over $36,500 per year = $100 per day (grYr <- growth^(1/dYears)) (grYr. <- round(100*(grYr-1), 1)) ## ## Regression line: linear spline ## (varyg <- c(3:14, 21)) Varyg <- names(incomeInequality)[varyg] str(F01ps <- reshape(incomeInequality[c(1, varyg)], idvar='Year', ids=F1.PikettySeaz$Year, times=Varyg, timevar='pctile', varying=list(Varyg), direction='long')) names(F01ps)[2:3] <- c('variable', 'value') F01ps$variable <- factor(F01ps$variable) # linear spline basis function with knot at 1970 F01ps$t1970p <- pmax(0, F01ps$Year-1970) table(nas <- is.na(F01ps$value)) # 6 NAs, one each of the Piketty-Saez variables in 2011 F01i <- F01ps[!nas, ] # formula: # log(value/1000) ~ b*Year + (for each variable: # different intercept + (different slope after 1970)) Fit <- lm(log(value/1000)~Year+variable*t1970p, F01i) anova(Fit) # all highly significant # The residuals may show problems with the model, # but we will ignore those for now. # Model predictions str(Pred <- predict(Fit)) ## ## Combined plot ## # Plot to a file? Wikimedia Commons prefers svg format. ## Not run: if(FALSE){ svg('incomeInequality8.svg') # If you want software to convert svg to another format # such as png, consider GIMP (www.gimp.org). # Base plot # Leave extra space on the right to label # with growth since 1970 op <- par(mar=c(5, 4, 4, 5)+0.1) matplot(incomeInequality$Year, incomeInequality[plotCols]/1000, log='y', type='l', col=plotColors, lty=plotLty, xlab='', ylab='', las=1, axes=FALSE, lwd=3) axis(1, at=seq(1950, 2010, 10), labels=c(1950, NA, 1970, NA, 1990, NA, 2010), cex.axis=1.5) yat <- c(10, 50, 100, 500, 1000, 5000, 10000) axis(2, yat, labels=c('$10K', '$50K', '$100K', '$500K', '$1M', '$5M', '$10M'), las=1, cex.axis=1.2) # Label the lines pctls <- paste(c(20, 40, 50, 60, 80, 90, 95, 99, 99.5, 99.9, 99.99), '%', sep='') lineLbl0 <- c('Year', 'families K', pctls, 'realGDP.M', 'GDP deflator', 'pop-K', 'realGDPperFamily', '95 pct(IRS / Census)', 'size of household', 'average family income', 'mean/median') (lineLbls <- lineLbl0[plotCols]) sel75 <- (incomeInequality$Year==1975) laby <- incomeInequality[sel75, plotCols]/1000 text(1973.5, c(1.2, 1.2, 1.3, 1.5, 1.9)*laby[-1], lineLbls[-1], cex=1.2) text(1973.5, 1.2*laby[1], lineLbls[1], cex=1.2, srt=10) ## ## Add lines + points for the knots in 1970 ## End <- numeric(kcols) F01names <- names(incomeInequality) for(i in seq(length=kcols)){ seli <- (as.character(F01i$variable) == F01names[plotCols[i]]) # with(F01i[seli, ], lines(Year, exp(Pred[seli]), # col=plotColors[i])) yri <- F01i$Year[seli] predi <- exp(Pred[seli]) lines(yri, predi, col=plotColors[i]) End[i] <- predi[length(predi)] sel70i <- (yri==1970) points(yri[sel70i], predi[sel70i], col=plotColors[i]) } ## ## label growth rates ## table(sel70. <- (incomeInequality$Year>1969)) (lastYrs <- incomeInequality[sel70., 'Year']) (lastYr. <- max(lastYrs)+4) #text(lastYr., End, gR., xpd=NA) text(lastYr., End, paste(gr[2, plotCols], '%', sep=''), xpd=NA) text(lastYr.+7, End, paste(grYr.[2, plotCols], '%', sep=''), xpd=NA) ## ## Label the presidents ## abline(v=c(1953, 1961, 1969, 1977, 1981, 1989, 1993, 2001, 2009)) (m99.95 <- with(incomeInequality, sqrt(P99.9*P99.99))/1000) text(1949, 5000, 'Truman') text(1956.8, 5000, 'Eisenhower', srt=90) text(1963, 5000, 'Kennedy', srt=90) text(1966.8, 5000, 'Johnson', srt=90) text(1971, 5*m99.95[24], 'Nixon', srt=90) text(1975, 5*m99.95[28], 'Ford', srt=90) text(1978.5, 5*m99.95[32], 'Carter', srt=90) text(1985.1, m99.95[38], 'Reagan' ) text(1991, 0.94*m99.95[44], 'GHW Bush', srt=90) text(1997, m99.95[50], 'Clinton') text(2005, 1.1*m99.95[58], 'GW Bush', srt=90) text(2010, 1.2*m99.95[62], 'Obama', srt=90) ## ## Done ## par(op) # reset margins dev.off() # for plot to a file } ## End(Not run)"
"Ecdat-IncomeUK","Ecdat","IncomeUK","Seasonally Unadjusted Quarterly Data on Disposable Income and Expenditure",58,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/IncomeUK.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/IncomeUK.html","IncomeUK R Documentation   Seasonally Unadjusted Quarterly Data on Disposable Income and Expenditure   Description  
quarterly observations from 1971–1 to 1985–2   
number of observations : 58   
observation : country   
country : United Kingdom    Usage   data(IncomeUK)   Format  
A time series containing :    income
total disposable income (million Pounds, current prices)   consumption
consumer expenditure (million Pounds, current prices)     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapters 8 and 9.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Irates","Ecdat","Irates","Monthly Interest Rates",531,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Irates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Irates.html","Irates R Documentation   Monthly Interest Rates   Description  
monthly observations from 1946–12 to 1991–02   
number of observations : 531   
observation : country   
country : United–States    Usage   data(Irates)   Format  
A time series containing :    r1
interest rate for a maturity of 1 months (% per year).   r2
interest rate for a maturity of 2 months (% per year).   r3
interest rate for a maturity of 3 months (% per year).   r5
interest rate for a maturity of 5 months (% per year).   r6
interest rate for a maturity of 6 months (% per year).   r11
interest rate for a maturity of 11 months (% per year).   r12
interest rate for a maturity of 12 months (% per year).   r36
interest rate for a maturity of 36 months (% per year).   r60
interest rate for a maturity of 60 months (% per year).   r120
interest rate for a maturity of 120 months (% per year).     Source  
McCulloch, J.H. and H.C. Kwon (1993) U.S. term structure data, 1947–1991 , Ohio State Working Paper 93-6, Ohio State University, Columbus.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 8.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Journals","Ecdat","Journals","Economic Journals Data Set",180,10,1,0,4,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Journals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Journals.html","Journals R Documentation   Economic Journals Data Set   Description  
a cross-section from 2000   
number of observations : 180   
observation : goods    Usage   data(Journals)   Format  
A dataframe containing :    title
journal title   pub
publisher   society
scholarly society ?   libprice
library subscription price   pages
number of pages   charpp
characters per page   citestot
total number of citations   date1
year journal was founded   oclc
number of library subscriptions   field
field description     Source  
Professor Theodore Bergstrom of the Department of Economics at the University of California, San Diego.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 6.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Kakadu","Ecdat","Kakadu","Willingness to Pay for the Preservation of the Kakadu National Park",1827,22,5,0,6,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Kakadu.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Kakadu.html","Kakadu R Documentation    Willingness to Pay for the Preservation of the Kakadu National Park    Description  
a cross-section   
number of observations : 1827   
observation : individuals   
country : Australia    Usage   data(Kakadu)   Format  
A dataframe containing :    lower  
lower bound of willingness to pay, 0 if observation is left censored    upper  
upper bound of willingness to pay, 999 if observation is right censored    answer  
an ordered factor with levels nn (respondent answers no, no),  ny (respondent answers no, yes or yes, no), yy (respondent answers yes, yes)    recparks  
the greatest value of national parks and nature reserves is in recreation activities (from 1 to 5)    jobs  
jobs are the most important thing in deciding how to use our natural resources (from 1 to 5)    lowrisk  
development should be allowed to proceed where environmental damage from activities such as mining is possible but very unlikely (from 1 to 5)    wildlife  
it's important to have places where wildlife is preserved (from 1 to 5)    future  
it's important to consider future generations (from 1 to 5)    aboriginal  
in deciding how to use areas such as Kakadu national park, their importance to the local aboriginal people should be a major factor (from 1 to 5)    finben  
in deciding how to use our natural resources such as mineral deposits and forests, the most important thing is the financial benefits for Australia (from 1 to 5)    mineparks  
if areas within natural parks are set aside for development projects such as mining, the value of the parks is greatly reduced (from 1 to 5)    moreparks  
there should be more national parks created from state forests (from 1 to 5)    gov  
the government pays little attention to the people in making decisions (from 1 to 4)    envcon  
the respondent recycles things such as paper or glass and regularly buys unbleached toilet paper or environmentally friendly products?    vparks  
the respondent has visited a national park or bushland recreation area in the previous 12 months?    tvenv  
the respondent watches TV programs about the environment? (from 1 to 9)    conservation  
the respondent is member of a conservation organization?    sex
male,female   age
age   schooling
years of schooling   income  
respondent's income in thousands of dollars    major  
the respondent received the major–impact scenario of the Kakadu conservation zone survey ?      Source  
Werner, Megan (1999) “Allowing for zeros in dichotomous–choice contingent–valuation models”, Journal of Business and Economic Statistics , 17(4) , October, 479–486.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Ketchup","Ecdat","Ketchup","Choice of Brand for Ketchup",4956,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Ketchup.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Ketchup.html","Ketchup R Documentation   Choice of Brand for Ketchup   Description  
a cross-section   
number of observations : 4956   
observation : individuals   
country : United States    Usage   data(Ketchup)   Format  
A dataframe containing :    hid
individuals identifiers   id
purchase identifiers   choice  
one of heinz , hunts , delmonte , stb (store brand)    price.z
price of brand z     Source  
Kim, Byong–Do, Robert C. Blattberg and Peter E. Rossi (1995) “Modeling the distribution of price sensitivity and implications for optimal retail pricing”, Journal of Business Economics and Statistics , 13(3) , 291.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Catsup , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Klein","Ecdat","Klein","Klein's Model I",22,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Klein.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Klein.html","Klein R Documentation   Klein's Model I   Description  
annual observations from 1920 to 1941   
number of observations : 22   
observation : country   
country : United States    Usage   data(Klein)   Format  
A time series containing :    cons
consumption   profit
corporate profits   privwage
private wage bill   inv
investment   lcap
previous year's capital stock   gnp
GNP   pubwage
government wage bill   govspend
government spending   taxe
taxes     Source  
Klein, L. (1950) Economic fluctuations in the United States, 1921-1941 , New York, John Wiley and Sons.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F15.1.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-LaborSupply","Ecdat","LaborSupply","Wages and Hours Worked",5320,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/LaborSupply.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/LaborSupply.html","LaborSupply R Documentation   Wages and Hours Worked   Description  
a panel of 532 observations from 1979 to 1988   
number of observations : 5320    Usage   data(LaborSupply)   Format  
A dataframe containing :    lnhr
log of annual hours worked   lnwg
log of hourly wage   kids
number of children   age
age   disab
bad health   id
id   year
year     Source  
Ziliak, Jim (1997) “Efficient Estimation With Panel Data when Instruments are Predetermined: An Empirical Comparison of Moment-Condition Estimators”, Journal of Business and Economic Statistics , 419–431 .    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 708–15, 754–6.   
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Labour","Ecdat","Labour","Belgian Firms",569,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Labour.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Labour.html","Labour R Documentation   Belgian Firms   Description  
a cross-section from 1996   
number of observations : 569   
observation : production units   
country : Belgium    Usage   data(Labour)   Format  
A dataframe containing :    capital
total fixed assets, end of 1995 (in 1000000 euro)   labour
number of workers (employment)   output
value added (in 1000000 euro)   wage
wage costs per worker (in 1000 euro)     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 4.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Longley","Ecdat","Longley","The Longley Data",16,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Longley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Longley.html","Longley R Documentation   The Longley Data   Description  
annual observations from 1947 to 1962   
number of observations : 16   
observation : country   
country : United States    Usage   data(Longley)   Format  
A time series containing :    employ
employment (1,000s)   price
GNP deflator   gnp
nominal GNP (millions)   armed
armed forces     Source  
Longley, J. (1967) “An appraisal of least squares programs from the point of view of the user”, Journal of the American Statistical Association , 62 , 819-841.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F4.2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-LT","Ecdat","LT","Dollar Sterling Exchange Rate",200,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/LT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/LT.html","LT R Documentation   Dollar Sterling Exchange Rate   Description  
annual observations from 1791 to 1990   
number of observations : 200   
observation : country   
country : United Kingdom    Usage   data(LT)   Format  
A time series containing :    s
US *Dollar / *Pound exchange rate   uswpi
US wholesale price index, normalized to 100 for 1914   ukwpi
US wholesale price index, normalized to 100 for 1914     Source  
Lothian, J. and M. Taylor (1996) “Real exchange rate behavior: the recent float from the perspective of the past two centuries”, Journal of Political Economy , 104 , 488-509.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 9, 613-621.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Macrodat","Ecdat","Macrodat","Macroeconomic Time Series for the United States",168,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Macrodat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Macrodat.html","Macrodat R Documentation    Macroeconomic Time Series for the United States   Description  
quarterly observations from 1959-1 to 2000-4   
number of observations : 168   
observation : country   
country : United States    Usage   data(Macrodat)   Format  
A time series containing :    lhur  
unemployment rate (average of months in quarter)   punew  
CPI (Average of Months in Quarter)   fyff  
federal funds interest rate (last month in quarter)   fygm3  
3 month treasury bill interest rate (last month in quarter)   fygt1  
1 year treasury bond interest rate (last month in quarter)   exruk  
dollar / Pound exchange rate (last month in quarter)   gdpjp  
real GDP for Japan     Source  
Bureau of Labor Statistics, OECD, Federal Reserve.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 12 and 14.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Males","Ecdat","Males","Wages and Education of Young Males",4360,12,3,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Males.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Males.html","Males R Documentation   Wages and Education of Young Males   Description  
a panel of 545 observations from 1980 to 1987   
number of observations : 4360   
observation : individuals   
country : United States    Usage   data(Males)   Format  
A dataframe containing :    nr
identifier   year
year   school
years of schooling   exper
years of experience (=age-6-school)   union
wage set by collective bargaining ?   ethn  
a factor with levels ( black , hisp , other )    maried
married ?   health
health problem ?   wage
log of hourly wage   industry
a factor with 12 levels   occupation
a factor with 9 levels   residence  
a factor with levels ( rural area , north east , northern central , south )      Source  
National Longitudinal Survey (NLS Youth Sample).   
Vella, F. and M. Verbeek (1998) “Whose wages do unions raise ? A dynamic model of unionism and wage”, Journal of Applied Econometrics , 13 , 163–183.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 10.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-ManufCost","Ecdat","ManufCost","Manufacturing Costs",25,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/ManufCost.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/ManufCost.html","ManufCost R Documentation   Manufacturing Costs   Description  
annual observations from 1947 to 1971   
number of observations : 25   
observation : country   
country : United States    Usage   data(ManufCost)   Format  
A time series containing :    cost
cost index   sk
capital cost share   sl
labor cost share   se
energy cost share   sm
materials cost share   pk
capital price   pl
labor price   pe
energy price   pm
materials price     Source  
Berndt, E. and D. Wood (1975) “Technology, prices and the derived demand for energy”, Journal of Economics and Statistics , 57 , 376-384.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F14.1.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Mathlevel","Ecdat","Mathlevel","Level of Calculus Attained for Students Taking Advanced Micro-economics",609,8,2,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mathlevel.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mathlevel.html","Mathlevel R Documentation   Level of Calculus Attained for Students Taking Advanced Micro–economics   Description  
a cross-section from 1983 to 1986   
number of observations : 609   
observation : individuals   
country : United States    Usage   data(Mathlevel)   Format  
A dataframe containing :    mathlevel
highest level of math attained , an ordered factor with levels 170, 171a, 172, 171b, 172b, 221a, 221b   sat
sat Math score   language
foreign language proficiency ?   sex
male, female   major  
one of other , eco , oss  (other social sciences), ns (natural sciences), hum (humanities)    mathcourse  
number of courses in advanced math (0 to 3)    physiccourse  
number of courses in physics (0 to 2)    chemistcourse  
number of courses in chemistry (0 to 2)      Source  
Butler, J.S., T. Aldrich Finegan and John J. Siegfried (1998) “Does more calculus improve student learning in intermediate micro and macroeconomic theory ?”, Journal of Applied Econometrics , 13(2) , April, 185–202.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-MCAS","Ecdat","MCAS","The Massachusetts Test Score Data Set",220,17,0,0,2,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MCAS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/MCAS.html","MCAS R Documentation   The Massachusetts Test Score Data Set   Description  
a cross-section from 1997-1998   
number of observations : 220   
observation : schools   
country : United States    Usage   data(MCAS)   Format  
A dataframe containing :    code
district code (numerical)   municipa
municipality (name)   district
district name   regday
spending per pupil, regular   specneed
spending per pupil, special needs   bilingua
spending per pupil, bilingual   occupday
spending per pupil, occupational   totday
spending per pupil, total   spc
students per computer   speced
special education students   lnchpct
eligible for free or reduced price lunch   tchratio
students per teacher   percap
per capita income   totsc4  
4th grade score ( math+english+science )    totsc8  
8th grade score ( math+english+science )    avgsalary
average teacher salary   pctel
percent English learners     Source  
Massachusetts Comprehensive Assessment System (MCAS), Massachusetts Department of Education, 1990 U.S. Census.    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 7.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-MedExp","Ecdat","MedExp","Structure of Demand for Medical Care",5574,15,5,0,6,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MedExp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/MedExp.html","MedExp R Documentation   Structure of Demand for Medical Care   Description  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/    
number of observations : 5574    Usage   data(MedExp)   Format  
A time series containing :    med  
annual medical expenditures in constant dollars excluding dental and outpatient mental   lc  
log(coinsrate+1) where coinsurance rate is 0 to 100    idp
individual deductible plan ?   lpi  
log (annual participation incentive payment) or 0 if no payment   fmde  
log (max(medical deductible expenditure)) if IDP =1 and MDE >1 or 0 otherwise    physlim
physical limitation ?   ndisease
number of chronic diseases   health
self–rate health (excellent,good,fair,poor)   linc
log of annual family income (in \$)   lfam
log of family size   educdec
years of schooling of household head   age
exact age   sex
sex (male,female)   child
age less than 18 ?   black
is household head black ?     Source  
Deb, P. and P.K. Trivedi (2002) “The Structure of Demand for Medical Care: Latent Class versus Two-Part Models”, Journal of Health Economics , 21 , 601–625.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge.    See Also  
DoctorContacts ,  Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Metal","Ecdat","Metal","Production for SIC 33",27,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Metal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Metal.html","Metal R Documentation   Production for SIC 33   Description  
a cross-section   
number of observations : 27   
observation : regional   
country : United States    Usage   data(Metal)   Format  
A dataframe containing :    va
output   labor
labor input   capital
capital input     Source  
Aigner, D., K. Lovell and P. Schmidt (1977) “Formulation and estimation of stochastic frontier production models”, Journal of Econometrics , 6 , 21-37.   
Hildebrand, G. and T. Liu (1957) Manufacturing production functions in the United States , Ithaca, N.Y.: Cornell University Press.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F6.1.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Mishkin","Ecdat","Mishkin","Inflation and Interest Rates",491,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mishkin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mishkin.html","Mishkin R Documentation   Inflation and Interest Rates   Description  
monthly observations from 1950-2 to 1990-12   
number of observations : 491   
observation : country   
country : United States    Usage   data(Mishkin)   Format  
A time series containing :    pai1
one-month inflation rate (in percent, annual rate)   pai3
three-month inflation rate (in percent, annual rate)   tb1
one-month T-bill rate (in percent, annual rate)   tb3
three-month T-bill rate (in percent, annual rate)   cpi
CPI for urban consumers, all items (the 1982-1984 average is set to 100)     Source  
Mishkin, F. (1992) “Is the Fisher effect for real ?”, Journal of Monetary Economics , 30 , 195-215.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 2, 176-184.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Mode","Ecdat","Mode","Mode Choice",453,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mode.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mode.html","Mode R Documentation   Mode Choice   Description  
a cross-section   
number of observations : 453   
observation : individuals    Usage   data(Mode)   Format  
A dataframe containing :    choice
one of car, carpool, bus or rail   cost.z
cost of mode z   time.z
time of mode z     References  
Kenneth Train's home page : http://elsa.berkeley.edu/~train/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-ModeChoice","Ecdat","ModeChoice","Data to Study Travel Mode Choice",840,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/ModeChoice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/ModeChoice.html","ModeChoice R Documentation   Data to Study Travel Mode Choice   Description  
a cross-section   
number of observations : 840   
observation : individuals   
country : Australia    Usage   data(ModeChoice)   Format  
A dataframe containing :    mode
choice : air, train, bus or car   ttme
terminal waiting cost time, 0 for car   invc
in vehicle cost-cost component   invt
travel time in vehicle   gc
generalized cost measure   hinc
household income   psize
party size in mode chosen     Source  
Greene, W.H. and D. Hensher (1997) Multinomial logit and discrete choice models in Greene, W. H. (1997) LIMDEP version 7.0 user's manual revised , Plainview, New York econometric software, Inc .    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F21.2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Mofa","Ecdat","Mofa","International Expansion of U.S. MOFAs (majority-owned Foreign Affiliates in Fire (finance, Insurance and Real Estate)",50,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mofa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mofa.html","Mofa R Documentation    International Expansion of U.S. MOFAs (majority–owned Foreign Affiliates in Fire (finance, Insurance and Real Estate)   Description  
a cross-section from 1982   
number of observations : 50   
observation : country   
country : United States    Usage   data(Mofa)   Format  
A dataframe containing :    capexp  
capital expenditures made by the MOFAs of nonbank U.S. corporations in finance, insurance and real estate. Source: ""U.S. Direct Investment Abroad: 1982 Benchmark Survey data."" Table III.C 6.    gdp  
gross domestic product. Source: ""World Bank, World Development Report 1984."" Table 3. (This variable is scaled by a factor of 1/100,000)    sales
sales made by the majority owned foreign affiliates of nonbank U.S. parents in finance, insurance and real estate. Source: ""U.S. Direct Investment Abroad: 1982 Benchmark Survey Data."" Table III.D 3. (This variable is scaled by a factor of 1/100)   nbaf
the number of U.S. affiliates in the host country. Source: ""U.S. Direct Investment Abroad: 1982 Benchmark Survey Data."" Table 5. (This variable is scaled by a factor of 1/100)   netinc
net income earned by MOFAs of nonbank U.S. corporations operating in the nonbanking financial sector of the host country. Source: ""U.S. Direct Investment Abroad: 1982 Benchmark Survey Data."" Table III.D 6.(This variable is scaled by a factor of 1/10)     Source  
Ioannatos, Petros E. (1995) “Censored regression estimation under unobserved heterogeneity : a stochastic parameter approach”, Journal of Business and Economics Statistics , 13(3) , July, 327–335.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Money","Ecdat","Money","Money, GDP and Interest Rate in Canada",128,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Money.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Money.html","Money R Documentation   Money, GDP and Interest Rate in Canada   Description  
quarterly observations from 1967-1 to 1998-4   
number of observations : 128   
observation : country   
country : Canada    Usage   data(Money)   Format  
A time series containing :    m
log of the real money supply   y
the log of GDP, in 1992 dollars, seasonally adjusted   p
the log of the price level   r
the 3-month treasury till rate     Source  
CANSIM Database of Statistics Canada.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 7 and 8.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-MoneyUS","Ecdat","MoneyUS","Macroeconomic Series for the United States",164,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MoneyUS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/MoneyUS.html","MoneyUS R Documentation   Macroeconomic Series for the United States   Description  
quarterly observations from 1954–01 to 1994–12   
number of observations : 164   
country : United States    Usage   data(MoneyUS)   Format  
A time series containing :    m
log of real M1 money stock   infl
quarterly inflation rate (change in log prices), % per year   cpr
commercial paper rate, % per year   y
log real GDP (in billions of 1987 dollars)   tbr
treasury bill rate     Source  
Hoffman, D.L. and R.H. Rasche (1996) “Assessing forecast performance in a cointegrated system”, Journal of Applied Econometrics , 11 , 495–517.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 9.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Mpyr","Ecdat","Mpyr","Money, National Product and Interest Rate",90,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mpyr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mpyr.html","Mpyr R Documentation   Money, National Product and Interest Rate   Description  
annual observations from 1900 to 1989   
number of observations : 90   
observation : country   
country : United States    Usage   data(Mpyr)   Format  
A time series containing :    m
natural log of M1   p
natural log of the net national product price deflator   y
natural log of the net national product   r
the commercial paper rate in percent at an annual rate     Source  
Stock, J. and M. Watson (1999) “Testing for common trends”, Journal of the American Statistical Association , 83 , 1097-1107.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 10, 665-667.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Mroz","Ecdat","Mroz","Labor Supply Data",753,18,2,0,2,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Mroz.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Mroz.html","Mroz R Documentation   Labor Supply Data   Description  
a cross-section   
number of observations : 753   
observation : individuals   
country : United States    Usage   data(Mroz)   Format  
A dataframe containing :    work  
work at home in 1975? (Same carData::Mroz[['lfp']] = labor force participation.)    hoursw
wife's hours of work in 1975   child6  
number of children less than 6 years old in household (Same as carData::Mroz['k5'] .)    child618  
number of children between ages 6 and 18 in household (Same as carData::Mroz['k618'] )    agew
wife's age   educw  
wife's educational attainment, in years    hearnw  
wife's average hourly earnings, in 1975 dollars    wagew  
wife's wage reported at the time of the 1976 interview (not= 1975 estimated wage)    hoursh
husband's hours worked in 1975   ageh
husband's age   educh  
husband's educational attainment, in years    wageh
husband's wage, in 1975 dollars   income
family income, in 1975 dollars   educwm  
wife's mother's educational attainment, in years    educwf  
wife's father's educational attainment, in years    unemprate  
unemployment rate in county of residence, in percentage points    city
lives in large city (SMSA) ?   experience  
actual years of wife's previous labor market experience      Details  
These data seem to have come from the same source as carData::Mroz , though each data set has variables not in the other. The variables that are shared have different names.  
On 2019-11-04 Bruno Rodrigues explained that Ecdat::Mroz['work'] had the two labels incorrectly swapped, and wooldridge::mroz['inlf'] was correct; wooldridge matches carData::Mroz['lfp'] .   Source  
Mroz, T. (1987) “The sensitivity of an empirical model of married women's hours of work to economic and statistical assumptions”, Econometrica , 55 , 765-799.   
1976 Panel Study of Income Dynamics.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F4.1.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations , Mroz   mroz     Examples    head(Mroz) #If 'car' and / or 'carData' is also in the path, # then use the following to be clear that # you want this version: head(Ecdat::Mroz)"
"Ecdat-MunExp","Ecdat","MunExp","Municipal Expenditure Data",2385,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MunExp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/MunExp.html","MunExp R Documentation   Municipal Expenditure Data   Description  
a panel of 265 observations from 1979 to 1987   
number of observations : 2385   
observation : regional   
country : Sweden    Usage   data(MunExp)   Format  
A dataframe containing :    id
identification   year
date   expend
expenditure   revenue
revenue from taxes and fees   grants
grants from Central Government     Source  
Dahlberg, M. and E. Johansson (2000) “An examination of the dynamic behavior of local government using GMM boot-strapping methods”, Journal of Applied Econometrics , 21 , 333-355.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F18.1.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-MW","Ecdat","MW","Growth of Disposable Income and Treasury Bill Rate",50,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MW.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/MW.html","MW R Documentation   Growth of Disposable Income and Treasury Bill Rate   Description  
quarterly observations from 1963-3 to 1975-4   
number of observations : 50   
observation : country   
country : United States    Usage   data(MW)   Format  
A time series containing :    rdi
the rate of growth of real U.S. disposable income, seasonally adjusted   trate
the U.S. treasury bill rate     Source  
MacKinnon, J. G. and H. T. White (1985) “Some heteroskedasticity consistent covariance matrix estimators with improved finite sample properties”, Journal of Econometrics , 29 , 305-325.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 5.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-NaturalPark","Ecdat","NaturalPark","Willingness to Pay for the Preservation of the Alentejo Natural Park",312,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/NaturalPark.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/NaturalPark.html","NaturalPark R Documentation   Willingness to Pay for the Preservation of the Alentejo Natural Park   Description  
a cross-section from 1987   
number of observations : 312   
observation : individuals   
country : Portugal    Usage   data(NaturalPark)   Format  
A dataframe containing :    bid1
initial bid, in euro   bidh
higher bid   bidl
lower bid   answers  
a factor with levels ( nn , ny , yn , yy )    age
age in 6 classes   sex
a factor with levels (male,female)   income
income in 8 classes     Source  
Nunes, Paulo (2000) Contingent Valuation of the Benefits of natural areas and its warmglow component , PhD thesis 133, FETEW , KU Leuven .    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 7.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Nerlove","Ecdat","Nerlove","Cost Function for Electricity Producers, 1955",159,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Nerlove.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Nerlove.html","Nerlove R Documentation   Cost Function for Electricity Producers, 1955   Description  
a cross-section from 1955 to 1955   
number of observations : 159   
observation : production units   
country : United States    Usage   data(Nerlove)   Format  
A dataframe containing :    cost
total cost   output
total output   pl
wage rate   sl
cost share for labor   pk
capital price index   sk
cost share for capital   pf
fuel price   sf
cost share for fuel     Source  
Nerlove, M. (1963) Returns to scale in electricity industry in Christ, C. ed. (1963) Measurement in Economics: Studies in Mathematical Economics and Econometrics in Memory of Yehuda Grunfeld , Stanford, California, Stanford University Press .   
Christensen, L. and W. H. Greene (1976) “Economies of scale in U.S. electric power generation”, Journal of Political Economy , 84 , 655-676.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F14.2.   
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 1, 76-84.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-nkill.byCountryYr","Ecdat","nkill.byCountryYr","Global Terrorism Database yearly summaries",206,46,0,0,0,0,46,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/nkill.byCountryYr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/nkill.byCountryYr.html","terrorism R Documentation    Global Terrorism Database yearly summaries    Description  
The Global Terrorism Database (GTD) ""is a database of incidents of terrorism from 1970 onward"". Through 2015, this database contains information on 141,966 incidents.  
terrorism provides a few summary statistics along with an ordered  factor methodology , which Pape et al.  insisted is necessary, because an increase of over 70 percent in suicide terrorism between 2007 and 2013 is best explained by a methodology change in GTD that occurred on 2011-11-01; Pape's own Suicide Attack Database showed a 19 percent decrease over the same period.   Usage    data(terrorism) data(incidents.byCountryYr) data(nkill.byCountryYr)    Format  
incidents.byCountryYr and nkill.byCountryYr are matrices giving the numbers of incidents and numbers of deaths by year and by location of the event for 206 countries (rows) and for all years between 1970 and 2016 (columns) except for 1993, for which the entries are all NA, because the raw data previously collected was lost (though the total for that year is available in the data.frame  terrorism ).  
NOTES:  
1. For nkill.byCountryYr and for terrorism[c('nkill', 'nkill.us')] , NAs in GTD were treated as 0. Thus the actual number of deaths were likely higher, unless this was more than offset by incidents being classified as terrorism, when they should not have been.  
2. incidents.byCountryYr and nkill.byCountryYr are NA for 1993, because the GTD data for that year were lost.  
terrorism is a data.frame  containing the following:   year
integer year, 1970:2016.   methodology  
an ordered factor giving the methodology / organization responsible for the data collection for most of the given year. The Pinkerton Global Intelligence Service ( PGIS ) managed data collection from 1970-01-01 to 1997-12-31. The Center for Terrorism and Intelligence Studies ( CETIS ) managed the project from 1998-01-01 to 2008-03-31. The Institute for the Study of Violent Groups ( ISVG ) carried the project from 2008-04-01 to 2011-10-31. The National Consortium for the Study of Terrorism and Responses to Terrorism ( START ) has managed data collection since 2011-11-01. For this variable, partial years are ignored, so methodology = CEDIS for 1998:2007, ISVG for 2008:2011, and START for 2012:2014.   method  
a character vector consisting of the first character of the levels of methodology :  
c('p', 'c', 'i', 's')    incidents  
integer number of incidents identified each year.  
NOTE: sum(terrorism[[""incidents""]]) = 146920 = 141966 in the GTD database plus 4954 for 1993, for which the incident-level data were lost.   incidents.us  
integer number of incidents identified each year with country_txt = ""United States"".   suicide  
integer number of incidents classified as ""suicide"" by GTD variable suicide = 1. For 2007, this is 359, the number reported by Pape et al. For 2013, it is 624, which is 5 more than the 619 mentioned by Pape et al. Without checking with the SMART project administrators, one might suspect that 5 more suicide incidents from 2013 were found after the data Pape et al. analyzed but before the data used for this analysis.   suicide.us  
Number of suicide incidents by year with country_txt = ""United States"".   nkill  
number of confirmed fatalities for incidents in the given year, including attackers = sum(nkill, na.rm=TRUE) in the GTD incident data.  
NOTE: nkill in the GTD incident data includes both perpetrators and victims when both are available. It includes one when only one is available and is NA when neither is available. However, in most cases, we might expect that the more spectacular and lethal incidents would likely be more accurately reported. To the extent that this is true, it means that when numbers are missing, they are usually zero or small. This further suggests that the summary numbers recorded here probably represent a slight but not substantive undercount.   nkill.us  
number of U.S. citizens who died as a result of incidents for that year = sum(nkill.us, na.rm=TRUE) in the GTD incident data.  
NOTES:  
1. This is subject to the same likely modest undercount discussed with nkill .)   
2. These are U.S. citizens killed regardless of location. This explains at least part of the discrepancies between  terrorism[, 'nkill.us'] and nkill.byCountryYr['United States', ] .    nwound  
number of people wounded. (This is subject to the same likely modest undercount discussed with nkill .)    nwound.us  
Number of U.S. citizens wounded in terrorist incidents for that year = sum(nwound.us, na.rm=TRUE) in the GTD incident data. (This is subject to the same likely modest undercount discussed with nkill .)    pNA.nkill, pNA.nkill.us, pNA.nwound, pNA.nwound.us  
proportion of observations by year with missing values. These numbers are higher for the early data than more recent numbers. This is particularly true for nkill.us  and nwound.us , which exceed 90 percent for most of the period with methodology = PGIS , prior to 1998.   worldPopulation, USpopulation  
Estimated de facto population in thousands living in the world and in the US as of 1 July of the year indicated, according to the Population Division of the Department of Economic and Social Affairs of the United Nations; see ""Sources"" below.   worldDeathRate, USdeathRate  
Crude death rate  (deaths per 1,000 population) worldwide and in the US, according to the World Bank; see ""Sources"" below. This World Bank data set includes USdeathRate for each year from 1900 to 2014.  
The worldDeathRate numbers here were read manually from a plot on that web page, except for the the number for 2015, which was estimated as a reduction of 0.73 percent from 2014, which was the average rate of decline (ratio of two successive years) for 1990 to 2014. The same method was used to estimate the USdeathRate for 2015 as the same as for 2014.  
NOTE: USdeathRate is to two significant digits only, unlike worldDeathRate , which has four significant digits.   worldDeaths, USdeaths  
number of deaths by year in the world and US   
worldDeaths = worldPopulation * worldDeathRate .  
USdeaths were computed by summing across age groups in ""Deaths_5x1.txt"" for the United States, downloaded from https://www.mortality.org/cgi-bin/hmd/country.php?cntr=USA&level=1 from the Human Mortality Database; see sources below.   kill.pmp, kill.pmp.us  
terrorism deaths per million population worldwide and in the US =  
0.001 * nkill / worldPopulation     pkill, pkill.us  
terrorism deaths as a proportion of total deaths worldwide and in the US   
pkill = nkill / worldDeaths   
pkill.us = nkill.us / USdeaths      Details  
As noted with the ""description"" above, Pape et al. noted that the GTD reported an increase in suicide terrorism of over 70 percent between 2007 and 2013, while their Suicide Attack Database  showed a 19 percent decrease over the same period. Pape et al. insisted that the most likely explanation for this difference is the change in the organization responsible for managing that data collection from ISVG to START .  
If the issue is restricted to how incidents are classified as ""suicide terrorism"", this concern does not affect the other variables in this summary.  
However, if it also impacts what incidents are classified as ""terrorism"", it suggests larger problems.   Author(s)  
Spencer Graves   Source  
National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2017). Global Terrorism Database [Data file]. Retrieved from https://start.umd.edu/gtd [accessed 2018-04-08].  
See also the Global Terrorism Database maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START, 2015), https://www.start.umd.edu/gtd .  
The world and US population figures came from ""Total Population - Both Sexes"", World Population Prospects 2015, published by the Population Division of the Department of Economic and Social Affairs of the United Nations accessed 2016-09-05 (at a web link that has since changed: No longer at https://esa.un.org/unpd/wpp/Download/Standard/Population , as it was when the data current used here was downloaded, 2016-09-05. Fortunately, as of 2020-02-09, such data seem to be available at https://population.un.org/wpp/Download/Standard/Population/ .  
Human Mortality Database. University of California, Berkeley (USA), and Max Planck Institute for Demographic Research (Germany).     References  
Robert Pape, Keven Ruby, Vincent Bauer and Gentry Jenkins, ""How to fix the flaws in the Global Terrorism Database and why it matters"" , The Washington Post , August 11, 2014 (accessed 2016-01-09).   Examples    data(terrorism) ## ## plot deaths per million population ## plot(kill.pmp~year, terrorism, pch=method, type='b') plot(kill.pmp.us~year, terrorism, pch=method, type='b', log='y', las=1) # terrorism as parts per 10,000 # of all deaths plot(pkill*1e4~year, terrorism, pch=method, type='b', las=1) plot(pkill.us*1e4~year, terrorism, pch=method, type='b', log='y', las=1) # plot number of incidents, number killed, # and proportion NA plot(incidents~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method, log='y') plot(pNA.nkill.us~year, terrorism, type='b', pch=method) abline(v=1997.5, lty='dotted', col='red') ## ## by country by year ## data(incidents.byCountryYr) data(nkill.byCountryYr) yr <- as.integer(colnames( incidents.byCountryYr)) str(maxDeaths <- apply(nkill.byCountryYr, 1, max) ) str(omax <- order(maxDeaths, decreasing=TRUE)) head(maxDeaths[omax], 8) tolower(substring( names(maxDeaths[omax[1:8]]), 1, 2)) pch. <- c('i', 'g', 'f', 'l', 's', 'c', 'u', 'p') cols <- 1:4 matplot(yr, sqrt(t( nkill.byCountryYr[omax[1:8], ])), type='b', pch=pch., axes=FALSE, ylab='(square root scale) ', xlab='', col=cols, main='number of terrorism deaths\nby country') axis(1) (max.nk <- max(nkill.byCountryYr[omax[1:8], ])) i.nk <- c(1, 100, 1000, 3000, 5000, 7000, 10000) cbind(i.nk, sqrt(i.nk)) axis(2, sqrt(i.nk), i.nk, las=1) ip <- paste(pch., names(maxDeaths[omax[1:8]])) legend('topleft', ip, cex=.55, col=cols, text.col=cols)"
"Ecdat-nonEnglishNames","Ecdat","nonEnglishNames","Names with Character Set Problems",11,2,0,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/nonEnglishNames.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/nonEnglishNames.html","nonEnglishNames R Documentation    Names with Character Set Problems    Description  
A data.frame describing names containing character codes rare or non-existent in standard English text, e.g., with various accent marks that may not be coded consistently in different locales or by different software.    Usage   data(nonEnglishNames)   Format  
A data.frame with two columns:    nonEnglish  
a character vector containing names that often have non-standard characters with the non-standard characters replaced by ""_""    English  
a character vector containing a standard English-character translation of nonEnglish       See Also  
grepNonStandardCharacters ,  subNonStandardCharacters     Examples    data(nonEnglishNames) all.equal(ncol(nonEnglishNames), 2)"
"Ecdat-nuclearWeaponStates","Ecdat","nuclearWeaponStates","Nations with nuclear weapons",9,17,1,3,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/nuclearWeaponStates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/nuclearWeaponStates.html","nuclearWeaponStates R Documentation   Nations with nuclear weapons   Description  
Data on the 9 nuclear-weapon states as of April 2019.   Usage   data(nuclearWeaponStates)   Format  
A dataframe containing :    nation  
The name of the country (character). The former USSR is listed here as Russia.   ctry  
ISO 31661- alpha-2 two-letter country codes (character).   firstTest  
Date of first test of a nuclear weapon.  
For Israel, which has not publicly acknowledged that it has nuclear weapons, this uses the Date of the Vela Incident .   firstTestYr  
lubridate::decimal_date(firstTest)     yearsSinceLastFirstTest  
c(NA, diff(firstTestYr))     nuclearWeapons  
number of nuclear weapons   nYieldNA, nLowYield, nMidYield, nHighYield  
number of weapons for which the yield in (nYieldNA) = unknown or variable, (nLowYield) = at most 15 kt (kilotons), the size of the Hiroshima bomb, (nMidYield) = greater than 15 but less that 50 kt, and (nHighYield) = at least 50 kt.   popM, popYr  
popM = estimated population in millions for year popYr , per the Wikipedia article for the indicated country on 2020-02-05.   GDP_B, GDPyr  
GDP_B = nominal Gross Domestic Product in billions of US dollars for year GDPyr , per the Wikipedia article for the indicated country on 2020-02-05.   Maddison  
Country code used by the Maddison Project .    startNucPgm  
Estimated date of the substantive commitment of the country to obtain nuclear weapons. See 'Details' below   startNucPgmYr  
lubridate::decimal_date(startNucPgm)       Details  
Most of the contents of this dataset are easily defined and not controversial. That's not true for the date upon which each country started its nuclear program, coded in startNucPgm and startNucPgmYr . The following summarizes the rationale behind the selection of the date for each country in this dataset.  

US  The Manhattan Project started in stages. It was officially brought to the attention of the US government by a letter officially from Albert Einstein to US President Roosevelt , 1939-08-02. It was officially authorized 1942-01-19 . We use this later date as the date of the start of the US nuclear-weapons program.   
RU  Russian scientists were studying uranium before the first world war but didn't get much official attention until the atomic bombing of Hiroshima, 1945-08-06. Shortly thereafter on 1945-08-22 , Stalin appointed Lavrentiy Beria . Beria was a able administrator and guided the project to fruition in four years.  
GB  British scientists were among the leaders in nuclear technology in the late nineteenth century. They welcomed German-Jewish physicists Otto Frisch and Rudolf Peierls , who estimated in 1939 that only a few pounds or kilograms of uranium-235 might be enough to achieve a critical mass, whereas several tonnes of natural uranium would likely be required . Because of the war, this information was passed to scientists in the United States, who developed it into the bomb dropped on Hiroshima 1945-08-06 , with help from British and Canadian scientists and Canadian industry. After the war, the US refused to share much of the information developed in the Manhattan Project with the British. British elites felt disrespected by US. On 1947-01-08 , the British government decided to initiate their own nuclear-weapons program.  
FR  France was one of the nuclear pioneers, going back to the work of Marie Curie and Henri Becquerel in the 1890s. In 1956 the French were deeply offended by the refusal of the US to support them in the Suez Crisis . On France and Israel secretly agreed to collaborate in the development of nuclear weapons .  
CN   Mao Zedong reportedly decided to begin a Chinese nuclear-weapons program during the First Taiwan Strait Crisis of 1954–1955 . That crisis was resolved shortly after  1955-04-23 , when China stated it was willing to negotiate. We use this as the date of the start of China's nuclear weapons program.  
IN  Indian scientists started research on nuclear weapons before Indian independence but didn't make a substantive commitment to actually making a nuclear weapon until they lost territory to China in the Sino-Indian War that ended 1962-11-21. We use that date as the date for the initiation of India's nuclear-weapons program.  
IL Israel's first Prime Minister David Ben-Gurion was reportedly ""nearly obsessed"" with obtaining nuclear weapons to prevent the Holocaust from recurring. For present purposes, we use 1949-03-10, the date of the end of the 1948 Arab–Israeli War , as the beginning of Israel's nuclear-weapons program.  
PK  Pakistan's elite were totally humiliated by their defeat in the Indo-Pakistani War of 1971 , 1971-12-03 / -16: That war ended the  Bangladesh Liberation War , by which Pakistan lost over half their population and 14 percent of their land area. Prime Minister Zulfiqar Ali Bhutto compared Pakistan's surrender to the Treaty of Versailles, which Germany was forced to sign in 1919. Bhutto observed 1972-01-20 that a Pakistani scientist had been part of the Manhattan Project, and Pakistani scientists could do the same in Pakistan. While significant funding seemed not to have come until later, 1972-01-20 is the date we will use here for the beginning of Pakistan's nuclear-weapons program.  
KP  The 1950-1953 Korean War ended with a cease-fire, not an official end to hostilities. Since then North Korea has perceived nuclear threats from the US. In 1956 the Soviet Union began giving North Korean scientists and engineers ""basic knowledge"" to help them initiate a nuclear program. About 1962, North Korea committed itself to what it called ""all-fortressization"" , which was the beginning of the hyper-militarized North Korea of today. North Korea reportedly asked the Soviet Union for help with a nuclear weapons program in 1963 and was turned down. China turned down similar requests in 1964 and 1974. Around 1980 North Korea began mining its own supplies of uranium and building its own factory to produce yellowcake . (See also Bolton, 2012.) For lack of something better, we use 1980-01-01 as the start of North Korea's nuclear weapons program. They clearly wanted nuclear weapons much earlier but didn't seem to move seriously in the direction of developing nuclear weapons until around     Source  
Overview from World Nuclear Weapon Stockpile    
firstTest from Wikipedia, ""List of states with nuclear weapons""    
US from Hans M. Kristensen & Robert S. Norris (2018) United States nuclear forces,2018, Bulletin of the Atomic Scientists, 74:2, 120-131, DOI: 10.1080/00963402.2018.143821    
Russia from Hans M. Kristensen & Matt Korda (2019) Russian nuclear forces, 2019, Bulletin of the Atomic Scientists, 75:2, 73-84, DOI: 10.1080/00963402.2019.1580891    
UK from Robert S. Norris and Hans M. Kristensen (2013) The British nuclear stockpile, 1953-2013, Bulletin of the Atomic Scientists, 69:4, 69-75s    
France from Robert S. Norris & Hans M. Kristensen (2008) French nuclear forces, 2008, Bulletin of the Atomic Scientists, 64:4, 52-54, 57   
China from Hans M. Kristensen & Robert S. Norris (2018) Chinese nuclear forces, 2018,Bulletin of the Atomic Scientists, 74:4, 289-295    
India from Hans M. Kristensen & Robert S. Norris (2017) Indian nuclear forces, 2017,Bulletin of the Atomic Scientists, 73:4, 205-209    
Israel from Hans M. Kristensen and Robert S. Norris (2014) Israeli nuclear weapons, 2014, Bulletin of the Atomic Scientists, 70:6, 97-115    
Pakistan from Hans M. Kristensen, Robert S. Norris & Julia Diamond (2018)Pakistani nuclear forces, 2018, Bulletin of the Atomic Scientists, 74:5, 348-358    
North Korea from Hans M. Kristensen & Robert S. Norris (2018) North Korean nuclear capabilities, 2018, Bulletin of the Atomic Scientists, 74:1, 41-51    
Derek Bolton (2012) North Korea's Nuclear Program (2012-08, American Security Program, accessed 2020-07-15) https://www.americansecurityproject.org/ASP%20Reports/Ref%200072%20-%20North%20Korea’s%20Nuclear%20Program%20.pdf     Examples    data(nuclearWeaponStates) plot(yearsSinceLastFirstTest~firstTest, nuclearWeaponStates, type='h', xlab='', ylab='') with(nuclearWeaponStates, text(firstTest, yearsSinceLastFirstTest, ctry))"
"Ecdat-OCC1950","Ecdat","OCC1950","Evolution of occupational distribution in the US",281,31,0,0,0,0,31,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/OCC1950.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/OCC1950.html","OCC1950 R Documentation    Evolution of occupational distribution in the US   Description  
Proportion of the US population in each of the 283 OCC1950 occupation codes for each year in the Integrated Public Use Microdata Series (IPUMS) - US database .   Usage   data(""OCC1950"")   Format  
A matrix with one row for each of 281 OCC1950 occupation codes in IPUMS-US and one column for each year in their dataset as of 2020-03-17, being c(1850:1880, 1900:2000, 2001:2016) .    Details  
This dataset was created using the code in the IPUMS vignette in the Ecfun package using  tapply(HHWT, IPUMSdata[c(""OCC1950"", ""YEAR"")], sum) , then normalizing so the total for each year was 1.   
In fact a plot of the sums for each year of  HHWT were close to the USGDPpresidents$population.K*1000 except for 1970, when they were double.  
Universe Note from the IPUMS documentation for their variable OCC1950 : ""New Workers"" are persons seeking employment for the first time, who had not yet secured their first job.   
OCC1950 applies the 1950 Census Bureau occupational classification system to occupational data, to enhance comparability across years. For pre-1940 samples created at the University of Minnesota, the alphabetic responses supplied by enumerators were directly coded into the 1950 classification. For other samples, the information in the variable OCC was recoded into the 1950 classification. Codes above 970 are non-occupational responses retained in the historical census samples or blank/unknown. The design of OCC1950 is described at length in ""Integrated Occupation and Industry Codes and Occupational Standing Variables in the IPUMS."". The composition of the 1950 occupation categories is described in detail in U.S. Bureau of the Census, Alphabetic Index of Occupations and Industries: 1950 (Washington D.C., 1950).  
In 1850-1880, any laborer with no specified industry in a household with a farmer is recoded into farm labor. In 1860-1900, any woman with an occupational response of ""housekeeper"" enters the non-occupational category ""keeping house"" if she is related to the head of household. Cases affected by these imputation procedures are identified by an appropriate data quality flag (present in the raw IPUMS data but ignored for this summary).  
A parallel variable called OCC1990, available for the samples from 1950 onward, codes occupations into a simplified version of the 1990 occupational coding scheme."" [OCC1990 was ignored for the present purposes, because it is not coded for data prior to 1950.]   
NOTE: In the 2020-03-17 extraction, there were 283 OCC1950 codes documented, but only 291 of them were actually in the data I got. The codes for ""Not yet classified"" and ""New Workers"" were not used.   Source  
Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas, and Matthew Sobek (2020) IPUMS USA: Version 10.0 [dataset]. Minneapolis, MN: IPUMS .   Examples    data(OCC1950)"
"Ecdat-OFP","Ecdat","OFP","Visits to Physician Office",4406,19,7,0,8,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/OFP.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/OFP.html","OFP R Documentation   Visits to Physician Office   Description  
a cross-section   
number of observations : 4406   
observation : individuals   
country : United States    Usage   data(OFP)   Format  
A dataframe containing :    ofp
number of physician office visits   ofnp
number of nonphysician office visits   opp
number of physician outpatient visits   opnp
number of nonphysician outpatient visits   emr
number of emergency room visits   hosp
number of hospitalizations   numchron
number of chronic conditions   adldiff
the person has a condition that limits activities of daily living ?   age
age in years (divided by 10)   black
is the person African–American ?   sex
is the person male ?   maried
is the person married ?   school
number of years of education   faminc
family income in 10000\$   employed
is the person employed ?   privins  
is the person covered by private health insurance?    medicaid
is the person covered by medicaid ?   region  
the region ( noreast , midwest , west )    hlth
self-perceived health (excellent, poor, other)     Source  
Deb, P. and P.K. Trivedi (1997) “Demand for Medical Care by the Elderly: A Finite Mixture Approach”, Journal of Applied Econometrics , 12 , 313-326..    References  
Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 6.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Oil","Ecdat","Oil","Oil Investment",53,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Oil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Oil.html","Oil R Documentation   Oil Investment   Description  
a cross-section from 1969 to 1992   
number of observations : 53   
observation : production units   
country : United Kingdom    Usage   data(Oil)   Format  
A dataframe containing :    dur  
duration of the appraisal lag in months (time span between discovery of an oil field and beginning of development, i.e. approval of annex B).    size  
size of recoverable reserves in millions of barrels    waterd
depth of the sea in metres   gasres  
size of recoverable gas reserves in billions of cubic feet    operator  
equity market value (in 1991 million pounds) of the company operating the oil field    p  
real after–tax oil price measured at time of annex B approval    vardp  
volatility of the real oil price process measured as the squared recursive standard errors of the regression of codept-pt-1 on a constant    p97  
adaptive expectations (with parameter theta=0.97) for the real after–tax oil prices formed at the time of annex B approval   varp97  
volatility of the adaptive expectations (with parameter theta=0.97) for real after tax oil prices measured as the squared recursive standard errors of the regression of pt on pte(theta)     p98  
adaptive expectations (with parameter theta=0.98) for the real after–tax oil prices formed at the time of annex B approval   varp98  
volatility of the adaptive expectations (with parameter theta=0.98) for real after tax oil prices measured as the squared recursive standard errors of the regression of pt on pte(theta)       Source  
Favero, Carlo A., M. Hashem Pesaran and Sunil Sharma (1994) “A duration model of irreversible oil investment : theory and empirical evidence”, Journal of Applied Econometrics , 9(S) , S95–S112.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Orange","Ecdat","Orange","The Orange Juice Data Set",642,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Orange.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Orange.html","Orange R Documentation   The Orange Juice Data Set   Description  
monthly observations from 1948-01 to 2001-06   
number of observations : 642   
observation : country   
country : United States    Usage   data(Orange)   Format  
A time series containing :    priceoj
producer price for frozen orange juice   pricefg
producer price index for finished goods   fdd
freezing degree days (from daily minimum temperature recorded at Orlando area airports)     Source  
U.S. Bureau of Labor Statistics for PPIOJ and PWFSA , National Oceanic and Atmospheric Administration (NOAA) of the U.S Department of Commerce for fdd .    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Participation","Ecdat","Participation","Labor Force Participation",872,7,2,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Participation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Participation.html","Participation R Documentation   Labor Force Participation   Description  
a cross-section   
number of observations : 872   
observation : individuals   
country : Switzerland    Usage   data(Participation)   Format  
A dataframe containing :    lfp
labour force participation ?   lnnlinc
the log of nonlabour income   age
age in years divided by 10   educ
years of formal education   nyc
the number of young children (younger than 7)   noc
number of older children   foreign
foreigner ?     Source  
Gerfin, Michael (1996) “Parametric and semiparametric estimation of the binary response”, Journal of Applied Econometrics , 11(3) , 321-340.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 11.   
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-PatentsHGH","Ecdat","PatentsHGH","Dynamic Relation Between Patents and R&D",1730,18,1,0,1,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/PatentsHGH.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/PatentsHGH.html","PatentsHGH R Documentation   Dynamic Relation Between Patents and R\&D   Description  
a panel of 346 observations from 1975 to 1979  
number of observations : 1730   
observation : production units   
country : United States    Usage   data(PatentsHGH)   Format  
A dataframe containing :    obsno
firm index   year
year   cusip 
Compustat's identifying number for the firm (Committee on Uniform Security Identification Procedures number)    ardsic  
a two-digit code for the applied R&D industrial classification (roughly that in Bound, Cummins, Griliches, Hall, and Jaffe, in the Griliches R&D, Patents, and Productivity volume)    scisect  
is the firm in the scientific sector ?    logk  
the logarithm of the book value of capital in 1972.    sumpat  
the sum of patents applied for between 1972-1979.   logr 
the logarithm of R&D spending during the year (in 1972 dollars)    logr1 
the logarithm of R&D spending (one year lag)    logr2 
the logarithm of R&D spending (two years lag)    logr3 
the logarithm of R&D spending (three years lag)    logr4 
the logarithm of R&D spending (four years lag)    logr5 
the logarithm of R&D spending (five years lag)    pat  
the number of patents applied for during the year that were eventually granted    pat1
the number of patents (one year lag)   pat2
the number of patents (two years lag)   pat3  
the number of patents (three years lag)    pat4  
the number of patents (four years lag)      Source  
Hall, Bronwyn, Zvi Griliches and Jerry Hausman (1986) “Patents and R&D: Is There a Lag?”, International Economic Review , 27 , 265-283.    References  
Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 9.   
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 792–5.    See Also  
PatentsRD , Index.Source ,  Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-PatentsRD","Ecdat","PatentsRD","Patents, R&D and Technological Spillovers for a Panel of Firms",1629,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/PatentsRD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/PatentsRD.html","PatentsRD R Documentation   Patents, R\&D and Technological Spillovers for a Panel of Firms   Description  
a panel of 181 observations from 1983 to 1991   
number of observations : 1629   
observation : production units   
country : world    Usage   data(PatentsRD)   Format  
A dataframe containing :    year
year   fi
firm's id   sector  
firm's main industry sector, one of aero (aerospace), chem (chemistry),  comput (computer), drugs , elec (electricity), food , fuel (fuel and mining), glass , instr (instruments), machin (machinery), metals , other , paper , soft (software), motor (motor vehicles)   geo  
geographic area, one of eu (European Union), japan , usa , rotw (rest of the world)    patent  
numbers of European patent applications    rdexp
log of R\&D expenditures   spil
log of spillovers     Source  
Cincer, Michele (1997) “Patents, R \& D and technological spillovers at the firm level : some evidence from econometric count models for panel data”, Journal of Applied Econometrics , 12(3) , May–June, 265–280.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ . Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 7.    See Also  
PatentsHGH , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-PE","Ecdat","PE","Price and Earnings Index",132,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/PE.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/PE.html","PE R Documentation   Price and Earnings Index   Description  
annual observations from 1800 to 1931   
number of observations : 132   
observation : country   
country : United States    Usage   data(PE)   Format  
A time series containing :    price
S\&P composite stock price index   earnings
S\&P composite earnings index     Source  
Robert Shiller.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 8.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-politicalKnowledge","Ecdat","politicalKnowledge","Political knowledge in the US and Europe",4,12,0,1,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/politicalKnowledge.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/politicalKnowledge.html","politicalKnowledge R Documentation   Political knowledge in the US and Europe   Description  
Data from McChesney and Nichols (2010) on domestic and international knowledge in Denmark, Finland, the UK and the US among college graduates, people with some college, and roughly 12th grade only.   Usage    data(politicalKnowledge)    Format  
A data.frame containing 12 columns and 4 rows.    country  
a character vector of Denmark, Finland, UK, and US, being the four countries compared in this data set.   DomesticKnowledge.hs, DomesticKnowledge.sc, DomesticKnowledge.c  
percent correct answers to calibrated questions regarding knowledge of prominent items in domestic news in a survey of residents of the four countries among college graduates (ending "" .c ""), some college ("" .sc "") and high school ("" .hs ""). Source: McChesney and Nichols (2010, chapter 1, chart 8).   InternationalKnowledge.hs, InternationalKnowledge.sc, InternationalKnowledge.c  
percent correct answers to calibrated questions regarding knowledge of prominent items in international news in a survey of residents of the four countries by education level as for DomesticKnowledge . Source: McChesney and Nichols (2010, chapter 1, chart 7).   PoliticalKnowledge.hs, PoliticalKnowledge.sc, PoliticalKnowledge.c  
average of domestic and international knowledge    PublicMediaPerCapita  
Per capital spending on public media in 2007 in US dollars from McChesney and Nichols (2010, chapter 4, chart 1)    PublicMediaRel2US  
Spending on public media relative to the US, being PublicMediaPerCapita / PublicMediaPerCapita[4] .     Author(s)  
Spencer Graves   Source  
Robert W. McChesney and John Nichols (2010) The Death and Life of American Journalism (Nation Books)    Examples    ## ## 1. Combine first 2 rows ## data(politicalKnowledge) pk <- politicalKnowledge[-1,] pk[1, -1] <- ((politicalKnowledge[1, -1] + politicalKnowledge[2, -1])/2) pk[1, 'country'] <- 'DK-FI' ## ## 2. plot ## xlim <- range(pk[, 'PublicMediaPerCapita']) ylim <- 100*range(pk[2:7]) text.cex <- 2 # to label the lines (US.UK <- (pk[2, -1]+pk[3, -1])/2) #png('Knowledge v. public media.png') op <- par(mar=c(5, 7, 4, 2)+.1) plot(c(0, 110), 100*ylim, type='n', axes=FALSE, xlab='public media $ per capita', ylab='Political Knowledge\n(% of standard questions)', cex.lab=2) axis(1, cex.axis=2) axis(2, las=2, cex.axis=2) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.hs, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.sc, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.c, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.hs, type='b', pch=' ')) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.sc, type='b', pch=' ')) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.c, type='b', pch=' ')) with(US.UK, text(PublicMediaPerCapita, 100*PoliticalKnowledge.hs, 'High School\nor less', srt=37, cex=1.5)) with(US.UK, text(PublicMediaPerCapita, 100*PoliticalKnowledge.sc, 'some\ncollege', srt=10.5, cex=1.5)) with(US.UK, text(PublicMediaPerCapita, 100*PoliticalKnowledge.c, ""Bachelor's\nor more"", srt=-1, cex=1.5)) par(op) #dev.off() ## ## redo for Wikimedia commons ## without English axis labels ## to facilitate multilingual use ## #svg('Knowledge v. public media.svg') op <- par(mar=c(3,3,2,2)+.1) plot(c(0, 110), 100*ylim, type='n', axes=FALSE, xlab='', ylab='', cex.lab=2) axis(1, cex.axis=2) axis(2, las=2, cex.axis=2) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.hs, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.sc, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, text(PublicMediaPerCapita, 100*PoliticalKnowledge.c, country, cex=text.cex, xpd=NA, col=c('forestgreen', 'orange', 'red'))) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.hs, type='b', pch=' ')) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.sc, type='b', pch=' ')) with(pk, lines(PublicMediaPerCapita, 100*PoliticalKnowledge.c, type='b', pch=' ')) par(op) #dev.off()"
"Ecdat-Pound","Ecdat","Pound","Pound-dollar Exchange Rate",778,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Pound.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Pound.html","Pound R Documentation   Pound-dollar Exchange Rate   Description  
weekly observations from 1975 to 1989   
number of observations : 778   
observation : country   
country : Germany    Usage   data(Pound)   Format  
A dataframe containing :    date  
the date of the observation (19850104 is January, 4, 1985)    s  
the ask price of the dollar in units of Pound in the spot market on Friday of the current week    f  
the ask price of the dollar in units of Pound in the 30-day forward market on Friday of the current week    s30  
the bid price of the dollar in units of Pound in the spot market on the delivery date on a current forward contract      Source  
Bekaert, G. and R. Hodrick (1993) “On biases in the measurement of foreign exchange risk premiums”, Journal of International Money and Finance , 12 , 115-138.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 6, 438-443.    See Also  
DM , Yen , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-PPP","Ecdat","PPP","Exchange Rates and Price Indices for France and Italy",186,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/PPP.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/PPP.html","PPP R Documentation   Exchange Rates and Price Indices for France and Italy   Description  
monthly observations from 1981–01 to 1996–06   
number of observations : 186   
observation : country   
country : France and Italy    Usage   data(PPP)   Format  
A time series containing :    lnit
log price index Italy   lnfr
log price index France   lnx
log exchange rate France/Italy   cpiit
consumer price index Italy   cpifr
consumer price index France     Source  
Datastream .    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapters 8 and 9.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Pricing","Ecdat","Pricing","Returns of Size-based Portfolios",418,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Pricing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Pricing.html","Pricing R Documentation   Returns of Size-based Portfolios   Description  
monthly observations from 1959–02 to 1993–11   
number of observations : 418    Usage   data(Pricing)   Format  
A time series containing :    r1
monthly return on portfolio 1 (small firms)   r2
monthly return on portfolio 2   r3
monthly return on portfolio 3   r4
monthly return on portfolio 4   r5
monthly return on portfolio 5   r6
monthly return on portfolio 6   r7
monthly return on portfolio 7   r8
monthly return on portfolio 8   r9
monthly return on portfolio 9   r10
monthly return on portfolio 10 (large firms)   rf
risk free rate (return on 3-month T-bill)   cons
real per capita consumption growth based on total US personal consumption expenditures (nondurables and services)     Source  
Center for research in security prices.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 5.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Produc","Ecdat","Produc","Us States Production",816,10,0,0,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Produc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Produc.html","Produc R Documentation   Us States Production   Description  
a panel of 48 observations from 1970 to 1986   
number of observations : 816   
observation : regional   
country : United States    Usage   data(Produc)   Format  
A dataframe containing :    state
the state   year
the year   pcap
private capital stock   hwy
highway and streets   water
water and sewer facilities   util
other public buildings and structures   pc
public capital   gsp
gross state products   emp  
labor input measured by the employment in non–agricultural payrolls    unemp
state unemployment rate     Source  
Munnell, A. (1990) “Why has productivity growth declined? Productivity and public investment”, New England Economic Review , 3–22.   
Baltagi, B. H. and N. Pinnoi (1995) “Public capital stock and state productivity growth: further evidence”, Empirical Economics , 20 , 351–359.    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-PSID","Ecdat","PSID","Panel Survey of Income Dynamics",4856,8,0,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/PSID.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/PSID.html","PSID R Documentation   Panel Survey of Income Dynamics   Description  
a cross-section from 1993   
number of observations : 4856   
observation : individuals   
country : United States    Usage   data(PSID)   Format  
A dataframe containing :    intnum
1968 interview number   persnum
person number   age
age of individual   educatn
highest grade completed   earnings
total labor income   hours
annual work hours   kids
live births to this individual   married  
last known marital status (married, never married, windowed, divorced, separated, NA/DF , no histories)      Source  
Panel Survey of Income Dynamics.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 295–300.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-RetSchool","Ecdat","RetSchool","Return to Schooling",5225,17,9,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/RetSchool.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/RetSchool.html","RetSchool R Documentation   Return to Schooling   Description  
a panel of 48 observations from 1970 to 1986   
number of observations : 5225   
observation : individuals   
country : United States    Usage   data(RetSchool)   Format  
A time series containing :    wage76
wage in 1876   grade76
grade level in 1976   exp76
experience 1n 1976   black
black ?   south76
lived in south in 1976 ?   smsa76
lived in SMSA in 1976 ?   region  
region, a factor with levels ( un ,  midatl , enc , wnc ,  sa , esc , wsc , m , p )    smsa66
lived in SMSA in 1966 ?   momdad14
lived with both parents at age 14 ?   sinmom14
lived with mother only at age 14 ?   nodaded
father has no formal education ?   nomomed
mother has no formal education ?   daded
mean grade level of father   momed
mean grade level of mother   famed
father's and mother's education, a factor with 9 levels   age76
age in 1976   col4
is any 4-year college nearby ?     Source  
Kling, Jeffrey R. (2001) “Interpreting Instrumental Variables Estimates of the Return to Schooling”, Journal of Business and Economic Statistics , 19(3) , July, 358–364.   
Dehejia, R.H. and S. Wahba (2002) “Propensity-score Matching Methods for Nonexperimental Causal Studies”, Restat , 151–161.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge.    See Also  
Schooling ,  Treatment , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Schooling","Ecdat","Schooling","Wages and Schooling",3010,28,16,0,17,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Schooling.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Schooling.html","Schooling R Documentation   Wages and Schooling   Description  
a cross-section from 1976   
number of observations : 3010   
observation : individuals   
country : United States    Usage   data(Schooling)   Format  
A dataframe containing :    smsa66
lived in SMSA in 1966 ?   smsa76
lived in SMSA in 1976 ?   nearc2
grew up near 2-yr college ?   nearc4
grew up near 4-yr college ?   nearc4a  
grew up near 4-year public college ?    nearc4b  
grew up near 4-year private college ?    ed76
education in 1976   ed66
education in 1966   age76
age in 1976   daded  
dad's education (imputed avg if missing)    nodaded
dad's education imputed ?   momed
mother's education   nomomed
mom's education imputed ?   momdad14  
lived with mom and dad at age 14 ?    sinmom14
single mom at age 14 ?   step14
step parent at age 14 ?   south66
lived in south in 1966 ?   south76
lived in south in 1976 ?   lwage76  
log wage in 1976 (outliers trimmed)    famed
mom-dad education class (1-9)   black
black ?   wage76
wage in 1976 (raw, cents per hour)   enroll76
enrolled in 1976 ?   kww
the kww score   iqscore
a normed IQ score   mar76
married in 1976 ?   libcrd14
library card in home at age 14 ?   exp76
experience in 1976     Source  
National Longitudinal Survey of Young Men (NLSYM).   
Card, D. (1995) Using geographical variation in college proximity to estimate the return to schooling in Christofides, L.N., E.K. Grant and R. Swidinsky (1995)  Aspects of labour market behaviour : essays in honour of John Vanderkamp , University of Toronto Press, Toronto.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 5.    See Also  
RetSchool ,  Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Solow","Ecdat","Solow","Solow's Technological Change Data",41,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Solow.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Solow.html","Solow R Documentation   Solow's Technological Change Data   Description  
annual observations from 1909 to 1949   
number of observations : 41   
observation : country   
country : United States    Usage   data(Solow)   Format  
A time series containing :    q
output   k
capital/labor ratio   A
index of technology     Source  
Solow, R. (1957) “Technical change and the aggregate production function”, Review of Economics and Statistics , 39 , 312-320.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F7.2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Somerville","Ecdat","Somerville","Visits to Lake Somerville",659,8,2,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Somerville.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Somerville.html","Somerville R Documentation   Visits to Lake Somerville   Description  
a cross-section from 1980   
number of observations : 659   
observation : individuals   
country : United States    Usage   data(Somerville)   Format  
A dataframe containing :    visits  
annual number of visits to lake Somerville    quality  
quality ranking score for lake Somerville    ski  
engaged in water–skiing at the lake ?    income
annual household income   feeSom  
annual user fee paid at lake Somerville ?    costCon  
expenditures when visiting lake Conroe    costSom  
expenditures when visiting lake Somerville    costHoust  
expenditures when visiting lake Houston      Source  
Seller, Christine, John R. Stoll and Jean–Paul Chavas (1985) “Valuation of empirical measures of welfare change : a comparison of nonmarket techniques”, Land Economics , 61(2) , May, 156–175.   
Gurmu, Shiferaw and Pravin K. Trivedi (1996) “ Excess zeros in count models for recreational trips”, Journal of Business and Economics Statistics , 14(4) , October, 469–477.   
Santos Silva, Jao M. C. (2001) “A score test for non–nested hypotheses with applications to discrete data models”, Journal of Applied Econometrics , 16(5) , 577–597.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 . Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 6.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-SP500","Ecdat","SP500","Returns on Standard & Poor's 500 Index",2783,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/SP500.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/SP500.html","SP500 R Documentation   Returns on Standard \& Poor's 500 Index   Description  
daily observations from 1981–01 to 1991–04   
number of observations : 2783    Usage   data(SP500)   Format  
A dataframe containing :    r500
daily return S\&P500 (change in log index)     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Star","Ecdat","Star","Effects on Learning of Small Class Sizes",5748,8,2,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Star.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Star.html","Star R Documentation   Effects on Learning of Small Class Sizes   Description  
a cross-section from 1985-89   
number of observations : 5748   
observation : individuals   
country : United States    Usage   data(Star)   Format  
A dataframe containing :    tmathssk
total math scaled score   treadssk
total reading scaled score   classk
type of class, a factor with levels (regular,small.class,regular.with.aide)   totexpk
years of total teaching experience   sex
a factor with levels (boy,girl)   freelunk
qualified for free lunch ?   race
a factor with levels (white,black,other)   schidkn
school indicator variable     Source  
Project STAR:   
Description from 2001-06-02 .  Description from 2011-06-18 .    References  
Stock, James H. and Mark W. Watson (2003) Introduction to Econometrics , Addison-Wesley Educational Publishers, chapter 11.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Strike","Ecdat","Strike","Strike Duration Data",62,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Strike.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Strike.html","Strike R Documentation   Strike Duration Data   Description  
a cross-section from 1968 to 1976   
number of observations : 62   
country : United States    Usage   data(Strike)   Format  
A dataframe containing :    duration
strike duration in days   prod
unanticipated output     Source  
Kennan, J. (1985) “The duration of contract strikes in U.S. manufacturing”, Journal of Econometrics , 28 , 5-28.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F22.1.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-StrikeDur","Ecdat","StrikeDur","Strikes Duration",566,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/StrikeDur.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/StrikeDur.html","StrikeDur R Documentation   Strikes Duration   Description  
a cross-section from 1968 to 1976   
number of observations : 566   
country : United States    Usage   data(StrikeDur)   Format  
A dataframe containing :    dur
duration of the strike in days   gdp
measure of stage of business cycle (deviation of monthly log industrial production in manufacturing from prediction from OLS on time, time-squared and monthly dummies)     Source  
Kennan, J. (1985) “The Duration of Contract strikes in U.S. Manufacturing”, Journal of Econometrics , 28 , 5-28.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 574–5 and 582.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-StrikeNb","Ecdat","StrikeNb","Number of Strikes in Us Manufacturing",108,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/StrikeNb.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/StrikeNb.html","StrikeNb R Documentation   Number of Strikes in Us Manufacturing   Description  
monthly observations from 1968(1) to 1976 (12)   
number of observations : 108   
observation : country   
country : United States    Usage   data(StrikeNb)   Format  
A time series containing :    strikes
number of strikes (number of contract strikes in U.S. manufacturing beginning each month)   output
level of economic activity (measured as cyclical departure of aggregate production from its trend level)   time
a time trend from 1 to 108     Source  
Kennan, J. (1985) “The Duration of Contract strikes in U.S. Manufacturing”, Journal of Econometrics , 28 , 5-28.   
Cameron, A.C. and Trivedi P.K. (1990) “Regression Based Tests for Overdispersion in the Poisson Model”, Journal of Econometrics , December, 347-364.    References  
Cameron, A.C. and Trivedi P.K. (1998) Regression analysis of count data , Cambridge University Press, http://cameron.econ.ucdavis.edu/racd/racddata.html , chapter 7.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-SumHes","Ecdat","SumHes","The Penn Table",3250,7,2,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/SumHes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/SumHes.html","SumHes R Documentation   The Penn Table   Description  
a panel of 125 observations from 1960 to 1985   
number of observations : 3250   
observation : country   
country : World    Usage   data(SumHes)   Format  
A dataframe containing :    year
the year   country
the country name (factor)   opec
OPEC member ?   com
communist regime ?   pop
country's population (in thousands)   gdp
real GDP per capita (in 1985 US dollars)   sr
saving rate (in percent)     Source  
Summers, R. and A. Heston (1991) “The Penn world table (mark 5): an expanded set of international comparisons, 1950-1988”, Quarterly Journal of Economics , 29 , 229-256.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 5, 358-363.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Tbrate","Ecdat","Tbrate","Interest Rate, GDP and Inflation",188,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Tbrate.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Tbrate.html","Tbrate R Documentation   Interest Rate, GDP and Inflation   Description  
quarterly observations from 1950-1 to 1996-4   
number of observations : 188   
observation : country   
country : Canada    Usage   data(Tbrate)   Format  
A time series containing :    r
the 91-day treasury bill rate   y
the log of real GDP   pi
the inflation rate     Source  
CANSIM database of Statistics Canada.    References  
Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods , New York, Oxford University Press, chapter 2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-terrorism","Ecdat","terrorism","Global Terrorism Database yearly summaries",46,25,0,1,1,0,23,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/terrorism.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/terrorism.html","terrorism R Documentation    Global Terrorism Database yearly summaries    Description  
The Global Terrorism Database (GTD) ""is a database of incidents of terrorism from 1970 onward"". Through 2015, this database contains information on 141,966 incidents.  
terrorism provides a few summary statistics along with an ordered  factor methodology , which Pape et al.  insisted is necessary, because an increase of over 70 percent in suicide terrorism between 2007 and 2013 is best explained by a methodology change in GTD that occurred on 2011-11-01; Pape's own Suicide Attack Database showed a 19 percent decrease over the same period.   Usage    data(terrorism) data(incidents.byCountryYr) data(nkill.byCountryYr)    Format  
incidents.byCountryYr and nkill.byCountryYr are matrices giving the numbers of incidents and numbers of deaths by year and by location of the event for 206 countries (rows) and for all years between 1970 and 2016 (columns) except for 1993, for which the entries are all NA, because the raw data previously collected was lost (though the total for that year is available in the data.frame  terrorism ).  
NOTES:  
1. For nkill.byCountryYr and for terrorism[c('nkill', 'nkill.us')] , NAs in GTD were treated as 0. Thus the actual number of deaths were likely higher, unless this was more than offset by incidents being classified as terrorism, when they should not have been.  
2. incidents.byCountryYr and nkill.byCountryYr are NA for 1993, because the GTD data for that year were lost.  
terrorism is a data.frame  containing the following:   year
integer year, 1970:2016.   methodology  
an ordered factor giving the methodology / organization responsible for the data collection for most of the given year. The Pinkerton Global Intelligence Service ( PGIS ) managed data collection from 1970-01-01 to 1997-12-31. The Center for Terrorism and Intelligence Studies ( CETIS ) managed the project from 1998-01-01 to 2008-03-31. The Institute for the Study of Violent Groups ( ISVG ) carried the project from 2008-04-01 to 2011-10-31. The National Consortium for the Study of Terrorism and Responses to Terrorism ( START ) has managed data collection since 2011-11-01. For this variable, partial years are ignored, so methodology = CEDIS for 1998:2007, ISVG for 2008:2011, and START for 2012:2014.   method  
a character vector consisting of the first character of the levels of methodology :  
c('p', 'c', 'i', 's')    incidents  
integer number of incidents identified each year.  
NOTE: sum(terrorism[[""incidents""]]) = 146920 = 141966 in the GTD database plus 4954 for 1993, for which the incident-level data were lost.   incidents.us  
integer number of incidents identified each year with country_txt = ""United States"".   suicide  
integer number of incidents classified as ""suicide"" by GTD variable suicide = 1. For 2007, this is 359, the number reported by Pape et al. For 2013, it is 624, which is 5 more than the 619 mentioned by Pape et al. Without checking with the SMART project administrators, one might suspect that 5 more suicide incidents from 2013 were found after the data Pape et al. analyzed but before the data used for this analysis.   suicide.us  
Number of suicide incidents by year with country_txt = ""United States"".   nkill  
number of confirmed fatalities for incidents in the given year, including attackers = sum(nkill, na.rm=TRUE) in the GTD incident data.  
NOTE: nkill in the GTD incident data includes both perpetrators and victims when both are available. It includes one when only one is available and is NA when neither is available. However, in most cases, we might expect that the more spectacular and lethal incidents would likely be more accurately reported. To the extent that this is true, it means that when numbers are missing, they are usually zero or small. This further suggests that the summary numbers recorded here probably represent a slight but not substantive undercount.   nkill.us  
number of U.S. citizens who died as a result of incidents for that year = sum(nkill.us, na.rm=TRUE) in the GTD incident data.  
NOTES:  
1. This is subject to the same likely modest undercount discussed with nkill .)   
2. These are U.S. citizens killed regardless of location. This explains at least part of the discrepancies between  terrorism[, 'nkill.us'] and nkill.byCountryYr['United States', ] .    nwound  
number of people wounded. (This is subject to the same likely modest undercount discussed with nkill .)    nwound.us  
Number of U.S. citizens wounded in terrorist incidents for that year = sum(nwound.us, na.rm=TRUE) in the GTD incident data. (This is subject to the same likely modest undercount discussed with nkill .)    pNA.nkill, pNA.nkill.us, pNA.nwound, pNA.nwound.us  
proportion of observations by year with missing values. These numbers are higher for the early data than more recent numbers. This is particularly true for nkill.us  and nwound.us , which exceed 90 percent for most of the period with methodology = PGIS , prior to 1998.   worldPopulation, USpopulation  
Estimated de facto population in thousands living in the world and in the US as of 1 July of the year indicated, according to the Population Division of the Department of Economic and Social Affairs of the United Nations; see ""Sources"" below.   worldDeathRate, USdeathRate  
Crude death rate  (deaths per 1,000 population) worldwide and in the US, according to the World Bank; see ""Sources"" below. This World Bank data set includes USdeathRate for each year from 1900 to 2014.  
The worldDeathRate numbers here were read manually from a plot on that web page, except for the the number for 2015, which was estimated as a reduction of 0.73 percent from 2014, which was the average rate of decline (ratio of two successive years) for 1990 to 2014. The same method was used to estimate the USdeathRate for 2015 as the same as for 2014.  
NOTE: USdeathRate is to two significant digits only, unlike worldDeathRate , which has four significant digits.   worldDeaths, USdeaths  
number of deaths by year in the world and US   
worldDeaths = worldPopulation * worldDeathRate .  
USdeaths were computed by summing across age groups in ""Deaths_5x1.txt"" for the United States, downloaded from https://www.mortality.org/cgi-bin/hmd/country.php?cntr=USA&level=1 from the Human Mortality Database; see sources below.   kill.pmp, kill.pmp.us  
terrorism deaths per million population worldwide and in the US =  
0.001 * nkill / worldPopulation     pkill, pkill.us  
terrorism deaths as a proportion of total deaths worldwide and in the US   
pkill = nkill / worldDeaths   
pkill.us = nkill.us / USdeaths      Details  
As noted with the ""description"" above, Pape et al. noted that the GTD reported an increase in suicide terrorism of over 70 percent between 2007 and 2013, while their Suicide Attack Database  showed a 19 percent decrease over the same period. Pape et al. insisted that the most likely explanation for this difference is the change in the organization responsible for managing that data collection from ISVG to START .  
If the issue is restricted to how incidents are classified as ""suicide terrorism"", this concern does not affect the other variables in this summary.  
However, if it also impacts what incidents are classified as ""terrorism"", it suggests larger problems.   Author(s)  
Spencer Graves   Source  
National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2017). Global Terrorism Database [Data file]. Retrieved from https://start.umd.edu/gtd [accessed 2018-04-08].  
See also the Global Terrorism Database maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START, 2015), https://www.start.umd.edu/gtd .  
The world and US population figures came from ""Total Population - Both Sexes"", World Population Prospects 2015, published by the Population Division of the Department of Economic and Social Affairs of the United Nations accessed 2016-09-05 (at a web link that has since changed: No longer at https://esa.un.org/unpd/wpp/Download/Standard/Population , as it was when the data current used here was downloaded, 2016-09-05. Fortunately, as of 2020-02-09, such data seem to be available at https://population.un.org/wpp/Download/Standard/Population/ .  
Human Mortality Database. University of California, Berkeley (USA), and Max Planck Institute for Demographic Research (Germany).     References  
Robert Pape, Keven Ruby, Vincent Bauer and Gentry Jenkins, ""How to fix the flaws in the Global Terrorism Database and why it matters"" , The Washington Post , August 11, 2014 (accessed 2016-01-09).   Examples    data(terrorism) ## ## plot deaths per million population ## plot(kill.pmp~year, terrorism, pch=method, type='b') plot(kill.pmp.us~year, terrorism, pch=method, type='b', log='y', las=1) # terrorism as parts per 10,000 # of all deaths plot(pkill*1e4~year, terrorism, pch=method, type='b', las=1) plot(pkill.us*1e4~year, terrorism, pch=method, type='b', log='y', las=1) # plot number of incidents, number killed, # and proportion NA plot(incidents~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method) plot(nkill.us~year, terrorism, type='b', pch=method, log='y') plot(pNA.nkill.us~year, terrorism, type='b', pch=method) abline(v=1997.5, lty='dotted', col='red') ## ## by country by year ## data(incidents.byCountryYr) data(nkill.byCountryYr) yr <- as.integer(colnames( incidents.byCountryYr)) str(maxDeaths <- apply(nkill.byCountryYr, 1, max) ) str(omax <- order(maxDeaths, decreasing=TRUE)) head(maxDeaths[omax], 8) tolower(substring( names(maxDeaths[omax[1:8]]), 1, 2)) pch. <- c('i', 'g', 'f', 'l', 's', 'c', 'u', 'p') cols <- 1:4 matplot(yr, sqrt(t( nkill.byCountryYr[omax[1:8], ])), type='b', pch=pch., axes=FALSE, ylab='(square root scale) ', xlab='', col=cols, main='number of terrorism deaths\nby country') axis(1) (max.nk <- max(nkill.byCountryYr[omax[1:8], ])) i.nk <- c(1, 100, 1000, 3000, 5000, 7000, 10000) cbind(i.nk, sqrt(i.nk)) axis(2, sqrt(i.nk), i.nk, las=1) ip <- paste(pch., names(maxDeaths[omax[1:8]])) legend('topleft', ip, cex=.55, col=cols, text.col=cols)"
"Ecdat-Tobacco","Ecdat","Tobacco","Households Tobacco Budget Share",2724,9,0,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Tobacco.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Tobacco.html","Tobacco R Documentation   Households Tobacco Budget Share   Description  
a cross-section from 1995-96   
number of observations : 2724   
observation : individuals   
country : Belgium    Usage   data(Tobacco)   Format  
A dataframe containing :    occupation  
a factor with levels ( bluecol , whitecol ,  inactself ), the last level being inactive and self-employed    region  
a factor with levels ( flanders , wallon ,  brussels )    nkids
number of kids of more than two years old   nkids2
number of kids of less than two years old   nadults
number of adults in household   lnx
log of total expenditures   stobacco  
budget share of tobacco    salcohol  
budget share of alcohol    age
age in brackets (0-4)     Source  
National Institute of Statistics (NIS), Belgium.    References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons, chapter 7.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Train","Ecdat","Train","Stated Preferences for Train Traveling",2929,11,1,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Train.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Train.html","Train R Documentation   Stated Preferences for Train Traveling   Description  
a cross-section from 1987   
number of observations : 2929   
observation : individuals   
country : Netherland    Usage   data(Train)   Format  
A dataframe containing :    id
individual identifier   choiceid
choice identifier   choice
one of choice1, choice2   pricez  
price of proposition z (z=1,2) in cents of guilders    timez  
travel time of proposition z (z=1,2) in minutes    comfortz  
comfort of proposition z (z=1,2), 0, 1 or 2 in decreasing comfort order    changez  
number of changes for proposition z (z=1,2)      Source  
Meijer, Erik and Jan Rouwendal (2005) “Measuring welfare effects in models with random coefficients”, Journal of Applied Econometrics , forthcoming .   
Ben–Akiva, M., D. Bolduc and M. Bradley (1993) “Estimation of travel choice models with randomly distributed values of time”, Transportation Research Record , 1413 , 88–97.   
Carson, R.T., L. Wilks and D. Imber (1994) “Valuing the preservation of Australia's Kakadu conservation zone”, Oxford Economic Papers , 46 , 727–749.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-TranspEq","Ecdat","TranspEq","Statewide Data on Transportation Equipment Manufacturing",25,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/TranspEq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/TranspEq.html","TranspEq R Documentation    Statewide Data on Transportation Equipment Manufacturing   Description  
a cross-section   
number of observations : 25   
observation : regional   
country : United States    Usage   data(TranspEq)   Format  
A dataframe containing :    state
state name   va
output   capital
capital input   labor
labor input   nfirm
number of firms     Source  
Zellner, A. and N. Revankar (1970) “Generalized production functions”, Review of Economic Studies , 37 , 241-250.    References  
Greene, W.H. (2003) Econometric Analysis , Prentice Hall, http://www.prenhall.com/greene/greene1.html , Table F9.2.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Treatment","Ecdat","Treatment","Evaluating Treatment Effect of Training on Earnings",2675,10,4,0,1,4,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Treatment.html","Treatment R Documentation   Evaluating Treatment Effect of Training on Earnings   Description  
a cross-section from 1974   
number of observations : 2675   
country : United States    Usage   data(Treatment)   Format  
A dataframe containing :    treat
treated ?   age
age   educ
education in years   ethn  
a factor with levels ("" other "", "" black "", "" hispanic "")    married
married ?   re74
real annual earnings in 1974 (pre-treatment)   re75
real annual earnings in 1975 (pre-treatment)   re78
real annual earnings in 1978 (post-treatment)   u74
unemployed in 1974 ?   u75
unemployed in 1975 ?     Source  
Lalonde, R. (1986) “Evaluating the Econometric Evaluations of Training Programs with Experimental Data”, American Economic Review , 604–620.   
Dehejia, R.H. and S. Wahba (1999) “Causal Effects in Nonexperimental Studies: reevaluating the Evaluation of Training Programs”, JASA , 1053–1062.   
Dehejia, R.H. and S. Wahba (2002) “Propensity-score Matching Methods for Nonexperimental Causal Studies”, Restat , 151–161.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 889–95.    See Also  
RetSchool , Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Tuna","Ecdat","Tuna","Choice of Brand for Tuna",13705,8,0,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Tuna.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Tuna.html","Tuna R Documentation   Choice of Brand for Tuna   Description  
a cross-section   
number of observations : 13705   
observation : individuals   
country : United States    Usage   data(Tuna)   Format  
A dataframe containing :    hid
individuals identifiers   id
purchase identifiers   choice  
one of skw (Starkist water), cosw (Chicken of the sea water), pw (store–specific private label water), sko (Starkist oil), coso (Chicken of the sea oil)   price.z
price of brand z     Source  
Kim, Byong–Do, Robert C. Blattberg and Peter E. Rossi (1995) “Modeling the distribution of price sensitivity and implications for optimal retail pricing”, Journal of Business Economics and Statistics , 13(3) , 291.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-UnempDur","Ecdat","UnempDur","Unemployment Duration",3343,11,5,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/UnempDur.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/UnempDur.html","UnempDur R Documentation   Unemployment Duration   Description  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20    
number of observations : 3343    Usage   data(UnempDur)   Format  
A time series containing :    spell
length of spell in number of two-week intervals   censor1
= 1 if re-employed at full-time job   censor2
= 1 if re-employed at part-time job   censor3
1 if re-employed but left job: pt-ft status unknown   censor4
1 if still jobless   age
age   ui
= 1 if filed UI claim   reprate
eligible replacement rate   disrate
eligible disregard rate   logwage
log weekly earnings in lost job (1985\$)   tenure
years tenure in lost job     Source  
McCall, B.P. (1996) “Unemployment Insurance Rules, Joblessness, and Part-time Work”, Econometrica , 64 , 647–682.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp. 603–8, 632–6, 658–62, 671–4 and 692.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Unemployment","Ecdat","Unemployment","Unemployment Duration",452,12,9,0,5,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Unemployment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Unemployment.html","Unemployment R Documentation   Unemployment Duration   Description  
a cross-section from 1993   
number of observations : 452   
observation : individuals   
country : United States    Usage   data(Unemployment)   Format  
A dataframe containing :    duration  
duration of first spell of unemployment, t, in weeks   spell
1 if spell is complete   race
one of nonwhite, white   sex
one of male, female   reason  
reason for unemployment, one of new (new entrant), lose (job loser), leave (job leaver), reentr (labor force reentrant)    search
'yes' if (1) the unemployment spell is completed between the first and second surveys and number of methods used to search > average number of methods used across all records in the sample, or, (2) for individuals who remain unemployed for consecutive surveys, if the number of methods used is strictly nondecreasing at all survey points, and is strictly increasing at least at one survey point   pubemp
'yes' if an individual used a public employment agency to search for work at any survey points relating to the individuals first unemployment spell   ftp1
1 if an individual is searching for full time work at survey 1   ftp2
1 if an individual is searching for full time work at survey 2   ftp3
1 if an individual is searching for full time work at survey 3   ftp4
1 if an individual is searching for full time work at survey 4   nobs
number of observations on the first spell of unemployment for the record     Source  
Romeo, Charles J. (1999) “Conducting inference in semiparametric duration models under inequality restrictions on the shape of the hazard implied by the job search theory”, Journal of Applied Econometrics , 14(6) , 587–605.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-University","Ecdat","University","Provision of University Teaching and Research",62,17,0,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/University.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/University.html","University R Documentation   Provision of University Teaching and Research   Description  
a cross-section from 1988   
number of observations : 62   
observation : schools   
country : United Kingdom    Usage   data(University)   Format  
A dataframe containing :    undstudents
undergraduate students   poststudents
postgraduate students   nassets
net assets   acnumbers
academic numbers   acrelnum
academic related numbers   clernum
clerical numbers   compop
computer operators   techn
technicians   stfees
student fees   acpay
academic pay   acrelpay
academic related pay   secrpay
secretarial pay   admpay
admin pay   agresrk
aggregate research rank   furneq
furniture and equipment   landbuild
land and buildings   resgr
research grants     Source  
Glass, J.C., D.G. McKillop and N. Hyndman (1995) “Efficiency in the provision of university teaching and research : an empirical analysis of UK universities”, Journal of Applied Econometrics , 10(1) , January–March, 61–72.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-USclassifiedDocuments","Ecdat","USclassifiedDocuments","Official Secrecy of the United States Government",29,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/USclassifiedDocuments.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/USclassifiedDocuments.html","USclassifiedDocuments R Documentation    Official Secrecy of the United States Government   Description  
Data on classification activity of the United States government.  
Fitzpatrick (2013) notes that the dramatic jump in derivative classification activity ( DerivClassActivity ) that occurred in 2009 coincided with ""New guidance issued to include electronic environment"". Apart from the jump in 2009, the DerivClassActivity tended to increase by roughly 12 percent per year (with a standard deviation of the increase in the natural logarithm of DerivClassActivity of 0.18).   Usage    data(USclassifiedDocuments)    Format  
A dataframe containing :    year  
the calendar year   OCAuthority  
Number of people in the government designated as Original Classification Authorities for the indicated year .   OCActivity  
Original classification activity for the indicated year: These are the number of documents created with an original classification, i.e., so designated by an official Original Classification Authority.   TenYearDeclass  
Percent of OCActivity covered by the 10 year declassification rules.   DerivClassActivity  
Derivative classification activity for the indicated year: These are the number of documents created that claim another document as the authority for classification.     Details  
The lag 1 autocorrelation of the first difference of the logarithms of  DerivClassActivity through 2008 is -0.52 . However, because there are only 13 numbers (12 differences), this negative correlation is not statistically significant.   Source  
Fitzpatrick, John P. (2013) Annual Report to the President for 2012 , United States Information Security Oversight Office, National Archives and Record Administration, June 20, 2013. Information Security Oversight Office (ISOO) of the National Archives.     Examples    ## ## 1. plot DerivClassActivity ## plot(DerivClassActivity~year, USclassifiedDocuments) # Exponential growth? plot(DerivClassActivity~year, USclassifiedDocuments, log='y') # A jump in 2009 as discussed by Fitzpatrick (2013). # Otherwise plausibly a straight line. ## ## 2. First difference? ## plot(diff(log(DerivClassActivity))~year[-1], USclassifiedDocuments) # Jump in 2009 but otherwise on distribution ## ## 3. autocorrelation? ## sel <- with(USclassifiedDocuments, (1995 < year) & (year < 2009) ) acf(diff(log(USclassifiedDocuments$ DerivClassActivity[sel]))) # lag 1 autocorrelation = (-0.52). # However, with only 12 numbers, # this is not statistically significant."
"Ecdat-USFinanceIndustry","Ecdat","USFinanceIndustry","US Finance Industry Profits",84,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/USFinanceIndustry.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/USFinanceIndustry.html","USFinanceIndustry R Documentation    US Finance Industry Profits    Description  
A data.frame giving the profits of the finance industry in the United States as a proportion of total corporate domestic profits.    Usage   data(USFinanceIndustry)   Format  
A data.frame with the following columns:    year
integer year starting with 1929   CorporateProfitsAdj  
Corporate profits with inventory valuation and capital consumption adjustments in billions of current (not adjusted for inflation) US dollars    Domestic
Domestic industries profits in billions   Financial
Financial industries profits in billions   Nonfinancial
Nonfinancial industries profits in billions   restOfWorld  
Profits of the ""Rest of the world"" in their contribution to US Gross Domestic Product in billions    FinanceProportion
= Financial/Domestic     Details  
This is extracted from Table 6.16 of the National Income and Product Accounts (NIPA) compiled by the Bureau of Economic Analysis of the United States federal government. This table comes in four parts, A (1929-1947), B (1948-1987), C (1987-2000), and D (1998-present). Parts A, B, C and D contain different numbers of data elements, but the first five have the same names and are the only ones used here. The overlap between parts C and D (1998-2000) have a root mean square relative difference of 0.7 percent; there were no differences between the numbers in the overlap period between parts B and C (1987).   
This was created using the following command:   
demoDir <- system.file('demoFiles', package='Ecdat')   demoCsv <- dir(demoDir, pattern='csv$', full.names=TRUE)    
nipa6.16 <- readNIPA(demoCsv)   USFinanceIndustry <- as.data.frame(nipa6.16)   names(USFinanceIndustry) <- c('year', 'CorporateProfitsAdj', 'Domestic', 'Financial', 'Nonfinancial', 'restOfWorld')   USFinanceIndustry$FinanceProportion <- with(USFinanceIndustry, Financial/Domestic)     Source  
https://www.bea.gov : Under ""U.S. Economic Accounts"", first select ""Corporate Profits"" under ""National"". Then next to ""Interactive Tables"", select, ""National Income and Product Accounts Tables"". From there, select ""Begin using the data..."". Under ""Section 6 - income and employment by industry"", select each of the tables starting ""Table 6.16"". As of February 2013, there were 4 such tables available: Table 6.16A, 6.16B, 6.16C and 6.16D. Each of the last three are available in annual and quarterly summaries. The  USFinanceIndustry data combined the first 4 rows of the 4 annual summary tables.    See Also  
readNIPA     Examples    data(USFinanceIndustry) plot(FinanceProportion~year, USFinanceIndustry, type='b', ylim=c(0, max(FinanceProportion, na.rm=TRUE)), xlab='', ylab='', las=1, cex.axis=2, bty='n', lwd=2, col='blue') # Write to a file for Wikimedia Commons ## Not run: if(FALSE){ svg('USFinanceIndustry.svg') plot(FinanceProportion~year, USFinanceIndustry, type='b', ylim=c(0, max(FinanceProportion, na.rm=TRUE)), xlab='', ylab='', las=1, cex.axis=2, bty='n', lwd=2, col='blue') dev.off() } ## End(Not run)"
"Ecdat-USGDPpresidents","Ecdat","USGDPpresidents","US GDP per capita with presidents and wars",262,12,1,0,3,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/USGDPpresidents.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/USGDPpresidents.html","USGDPpresidents R Documentation    US GDP per capita with presidents and wars    Description  
It is commonly claimed that Franklin Roosevelt (FDR) did not end the Great Depression: World War II (WW2) did. This is supported by the 10.6 percent growth per year in real Gross Domestic Product (GDP) per capita seen in the standard GDP estimates from 1940 to 1945. It is also supported by the rapid decline in unemployment during the war.  
However, no comparable growth spurts in GDP per capita catch the eye in a plot of log(GDP per capita) from 1790 to 2015, whether associated with a war or not, using data from Measuring Worth. The only other features of that plot that seem visually comparable are the economic disaster of Herbert Hoover's presidency (when GDP per capital fell by 10 percent per year, 1929-1932), the impressive growth of the US economy during the first seven years of Franklin Roosevelt's presidency (6.4 percent per year, 1933-1940), and the post-World War II recession (when GDP per capita fell by 7.9 percent per year, 1945-1947). (NOTE: The web site for Measuring Worth, https://measuringworth.com/ still works, but has not always been maintained to current internet security standards. Therefore, the link is provided here in text but not as a link.)   
Closer inspection of this plot suggests that the US economy has generally grown faster after FDR than before. This might plausibly be attributed to  ""The Keynesian Ascendancy 1939-1979"" .  
Unemployment dropped during the First World War as it did during WW2. Comparable unemployment data are not available for the U.S. during other major wars, most notably the American Civil War and the Mexican-American War .  
This data set provides a platform for testing the effects of presidency, war, and Keynes. It does this by combining the numbers for US population and real GDP per capital dollars from Measuring Worth with the presidency and a list of major wars and an estimate of the battle deaths by year per million population. (As noted above, the web address for measuring worth, https://measuringworth.com/ , often gives security warnings but still seems to provide the data as before.)  
US unemployment is also considered.     Usage    data(USGDPpresidents)    Format  
A data.frame containing 259 observations on the following variables:    Year 
integer: the year, c(seq(1610, 1770, 10), 1774:2015)     CPI  
Numeric: U. S. Consumer Price Index per Officer and Williamson (2015). Average 1982-84 = 100.   GDPdeflator  
numeric: Implicit price deflators for Gross Domestic Product with 2012s = 100 per Johnston and Williamson.   population.K 
integer: US population in thousands.  
Population figures for 1610 to 1780 came from Springston (2013). The rest came from Johnston and Williamson. (The early population figures reflect only the European settlers in the British colonies that eventually became the US.)    realGDPperCapita  
numeric: real Gross Domestic Product per capita in 2012 dollars   executive  
ordered : Crown of England through 1774, followed by the  ""ContinentalCongress"" and the ""ArticlesOfConfederation"" until Washington, who became President under the current base constitution in 1789. Two nineteenth century presidents are not listed here (William Henry Harrison and James A. Garfield), because they died so soon after inauguration that any contribution they made to the economic growth of the nation might seem too slight to measure accurately in annual data like this; their contributions therefore appear combined with their replacements (John Tyler and Chester A. Arthur, respectively). The service of two other presidents is officially combined here: ""Taylor-Fillmore"" refers to the 16 months served by Zachary Taylor with the 32 months of Millard Fillmore. These modifications make Barack Obama  number 41 on this list, even though he's the 44th president of the U.S.   war  
ordered : This lists the major wars in US history by years involving active hostilities. A war is ""major"" for present purposes if it met two criteria:  
(1) It averaged at least 10 battle deaths per year per million US population.  
(2) It was listed in one of two lists of wars: For wars since 1816, it must have appeared in the Correlates of War . For wars between 1790 and 1815, it must have appeared in the Wikipedia  ""List of wars involving the United States"" .  
The resulting list includes a few adjustments to the list of wars that might come readily to mind for people moderately familiar with US history.  
A traditional list might start with the American Revolution, the War of 1812, the Mexican-American war, the Civil War, the Spanish-American war, World Wars I and II, Korea, and Vietnam. In addition, the  Northwest Indian War involved very roughly 30 battle deaths per year per million population 1785-1795. This compares with the roughly 100 battle deaths per year 1812-1815 for the  War of 1812 .  
For present purposes, the Spanish-American War is combined with the lesser-known American-Philippine War: The latter involved 50 percent more battle deaths but over a longer period of time and arguably with less impact on the stature of the US as a growing world power. However, its magnitude suggest it might have impacted the US economy in a way roughly comparable to the Spanish-American war. The two are therefore listed here together as ""Spanish-American-Philippine"" war.  
The Correlates of War (COW) data include multiple US uses of military force during the Vietnam War era. It starts with ""Vietnam Phase 1"", 1961-65, with 506 battle deaths in the COW data base. It includes the ""Second Laotian"" war phases 1 and 2, plus engagement with a ""Communist Coalition"" and Khmer Rouge as well as actions in the Dominican Republic and Guatemala. The current data.frame includes only ""Vietnam"", referring primarily to COW's ""Vietnam War, Phase 2"", 1965-1973. The associated battle deaths include battle deaths from these other, lesser concurrent conflicts.  
The COW data currently ends in 2007. However, the post-2000 conflicts in Afghanistan and Iraq averaged less than 1,000 battle deaths per year or roughly 3 battle deaths per year per million population. This is below the threshold of 10 battle deaths per year per million population. This in turn suggests that any impact of those conflicts on the US economy might be small and difficult to estimate.    battleDeaths  
numeric: Numbers of battle deaths by year estimated by allocating to the different years the totals reported for each major war in proportion to the number of days officially in conflict each year. The totals were obtained (in August-September 2015) from The Correlates of War data for conflicts since 1816 and from Wikipedia for previous wars, as noted above.   battleDeathsPMP  
numeric: battle deaths per million population = 1000*battleDeaths/population.K .   Keynes  
integer taking the value 1 between 1939 and 1979 and 0 otherwise, as suggested by the section entitled ""The Keynesian Ascendancy 1939-1979"" in the Wikipedia article on  John Maynard Keynes .   unemployment  
Estimated US unemployment rate   unempSource  
ordered giving the source for US unemployment:   1800-1889
Lebergott   1890-1929
Romer   1930-1939
Coen   1940-present
BLS    
Clearly, the more recent numbers should be more accurate.     Details  
rownames(USGDPpresidents) = Year     Author(s)  
Spencer Graves   Source  
Louis Johnston and Samuel H. Williamson, ""What Was the U.S. GDP Then?"", Measuring Worth, accessed 2015-09-08. (NOTE: This came from https://www.measuringworth.org/usgdp/ . this web link generally works as of 2020-02-09 but routinely returns a warning, e.g., ""SSL certificate problem"". The web site seems to be good but not maintained to current security standards.)  
Sarkees, Meredith Reid; Wayman, Frank (2010).  ""The Correlates of War Project: COW War Data, 1816 - 2007 (v4.0)"" , accessed 2015-09-02.  
Wikipedia, ""List of wars involving the United States"" , accessed 2015-09-13.  
Wikipedia, ""Unemployment in the United States"" . See also https://en.wikipedia.org/wiki/User_talk:Peace01234#Unemployment_Data . Accessed 2016-07-08.  
Stanley Lebergott (1964). Manpower in Economic Growth: The American Record since 1800. Pages 164-190. New York: McGraw-Hill. Cited from Wikipedia, ""Unemployment in the United States"" , accessed 2016-07-08.  
Christina Romer (1986). ""Spurious Volatility in Historical Unemployment Data"", The Journal of Political Economy, 94(1): 1-37.   
Robert M. Coen (1973) Labor Force and Unemployment in the 1920's and 1930's: A Re-Examination Based on Postwar Experience"", The Review of Economics and Statistics, 55(1): 46-55.  
The unemployment data since 1940 are from series LNS14000000 from the Current Population Survey. These data are available as a monthly series from the Current Population Survey of the Bureau of Labor Statistics .  
Chuck Springston, ""Population of the 13 Colonies 1610-1790"", October 28, 2013     Examples    ## ## GDP, Presidents and Wars ## data(USGDPpresidents) (wars <- levels(USGDPpresidents$war)) nWars <- length(wars) plot(realGDPperCapita/1000~Year, USGDPpresidents, log='y', type='l', ylab='average annual income (K$)', las=1) abline(v=c(1929, 1933, 1945), lty='dashed') text(1930, 2.5, ""Hoover"", srt=90, cex=0.9) text(1939.5, 30, 'FDR', srt=90, cex=1.1, col='blue') # label wars (logGDPrange <- log(range(USGDPpresidents$realGDPperCapita, na.rm=TRUE)/1000)) (yrRange <- range(USGDPpresidents$Year)) (yrMid <- mean(yrRange)) for(i in 2:nWars){ w <- wars[i] sel <- (USGDPpresidents$war==w) yrs <- range(USGDPpresidents$Year[sel]) abline(v=yrs, lty='dotted', col='grey') yr. <- mean(yrs) w.adj <- (0.5 - 0.6*(yr.-yrMid)/diff(yrRange)) logy <- (logGDPrange[1]+w.adj*diff(logGDPrange)) y. <- exp(logy) text(yr., y., w, srt=90, col='red', cex=0.5) } ## ## CPI v. GDPdeflator ## plot(GDPdeflator~CPI, USGDPpresidents, type='l', log='xy') ## ## Unemployment ## plot(unemployment~Year, USGDPpresidents, type='l')"
"Ecdat-USstateAbbreviations","Ecdat","USstateAbbreviations","Standard abbreviations for states of the United States",76,10,0,10,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/USstateAbbreviations.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/USstateAbbreviations.html","USstateAbbreviations R Documentation    Standard abbreviations for states of the United States   Description  
The object returned by readUSstateAbbreviations() on May 20, 2013.    Usage    data(USstateAbbreviations)   Format  
A data.frame containing 10 different character vectors of names or codes for 76 different political entities including the United States, the 50 states within the US, plus the District of Columbia, US territories and other political designation, some of which are obsolete but are included for historical reference.    Name
The standard name of the entity.   Status  
description of status, e.g., state / commonwealth vs. island, territory, military mail code, etc.    ISO, ANSI.letters, ANSI.digits, USPS, USCG, Old.GPO, AP, Other  
Alternative abbreviations used per different standards. The most commonly used among these may be the 2-letter codes officially used by the US Postal Service ( USPS ).      Details  
This was read from  the Wikipedia article on ""List of U.S. state abbreviations""     Source  
the Wikipedia article on ""List of U.S. state abbreviations""     See Also  
readUSstateAbbreviations   showNonASCII   grepNonStandardCharacters   subNonStandardCharacters     Examples    ## ## to use ## data(USstateAbbreviations) ## ## to update ## ## Not run: USstateAbb2 <- readUSstateAbbreviations() ## End(Not run)"
"Ecdat-UStaxWords","Ecdat","UStaxWords","Number of Words in US Tax Law",7,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/UStaxWords.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/UStaxWords.html","UStaxWords R Documentation   Number of Words in US Tax Law   Description  
Thousands of words in US tax law for 1995 to 2015 in 10 year intervals. This includes income taxes and all taxes in the code itself (written by congress) and regulations (written by government administrators). For 2015 only EntireTaxCodeAndRegs is given; for other years, this number is broken down by income tax vs. other taxes and code vs. regulations.   Usage   data(UStaxWords)   Format  
A data.frame containing:    year
tax year   IncomeTaxCode  
number of words in thousands in the US income tax code    otherTaxCode  
number of words in thousands in US tax code other than income tax    EntireTaxCode  
number of words in thousands in the US tax code    IncomeTaxRegulations  
number of words in thousands in US income tax regulations    otherTaxRegulations  
number of words in thousands in US tax regulations other than income tax    IncomeTaxCodeAndRegs  
number of words in thousands in both the code and regulations for the US income tax    otherTaxCodeAndRegs  
number of words in thousands in both code and regulations for US taxes apart from income taxes.    EntireTaxCodeAndRegs  
number of words in thousands in US tax code and regulations      Details  
Thousands of words in the US tax code and federal tax regulations, 1955-2015. This is based on data from the Tax Foundation ( taxfoundation.org ), adjusted to eliminate an obvious questionable observation in otherTaxRegulations for 1965. The numbers of words in otherTaxRegulations was not reported directly by the Tax Foundation but is easily computed as the difference between their Income and Entire tax numbers. This series shows the numbers falling by 48 percent between 1965 and 1975 and by 1.5 percent between 1995 and 2005. These are the only declines seen in these numbers and seem inconsistent with the common concern (expressed e.g., in Moody, Warcholik and Hodge, 2005) about the difficulties of simplifying any governmental program, because vested interest appear to defend almost anything. Lessig (2011) notes that virtually all provisions of US law that favor certain segments of society are set to expire after a modest number of years. These sunset provisions provide recurring opportunities for incumbent politicians to extort campaign contributions from those same segments to ensure the continuation of the favorable treatment.  
The decline of 48 percent in otherTaxRegulations seems more curious for two additional reasons: First, it was preceded by a tripling of otherTaxRegulations between 1955 and 1965. Second, it was NOT accompanied by any comparable behavior of otherTaxCode . Instead, the latter grew each decade by between 17 and 53 percent, similar to but slower than the growth in IncomeTaxCode and IncomeTaxRegulations .   
Accordingly, otherTaxRegulations for 1965 is replaced by the average of the numbers for 1955 and 1975, and EntireTaxRegulations for 1965 is comparably adjusted. This replaces (1322, 2960) for those two variables for 1965 with (565, 2203). In addition, otherTaxCodeAndRegs and  EntireTaxCodeAndRegulations are also changed from (1626, 3507) to (870, 2751).   
Independent of whether this adjustment is correct or not, it's clear that there have been roughly 3 words of regulations for each word in the tax code. Most of these are income tax regulations, which have recently contained 4.5 words for every word in code. The income tax code currently includes roughly 50 percent more words than other tax code.    Author(s)  
Spencer Graves   Source  
Tax Foundation: Number of Words in Internal Revenue Code and Federal Tax Regulations, 1955-2005  Scott Greenberg, ""Federal Tax Laws and Regulations are Now Over 10 Million Words Long"", October 08, 2015     References  
J. Scott Moody, Wendy P. Warcholik, and Scott A. Hodge (2005) ""The Rising Cost of Complying with the Federal Income Tax"", The Tax Foundation Special Report No. 138.    Examples    data(UStaxWords) plot(EntireTaxCodeAndRegs/1000 ~ year, UStaxWords, type='b', ylab='Millions of words in US tax code & regs') # Write to a file for Wikimedia Commons ## Not run: svg('UStaxWords.svg') ## End(Not run) matplot(UStaxWords$year, UStaxWords[c(2:3, 5:6)]/1000, type='b', bty='n', ylab='', ylim=c(0, max(UStaxWords$EntireTaxCodeAndRegs)/1000), las=1, xlab="""", cex.axis=2) lines(EntireTaxCodeAndRegs/1000~year, UStaxWords, lwd=2) ## Not run: dev.off() ## End(Not run) # lines 1:4 = IncomeTaxCode, otherTaxCode, # IncomeTaxRegulations, # and otherTaxRegulations, respectively ## ## Plotting the original numbers ## without the adjustment ## UStax. <- UStaxWords UStax.[2,c(6:7, 9:10)] <- c(1322, 2960, 1626, 3507) matplot(UStax.$year, UStax.[c(2:3, 5:6)]/1000, type='b', bty='n', ylab='', ylim=c(0, max( UStax.$EntireTaxCodeAndRegs)/1000), las=1, xlab="""", cex.axis=2) lines(EntireTaxCodeAndRegs/1000~year, UStax., lwd=2) # Note especially the anomalous behaviour of # line 4 = otherTaxRegulations. As noted with # ""details"" above, otherTaxRegulations could have # tripled between 1955 and 1965, then fallen by 48 # percent between 1965 and 1975. However, that # does not seem credible, especially since there # was no corresponding behavior in otherTaxCode. ## ## linear trend ## (newWdsPerYr <- lm(EntireTaxCodeAndRegs~year, UStaxWords)) plot(UStaxWords$year, resid(newWdsPerYr)) # Roughly 150,000 additional words added each year # since 1955. # No indication of nonlinearity. # adusted R-squared exceeds 99 percent. ## ## linear trend with increased slope ## during the Reagan years ## # linear spline with knots at # 1981 and 1989 Reagan <- pmax(0, pmin( (UStaxWords$year-1981)/8, 1)) plot(Reagan~year, UStaxWords, type='b') UStaxWords$Reagan <- Reagan ReaganMdl <- EntireTaxCodeAndRegs~year + Reagan fitReagan <- lm(ReaganMdl, UStaxWords ) summary(fitReagan)"
"Ecdat-VietNamH","Ecdat","VietNamH","Medical Expenses in Vietnam (household Level)",5999,11,3,0,4,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/VietNamH.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/VietNamH.html","VietNamH R Documentation   Medical Expenses in Vietnam (household Level)   Description  
a cross-section from 1997   
number of observations : 5999   
observation : households   
country : Vietnam    Usage   data(VietNamH)   Format  
A dataframe containing :    sex
gender of household head (male,female)   age
age of household head   educyr
schooling year of household head   farm
farm household ?   urban
urban household ?   hhsize
household size   lntotal
log household total expenditure   lnmed
log household medical expenditure   lnrlfood
log household food expenditure   lnexp12m
log of total household health care expenditure for 12 months   commune
commune     Source  
Vietnam World Bank Livings Standards Survey.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp.88–90.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-VietNamI","Ecdat","VietNamI","Medical Expenses in Vietnam (individual Level)",27765,12,4,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/VietNamI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/VietNamI.html","VietNamI R Documentation   Medical Expenses in Vietnam (individual Level)   Description  
a cross-section from 1997   
number of observations : 27765   
observation : individuals   
country : Vietnam    Usage   data(VietNamI)   Format  
A dataframe containing :    pharvis
number of direct pharmacy visits   lnhhexp
log of total medical expenditure   age
age of household head   sex
gender (male,female)   married
married ?   educ
completed diploma level ?   illness
number of of illnesses experiences in past 12 months   injury
injured during survey period ?   illdays
number of illness days   actdays
number of days of limited activity   insurance
respondent has health insurance coverage ?   commune
commune     Source  
Vietnam World Bank Livings Standards Survey.    References  
Cameron, A.C. and P.K. Trivedi (2005) Microeconometrics : methods and applications , Cambridge, pp.848–853.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Wages","Ecdat","Wages","Panel Data of Individual Wages",4165,12,8,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Wages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Wages.html","Wages R Documentation   Panel Data of Individual Wages   Description  
a panel of 595 observations from 1976 to 1982   
number of observations : 4165   
observation : individuals   
country : United States    Usage   data(Wages)   Format  
A dataframe containing :    exp
years of full-time work experience   wks
weeks worked   bluecol
blue collar ?   ind
works in a manufacturing industry ?   south
resides in the south ?   smsa
resides in a standard metropolitan statistical are ?   married
married ?   sex
a factor with levels (male,female)   union
individual's wage set by a union contract ?   ed
years of education   black
is the individual black ?   lwage
logarithm of wage     Source  
Cornwell, C. and P. Rupert (1988) “Efficient estimation with panel data: an empirical comparison of instrumental variables estimators”, Journal of Applied Econometrics , 3 , 149–155.   
Panel study of income dynamics.    References  
Baltagi, Badi H. (2003) Econometric analysis of panel data , John Wiley and sons, https://www.wiley.com/legacy/wileychi/baltagi/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Wages1","Ecdat","Wages1","Wages, Experience and Schooling",3294,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Wages1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Wages1.html","Wages1 R Documentation   Wages, Experience and Schooling   Description  
a panel of 595 observations from 1976 to 1982   
number of observations : 3294   
observation : individuals   
country : United States    Usage   data(Wages1)   Format  
A time series containing :    exper
experience in years   sex
a factor with levels (male,female)   school
years of schooling   wage
wage (in 1980 \$) per hour     References  
Verbeek, Marno (2004) A Guide to Modern Econometrics , John Wiley and Sons.    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,   
Index.Time.Series"
"Ecdat-Workinghours","Ecdat","Workinghours","Wife Working Hours",3382,12,3,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Workinghours.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Workinghours.html","Workinghours R Documentation   Wife Working Hours   Description  
a cross-section from 1987   
number of observations : 3382   
observation : individuals   
country : United States    Usage   data(Workinghours)   Format  
A dataframe containing :    hours
wife working hours per year   income
the other household income in hundreds of dollars   age
age of the wife   education
education years of the wife   child5
number of children for ages 0 to 5   child13
number of children for ages 6 to 13   child17
number of children for ages 14 to 17   nonwhite
non–white ?   owned
is the home owned by the household ?   mortgage
is the home on mortgage ?   occupation
occupation of the husband, one of mp (manager or   unemp
local unemployment rate in %     Source  
Lee, Myoung–Jae (1995) “Semi–parametric estimation of simultaneous equations with limited dependent variables : a case study of female labour supply”, Journal of Applied Econometrics , 10(2) , April–June, 187–200.    References  
Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/ .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"Ecdat-Yen","Ecdat","Yen","Yen-dollar Exchange Rate",778,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Yen.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Yen.html","Yen R Documentation   Yen-dollar Exchange Rate   Description  
weekly observations from 1975 to 1989   
number of observations : 778   
observation : country   
country : Japan    Usage   data(Yen)   Format  
A dataframe containing :    date  
the date of the observation (19850104 is January, 4, 1985)    s  
the ask price of the dollar in units of Yen in the spot market on Friday of the current week    f  
the ask price of the dollar in units of Yen in the 30-day forward market on Friday of the current week    s30  
the bid price of the dollar in units of Yen in the spot market on the delivery date on a current forward contract      Source  
Bekaert, G. and R. Hodrick (1993) “On biases in the measurement of foreign exchange risk premiums”, Journal of International Money and Finance , 12 , 115-138.    References  
Hayashi, F. (2000) Econometrics , Princeton University Press, http://fhayashi.fc2web.com/hayashi_econometrics.htm , chapter 6, 438-443.    See Also  
DM , Pound , Index.Source , Index.Economics , Index.Econometrics , Index.Observations ,  Index.Time.Series"
"Ecdat-Yogurt","Ecdat","Yogurt","Choice of Brand for Yogurts",2412,10,4,0,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Yogurt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Yogurt.html","Yogurt R Documentation   Choice of Brand for Yogurts   Description  
a cross-section   
number of observations : 2412   
observation : individuals   
country : United States    Usage   data(Yogurt)   Format  
A dataframe containing :    id
individuals identifiers   choice  
one of yoplait , dannon , hiland , weight (weight watcher)    feat.z  
is there a newspaper feature advertisement for brand z?    price.z
price of brand z     Source  
Jain, Dipak C., Naufel J. Vilcassim and Pradeep K. Chintagunta (1994) “A random–coefficients logit brand–choice model applied to panel data”, Journal of Business and Economics Statistics , 12(3) , 317.    References  
Journal of Business Economics and Statistics web site : https://amstat.tandfonline.com/loi/ubes20 .    See Also  
Index.Source , Index.Economics , Index.Econometrics , Index.Observations"
"evir-bmw","evir","bmw","Daily Log Returns on BMW Share Price",6146,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/bmw.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/bmw.html","bmw R Documentation   Daily Log Returns on BMW Share Price   Description  
These data are the daily log returns on BMW share price from Tuesday 2nd January 1973 until Tuesday 23rd July 1996. The data are contained in a numeric vector. The dates of each observation are contained in a times  attribute, which is an object of class ""POSIXct"" (see  DateTimeClasses ). Note that these data form an irregular time series because no trading takes place at the weekend.   Usage   data(bmw)   Format  
A numeric vector containing 6146 observations, with a  times attribute which is a POSIXct object of the same length."
"evir-danish","evir","danish","Danish Fire Insurance Claims",2167,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/danish.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/danish.html","danish R Documentation   Danish Fire Insurance Claims   Description  
These data describe large fire insurance claims in Denmark from Thursday 3rd January 1980 until Monday 31st December 1990. The data are contained in a numeric vector. The dates of each observation are contained in a times  attribute, which is an object of class ""POSIXct"" (see  DateTimeClasses ). They were supplied by Mette Rytgaard of Copenhagen Re. Note that these data form an irregular time series.   Usage   data(danish)   Format  
A numeric vector containing 2167 observations, with a  times attribute which is a POSIXct object of the same length."
"evir-nidd.annual","evir","nidd.annual","The River Nidd Data",35,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/nidd.annual.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/nidd.annual.html","nidd.annual R Documentation   The River Nidd Data   Description  
These data represent annual maximal levels of the River Nidd in Yorkshire. These data are suitable for analysis with gev .   Usage   data(nidd.annual)   Format  
A numeric vector containing 35 observations."
"evir-nidd.thresh","evir","nidd.thresh","The River Nidd Data",154,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/nidd.thresh.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/nidd.thresh.html","nidd.thresh R Documentation   The River Nidd Data   Description  
These data represent high river levels of the River Nidd in Yorkshire above a threshold value of 65. These data are suitable for analysis with gpd .   Usage   data(nidd.thresh)   Format  
A numeric vector containing 154 observations."
"evir-siemens","evir","siemens","Daily Log Returns on Siemens Share Price",6146,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/siemens.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/siemens.html","siemens R Documentation   Daily Log Returns on Siemens Share Price   Description  
These data are the daily log returns on Siemens share price from Tuesday 2nd January 1973 until Tuesday 23rd July 1996. The data are contained in a numeric vector. The dates of each observation are contained in a times  attribute, which is an object of class ""POSIXct"" (see  DateTimeClasses ). Note that these data form an irregular time series because no trading takes place at the weekend.   Usage   data(siemens)   Format  
A numeric vector containing 6146 observations, with a  times attribute which is a POSIXct object of the same length."
"evir-sp.raw","evir","sp.raw","SP Data to June 1993",8415,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/sp.raw.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/sp.raw.html","sp.raw R Documentation   SP Data to June 1993   Description  
The daily closing values of the S&P index from Monday 4th January 1960 until Friday 11th June 1993. The data are contained in a numeric vector. The dates of each observation are contained in a times  attribute, which is an object of class ""POSIXct"" (see  DateTimeClasses ).    Usage   data(sp.raw)   Format  
A numeric vector containing 8415 observations, with a  times attribute which is a POSIXct object of the same length."
"evir-spto87","evir","spto87","SP Return Data to October 1987",6985,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/evir/spto87.csv","https://vincentarelbundock.github.io/Rdatasets/doc/evir/spto87.html","spto87 R Documentation   SP Return Data to October 1987   Description  
The daily log returns on the S&P index value from Tuesday 5th January 1960 until Friday 16 October 1987. The data are contained in a numeric vector. The dates of each observation are contained in a times  attribute, which is an object of class ""POSIXct"" (see  DateTimeClasses ).    Usage   data(spto87)   Format  
A numeric vector containing 6985 observations, with a  times attribute which is a POSIXct object of the same length."
"forecast-gas","forecast","gas","Australian monthly gas production",476,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/forecast/gas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/forecast/gas.html","gas R Documentation   Australian monthly gas production   Description  
Australian monthly gas production: 1956–1995.    Usage    gas    Format  
Time series data    Source  
Australian Bureau of Statistics.    Examples    plot(gas) seasonplot(gas) tsdisplay(gas)"
"forecast-gold","forecast","gold","Daily morning gold prices",1108,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/forecast/gold.csv","https://vincentarelbundock.github.io/Rdatasets/doc/forecast/gold.html","gold R Documentation   Daily morning gold prices   Description  
Daily morning gold prices in US dollars. 1 January 1985 – 31 March 1989.    Usage    gold    Format  
Time series data    Examples    tsdisplay(gold)"
"forecast-taylor","forecast","taylor","Half-hourly electricity demand",4032,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/forecast/taylor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/forecast/taylor.html","taylor R Documentation   Half-hourly electricity demand   Description  
Half-hourly electricity demand in England and Wales from Monday 5 June 2000 to Sunday 27 August 2000. Discussed in Taylor (2003), and kindly provided by James W Taylor. Units: Megawatts    Usage    taylor    Format  
Time series data    Source  
James W Taylor    References  
Taylor, J.W. (2003) Short-term electricity demand forecasting using double seasonal exponential smoothing. Journal of the Operational Research Society , 54 , 799-805.    Examples    plot(taylor)"
"forecast-wineind","forecast","wineind","Australian total wine sales",176,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/forecast/wineind.csv","https://vincentarelbundock.github.io/Rdatasets/doc/forecast/wineind.html","wineind R Documentation   Australian total wine sales   Description  
Australian total wine sales by wine makers in bottles <= 1 litre. Jan 1980 – Aug 1994.    Usage    wineind    Format  
Time series data    Source  
Time Series Data Library. https://pkg.yangzhuoranyang.com/tsdl/     Examples    tsdisplay(wineind)"
"forecast-woolyrnq","forecast","woolyrnq","Quarterly production of woollen yarn in Australia",119,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/forecast/woolyrnq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/forecast/woolyrnq.html","woolyrnq R Documentation   Quarterly production of woollen yarn in Australia   Description  
Quarterly production of woollen yarn in Australia: tonnes. Mar 1965 – Sep 1994.    Usage    woolyrnq    Format  
Time series data    Source  
Time Series Data Library. https://pkg.yangzhuoranyang.com/tsdl/     Examples    tsdisplay(woolyrnq)"
"fpp2-a10","fpp2","a10","Monthly anti-diabetic drug subsidy in Australia from 1991 to 2008.",204,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/a10.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/a10.html","a10 R Documentation   Monthly anti-diabetic drug subsidy in Australia from 1991 to 2008.   Description  
Monthly government expenditure (millions of dollars) as part of the Pharmaceutical Benefit Scheme for products falling under ATC code A10 as recorded by the Australian Health Insurance Commission. July 1991 - June 2008.    Format  
Monthly time series of class ts .    Source  
Medicare Australia    Examples    autoplot(a10) ggseasonplot(a10)"
"fpp2-arrivals","fpp2","arrivals","International Arrivals to Australia",127,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/arrivals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/arrivals.html","arrivals R Documentation   International Arrivals to Australia   Description  
Quarterly international arrivals (in thousands) to Australia from Japan, New Zealand, UK and the US. 1981Q1 - 2012Q3.    Format  
Quarterly time series of class ts .    Source  
Tourism Research Australia.    Examples    autoplot(arrivals)"
"fpp2-ausair","fpp2","ausair","Air Transport Passengers Australia",47,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/ausair.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/ausair.html","ausair R Documentation   Air Transport Passengers Australia   Description  
Total annual air passengers (in millions) including domestic and international aircraft passengers of air carriers registered in Australia. 1970-2016.    Format  
Annual time series of class ts .    Source  
World Bank.    Examples    autoplot(ausair)"
"fpp2-ausbeer","fpp2","ausbeer","Quarterly Australian Beer production",218,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/ausbeer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/ausbeer.html","ausbeer R Documentation   Quarterly Australian Beer production   Description  
Total quarterly beer production in Australia (in megalitres) from 1956:Q1 to 2010:Q2.    Format  
Quarterly time series of class ts .    Source  
Australian Bureau of Statistics. Cat. 8301.0.55.001.    Examples    data(ausbeer) ggseasonplot(ausbeer)"
"fpp2-auscafe","fpp2","auscafe","Monthly expenditure on eating out in Australia",426,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/auscafe.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/auscafe.html","auscafe R Documentation   Monthly expenditure on eating out in Australia   Description  
The total monthly expenditure on cafes, restaurants and takeaway food services in Australia ($billion). April 1982 - September 2017.    Format  
Monthly time series of class ts .    Source  
Australian Bureau of Statistics. Catalogue No. 8501.0    Examples    autoplot(auscafe)"
"fpp2-austa","fpp2","austa","International visitors to Australia",36,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/austa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/austa.html","austa R Documentation   International visitors to Australia   Description  
Total international visitors to Australia (in millions). 1980-2015.    Format  
Annual time series of class ts .    Source  
International Visitor Survey, Tourism Research Australia.    Examples    autoplot(austa)"
"fpp2-austourists","fpp2","austourists","International Tourists to Australia: Total visitor nights.",68,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/austourists.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/austourists.html","austourists R Documentation   International Tourists to Australia: Total visitor nights.   Description  
Quarterly visitor nights (in millions) spent by international tourists to Australia. 1999-2015.    Format  
Quarterly time series of class ts .    Source  
Tourism Research Australia.    Examples    autoplot(austourists)"
"fpp2-calls","fpp2","calls","Call volume for a large North American bank",27716,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/calls.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/calls.html","calls R Documentation   Call volume for a large North American bank   Description  
Five-minute call volume handled on weekdays between 7:00am and 9:05pm, beginning 3 March 2003 for 164 days.    Format  
Time series object of class msts .    Source  
Rob Hyndman    Examples    autoplot(calls, xlab=""Weeks"")"
"fpp2-debitcards","fpp2","debitcards","Retail debit card usage in Iceland.",164,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/debitcards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/debitcards.html","debitcards R Documentation   Retail debit card usage in Iceland.   Description  
Monthly retail debit card usage in Iceland (million ISK). January 2000 - August 2013.    Format  
Monthly time series of class ts .    Source  
Statistics Iceland.    Examples    autoplot(debitcards)"
"fpp2-departures","fpp2","departures","Total monthly departures from Australia",498,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/departures.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/departures.html","departures R Documentation   Total monthly departures from Australia   Description  
Overseas departures from Australia: permanent departures, long-term (more than one year) residents departing, long-term (more than one year) visitors departing, short-term (less than one year) residents departing and short-term (less than one year) visitors departing. January 1976 - November 2016.    Format  
Multiple monthly time series of class mts containing the following series:   
 permanent permanent departures from Australia.
 reslong long-term resident departures from Australia.
 vislong long-term visitor departures from Australia.
 resshort short-term resident departures from Australia.
 visshort short-term visitor departures from Australia.    Source  
Australian Bureau of Statistics. Catalogue No 3401.02.    Examples    autoplot(departures, facets=TRUE)"
"fpp2-elecdaily","fpp2","elecdaily","Half-hourly and daily electricity demand for Victoria, Australia, in 2014",365,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/elecdaily.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/elecdaily.html","elecdemand R Documentation   Half-hourly and daily electricity demand for Victoria, Australia, in 2014   Description  
elecdemand is a half-hourly time series matrix with three columns:   
 Demand: Total electricity demand in GW for Victoria, Australia, every half-hour during 2014.
 WorkDay: taking value 1 on work days, and 0 otherwise.
 Temperature: half-hourly temperatures for Melbourne (BOM site 086071).   
elecdaily is a daily time series matrix with three columns:   
 Demand: Total electricity demand in GW for Victoria, Australia, every day during 2014.
 WorkDay: taking value 1 on work days, and 0 otherwise.
 Temperature: maximum daily temperatures for Melbourne (BOM site 086071).    Format  
Multiple time series of class mts .    Details  
This data is for operational demand, which is the demand met by local scheduled generating units, semi-scheduled generating units, and non-scheduled intermittent generating units of aggregate capacity larger than 30 MW, and by generation imports to the region. The operational demand excludes the demand met by non-scheduled non-intermittent generating units, non-scheduled intermittent generating units of aggregate capacity smaller than 30 MW, exempt generation (e.g. rooftop solar, gas tri-generation, very small wind farms, etc), and demand of local scheduled loads. It also excludes some very large industrial users (such as mines or smelters).    Source  
Australian Energy Market Operator, and the Australian Bureau of Meteorology.    Examples    summary(elecdemand) summary(elecdaily)"
"fpp2-elecdemand","fpp2","elecdemand","Half-hourly and daily electricity demand for Victoria, Australia, in 2014",17520,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/elecdemand.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/elecdemand.html","elecdemand R Documentation   Half-hourly and daily electricity demand for Victoria, Australia, in 2014   Description  
elecdemand is a half-hourly time series matrix with three columns:   
 Demand: Total electricity demand in GW for Victoria, Australia, every half-hour during 2014.
 WorkDay: taking value 1 on work days, and 0 otherwise.
 Temperature: half-hourly temperatures for Melbourne (BOM site 086071).   
elecdaily is a daily time series matrix with three columns:   
 Demand: Total electricity demand in GW for Victoria, Australia, every day during 2014.
 WorkDay: taking value 1 on work days, and 0 otherwise.
 Temperature: maximum daily temperatures for Melbourne (BOM site 086071).    Format  
Multiple time series of class mts .    Details  
This data is for operational demand, which is the demand met by local scheduled generating units, semi-scheduled generating units, and non-scheduled intermittent generating units of aggregate capacity larger than 30 MW, and by generation imports to the region. The operational demand excludes the demand met by non-scheduled non-intermittent generating units, non-scheduled intermittent generating units of aggregate capacity smaller than 30 MW, exempt generation (e.g. rooftop solar, gas tri-generation, very small wind farms, etc), and demand of local scheduled loads. It also excludes some very large industrial users (such as mines or smelters).    Source  
Australian Energy Market Operator, and the Australian Bureau of Meteorology.    Examples    summary(elecdemand) summary(elecdaily)"
"fpp2-elecequip","fpp2","elecequip","Electrical equipment manufactured in the Euro area.",195,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/elecequip.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/elecequip.html","elecequip R Documentation   Electrical equipment manufactured in the Euro area.   Description  
Monthly manufacture of electrical equipment: computer, electronic and optical products. January 1996 - March 2012. Data adjusted by working days; Euro area (17 countries). Industry new orders index. 2005=100.    Format  
Time series object of class ts .    Source  
Eurostat.    Examples    autoplot(elecequip)"
"fpp2-elecsales","fpp2","elecsales","Electricity sales to residential customers in South Australia.",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/elecsales.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/elecsales.html","elecsales R Documentation   Electricity sales to residential customers in South Australia.   Description  
Annual electricity sales for South Australia in GWh from 1989 to 2008. Electricity used for hot water has been excluded.    Format  
Time series object of class ts .    Source  
Australian Energy Market Operator.    Examples    autoplot(elecsales)"
"fpp2-euretail","fpp2","euretail","Quarterly retail trade: Euro area.",64,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/euretail.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/euretail.html","euretail R Documentation   Quarterly retail trade: Euro area.   Description  
Quarterly retail trade index in the Euro area (17 countries), 1996-2011, covering wholesale and retail trade, and repair of motor vehicles and motorcycles. (Index: 2005 = 100).    Format  
Quarterly time series of class ts .    Source  
Eurostat.    Examples    autoplot(euretail)"
"fpp2-gasoline","fpp2","gasoline","US finished motor gasoline product supplied.",1355,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/gasoline.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/gasoline.html","gasoline R Documentation   US finished motor gasoline product supplied.   Description  
Weekly data beginning 2 February 1991, ending 20 January 2017. Units are ""million barrels per day"".    Format  
Time series object of class ts .    Source  
US Energy Information Administration.    Examples    autoplot(gasoline, xlab=""Year"")"
"fpp2-goog","fpp2","goog","Daily closing stock prices of Google Inc",1000,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/goog.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/goog.html","goog R Documentation   Daily closing stock prices of Google Inc   Description  
Closing stock prices of GOOG from the NASDAQ exchange, for 1000 consecutive trading days between 25 February 2013 and 13 February 2017. Adjusted for splits. goog200 contains the first 200 observations from goog .    Format  
Daily time series of class ts .    Source  
https://goo.gl/5KBjL5     Examples    autoplot(goog)"
"fpp2-goog200","fpp2","goog200","Daily closing stock prices of Google Inc",200,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/goog200.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/goog200.html","goog R Documentation   Daily closing stock prices of Google Inc   Description  
Closing stock prices of GOOG from the NASDAQ exchange, for 1000 consecutive trading days between 25 February 2013 and 13 February 2017. Adjusted for splits. goog200 contains the first 200 observations from goog .    Format  
Daily time series of class ts .    Source  
https://goo.gl/5KBjL5     Examples    autoplot(goog)"
"fpp2-guinearice","fpp2","guinearice","Rice production (Guinea)",42,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/guinearice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/guinearice.html","guinearice R Documentation   Rice production (Guinea)   Description  
Total annual rice production (million metric tons) for Guinea. 1970-2011.    Format  
Annual time series of class ts .    Source  
World Bank.    Examples    autoplot(guinearice)"
"fpp2-h02","fpp2","h02","Monthly corticosteroid drug subsidy in Australia from 1991 to 2008.",204,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/h02.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/h02.html","h02 R Documentation   Monthly corticosteroid drug subsidy in Australia from 1991 to 2008.   Description  
Monthly government expenditure (millions of dollars) as part of the Pharmaceutical Benefit Scheme for products falling under ATC code H02 as recorded by the Australian Health Insurance Commission. July 1991 - June 2008.    Format  
Monthly time series of class ts .    Source  
Medicare Australia    Examples    autoplot(h02) ggseasonplot(h02)"
"fpp2-hyndsight","fpp2","hyndsight","Daily pageviews for the Hyndsight blog. 30 April 2014 to 29 April 2015.",365,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/hyndsight.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/hyndsight.html","hyndsight R Documentation   Daily pageviews for the Hyndsight blog. 30 April 2014 to 29 April 2015.   Description  
Hyndsight is Rob Hyndman's personal blog at  https://robjhyndman.com/hyndsight/ . This series contains the daily pageviews for one year, beginning 30 April 2014. The frequency is set to 7, to allow the weekly pattern to be modelled.    Format  
Time series object of class ts .    Source  
Rob Hyndman    Examples    autoplot(hyndsight, xlab=""Weeks"")"
"fpp2-insurance","fpp2","insurance","Insurance quotations and advertising expenditure.",40,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/insurance.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/insurance.html","insurance R Documentation   Insurance quotations and advertising expenditure.   Description  
Monthly quotations and monthly television advertising expenditure for a US insurance company. January 2002 to April 2005.    Format  
Monthly time series of class ts .    Source  
Kindly provided by Dave Reilly, Automatic Forecasting Systems.    Examples    autoplot(insurance)"
"fpp2-livestock","fpp2","livestock","Livestock (sheep) in Asia, 1961-2007.",47,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/livestock.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/livestock.html","livestock R Documentation   Livestock (sheep) in Asia, 1961-2007.   Description  
Annual sheep livestock numbers in Asia (in million head).    Format  
Annual time series of class ts .    Source  
United Nations.    Examples    autoplot(livestock)"
"fpp2-marathon","fpp2","marathon","Boston marathon winning times since 1897",120,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/marathon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/marathon.html","marathon R Documentation   Boston marathon winning times since 1897   Description  
Winning times (in minutes) for the Boston Marathon Men's Open Division. 1897-2016.    Format  
Annual time series of class ts .    Source  
Boston Athletic Association.  https://www.baa.org/races/boston-marathon/results/champions     Examples    autoplot(marathon)"
"fpp2-maxtemp","fpp2","maxtemp","Maximum annual temperatures at Moorabbin Airport, Melbourne",46,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/maxtemp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/maxtemp.html","maxtemp R Documentation   Maximum annual temperatures at Moorabbin Airport, Melbourne   Description  
Maximum annual temperatures (degrees Celsius) for Moorabbin Airport, Melbourne. 1971-2016.    Format  
Annual time series of class ts .    Source  
Australian Bureau of Meteorology.    Examples    autoplot(maxtemp)"
"fpp2-melsyd","fpp2","melsyd","Total weekly air passenger numbers on Ansett airline flights between Melbourne and Sydney, 1987-1992.",283,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/melsyd.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/melsyd.html","melsyd R Documentation   Total weekly air passenger numbers on Ansett airline flights between Melbourne and Sydney, 1987–1992.   Description  
Air traffic numbers are in thousands, and divided into first class, business class and economy class. There was a major pilots' industrial dispute during the data period resulting in some weeks with zero traffic. There was also at least two changes in the definitions of passenger classes.    Format  
Multiple time series of class mts .    Source  
Ansett Airlines (which no longer exists).    Examples    autoplot(melsyd, facets=TRUE)"
"fpp2-mens400","fpp2","mens400","Winning times in Olympic men's 400m track final. 1896-2016.",31,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/mens400.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/mens400.html","mens400 R Documentation   Winning times in Olympic men's 400m track final. 1896-2016.   Description  
Times in seconds for the gold-medal winner of the men's 400m track final at each Olympics since 1896. Missing values occur in 1916, 1940 and 1944 due to the World Wars.    Format  
time series of class ts with frequency 1/4.    Examples    autoplot(mens400)"
"fpp2-oil","fpp2","oil","Annual oil production in Saudi Arabia",49,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/oil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/oil.html","oil R Documentation   Annual oil production in Saudi Arabia   Description  
Annual oil production (millions of tonnes), Saudi Arabia, 1965-2013.    Format  
Annual time series of class ts .    Source  
BP.    Examples    autoplot(oil)"
"fpp2-prison","fpp2","prison","prison",48,32,0,0,0,0,32,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/prison.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/prison.html","prison R Documentation   prison   Description  
prison    Format  
Quarterly time series of prisoner numbers in Australia from 2005 to 2016, split by sex, state and legal status. prisonLF is a long-form version of the data of class data.frame , while prison is in wide form and of class mts .    Examples    autoplot(prison) head(prisonLF)"
"fpp2-prisonLF","fpp2","prisonLF","prison",1536,5,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/prisonLF.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/prisonLF.html","prison R Documentation   prison   Description  
prison    Format  
Quarterly time series of prisoner numbers in Australia from 2005 to 2016, split by sex, state and legal status. prisonLF is a long-form version of the data of class data.frame , while prison is in wide form and of class mts .    Examples    autoplot(prison) head(prisonLF)"
"fpp2-qauselec","fpp2","qauselec","Quarterly Australian Electricity production",218,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/qauselec.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/qauselec.html","qauselec R Documentation   Quarterly Australian Electricity production   Description  
Total quarterly electricity production in Australia (in billion kWh) from 1956:Q1 to 2010:Q2.    Format  
Quarterly time series of class ts .    Source  
Australian Bureau of Statistics. Cat. 8301.0.55.001.    Examples    autoplot(qauselec)"
"fpp2-qcement","fpp2","qcement","Quarterly Australian Portland Cement production",233,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/qcement.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/qcement.html","qcement R Documentation   Quarterly Australian Portland Cement production   Description  
Total quarterly production of Portland cement in Australia (in millions of tonnes) from 1956:Q1 to 2014:Q1.    Format  
Quarterly time series of class ts .    Source  
Australian Bureau of Statistics. Cat. 8301.0.55.001.    Examples    autoplot(qcement)"
"fpp2-qgas","fpp2","qgas","Quarterly Australian Gas Production",218,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/qgas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/qgas.html","qgas R Documentation   Quarterly Australian Gas Production   Description  
Total quarterly gas production in Australia (in petajoules) from 1956:Q1 to 2010:Q2.    Format  
Quarterly time series of class ts .    Source  
Australian Bureau of Statistics. Cat. 8301.0.55.001.    Examples    autoplot(qgas)"
"fpp2-sunspotarea","fpp2","sunspotarea","Annual average sunspot area (1875-2015)",141,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/sunspotarea.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/sunspotarea.html","sunspotarea R Documentation   Annual average sunspot area (1875-2015)   Description  
Annual averages of the daily sunspot areas (in units of millionths of a hemisphere) for the full sun. Sunspots are magnetic regions that appear as dark spots on the surface of the sun. The Royal Greenwich Observatory compiled daily sunspot observations from May 1874 to 1976. Later data are from the US Air Force and the US National Oceanic and Atmospheric Administration. The data have been calibrated to be consistent across the whole history of observations.    Format  
Annual time series of class ts .    Source  
NASA    Examples    autoplot(sunspotarea)"
"fpp2-uschange","fpp2","uschange","Growth rates of personal consumption and personal income in the USA.",187,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/uschange.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/uschange.html","uschange R Documentation   Growth rates of personal consumption and personal income in the USA.   Description  
Percentage changes in quarterly personal consumption expenditure, personal disposable income, production, savings and the unemployment rate for the US, 1960 to 2016.    Format  
Time series object of class ts .    Source  
Federal Reserve Bank of St Louis.    Examples    autoplot(uschange, facet=TRUE)"
"fpp2-usmelec","fpp2","usmelec","Electricity monthly total net generation. January 1973 - June 2013.",486,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/usmelec.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/usmelec.html","usmelec R Documentation   Electricity monthly total net generation. January 1973 - June 2013.   Description  
Electricity net generation measured in billions of kilowatt hours (kWh).    Format  
Time series object of class ts .    Source  
US Energy Information Administration.    Examples    autoplot(usmelec)"
"fpp2-visnights","fpp2","visnights","Quarterly visitor nights for various regions of Australia.",76,20,0,0,0,0,20,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/visnights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/visnights.html","visnights R Documentation   Quarterly visitor nights for various regions of Australia.   Description  
Total quarterly visitor nights (in millions) from 1998-2016 for twenty regions of Australia within six states. The states are: New South Wales, Queensland, South Australia, Victoria, Western Australia, and Other.    Format  
Time series object of class mts .    Source  
Tourism Research Australia.    Examples    autoplot(visnights)"
"fpp2-wmurders","fpp2","wmurders","Annual female murder rate (per 100,000 standard population) in the USA. 1950-2004.",55,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/fpp2/wmurders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/fpp2/wmurders.html","wmurders R Documentation   Annual female murder rate (per 100,000 standard population) in the USA. 1950-2004.   Description  
Total Murdered women, per 100 000 standard population.    Format  
Annual time series of class ts .    Source  
Gapminder Foundation.    Examples    autoplot(wmurders)"
"gap-aldh2","gap","aldh2","Internal functions for gap",263,18,1,0,1,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/aldh2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/aldh2.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-apoeapoc","gap","apoeapoc","Internal functions for gap",353,8,4,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/apoeapoc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/apoeapoc.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-cf","gap","cf","Internal functions for gap",186,24,4,0,0,0,24,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/cf.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/cf.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-cnv","gap","cnv","Internal functions for gap",602,5,0,2,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/cnv.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/cnv.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-crohn","gap","crohn","Internal functions for gap",387,212,2,0,1,0,211,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/crohn.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/crohn.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-fa","gap","fa","Internal functions for gap",127,13,1,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/fa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/fa.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-fsnps","gap","fsnps","Internal functions for gap",432,10,0,0,8,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/fsnps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/fsnps.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-hla","gap","hla","Internal functions for gap",271,8,2,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/hla.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/hla.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-inf1","gap","inf1","Internal functions for gap",92,8,0,5,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/inf1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/inf1.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-jma.cojo","gap","jma.cojo","Internal functions for gap",2,16,13,4,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/jma.cojo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/jma.cojo.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-l51","gap","l51","Internal functions for gap",51,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/l51.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/l51.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-lukas","gap","lukas","Internal functions for gap",85,4,1,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/lukas.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/lukas.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-mao","gap","mao","Internal functions for gap",340,19,2,13,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/mao.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/mao.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-meyer","gap","meyer","Internal functions for gap",306,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/meyer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/meyer.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-mfblong","gap","mfblong","Internal functions for gap",3000,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/mfblong.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/mfblong.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-mr","gap","mr","Internal functions for gap",9,7,0,1,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/mr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/mr.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-nep499","gap","nep499","Internal functions for gap",499,23,16,0,0,0,23,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/nep499.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/nep499.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"gap-PD","gap","PD","Internal functions for gap",825,22,5,16,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/gap/PD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gap/PD.html","gap-internal R Documentation   Internal functions for gap   Description  
These are internal functions.   
a2g gives allele-to-genotype conversion.   
chr_pos_a1_a2 produces SNPID format.   
circos.cnvplot produces circos plot of CNVs   
circos.cis.vs.trans.plot gives circos plot of cis/trans classification   
circos.mhtplot generates circos Manhattan plot with gene annotation   
cis.vs.trans.classification classifies hits, usually SNPs with associate id and (b)ase-(p)air position, to be cis or trans according to a panel which contains id, chr, start, end, gene variables.   
cnvplot is a cutomised function to plot CNVs genomewide   
cs is for calculation of credible set.   
g2a returns two alleles according to a genotype identifier.   
g2a.c is the C version of g2c.   
gc.control is used by gc.em().   
gc.lambda estimates the genomic control inflation statistic (lambda)   
gcode is as a2g.   
grec2g is undocumented.   
gsmr is a function for Mendelian randomization analysis.   
h2G is a utility function for heritability   
h2GE is a utility function for heritability involving gene-environment interaction   
h2l is a utility function for converting observed heritability to its counterpart under liability threshold model   
hap.control is used by hap.em().   
HapDesign and HapFreqSE both accept a haplo.em object to derieve a design/dosage matrix and standard error of haplotype frequency estimates. The former is appropriate for haplotype trend regression (HTR), e.g., within the generalized linear model (GLM) framework to be equivllant to a formal approach as implemented in the package haplo.stats and hap.score. However, they are expected to be compatible with objects from gc.em() gc.em and hap.em . The two functions are included as courtesy of Prof Andrea Foulkes from the useR!2008 tutorial.   
hap.score.glm, hap.score.podds are used by hap.score().   
invlogit, inverse logit transformation.   
inv_chr_pos_a1_a2 is the inverse function of chr_pos_a1_a2.   
invnormal, inverse normal transformation.   
is.miss is undocumented.   
KCC calculates disease prevalences in cases and controls for a given genotype relative risk, allele frequency and prevalencen of the disease in the whole population. It is used by tscc and pbsize2.   
k obtains 1st and 2nd order culumants for correlation coefficient.   
log10p is log10(p) for a normal deviate.   
log10pvalue gives log10(p) for any p, e.g., ""1.234e-1000"".   
logp is log(p) for a normal deviate.   
m2plem is an experimental function for PLEM format.   
makeRLEplot for RLE plot.   
mhtplot2d is for 2D Manhattan plot.   
mhtplot3d is for 3D Manhattan plot.   
miamiplot is for Miami plot.   
micombine is used to combine imputation results.   
PARn calculates population attributable risk (PAR) for a list of frequencies and relative risks (RRs).   
plem2m is also experimental for PLEM format.   
pvalue takes a z-statistic for a p value with scientific representation.   
ReadGRM is a function to read GCTA grm.gz and grm.id file   
ReadGRMPLINK is a function to read PLINK PI_HAT as a genomic relationship matrix.   
ReadGRMPCA is a function to read .eigenval and .eigenvec files from gcta –pca.   
ReadGRMBin is a function to read GCTA grm.bin files, modified from GCTA documentation.   
revhap recovers the allele indices for a given haplotype ID in a multiallelic system.   
revhap.i is similar to revhap.   
snptest_sample generates a sample file for SNPTEST.   
solve.skol is a function used by tscc.   
toETDT a function used to experiment with ETDT.   
ungcode recovers alleles from genotype(s).   
VR is a utility function for calculating variance of a ratio.   
weighted.median is a function for obtaining weighted median with interpolation.   
WriteGRM is a utility function to write GCTA grm.gz and grm.id files.   
WriteGRMBin is a utility function to write GCTA grm.bin files.   
WriteGRMSAS is a utility function to write a GRM object to SAS PROCs MIXED/GLIMMIX ldata.   
x2 is a simple chi-squared test of two proportions.   
z is a normal z-test of two proportions used by tscc.    Usage    a2g(a1,a2) chr_pos_a1_a2(chr,pos,a1,a2,prefix=""chr"",seps=c("":"",""_"",""_""),uppercase=TRUE) cis.vs.trans.classification(hits,panel,id,radius=1e6) g2a(g) g2a.c(g) h2G(V,VCOV,verbose=TRUE) h2GE(V,VCOV,verbose=TRUE) h2l(K=0.05,P=0.5,h2,se,verbose=TRUE) inv_chr_pos_a1_a2(chr_pos_a1_a2,prefix=""chr"",seps=c("":"",""_"",""_"")) KCC(model,GRR,p1,K) mhtplot3d(xyz=""INF1.merge.cis.vs.trans"", cols=c(""id"",""chr1"",""pos1"",""chr2"",""pos2"",""gene"",""target"",""log10p"",""x"",""y"",""col""), xy.scale=c(1.3e8,1.3e8),marker.size=4,log10p.max=400, prefix=c(""Sentinel"",""CHR"",""POS"",""CHR"",""POS"",""Gene"",""Target"",""-log10(p)""), postfix=""\u003c/br>"", json.file=""d3.json"",pretty=TRUE) ReadGRM(prefix=51) ReadGRMBin(prefix, AllN=FALSE, size=4) ReadGRMPLINK(prefix, diag=1) ReadGRMPCA(prefix) revhap(loci,hapid) snptest_sample(data,sample_file=""snptest.sample"",ID_1=""ID_1"",ID_2=""ID_2"", missing=""missing"",C=NULL,D=NULL,P=NULL) VR(v1,vv1,v2,vv2,c12) WriteGRM(prefix=51,id,N,GRM) WriteGRMBin(prefix, grm, N, id, size=4) WriteGRMSAS(grmlist, outfile=""gwas"")    Arguments  
a1  
Allele 1  
a2  
Allele 2  
g  
A genotype identifier  
model  
One of ""multiplicative"", ""additive"", ""recessive"", ""dominant"", ""overdominant""  
GRR  
Genotype relative risk  
p1  
Frequency of the risk allele  
K  
Prevalence of disease in the population  
loci  
A vector of number of alleles at all loci  
hapid  
Haplotype identifier     Details  
These functions are not so frequently called by users   Examples    ## Not run: # cnvplot(cnv) circos.cnvplot(cnv) # cvt <- cis.vs.trans.classification(hits=jma.cojo, panel=inf1, id=""uniprot"") cvt # circos.cis.vs.trans.plot(hits=""INF1.clumped"", panel=inf1, id=""uniprot"") # require(gap.datasets) g <- c(""IRS1"",""SPRY2"",""FTO"",""GRIK3"",""SNED1"",""HTR1A"",""MARCH3"",""WISP3"", ""PPP1R3B"",""RP1L1"",""FDFT1"",""SLC39A14"",""GFRA1"",""MC4R"") circos.mhtplot(mhtdata,g) # # zcat METAL/4E.BP1-1.tbl.gz | \ # awk 'NR==1 || ($1==4 && $2 >= 187158034 - 1e6 && $2 < 187158034 + 1e6)' > 4E.BP1.z tbl <- within(read.delim(""4E.BP1.z""),{logp <- logp(Effect/StdErr)}) z <- cs(tbl) l <- cs(tbl,log_p=""logp"") # d <- read.table(""INF1.merge.cis.vs.trans"",as.is=TRUE,header=TRUE) mhtplot2d(d) # d <- data.frame(ID_1=1,ID_2=1,missing=0,PC1=1,PC2=2,D1=1,P1=10) snptest_sample(d,C=paste0(""PC"",1:2),D=paste0(""D"",1:1),P=paste0(""P"",1:1)) # s <- chr_pos_a1_a2(1,c(123,321),letters[1:2],letters[2:1]) inv_chr_pos_a1_a2(s) inv_chr_pos_a1_a2(""chr1:123-A_B"",seps=c("":"",""-"",""_"")) # p <- mhtplot3d(pretty=FALSE) # pvalue(-1.96) ## End(Not run)"
"geepack-dietox","geepack","dietox","Growth curves of pigs in a 3x3 factorial experiment",861,8,0,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/dietox.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/dietox.html","dietox R Documentation   Growth curves of pigs in a 3x3 factorial experiment   Description  
The dietox data frame has 861 rows and 7 columns.    Usage    dietox    Format  
This data frame contains the following columns:    Weight
Weight in Kg   Feed
Cumulated feed intake in Kg   Time
Time (in weeks) in the experiment   Pig
Factor; id of each pig   Evit
Factor; vitamin E dose; see 'details'.   Cu
Factor, copper dose; see 'details'   Start
Start weight in experiment, i.e. weight at week 1.   Litter
Factor, id of litter of each pig     Details  
Data contains weight of slaughter pigs measured weekly for 12 weeks. Data also contains the startweight (i.e. the weight at week 1). The treatments are 3 different levels of Evit = vitamin E (dose: 0, 100, 200 mg dl-alpha-tocopheryl acetat /kg feed) in combination with 3 different levels of Cu=copper (dose: 0, 35, 175 mg/kg feed) in the feed. The cumulated feed intake is also recorded. The pigs are littermates.    Source  
Lauridsen, C., Højsgaard, S.,Sørensen, M.T. C. (1999) Influence of Dietary Rapeseed Oli, Vitamin E, and Copper on Performance and Antioxidant and Oxidative Status of Pigs. J. Anim. Sci.77:906-916    Examples    data(dietox) head(dietox) ## Not run: if (require(ggplot2)){ qplot(Time, Weight, data=dietox, col=Pig) + geom_line() + theme(legend.position = ""none"") + facet_grid(Evit~Cu) } else { coplot(Weight ~ Time | Evit * Cu, data=dietox) } ## End(Not run)"
"geepack-koch","geepack","koch","Ordinal Data from Koch",288,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/koch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/koch.html","koch R Documentation   Ordinal Data from Koch   Description  
The koch data frame has 288 rows and 4 columns.    Usage    koch    Format  
This data frame contains the following columns:    trt
a numeric vector   day
a numeric vector   y
an ordered factor with levels: 1 < 2 < 3   id
a numeric vector     Examples    data(koch) fit <- ordgee(ordered(y) ~ trt + as.factor(day), id=id, data=koch, corstr=""exch"") summary(fit)"
"geepack-muscatine","geepack","muscatine","Data on Obesity from the Muscatine Coronary Risk Factor Study.",14568,7,3,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/muscatine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/muscatine.html","muscatine R Documentation   Data on Obesity from the Muscatine Coronary Risk Factor Study.   Description  
The data are from the Muscatine Coronary Risk Factor (MCRF) study, a longitudinal survey of school-age children in Muscatine, Iowa. The MCRF study had the goal of examining the development and persistence of risk factors for coronary disease in children. In the MCRF study, weight and height measurements of five cohorts of children, initially aged 5-7, 7-9, 9-11, 11-13, and 13-15 years, were obtained biennially from 1977 to 1981. Data were collected on 4856 boys and girls. On the basis of a comparison of their weight to age-gender specific norms, children were classified as obese or not obese.    Usage    muscatine    Format  
A dataframe with 14568 rows and 7 variables:    id
identifier of child.   gender
gender of child   base_age
baseline age   age
current age   occasion
identifier of occasion of recording   obese
'yes' or 'no'   numobese
obese in numerical form: 1 corresponds to 'yes' and 0 corresponds to 'no'.     Source  
https://content.sph.harvard.edu/fitzmaur/ala2e/muscatine.txt    
Woolson, R.F. and Clarke, W.R. (1984). Analysis of categorical incompletel longitudinal data. Journal of the Royal Statistical Society, Series A, 147, 87-99.    Examples    muscatine$cage <- muscatine$age - 12 muscatine$cage2 <- muscatine$cage^2 f1 <- numobese ~ gender f2 <- numobese ~ gender + cage + cage2 + gender:cage + gender:cage2 gee1 <- geeglm(formula = f1, id = id, waves = occasion, data = muscatine, family = binomial(), corstr = ""independence"") gee2 <- geeglm(formula = f2, id = id, waves = occasion, data = muscatine, family = binomial(), corstr = ""independence"") tidy(gee1) tidy(gee2) QIC(gee1) QIC(gee2)"
"geepack-ohio","geepack","ohio","Ohio Children Wheeze Status",2148,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/ohio.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/ohio.html","ohio R Documentation   Ohio Children Wheeze Status   Description  
The ohio data frame has 2148 rows and 4 columns. The dataset is a subset of the six-city study, a longitudinal study of the health effects of air pollution.    Usage    ohio    Format  
This data frame contains the following columns:    resp
an indicator of wheeze status (1=yes, 0=no)   id
a numeric vector for subject id   age
a numeric vector of age, 0 is 9 years old   smoke
an indicator of maternal smoking at the first year of the study     References  
Fitzmaurice, G.M. and Laird, N.M. (1993) A likelihood-based method for analyzing longitudinal binary responses, Biometrika   80 : 141–151.    Examples    data(ohio) fit.ex <- geeglm(resp ~ age + smoke + age:smoke, id=id, data=ohio, family=binomial, corstr=""exch"", scale.fix=TRUE) QIC(fit.ex) fit.ar <- geeglm(resp ~ age + smoke + age:smoke, id=id, data=ohio, family=binomial, corstr=""ar1"", scale.fix=TRUE) QIC(fit.ex)"
"geepack-respdis","geepack","respdis","Clustered Ordinal Respiratory Disorder",111,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/respdis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/respdis.html","respdis R Documentation   Clustered Ordinal Respiratory Disorder   Description  
The respdis data frame has 111 rows and 3 columns. The study described in Miller et. al. (1993) is a randomized clinical trial of a new treatment of respiratory disorder. The study was conducted in 111 patients who were randomly assigned to one of two treatments (active, placebo). At each of four visits during the follow-up period, the response status of each patients was classified on an ordinal scale.    Usage    respdis    Format  
This data frame contains the following columns:    y1, y2, y3, y4
ordered factor measured at 4 visits for the response with levels, 1 < 2 < 3 , 1 = poor, 2 = good, and 3 = excellent   trt
a factor for treatment with levels, 1 = active, 0 = placebo.     References  
Miller, M.E., David, C.S., and Landis, R.J. (1993) The analysis of longitudinal polytomous data: Generalized estimating equation and connections with weighted least squares, Biometrics 49 : 1033-1048.    Examples    data(respdis) resp.l <- reshape(respdis, varying = list(c(""y1"", ""y2"", ""y3"", ""y4"")), v.names = ""resp"", direction = ""long"") resp.l <- resp.l[order(resp.l$id, resp.l$time),] fit <- ordgee(ordered(resp) ~ trt, id = id, data = resp.l, int.const = FALSE) summary(fit) z <- model.matrix( ~ trt - 1, data = respdis) ind <- rep(1:111, 4*3/2 * 2^2) zmat <- z[ind,,drop=FALSE] fit <- ordgee(ordered(resp) ~ trt, id = id, data = resp.l, int.const = FALSE, z = zmat, corstr = ""exchangeable"") summary(fit)"
"geepack-respiratory","geepack","respiratory","Data from a clinical trial comparing two treatments for a respiratory illness",444,8,5,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/respiratory.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/respiratory.html","respiratory R Documentation   Data from a clinical trial comparing two treatments for a respiratory illness   Description  
The data are from a clinical trial of patients with respiratory illness, where 111 patients from two different clinics were randomized to receive either placebo or an active treatment. Patients were examined at baseline and at four visits during treatment. The respiratory status (categorized as 1 = good, 0 = poor) was determined at each visit.    Usage    respiratory    Format  
A data frame with 444 observations on the following 8 variables.    center
a numeric vector   id
a numeric vector   treat
treatment or placebo   sex
M or F   age
in years at baseline   baseline
resporatory status at baseline   visit
id of each of four visits   outcome
respiratory status at each visit     Examples    data(respiratory) data(respiratory, package=""geepack"") respiratory$center <- factor(respiratory$center) head(respiratory) m1 <- glm(outcome ~ center + treat + age + baseline, data=respiratory, family=binomial()) gee.ind <- geeglm(outcome ~ center + treat + age + baseline, data=respiratory, id=id, family=binomial(), corstr=""independence"") gee.exc <- geeglm(outcome ~ center + treat + age + baseline, data=respiratory, id=id, family=binomial(), corstr=""exchangeable"") gee.uns <- geeglm(outcome ~ center + treat + age + baseline, data=respiratory, id=id, family=binomial(), corstr=""unstructured"") gee.ar1 <- geeglm(outcome ~ center + treat + age + baseline, data=respiratory, id=id, family=binomial(), corstr=""ar1"") mlist <- list(gee.ind, gee.exc, gee.uns, gee.ar1) do.call(rbind, lapply(mlist, QIC)) lapply(mlist, tidy)"
"geepack-seizure","geepack","seizure","Epiliptic Seizures",59,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/seizure.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/seizure.html","seizure R Documentation   Epiliptic Seizures   Description  
The seizure data frame has 59 rows and 7 columns. The dataset has the number of epiliptic seizures in each of four two-week intervals, and in a baseline eight-week inverval, for treatment and control groups with a total of 59 individuals.    Usage    seizure    Format  
This data frame contains the following columns:   y1
the number of epiliptic seizures in the 1st 2-week interval   y2
the number of epiliptic seizures in the 2nd 2-week interval   y3
the number of epiliptic seizures in the 3rd 2-week interval   y4
the number of epiliptic seizures in the 4th 2-week interval   trt
an indicator of treatment   base
the number of epilitic seizures in a baseline 8-week interval   age
a numeric vector of subject age     Source  
Thall, P.F. and Vail S.C. (1990) Some covariance models for longitudinal count data with overdispersion. Biometrics 46 : 657–671.    References  
Diggle, P.J., Liang, K.Y., and Zeger, S.L. (1994) Analysis of Longitudinal Data. Clarendon Press.    Examples    data(seizure) ## Diggle, Liang, and Zeger (1994) pp166-168, compare Table 8.10 seiz.l <- reshape(seizure, varying=list(c(""base"",""y1"", ""y2"", ""y3"", ""y4"")), v.names=""y"", times=0:4, direction=""long"") seiz.l <- seiz.l[order(seiz.l$id, seiz.l$time),] seiz.l$t <- ifelse(seiz.l$time == 0, 8, 2) seiz.l$x <- ifelse(seiz.l$time == 0, 0, 1) m1 <- geese(y ~ offset(log(t)) + x + trt + x:trt, id = id, data=seiz.l, corstr=""exch"", family=poisson) summary(m1) m2 <- geese(y ~ offset(log(t)) + x + trt + x:trt, id = id, data = seiz.l, subset = id!=49, corstr = ""exch"", family=poisson) summary(m2) ## Thall and Vail (1990) seiz.l <- reshape(seizure, varying=list(c(""y1"",""y2"",""y3"",""y4"")), v.names=""y"", direction=""long"") seiz.l <- seiz.l[order(seiz.l$id, seiz.l$time),] seiz.l$lbase <- log(seiz.l$base / 4) seiz.l$lage <- log(seiz.l$age) seiz.l$v4 <- ifelse(seiz.l$time == 4, 1, 0) m3 <- geese(y ~ lbase + trt + lbase:trt + lage + v4, sformula = ~ as.factor(time) - 1, id = id, data = seiz.l, corstr = ""exchangeable"", family=poisson) ## compare to Model 13 in Table 4, noticeable difference summary(m3) ## set up a design matrix for the correlation z <- model.matrix(~ age, data = seizure) # data is not seiz.l ## just to illustrate the scale link and correlation link m4 <- geese(y ~ lbase + trt + lbase:trt + lage + v4, sformula = ~ as.factor(time)-1, id = id, data = seiz.l, corstr = ""ar1"", family = poisson, zcor = z, cor.link = ""fisherz"", sca.link = ""log"") summary(m4)"
"geepack-sitka89","geepack","sitka89","Growth of Sitka Spruce Trees",632,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/sitka89.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/sitka89.html","sitka89 R Documentation   Growth of Sitka Spruce Trees   Description  
Impact of ozone on the growth of sitka spruce trees.    Usage    sitka89    Format  
A dataframe    size:
size of the tree measured in log(height*diamter^2)   time:
days after the 1st january, 1988   tree:
id number of a tree   treat:
ozone: grown under ozone environment, control: ozone free     Examples    data(sitka89)"
"geepack-spruce","geepack","spruce","Log-size of 79 Sitka spruce trees",1027,6,1,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/geepack/spruce.csv","https://vincentarelbundock.github.io/Rdatasets/doc/geepack/spruce.html","spruce R Documentation   Log-size of 79 Sitka spruce trees   Description  
The spruce data frame has 1027 rows and 6 columns. The data consists of measurements on 79 sitka spruce trees over two growing seasons. The trees were grown in four controlled environment chambers, of which the first two, containing 27 trees each, were treated with introduced ozone at 70 ppb whilst the remaining two, containing 12 and 13 trees, were controls.    Usage    spruce    Format  
This data frame contains the following columns:    chamber
a numeric vector of chamber numbers   ozone
a factor with levels enriched and normal   id
a numeric vector of tree id   time
a numeric vector of the time when the measurements were taken, measured in days since Jan. 1, 1988   wave
a numeric vector of the measurement number   logsize
a numeric vector of the log-size     Source  
Diggle, P.J., Liang, K.Y., and Zeger, S.L. (1994) Analysis of Longitudinal Data, Clarendon Press.    Examples    data(spruce) spruce$contr <- ifelse(spruce$ozone==""enriched"", 0, 1) sitka88 <- spruce[spruce$wave <= 5,] sitka89 <- spruce[spruce$wave > 5,] fit.88 <- geese(logsize ~ as.factor(wave) + contr + I(time/100*contr) - 1, id=id, data=sitka88, corstr=""ar1"") summary(fit.88) fit.89 <- geese(logsize ~ as.factor(wave) + contr - 1, id=id, data=sitka89, corstr=""ar1"") summary(fit.89)"
"ggplot2-diamonds","ggplot2","diamonds","Prices of over 50,000 round cut diamonds",53940,10,0,0,3,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/diamonds.html","diamonds R Documentation   Prices of over 50,000 round cut diamonds   Description  
A dataset containing the prices and other attributes of almost 54,000 diamonds. The variables are as follows:    Usage    diamonds    Format  
A data frame with 53940 rows and 10 variables:    price
price in US dollars (\$326–\$18,823)   carat
weight of the diamond (0.2–5.01)   cut
quality of the cut (Fair, Good, Very Good, Premium, Ideal)   color
diamond colour, from D (best) to J (worst)   clarity
a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))   x
length in mm (0–10.74)   y
width in mm (0–58.9)   z
depth in mm (0–31.8)   depth
total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43–79)   table
width of top of diamond relative to widest point (43–95)"
"ggplot2-economics","ggplot2","economics","US economic time series",574,6,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/economics.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/economics.html","economics R Documentation   US economic time series   Description  
This dataset was produced from US economic time series data available from  https://fred.stlouisfed.org/ . economics is in ""wide"" format, economics_long is in ""long"" format.    Usage    economics economics_long    Format  
A data frame with 574 rows and 6 variables:    date
Month of data collection   pce
personal consumption expenditures, in billions of dollars,  https://fred.stlouisfed.org/series/PCE   pop
total population, in thousands,  https://fred.stlouisfed.org/series/POP   psavert
personal savings rate,  https://fred.stlouisfed.org/series/PSAVERT/   uempmed
median duration of unemployment, in weeks,  https://fred.stlouisfed.org/series/UEMPMED   unemploy
number of unemployed in thousands,  https://fred.stlouisfed.org/series/UNEMPLOY    
An object of class tbl_df (inherits from tbl , data.frame ) with 2870 rows and 4 columns."
"ggplot2-economics_long","ggplot2","economics_long","US economic time series",2870,4,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/economics_long.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/economics_long.html","economics R Documentation   US economic time series   Description  
This dataset was produced from US economic time series data available from  https://fred.stlouisfed.org/ . economics is in ""wide"" format, economics_long is in ""long"" format.    Usage    economics economics_long    Format  
A data frame with 574 rows and 6 variables:    date
Month of data collection   pce
personal consumption expenditures, in billions of dollars,  https://fred.stlouisfed.org/series/PCE   pop
total population, in thousands,  https://fred.stlouisfed.org/series/POP   psavert
personal savings rate,  https://fred.stlouisfed.org/series/PSAVERT/   uempmed
median duration of unemployment, in weeks,  https://fred.stlouisfed.org/series/UEMPMED   unemploy
number of unemployed in thousands,  https://fred.stlouisfed.org/series/UNEMPLOY    
An object of class tbl_df (inherits from tbl , data.frame ) with 2870 rows and 4 columns."
"ggplot2-faithfuld","ggplot2","faithfuld","2d density estimate of Old Faithful data",5625,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/faithfuld.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/faithfuld.html","faithfuld R Documentation   2d density estimate of Old Faithful data   Description  
A 2d density estimate of the waiting and eruptions variables data faithful.    Usage    faithfuld    Format  
A data frame with 5,625 observations and 3 variables:    eruptions
Eruption time in mins   waiting
Waiting time to next eruption in mins   density
2d density estimate"
"ggplot2-luv_colours","ggplot2","luv_colours","'colors()' in Luv space",657,4,0,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/luv_colours.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/luv_colours.html","luv_colours R Documentation   colors() in Luv space   Description  
All built-in colors() translated into Luv colour space.    Usage    luv_colours    Format  
A data frame with 657 observations and 4 variables:    L,u,v
Position in Luv colour space   col
Colour name"
"ggplot2-midwest","ggplot2","midwest","Midwest demographics",437,28,1,3,0,0,25,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/midwest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/midwest.html","midwest R Documentation   Midwest demographics   Description  
Demographic information of midwest counties from 2000 US census    Usage    midwest    Format  
A data frame with 437 rows and 28 variables:    PID
Unique county identifier.   county
County name.   state
State to which county belongs to.   area
Area of county (units unknown).   poptotal
Total population.   popdensity
Population density (person/unit area).   popwhite
Number of whites.   popblack
Number of blacks.   popamerindian
Number of American Indians.   popasian
Number of Asians.   popother
Number of other races.   percwhite
Percent white.   percblack
Percent black.   percamerindan
Percent American Indian.   percasian
Percent Asian.   percother
Percent other races.   popadults
Number of adults.   perchsd
Percent with high school diploma.   percollege
Percent college educated.   percprof
Percent with professional degree.   poppovertyknown
Population with known poverty status.   percpovertyknown
Percent of population with known poverty status.   percbelowpoverty
Percent of people below poverty line.   percchildbelowpovert
Percent of children below poverty line.   percadultpoverty
Percent of adults below poverty line.   percelderlypoverty
Percent of elderly below poverty line.   inmetro
County considered in a metro area.   category
Miscellaneous.     Details  
Note: this dataset is included for illustrative purposes. The original descriptions were not documented and the current descriptions here are based on speculation. For more accurate and up-to-date US census data, see the  acs package ."
"ggplot2-mpg","ggplot2","mpg","Fuel economy data from 1999 to 2008 for 38 popular models of cars",234,11,1,6,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/mpg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/mpg.html","mpg R Documentation   Fuel economy data from 1999 to 2008 for 38 popular models of cars   Description  
This dataset contains a subset of the fuel economy data that the EPA makes available on https://fueleconomy.gov/ . It contains only models which had a new release every year between 1999 and 2008 - this was used as a proxy for the popularity of the car.    Usage    mpg    Format  
A data frame with 234 rows and 11 variables:    manufacturer
manufacturer name   model
model name   displ
engine displacement, in litres   year
year of manufacture   cyl
number of cylinders   trans
type of transmission   drv
the type of drive train, where f = front-wheel drive, r = rear wheel drive, 4 = 4wd   cty
city miles per gallon   hwy
highway miles per gallon   fl
fuel type   class
""type"" of car"
"ggplot2-msleep","ggplot2","msleep","An updated and expanded version of the mammals sleep dataset",83,11,0,5,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/msleep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/msleep.html","msleep R Documentation   An updated and expanded version of the mammals sleep dataset   Description  
This is an updated and expanded version of the mammals sleep dataset. Updated sleep times and weights were taken from V. M. Savage and G. B. West. A quantitative, theoretical framework for understanding mammalian sleep. Proceedings of the National Academy of Sciences, 104 (3):1051-1056, 2007.    Usage    msleep    Format  
A data frame with 83 rows and 11 variables:    name
common name   genus vore
carnivore, omnivore or herbivore?   order conservation
the conservation status of the animal   sleep_total
total amount of sleep, in hours   sleep_rem
rem sleep, in hours   sleep_cycle
length of sleep cycle, in hours   awake
amount of time spent awake, in hours   brainwt
brain weight in kilograms   bodywt
body weight in kilograms     Details  
Additional variables order, conservation status and vore were added from wikipedia."
"ggplot2-presidential","ggplot2","presidential","Terms of 11 presidents from Eisenhower to Obama",11,4,1,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/presidential.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/presidential.html","presidential R Documentation   Terms of 11 presidents from Eisenhower to Obama   Description  
The names of each president, the start and end date of their term, and their party of 11 US presidents from Eisenhower to Obama.    Usage    presidential    Format  
A data frame with 11 rows and 4 variables:    name
Last name of president   start
Presidency start date   end
Presidency end date   party
Party of president"
"ggplot2-seals","ggplot2","seals","Vector field of seal movements",1155,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/seals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/seals.html","seals R Documentation   Vector field of seal movements   Description  
This vector field was produced from the data described in Brillinger, D.R., Preisler, H.K., Ager, A.A. and Kie, J.G. ""An exploratory data analysis (EDA) of the paths of moving animals"". J. Statistical Planning and Inference 122 (2004), 43-63, using the methods of Brillinger, D.R., ""Learning a potential function from a trajectory"", Signal Processing Letters. December (2007).    Usage    seals    Format  
A data frame with 1155 rows and 4 variables    References  
https://www.stat.berkeley.edu/~brill/Papers/jspifinal.pdf"
"ggplot2-txhousing","ggplot2","txhousing","Housing sales in TX",8602,9,0,1,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/txhousing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/txhousing.html","txhousing R Documentation   Housing sales in TX   Description  
Information about the housing market in Texas provided by the TAMU real estate center, https://www.recenter.tamu.edu/ .    Usage    txhousing    Format  
A data frame with 8602 observations and 9 variables:    city
Name of multiple listing service (MLS) area   year,month,date
Date   sales
Number of sales   volume
Total value of sales   median
Median sale price   listings
Total active listings   inventory
""Months inventory"": amount of time it would take to sell all current listings at current pace of sales."
"ggplot2movies-movies","ggplot2movies","movies","Movie information and user ratings from IMDB.com.",58788,24,7,2,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2movies/movies.html","movies R Documentation   Movie information and user ratings from IMDB.com.   Description  
The internet movie database, http://imdb.com/ , is a website devoted to collecting movie data supplied by studios and fans. It claims to be the biggest movie database on the web and is run by amazon. More about information imdb.com can be found online,  http://imdb.com/help/show_leaf?about , including information about the data collection process,  http://imdb.com/help/show_leaf?infosource .    Usage    movies    Format  
A data frame with 28819 rows and 24 variables   

title. Title of the movie.   
year. Year of release.   
budget. Total budget (if known) in US dollars   
length. Length in minutes.   
rating. Average IMDB user rating.   
votes. Number of IMDB users who rated this movie.   
r1-10. Multiplying by ten gives percentile (to nearest 10%) of users who rated this movie a 1.   
mpaa. MPAA rating.   
action, animation, comedy, drama, documentary, romance, short. Binary variables representing if movie was classified as belonging to that genre.      Details  
Movies were selected for inclusion if they had a known length and had been rated by at least one imdb user.    References  
http://had.co.nz/data/movies/     Examples    dim(movies) head(movies)"
"gt-countrypops","gt","countrypops","Yearly populations of countries from 1960 to 2017",12470,5,0,3,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/countrypops.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/countrypops.html","countrypops R Documentation   Yearly populations of countries from 1960 to 2017   Description  
A dataset that presents yearly, total populations of countries. Total population is based on counts of all residents regardless of legal status or citizenship. Country identifiers include the English-language country names, and the 2- and 3-letter ISO 3166-1 country codes. Each row contains a  population value for a given year (from 1960 to 2017). Any NA values for populations indicate the non-existence of the country during that year.    Usage    countrypops    Format  
A tibble with 12470 rows and 5 variables:    country_name
Name of the country   country_code_2
The 2-letter ISO 3166-1 country code   country_code_3
The 3-letter ISO 3166-1 country code   year
The year for the population estimate   population
The population estimate, midway through the year     Function ID  
11-1    Source  
https://data.worldbank.org/indicator/SP.POP.TOTL     See Also  
Other Datasets: exibble ,  gtcars ,  pizzaplace ,  sp500 ,  sza     Examples    # Here is a glimpse at the data # available in `countrypops` dplyr::glimpse(countrypops)"
"gt-exibble","gt","exibble","A toy example tibble for testing with gt: exibble",8,9,1,6,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/exibble.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/exibble.html","exibble R Documentation   A toy example tibble for testing with gt: exibble   Description  
This tibble contains data of a few different classes, which makes it well-suited for quick experimentation with the functions in this package. It contains only eight rows with numeric, character, and factor columns. The last 4 rows contain NA values in the majority of this tibble's columns (1 missing value per column). The date , time , and datetime columns are character-based dates/times in the familiar ISO 8601 format. The row and  group columns provide for unique rownames and two groups ( grp_a and  grp_b ) for experimenting with the gt() function's rowname_col and  groupname_col arguments.    Usage    exibble    Format  
A tibble with 8 rows and 9 variables:    num
a numeric column ordered with increasingly larger values   char
a character column composed of names of fruits from a to  h   fctr
a factor column with numbers from 1 to 8, written out   date, time, datetime
character columns with dates, times, and datetimes   currency
a numeric column that is useful for testing currency-based formatting   row
a character column in the format row_X which can be useful for testing with row captions in a table stub   group
a character column with four grp_a values and four  grp_b values which can be useful for testing tables that contain row groups     Function ID  
11-6    See Also  
Other Datasets: countrypops ,  gtcars ,  pizzaplace ,  sp500 ,  sza     Examples    # Here is a glimpse at the data # available in `exibble` dplyr::glimpse(exibble)"
"gt-gtcars","gt","gtcars","Deluxe automobiles from the 2014-2017 period",47,15,1,7,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/gtcars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/gtcars.html","gtcars R Documentation   Deluxe automobiles from the 2014-2017 period   Description  
Expensive and fast cars. Not your father's mtcars . Each row describes a car of a certain make, model, year, and trim. Basic specifications such as horsepower, torque, EPA MPG ratings, type of drivetrain, and transmission characteristics are provided. The country of origin for the car manufacturer is also given.    Usage    gtcars    Format  
A tibble with 47 rows and 15 variables:    mfr
The name of the car manufacturer   model
The car's model name   year
The car's model year   trim
A short description of the car model's trim   bdy_style
An identifier of the car's body style, which is either  coupe , convertible , sedan , or hatchback   hp, hp_rpm
The car's horsepower and the associated RPM level   trq, trq_rpm
The car's torque and the associated RPM level   mpg_c, mpg_h
The miles per gallon fuel efficiency rating for city and highway driving   drivetrain
The car's drivetrain which, for this dataset is either  rwd (Rear Wheel Drive) or awd (All Wheel Drive)   trsmn
The codified transmission type, where the number part is the number of gears; the car could have automatic transmission ( a ), manual transmission ( m ), an option to switch between both types ( am ), or, direct drive ( dd )   ctry_origin
The country name for where the vehicle manufacturer is headquartered     Details  
All of the gtcars have something else in common (aside from the high asking prices): they are all grand tourer vehicles. These are proper GT cars that blend pure driving thrills with a level of comfort that is more expected from a fine limousine (e.g., a Rolls-Royce Phantom EWB). You'll find that, with these cars, comfort is emphasized over all-out performance. Nevertheless, the driving experience should also mean motoring at speed, doing so in style and safety.    Function ID  
11-3    See Also  
Other Datasets: countrypops ,  exibble ,  pizzaplace ,  sp500 ,  sza     Examples    # Here is a glimpse at the data # available in `gtcars` dplyr::glimpse(gtcars)"
"gt-pizzaplace","gt","pizzaplace","A year of pizza sales from a pizza place",49574,7,0,6,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/pizzaplace.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/pizzaplace.html","pizzaplace R Documentation   A year of pizza sales from a pizza place   Description  
A synthetic dataset that describes pizza sales for a pizza place somewhere in the US. While the contents are artificial, the ingredients used to make the pizzas are far from it. There are 32 different pizzas that fall into 4 different categories: classic (classic pizzas: 'You probably had one like it before, but never like this!'), chicken (pizzas with chicken as a major ingredient: 'Try the Southwest Chicken Pizza! You'll love it!'), supreme  (pizzas that try a little harder: 'My Soppressata pizza uses only the finest salami from my personal salumist!'), and, veggie (pizzas without any meats whatsoever: 'My Five Cheese pizza has so many cheeses, I can only offer it in Large Size!').    Usage    pizzaplace    Format  
A tibble with 49574 rows and 7 variables:    id
The ID for the order, which consists of one or more pizzas at a give date and time   date
A character representation of the order date, expressed in the ISO 8601 date format (YYYY-MM-DD)   time
A character representation of the order time, expressed as a 24-hour time the ISO 8601 extended time format (hh:mm:ss)   name
The short name for the pizza   size
The size of the pizza, which can either be S ,  M , L , XL (rare!), or XXL (even rarer!); most pizzas are available in the S , M , and L sizes but exceptions apply   type
The category or type of pizza, which can either be  classic , chicken , supreme , or veggie   price
The price of the pizza and the amount that it sold for (in USD)     Details  
Each pizza in the dataset is identified by a short name . The following listings provide the full names of each pizza and their main ingredients.   
Classic Pizzas:   

classic_dlx : The Classic Deluxe Pizza (Pepperoni, Mushrooms, Red Onions, Red Peppers, Bacon)   
big_meat : The Big Meat Pizza (Bacon, Pepperoni, Italian Sausage, Chorizo Sausage)   
pepperoni : The Pepperoni Pizza (Mozzarella Cheese, Pepperoni)   
hawaiian : The Hawaiian Pizza (Sliced Ham, Pineapple, Mozzarella Cheese)   
pep_msh_pep : The Pepperoni, Mushroom, and Peppers Pizza (Pepperoni, Mushrooms, and Green Peppers)   
ital_cpcllo : The Italian Capocollo Pizza (Capocollo, Red Peppers, Tomatoes, Goat Cheese, Garlic, Oregano)   
napolitana : The Napolitana Pizza (Tomatoes, Anchovies, Green Olives, Red Onions, Garlic)   
the_greek : The Greek Pizza (Kalamata Olives, Feta Cheese, Tomatoes, Garlic, Beef Chuck Roast, Red Onions)     
Chicken Pizzas:   

thai_ckn : The Thai Chicken Pizza (Chicken, Pineapple, Tomatoes, Red Peppers, Thai Sweet Chilli Sauce)   
bbq_ckn : The Barbecue Chicken Pizza (Barbecued Chicken, Red Peppers, Green Peppers, Tomatoes, Red Onions, Barbecue Sauce)   
southw_ckn : The Southwest Chicken Pizza (Chicken, Tomatoes, Red Peppers, Red Onions, Jalapeno Peppers, Corn, Cilantro, Chipotle Sauce)   
cali_ckn : The California Chicken Pizza (Chicken, Artichoke, Spinach, Garlic, Jalapeno Peppers, Fontina Cheese, Gouda Cheese)   
ckn_pesto : The Chicken Pesto Pizza (Chicken, Tomatoes, Red Peppers, Spinach, Garlic, Pesto Sauce)   
ckn_alfredo : The Chicken Alfredo Pizza (Chicken, Red Onions, Red Peppers, Mushrooms, Asiago Cheese, Alfredo Sauce)     
Supreme Pizzas:   

brie_carre : The Brie Carre Pizza (Brie Carre Cheese, Prosciutto, Caramelized Onions, Pears, Thyme, Garlic)   
calabrese : The Calabrese Pizza (‘Nduja Salami, Pancetta, Tomatoes, Red Onions, Friggitello Peppers, Garlic)   
soppressata : The Soppressata Pizza (Soppressata Salami, Fontina Cheese, Mozzarella Cheese, Mushrooms, Garlic)   
sicilian : The Sicilian Pizza (Coarse Sicilian Salami, Tomatoes, Green Olives, Luganega Sausage, Onions, Garlic)   
ital_supr : The Italian Supreme Pizza (Calabrese Salami, Capocollo, Tomatoes, Red Onions, Green Olives, Garlic)   
peppr_salami : The Pepper Salami Pizza (Genoa Salami, Capocollo, Pepperoni, Tomatoes, Asiago Cheese, Garlic)   
prsc_argla : The Prosciutto and Arugula Pizza (Prosciutto di San Daniele, Arugula, Mozzarella Cheese)   
spinach_supr : The Spinach Supreme Pizza (Spinach, Red Onions, Pepperoni, Tomatoes, Artichokes, Kalamata Olives, Garlic, Asiago Cheese)   
spicy_ital : The Spicy Italian Pizza (Capocollo, Tomatoes, Goat Cheese, Artichokes, Peperoncini verdi, Garlic)     
Vegetable Pizzas   

mexicana : The Mexicana Pizza (Tomatoes, Red Peppers, Jalapeno Peppers, Red Onions, Cilantro, Corn, Chipotle Sauce, Garlic)   
four_cheese : The Four Cheese Pizza (Ricotta Cheese, Gorgonzola Piccante Cheese, Mozzarella Cheese, Parmigiano Reggiano Cheese, Garlic)   
five_cheese : The Five Cheese Pizza (Mozzarella Cheese, Provolone Cheese, Smoked Gouda Cheese, Romano Cheese, Blue Cheese, Garlic)   
spin_pesto : The Spinach Pesto Pizza (Spinach, Artichokes, Tomatoes, Sun-dried Tomatoes, Garlic, Pesto Sauce)   
veggie_veg : The Vegetables + Vegetables Pizza (Mushrooms, Tomatoes, Red Peppers, Green Peppers, Red Onions, Zucchini, Spinach, Garlic)   
green_garden : The Green Garden Pizza (Spinach, Mushrooms, Tomatoes, Green Olives, Feta Cheese)   
mediterraneo : The Mediterranean Pizza (Spinach, Artichokes, Kalamata Olives, Sun-dried Tomatoes, Feta Cheese, Plum Tomatoes, Red Onions)   
spinach_fet : The Spinach and Feta Pizza (Spinach, Mushrooms, Red Onions, Feta Cheese, Garlic)   
ital_veggie : The Italian Vegetables Pizza (Eggplant, Artichokes, Tomatoes, Zucchini, Red Peppers, Garlic, Pesto Sauce)      Function ID  
11-5    See Also  
Other Datasets: countrypops ,  exibble ,  gtcars ,  sp500 ,  sza     Examples    # Here is a glimpse at the data # available in `pizzaplace` dplyr::glimpse(pizzaplace)"
"gt-sp500","gt","sp500","Daily S&P 500 Index data from 1950 to 2015",16607,7,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/sp500.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/sp500.html","sp500 R Documentation   Daily S&P 500 Index data from 1950 to 2015   Description  
This dataset provides daily price indicators for the S&P 500 index from the beginning of 1950 to the end of 2015. The index includes 500 leading companies and captures about 80\    Usage    sp500    Format  
A tibble with 16607 rows and 7 variables:    date
The date expressed as Date values   open, high, low, close
The day's opening, high, low, and closing prices in USD; the close price is adjusted for splits   volume
the number of trades for the given date   adj_close
The close price adjusted for both dividends and splits     Function ID  
11-4    See Also  
Other Datasets: countrypops ,  exibble ,  gtcars ,  pizzaplace ,  sza     Examples    # Here is a glimpse at the data # available in `sp500` dplyr::glimpse(sp500)"
"gt-sza","gt","sza","Twice hourly solar zenith angles by month & latitude",816,4,0,1,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/gt/sza.csv","https://vincentarelbundock.github.io/Rdatasets/doc/gt/sza.html","sza R Documentation   Twice hourly solar zenith angles by month & latitude   Description  
This dataset contains solar zenith angles (in degrees, with the range of 0-90) every half hour from 04:00 to 12:00, true solar time. This set of values is calculated on the first of every month for 4 different northern hemisphere latitudes. For determination of afternoon values, the presented tabulated values are symmetric about noon.    Usage    sza    Format  
A tibble with 816 rows and 4 variables:    latitude
The latitude in decimal degrees for the observations   month
The measurement month; all calculations where conducted for the first day of each month   tst
The true solar time at the given latitude and date (first of month ) for which the solar zenith angle is calculated   sza
The solar zenith angle in degrees, where NA s indicate that sunrise hadn't yet occurred by the tst value     Details  
The solar zenith angle (SZA) is one measure that helps to describe the sun's path across the sky. It's defined as the angle of the sun relative to a line perpendicular to the earth's surface. It is useful to calculate the SZA in relation to the true solar time. True solar time relates to the position of the sun with respect to the observer, which is different depending on the exact longitude. For example, two hours before the sun crosses the meridian (the highest point it would reach that day) corresponds to a true solar time of 10 a.m. The SZA has a strong dependence on the observer's latitude. For example, at a latitude of 50 degrees N at the start of January, the noontime SZA is 73.0 but a different observer at 20 degrees N would measure the noontime SZA to be 43.0 degrees.    Function ID  
11-2    Source  
Calculated Actinic Fluxes (290 - 700 nm) for Air Pollution Photochemistry Applications (Peterson, 1976), available at:  https://nepis.epa.gov/Exe/ZyPURL.cgi?Dockey=9100JA26.txt .    See Also  
Other Datasets: countrypops ,  exibble ,  gtcars ,  pizzaplace ,  sp500     Examples    # Here is a glimpse at the data # available in `sza` dplyr::glimpse(sza)"
"HistData-Arbuthnot","HistData","Arbuthnot","Arbuthnot's data on male and female birth ratios in London from 1629-1710.",82,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Arbuthnot.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Arbuthnot.html","Arbuthnot R Documentation    Arbuthnot's data on male and female birth ratios in London from 1629-1710.    Description  
John Arbuthnot (1710) used these time series data on the ratios of male to female christenings in London from 1629-1710 to carry out the first known significance test, comparing observed data to a null hypothesis. The data for these 81 years showed that in every year there were more male than female christenings.   
On the assumption that male and female births were equally likely, he showed that the probability of observing 82 years with more males than females was vanishingly small ( ~ 4.14 x 10^{-25} ). He used this to argue that a nearly constant birth ratio > 1 could be interpreted to show the guiding hand of a devine being. The data set adds variables of deaths from the plague and total mortality obtained by Campbell and from Creighton (1965).    Usage   data(Arbuthnot)   Format  
A data frame with 82 observations on the following 7 variables.    Year
a numeric vector, 1629-1710   Males
a numeric vector, number of male christenings   Females
a numeric vector, number of female christenings   Plague
a numeric vector, number of deaths from plague   Mortality
a numeric vector, total mortality   Ratio
a numeric vector, ratio of Males/Females   Total
a numeric vector, total christenings in London (000s)     Details  
Sandy Zabell (1976) pointed out several errors and inconsistencies in the Arbuthnot data. In particular, the values for 1674 and 1704 are identical, suggesting that the latter were copied erroneously from the former.   
Jim Oeppen <joeppen@health.sdu.dk> points out that: ""Arbuthnot's data are annual counts of public baptisms, not births. Birth-baptism delay meant that infant deaths could occur before baptism. As male infants are more likely to die than females, the sex ratio at baptism might be expected to be lower than the 'normal' male- female birth ratio of 105:100. These effects were not constant as there were trends in birth-baptism delay, and in early infant mortality. In addition, the English Civil War and Commonwealth period 1642-1660 is thought to have been a period of both under-registration and lower fertility, but it is not clear whether these had sex-specific effects.""    Source  
Arbuthnot, John (1710). ""An argument for Devine Providence, taken from the constant Regularity observ'd in the Births of both Sexes,"" Philosophical transactions , 27, 186-190. Published in 1711.    References  
Campbell, R. B., Arbuthnot and the Human Sex Ratio (2001).  Human Biology , 73:4, 605-610.   
Creighton, C. (1965). A History of Epidemics in Britain, 2nd edition, vol. 1 and 2. NY: Barnes and Noble.   
S. Zabell (1976). Arbuthnot, Heberden, and the Bills of Mortality . Technical Report No. 40, Department of Statistics, University of Chicago.    Examples    data(Arbuthnot) # plot the sex ratios with(Arbuthnot, plot(Year,Ratio, type='b', ylim=c(1, 1.20), ylab=""Sex Ratio (M/F)"")) abline(h=1, col=""red"") # add loess smooth Arb.smooth <- with(Arbuthnot, loess.smooth(Year,Ratio)) lines(Arb.smooth$x, Arb.smooth$y, col=""blue"", lwd=2) # plot the total christenings to observe the anomalie in 1704 with(Arbuthnot, plot(Year,Total, type='b', ylab=""Total Christenings""))"
"HistData-Armada","HistData","Armada","La Felicisima Armada",10,11,0,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Armada.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Armada.html","Armada R Documentation    La Felicisima Armada    Description  
The Spanish Armada (Spanish: Grande y Felicissima Armada , literally ""Great and Most Fortunate Navy"") was a Spanish fleet of 130 ships that sailed from La Coruna in August 1588. During its preparation, several accounts of its formidable strength were circulated to reassure allied powers of Spain or to intimidate its enemies. One such account was given by Paz Salas et Alvarez (1588). The intent was bring the forces of Spain to invade England, overthrow Queen Elizabeth I, and re-establish Spanish control of the Netherlands. However the Armada was not as fortunate as hoped: it was all destroyed in one week's fighting.   
de Falguerolles (2008) reports the table given here as Armada  as an early example of data to which multivariate methods might be applied.    Usage   data(""Armada"")   Format  
A data frame with 10 observations on the following 11 variables.    Armada
designation of the fleet, a factor with levels Andalucia Castilla Galeras Guipuscua Napoles Pataches Portugal Uantiscas Vizca Vrcas   ships
number of ships, a numeric vector   tons
total tons, a numeric vector   soldiers
number of soldiers, a numeric vector   sailors
number of sailors, a numeric vector   men
total of soldiers plus sailors, a numeric vector   artillery
a numeric vector   balls
a numeric vector   gunpowder
a numeric vector   lead
a numeric vector   rope
a numeric vector     Details  
Note that men = soldiers + sailors     Source  
de Falguerolles, A. (2008) L'analyse des donnees; before and around.  Journal Electronique d'Histoire des Probabilites et de la Statistique , 4 (2), http://www.jehps.net/Decembre2008/Falguerolles.pdf    References  
Pedro de Paz Salas and Antonio Alvares. La felicisima armada que elrey Don Felipe nuestro Senor mando juntar enel puerto de la ciudad de Lisboa enel Reyno de Portugal. Lisbon, 1588.    Examples    data(Armada) # delete character and redundant variable armada <- Armada[,-c(1,6)] armada.pca <- prcomp(armada, scale.=TRUE) summary(armada.pca) plot(armada.pca, type=""lines"", pch=16, cex=2) biplot(armada.pca)"
"HistData-Bowley","HistData","Bowley","Bowley's data on values of British and Irish trade, 1855-1899",45,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Bowley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Bowley.html","Bowley R Documentation    Bowley's data on values of British and Irish trade, 1855-1899    Description  
In one of the first statistical textbooks, Arthur Bowley (1901) used these data to illustrate an arithmetic and graphical analysis of time-series data using the total value of British and Irish exports from 1855-1899. He presented a line graph of the time-series data, supplemented by overlaid line graphs of 3-, 5- and 10-year moving averages. His goal was to show that while the initial series showed wide variability, moving averages made the series progressively smoother.    Usage   data(Bowley)   Format  
A data frame with 45 observations on the following 2 variables.    Year
Year, from 1855-1899   Value
total value of British and Irish exports (millions of Pounds)     Source  
Bowley, A. L. (1901). Elements of Statistics . London: P. S. King and Son, p. 151-154.   
Digitized from Bowley's graph.    Examples    data(Bowley) # plot the data with(Bowley,plot(Year, Value, type='b', lwd=2, ylab=""Value of British and Irish Exports"", main=""Bowley's example of the method of smoothing curves"")) # find moving averages-- use center alignment (requires width=ODD) #require(gtools, warn.conflicts=FALSE) # simpler version using stats::filter running <- function(x, width = 5){as.vector(stats::filter(x, rep(1 / width, width), sides = 2))} mav3<-running(Bowley$Value, width=3) mav5<-running(Bowley$Value, width=5) mav9<-running(Bowley$Value, width=9) lines(Bowley$Year, mav3, col='blue', lty=2) lines(Bowley$Year, mav5, col='green3', lty=3) lines(Bowley$Year, mav9, col='brown', lty=4) # add lowess smooth lines(lowess(Bowley), col='red', lwd=2) if(require(""ggplot2"", quietly=TRUE)) { ggplot(aes(x=Year, y=Value), data=Bowley) + geom_point() + geom_smooth(method=""loess"", formula=y~x) }"
"HistData-Cavendish","HistData","Cavendish","Cavendish's Determinations of the Density of the Earth",29,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Cavendish.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Cavendish.html","Cavendish R Documentation    Cavendish's Determinations of the Density of the Earth    Description  
Henry Cavendish carried out a series of experiments in 1798 to determine the mean density of the earth, as an indirect means to calculate the gravitational constant, G, in Newton's formula for the force (f) of gravitational attraction,  f = G m M / r^2  between two bodies of mass m and M.   
Stigler (1977) used these data to illustrate properties of robust estimators with real, historical data. For these data sets, he found that trimmed means performed as well or better than more elaborate robust estimators.    Usage   data(Cavendish)   Format  
A data frame with 29 observations on the following 3 variables.    density
Cavendish's 29 determinations of the mean density of the earth   density2
same as density , with the third value (4.88) replaced by 5.88   density3
same as density , omitting the the first 6 observations     Details  
Density values (D) of the earth are given as relative to that of water. If the earth is regarded as a sphere of radius R, Newton's law can be expressed as  G D = 3 g / (4 π R) , where g=9.806 m/s^2 is the acceleration due to gravity; so G is proportional to 1/D.   
density contains Cavendish's measurements as analyzed, where he treated the value 4.88 as if it were 5.88. density2 corrects this. Cavendish also changed his experimental apparatus after the sixth determination, using a stiffer wire in the torsion balance. density3 replaces the first 6 values with NA .   
The modern ""true"" value of D is taken as 5.517. The gravitational constant can be expressed as G = 6.674 * 10^-11 m^3/kg/s^2 .    Source  
Kyle Siegrist, ""Virtual Laboratories in Probability and Statistics"", http://www.math.uah.edu/stat/data/Cavendish.html    
Stephen M. Stigler (1977), ""Do robust estimators work with real data?"", Annals of Statistics , 5, 1055-1098    References  
Cavendish, H. (1798). Experiments to determine the density of the earth.  Philosophical Transactions of the Royal Society of London , 88 (Part II), 469-527. Reprinted in A. S. Mackenzie (ed.), The Laws of Gravitation , 1900, New York: American.   
Brownlee, K. A. (1965). Statistical theory and methodology in science and engineering , NY: Wiley, p. 520.    Examples    data(Cavendish) summary(Cavendish) boxplot(Cavendish, ylab='Density', xlab='Data set') abline(h=5.517, col=""red"", lwd=2) # trimmed means sapply(Cavendish, mean, trim=.1, na.rm=TRUE) # express in terms of G G <- function(D, g=9.806, R=6371) 3*g / (4 * pi * R * D) boxplot(10^5 * G(Cavendish), ylab='~ Gravitational constant (G)', xlab='Data set') abline(h=10^5 * G(5.517), col=""red"", lwd=2)"
"HistData-ChestSizes","HistData","ChestSizes","Chest measurements of Scottish Militiamen",16,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/ChestSizes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/ChestSizes.html","ChestSizes R Documentation    Chest measurements of Scottish Militiamen    Description  
Quetelet's data on chest measurements of 5738 Scottish Militiamen. Quetelet (1846) used this data as a demonstration of the normal distribution of physical characteristics and the concept of l'homme moyen .   
Stigler (1986) compared this table to the original 1817 source, and discovered some transcription errors, which he corrected (p. 208). These data are given separately in  ChestStigler . Gallagher (2020) used these data sets to re-consider the question of normality in these distributions.    Usage   data(ChestSizes)   Format  
A data frame with 16 observations on the following 2 variables. Total count=5738.    chest
Chest size (in inches)   count
Number of soldiers with this chest size     Source  
Velleman, P. F. and Hoaglin, D. C. (1981). Applications, Basics, and Computing of Exploratory Data Analysis . Belmont. CA: Wadsworth. Retrieved from Statlib: https://www.stat.cmu.edu/StatDat/Datafiles/MilitiamenChests.html     References  
A. Quetelet, Lettres a S.A.R. le Duc Regnant de Saxe-Cobourg et Gotha, sur la Theorie des Probabilites, Appliquee aux Sciences Morales et Politiques . Brussels: M. Hayes, 1846, p. 400.   
Eugene D. Gallagher (2020). Was Quetelet's Average Man Normal?, The American Statistician , 74:3, 301-306, DOI: 10.1080/00031305.2019.1706635  
Stephen M. Stigler (1986). The History of Statistics: The Measurement of Uncertainty before 1900 . Cambridge, MA: Harvard University Press, 1986, p. 208.    Examples    data(ChestSizes) # frequency polygon plot(ChestSizes, type='b') # barplot barplot(ChestSizes[,2], ylab=""Frequency"", xlab=""Chest size"") # calculate expected frequencies under normality, chest ~ N(xbar, std) n_obs <- sum(ChestSizes$count) xbar <- with(ChestSizes, weighted.mean(chest, count)) std <- with(ChestSizes, sd(rep(chest, count))) expected <- with(ChestSizes, diff(pnorm(c(32, chest) + .5, xbar, std)) * sum(count))"
"HistData-ChestStigler","HistData","ChestStigler","Chest measurements of Scottish Militiamen",16,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/ChestStigler.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/ChestStigler.html","ChestSizes R Documentation    Chest measurements of Scottish Militiamen    Description  
Quetelet's data on chest measurements of 5738 Scottish Militiamen. Quetelet (1846) used this data as a demonstration of the normal distribution of physical characteristics and the concept of l'homme moyen .   
Stigler (1986) compared this table to the original 1817 source, and discovered some transcription errors, which he corrected (p. 208). These data are given separately in  ChestStigler . Gallagher (2020) used these data sets to re-consider the question of normality in these distributions.    Usage   data(ChestSizes)   Format  
A data frame with 16 observations on the following 2 variables. Total count=5738.    chest
Chest size (in inches)   count
Number of soldiers with this chest size     Source  
Velleman, P. F. and Hoaglin, D. C. (1981). Applications, Basics, and Computing of Exploratory Data Analysis . Belmont. CA: Wadsworth. Retrieved from Statlib: https://www.stat.cmu.edu/StatDat/Datafiles/MilitiamenChests.html     References  
A. Quetelet, Lettres a S.A.R. le Duc Regnant de Saxe-Cobourg et Gotha, sur la Theorie des Probabilites, Appliquee aux Sciences Morales et Politiques . Brussels: M. Hayes, 1846, p. 400.   
Eugene D. Gallagher (2020). Was Quetelet's Average Man Normal?, The American Statistician , 74:3, 301-306, DOI: 10.1080/00031305.2019.1706635  
Stephen M. Stigler (1986). The History of Statistics: The Measurement of Uncertainty before 1900 . Cambridge, MA: Harvard University Press, 1986, p. 208.    Examples    data(ChestSizes) # frequency polygon plot(ChestSizes, type='b') # barplot barplot(ChestSizes[,2], ylab=""Frequency"", xlab=""Chest size"") # calculate expected frequencies under normality, chest ~ N(xbar, std) n_obs <- sum(ChestSizes$count) xbar <- with(ChestSizes, weighted.mean(chest, count)) std <- with(ChestSizes, sd(rep(chest, count))) expected <- with(ChestSizes, diff(pnorm(c(32, chest) + .5, xbar, std)) * sum(count))"
"HistData-Cholera","HistData","Cholera","William Farr's Data on Cholera in London, 1849",38,15,0,1,2,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Cholera.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Cholera.html","Cholera R Documentation    William Farr's Data on Cholera in London, 1849    Description  
In 1852, William Farr, published a report of the Registrar-General on mortality due to cholera in England in the years 1848-1849, during which there was a large epidemic throughout the country. Farr initially believed that cholera arose from bad air (""miasma"") associated with low elevation above the River Thames. John Snow (1855) later showed that the disease was principally spread by contaminated water.   
This data set comes from a paper by Brigham et al. (2003) that analyses some tables from Farr's report to examine the prevalence of death from cholera in the districts of London in relation to the available predictors from Farr's table.    Usage   data(""Cholera"")   Format  
A data frame with 38 observations on the following 15 variables.    district
name of the district in London, a character vector   cholera_drate
deaths from cholera in 1849 per 10,000 inhabitants, a numeric vector   cholera_deaths
number of deaths registered from cholera in 1849, a numeric vector   popn
population, in the middle of 1849, a numeric vector   elevation
elevation, in feet above the high water mark, a numeric vector   region
a grouping of the London districts, a factor with levels West North Central South Kent   water
water supply region, a factor with levels Battersea New River Kew ; see Details   annual_deaths
annual deaths from all causes, 1838-1844, a numeric vector   pop_dens
population density (persons per acre), a numeric vector   persons_house
persons per inhabited house, a numeric vector   house_valpp
average annual value of house, per person (pounds), a numeric vector   poor_rate
poor rate precept per pound of house value, a numeric vector   area
district area, a numeric vector   houses
number of houses, a numeric vector   house_val
total house values, a numeric vector     Details  
The supply of water was classified as “Thames, between Battersea and Waterloo Bridges” (central London), “New River, Rivers Lea and Ravensbourne”, and “Thames, at Kew and Hammersmith” (western London). The factor levels use abbreviations for these.   
The data frame is sorted by increasing elevation above the high water mark.    Source  
Bingham P., Verlander, N. Q., Cheal M. J. (2004). John Snow, William Farr and the 1849 outbreak of cholera that affected London: a reworking of the data highlights the importance of the water supply.  Public Health , 118(6), 387-394, Table 2. (The data was kindly supplied by Neville Verlander, including additional variables not shown in their Table 2.)    References  
Registrar-General (1852). Report on the Mortality of Cholera in England 1848-49 , W. Clowes and Sons, for Her Majesty's Stationary Office. Written by William Farr.  https://ia800309.us.archive.org/22/items/b24751297/b24751297.pdf  The relevant tables are at pages clii – clvii.    See Also  
Snow.deaths   Examples    data(Cholera) # plot cholera deaths vs. elevation plot(cholera_drate ~ elevation, data=Cholera, pch=16, cex.lab=1.2, cex=1.2, xlab=""Elevation above high water mark (ft)"", ylab=""Deaths from cholera in 1849 per 10,000"") # Farr's mortality ~ 1/ elevation law elev <- c(0, 10, 30, 50, 70, 90, 100, 350) mort <- c(174, 99, 53, 34, 27, 22, 20, 6) lines(mort ~ elev, lwd=2, col=""blue"") # better plots, using car::scatterplot if(require(""car"", quietly=TRUE)) { # show separate regression lines for each water supply scatterplot(cholera_drate ~ elevation | water, data=Cholera, smooth=FALSE, pch=15:17, id=list(n=2, labels=sub("",.*"", """", Cholera$district)), col=c(""red"", ""darkgreen"", ""blue""), legend=list(coords=""topleft"", title=""Water supply""), xlab=""Elevation above high water mark (ft)"", ylab=""Deaths from cholera in 1849 per 10,000"") scatterplot(cholera_drate ~ poor_rate | water, data=Cholera, smooth=FALSE, pch=15:17, id=list(n=2, labels=sub("",.*"", """", Cholera$district)), col=c(""red"", ""darkgreen"", ""blue""), legend=list(coords=""topleft"", title=""Water supply""), xlab=""Poor rate per pound of house value"", ylab=""Deaths from cholera in 1849 per 10,000"") } # fit a logistic regression model a la Bingham etal. fit <- glm( cbind(cholera_deaths, popn) ~ water + elevation + poor_rate + annual_deaths + pop_dens + persons_house, data=Cholera, family=binomial) summary(fit) # odds ratios cbind( OR = exp(coef(fit))[-1], exp(confint(fit))[-1,] ) if (require(effects)) { eff <- allEffects(fit) plot(eff) }"
"HistData-CushnyPeebles","HistData","CushnyPeebles","Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives",11,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/CushnyPeebles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/CushnyPeebles.html","CushnyPeebles R Documentation    Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives    Description  
Cushny and Peebles (1905) studied the effects of hydrobromides related to scopolamine and atropine in producing sleep. The sleep of mental patients was measured without hypnotic ( Control ) and after treatment with one of three drugs: L. hyoscyamine hydrobromide ( L_hyoscyamine ), L. hyoscine hydrobromide ( L_hyoscyine ), and a mixture (racemic) form, DL_hyoscine , called atropine. The L (levo) and D (detro) form of a given molecule are optical isomers (mirror images).   
The drugs were given on alternate evenings, and the hours of sleep were compared with the intervening control night. Each of the drugs was tested in this manner a varying number of times in each subject. The average number of hours of sleep for each treatment is the response.   
Student (1908) used these data to illustrate the paired-sample t-test in small samples, testing the hypothesis that the mean difference between a given drug and the control condition was zero. This data set became well known when used by Fisher (1925). Both Student and Fisher had problems labeling the drugs correctly (see Senn & Richardson (1994)), and consequently came to wrong conclusions.   
But as well, the sample sizes (number of nights) for each mean differed widely, ranging from 3-9, and this was not taken into account in their analyses. To allow weighted analyses, the number of observations for each mean is contained in the data frame CushnyPeeblesN .    Usage    data(CushnyPeebles) data(CushnyPeeblesN)    Format  
CushnyPeebles : A data frame with 11 observations on the following 4 variables.    Control
a numeric vector: mean hours of sleep   L_hyoscyamine
a numeric vector: mean hours of sleep   L_hyoscine
a numeric vector: mean hours of sleep   D_hyoscine
a numeric vector: mean hours of sleep    
CushnyPeeblesN : A data frame with 11 observations on the following 4 variables.    Control
a numeric vector: number of observations   L_hyoscyamine
a numeric vector: number of observations   L_hyoscine
a numeric vector: number of observations   DL_hyoscine
a numeric vector: number of observations     Details  
The last patient (11) has no Control observations, and so is often excluded in analyses or other versions of this data set.    Source  
Cushny, A. R., and Peebles, A. R. (1905), ""The Action of Optical Isomers. II: Hyoscines,"" Journal of Physiology , 32, 501-510.    References  
Fisher, R. A. (1925), Statistical Methods for Research Workers , Edinburgh and London: Oliver & Boyd.   
Student (1908), ""The Probable Error of a Mean,"" Biometrika , 6, 1-25.   
Senn, S.J. and Richardson, W. (1994), ""The first t-test"", Statistics in Medicine , 13, 785-803.    See Also  
sleep for an alternative form of this data set.    Examples    data(CushnyPeebles) # quick looks at the data plot(CushnyPeebles) boxplot(CushnyPeebles, ylab=""Hours of Sleep"", xlab=""Treatment"") ########################## # Repeated measures MANOVA CPmod <- lm(cbind(Control, L_hyoscyamine, L_hyoscine, DL_hyoscine) ~ 1, data=CushnyPeebles) # Assign within-S factor and contrasts Treatment <- factor(colnames(CushnyPeebles), levels=colnames(CushnyPeebles)) contrasts(Treatment) <- matrix( c(-3, 1, 1, 1, 0,-2, 1, 1, 0, 0,-1, 1), ncol=3) colnames(contrasts(Treatment)) <- c(""Control.Drug"", ""L.DL"", ""L_hy.DL_hy"") Treats <- data.frame(Treatment) if (require(car)) { (CPaov <- Anova(CPmod, idata=Treats, idesign= ~Treatment)) } summary(CPaov, univariate=FALSE) if (require(heplots)) { heplot(CPmod, idata=Treats, idesign= ~Treatment, iterm=""Treatment"", xlab=""Control vs Drugs"", ylab=""L vs DL drug"") pairs(CPmod, idata=Treats, idesign= ~Treatment, iterm=""Treatment"") } ################################ # reshape to long format, add Ns CPlong <- stack(CushnyPeebles)[,2:1] colnames(CPlong) <- c(""treatment"", ""sleep"") CPN <- stack(CushnyPeeblesN) CPlong <- data.frame(patient=rep(1:11,4), CPlong, n=CPN$values) str(CPlong)"
"HistData-CushnyPeeblesN","HistData","CushnyPeeblesN","Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives",11,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/CushnyPeeblesN.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/CushnyPeeblesN.html","CushnyPeebles R Documentation    Cushny-Peebles Data: Soporific Effects of Scopolamine Derivatives    Description  
Cushny and Peebles (1905) studied the effects of hydrobromides related to scopolamine and atropine in producing sleep. The sleep of mental patients was measured without hypnotic ( Control ) and after treatment with one of three drugs: L. hyoscyamine hydrobromide ( L_hyoscyamine ), L. hyoscine hydrobromide ( L_hyoscyine ), and a mixture (racemic) form, DL_hyoscine , called atropine. The L (levo) and D (detro) form of a given molecule are optical isomers (mirror images).   
The drugs were given on alternate evenings, and the hours of sleep were compared with the intervening control night. Each of the drugs was tested in this manner a varying number of times in each subject. The average number of hours of sleep for each treatment is the response.   
Student (1908) used these data to illustrate the paired-sample t-test in small samples, testing the hypothesis that the mean difference between a given drug and the control condition was zero. This data set became well known when used by Fisher (1925). Both Student and Fisher had problems labeling the drugs correctly (see Senn & Richardson (1994)), and consequently came to wrong conclusions.   
But as well, the sample sizes (number of nights) for each mean differed widely, ranging from 3-9, and this was not taken into account in their analyses. To allow weighted analyses, the number of observations for each mean is contained in the data frame CushnyPeeblesN .    Usage    data(CushnyPeebles) data(CushnyPeeblesN)    Format  
CushnyPeebles : A data frame with 11 observations on the following 4 variables.    Control
a numeric vector: mean hours of sleep   L_hyoscyamine
a numeric vector: mean hours of sleep   L_hyoscine
a numeric vector: mean hours of sleep   D_hyoscine
a numeric vector: mean hours of sleep    
CushnyPeeblesN : A data frame with 11 observations on the following 4 variables.    Control
a numeric vector: number of observations   L_hyoscyamine
a numeric vector: number of observations   L_hyoscine
a numeric vector: number of observations   DL_hyoscine
a numeric vector: number of observations     Details  
The last patient (11) has no Control observations, and so is often excluded in analyses or other versions of this data set.    Source  
Cushny, A. R., and Peebles, A. R. (1905), ""The Action of Optical Isomers. II: Hyoscines,"" Journal of Physiology , 32, 501-510.    References  
Fisher, R. A. (1925), Statistical Methods for Research Workers , Edinburgh and London: Oliver & Boyd.   
Student (1908), ""The Probable Error of a Mean,"" Biometrika , 6, 1-25.   
Senn, S.J. and Richardson, W. (1994), ""The first t-test"", Statistics in Medicine , 13, 785-803.    See Also  
sleep for an alternative form of this data set.    Examples    data(CushnyPeebles) # quick looks at the data plot(CushnyPeebles) boxplot(CushnyPeebles, ylab=""Hours of Sleep"", xlab=""Treatment"") ########################## # Repeated measures MANOVA CPmod <- lm(cbind(Control, L_hyoscyamine, L_hyoscine, DL_hyoscine) ~ 1, data=CushnyPeebles) # Assign within-S factor and contrasts Treatment <- factor(colnames(CushnyPeebles), levels=colnames(CushnyPeebles)) contrasts(Treatment) <- matrix( c(-3, 1, 1, 1, 0,-2, 1, 1, 0, 0,-1, 1), ncol=3) colnames(contrasts(Treatment)) <- c(""Control.Drug"", ""L.DL"", ""L_hy.DL_hy"") Treats <- data.frame(Treatment) if (require(car)) { (CPaov <- Anova(CPmod, idata=Treats, idesign= ~Treatment)) } summary(CPaov, univariate=FALSE) if (require(heplots)) { heplot(CPmod, idata=Treats, idesign= ~Treatment, iterm=""Treatment"", xlab=""Control vs Drugs"", ylab=""L vs DL drug"") pairs(CPmod, idata=Treats, idesign= ~Treatment, iterm=""Treatment"") } ################################ # reshape to long format, add Ns CPlong <- stack(CushnyPeebles)[,2:1] colnames(CPlong) <- c(""treatment"", ""sleep"") CPN <- stack(CushnyPeeblesN) CPlong <- data.frame(patient=rep(1:11,4), CPlong, n=CPN$values) str(CPlong)"
"HistData-Dactyl","HistData","Dactyl","Edgeworth's counts of dactyls in Virgil's Aeneid",60,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Dactyl.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Dactyl.html","Dactyl R Documentation    Edgeworth's counts of dactyls in Virgil's Aeneid    Description  
Edgeworth (1885) took the first 75 lines in Book XI of Virgil's Aeneid and classified each of the first four ""feet"" of the line as a dactyl (one long syllable followed by two short ones) or not.   
Grouping the lines in blocks of five gave a 4 x 25 table of counts, represented here as a data frame with ordered factors, Foot and  Lines . Edgeworth used this table in what was among the first examples of analysis of variance applied to a two-way classification.    Usage   data(Dactyl)   Format  
A data frame with 60 observations on the following 3 variables.    Foot
an ordered factor with levels 1 < 2 < 3 < 4   Lines
an ordered factor with levels 1:5 < 6:10 < 11:15 < 16:20 < 21:25 < 26:30 < 31:35 < 36:40 < 41:45 < 46:50 < 51:55 < 56:60 < 61:65 < 66:70 < 71:75   count
number of dactyls     Source  
Stigler, S. (1999)  Statistics on the Table  Cambridge, MA: Harvard University Press, table 5.1.    References  
Edgeworth, F. Y. (1885). On methods of ascertaining variations in the rate of births, deaths and marriages.  Journal of the [Royal] Statistical Society , 48, 628-649.    Examples    data(Dactyl) # display the basic table xtabs(count ~ Foot+Lines, data=Dactyl) # simple two-way anova anova(dact.lm <- lm(count ~ Foot+Lines, data=Dactyl)) # plot the lm-quartet op <- par(mfrow=c(2,2)) plot(dact.lm) par(op) # show table as a simple mosaicplot mosaicplot(xtabs(count ~ Foot+Lines, data=Dactyl), shade=TRUE)"
"HistData-DrinksWages","HistData","DrinksWages","Elderton and Pearson's (1910) data on drinking and wages",70,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/DrinksWages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/DrinksWages.html","DrinksWages R Documentation    Elderton and Pearson's (1910) data on drinking and wages    Description  
In 1910, Karl Pearson weighed in on the debate, fostered by the temperance movement, on the evils done by alcohol not only to drinkers, but to their families. The report ""A first study of the influence of parental alcoholism on the physique and ability of their offspring"" was an ambitious attempt to the new methods of statistics to bear on an important question of social policy, to see if the hypothesis that children were damaged by parental alcoholism would stand up to statistical scrutiny.   
Working with his assistant, Ethel M. Elderton, Pearson collected voluminous data in Edinburgh and Manchester on many aspects of health, stature, intelligence, etc. of children classified according to the drinking habits of their parents. His conclusions where almost invariably negative: the tendency of parents to drink appeared unrelated to any thing he had measured.   
The firestorm that this report set off is well described by Stigler (1999), Chapter 1. The data set DrinksWages is just one of Pearsons many tables, that he published in a letter to The Times , August 10, 1910.   Usage   data(DrinksWages)   Format  
A data frame with 70 observations on the following 6 variables, giving the number of non-drinkers ( sober ) and drinkers ( drinks ) in various occupational categories ( trade ).    class
wage class: a factor with levels A B C   trade
a factor with levels baker barman billposter ... wellsinker wireworker   sober
the number of non-drinkers, a numeric vector   drinks
the number of drinkers, a numeric vector   wage
weekly wage (in shillings), a numeric vector   n
total number, a numeric vector     Details  
The data give Karl Pearson's tabulation of the father's trades from an Edinburgh sample, classified by whether they drink or are sober, and giving average weekly wage.   
The wages are averages of the individuals' nominal wages. Class A is those with wages under 2.5s.; B: those with wages 2.5s. to 30s.; C: wages over 30s.    Source  
Pearson, K. (1910). The Times , August 10, 1910.   
Stigler, S. M. (1999).  Statistics on the Table: The History of Statistical Concepts and Methods . Harvard University Press, Table 1.1    References  
M. E. Elderton & K. Pearson (1910). A first study of the influence of parental alcoholism on the physique and ability of their offspring, Eugenics Laboratory Memoirs, 10.    Examples    data(DrinksWages) plot(DrinksWages) # plot proportion sober vs. wage | class with(DrinksWages, plot(wage, sober/n, col=c(""blue"",""red"",""green"")[class])) # fit logistic regression model of sober on wage mod.sober <- glm(cbind(sober, n) ~ wage, family=binomial, data=DrinksWages) summary(mod.sober) op <- par(mfrow=c(2,2)) plot(mod.sober) par(op) # TODO: plot fitted model"
"HistData-EdgeworthDeaths","HistData","EdgeworthDeaths","Edgeworth's Data on Death Rates in British Counties",42,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/EdgeworthDeaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/EdgeworthDeaths.html","EdgeworthDeaths R Documentation    Edgeworth's Data on Death Rates in British Counties    Description  
In 1885, Francis Edgeworth published a paper, On methods of ascertaining variations in the rate of births, deaths and marriages . It contained among the first examples of two-way tables, analyzed to show variation among row and column factors, in a way that Fisher would later formulate as the Analysis of Variance.  
Although the data are rates per 1000, they provide a good example of a two-way ANOVA with n=1 per cell, where an additive model fits reasonably well.  
Treated as frequencies, the data is also a good example of a case where the independence model fits reasonably well.    Usage   data(""EdgeworthDeaths"")   Format  
A data frame with 42 observations on the following 3 variables.    County
a factor with levels Berks Herts Bucks Oxford Bedford Cambridge   year
an ordered factor with levels 1876 < 1877 < 1878 < 1879 < 1880 < 1881 < 1882   Freq
a numeric vector, death rate per 1000 population     Details  
Edgeworth's data came from the Registrar General's report for the final year, 1883. The Freq variable represents death rates per 1000 population in the six counties listed.    Source  
The data were scanned from Table 5.2 in Stigler, S. M. (1999) Statistics on the Table: The History of Statistical Concepts and Methods , Harvard University Press.    References  
Edgeworth, F. Y. (1885). On Methods of Ascertaining Variations in the Rate of Births, Deaths, and Marriages. Journal of the Statistical Society of London , 48(4), 628-649. doi:10.2307/2979201    Examples    data(EdgeworthDeaths) # fit the additive ANOVA model library(car) # for Anova() EDmod <- lm(Freq ~ County + year, data=EdgeworthDeaths) Anova(EDmod) # now, consider as a two-way table of frequencies library(vcd) library(MASS) structable( ~ County + year, data=EdgeworthDeaths) loglm( Freq ~ County + year, data=EdgeworthDeaths) mosaic( ~ County + year, data=EdgeworthDeaths, shade=TRUE, legend=FALSE, labeling=labeling_values, gp=shading_Friendly)"
"HistData-Fingerprints","HistData","Fingerprints","Waite's data on Patterns in Fingerprints",36,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Fingerprints.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Fingerprints.html","Fingerprints R Documentation    Waite's data on Patterns in Fingerprints    Description  
Waite (1915) was interested in analyzing the association of patterns in fingerprints, and produced a table of counts for 2000 right hands, classified by the number of fingers describable as a ""whorl"", a ""small loop"" (or neither). Because each hand contributes five fingers, the number of Whorls + Loops cannot exceed 5, so the contingency table is necessarily triangular.   
Karl Pearson (1904) introduced the test for independence in contingency tables, and by 1913 had developed methods for ""restricted contingency tables,"" such as the triangular table analyzed by Waite. The general formulation of such tests for association in restricted tables is now referred to as models for quasi-independence.    Usage   data(Fingerprints)   Format  
A frequency data frame with 36 observations on the following 3 variables, representing a 6 x 6 table giving the cross-classification of the fingers on 2000 right hands as a whorl, small loop or neither.    Whorls
Number of whorls, an ordered factor with levels 0 < 1 < 2 < 3 < 4 < 5   Loops
Number of small loops, an ordered factor with levels 0 < 1 < 2 < 3 < 4 < 5   count
Number of hands     Details  
Cells for which Whorls + Loops>5 have NA for count     Source  
Stigler, S. M. (1999).  Statistics on the Table . Cambridge, MA: Harvard University Press, table 19.4.    References  
Pearson, K. (1904). Mathematical contributions to the theory of evolution. XIII. On the theory of contingency and its relation to association and normal correlation. Reprinted in Karl Pearson's Early Statistical Papers , Cambridge: Cambridge University Press, 1948, 443-475.   
Waite, H. (1915). The analysis of fingerprints, Biometrika , 10, 421-478.    Examples    data(Fingerprints) xtabs(count ~ Whorls + Loops, data=Fingerprints)"
"HistData-Galton","HistData","Galton","Galton's data on the heights of parents and their children",928,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Galton.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Galton.html","Galton R Documentation    Galton's data on the heights of parents and their children    Description  
Galton (1886) presented these data in a table, showing a cross-tabulation of 928 adult children born to 205 fathers and mothers, by their height and their mid-parent's height. He visually smoothed the bivariate frequency distribution and showed that the contours formed concentric and similar ellipses, thus setting the stage for correlation, regression and the bivariate normal distribution.    Usage   data(Galton)   Format  
A data frame with 928 observations on the following 2 variables.    parent
a numeric vector: height of the mid-parent (average of father and mother)   child
a numeric vector: height of the child     Details  
The data are recorded in class intervals of width 1.0 in. He used non-integer values for the center of each class interval because of the strong bias toward integral inches.   
All of the heights of female children were multiplied by 1.08 before tabulation to compensate for sex differences. See Hanley (2004) for a reanalysis of Galton's raw data questioning whether this was appropriate.    Source  
Galton, F. (1886). Regression Towards Mediocrity in Hereditary Stature  Journal of the Anthropological Institute , 15, 246-263    References  
Friendly, M. & Denis, D. (2005). The early origins and development of the scatterplot. Journal of the History of the Behavioral Sciences , 41, 103-130.   
Galton, F. (1869). Hereditary Genius: An Inquiry into its Laws and Consequences . London: Macmillan.   
Hanley, J. A. (2004). ""Transmuting"" Women into Men: Galton's Family Data on Human Stature.  The American Statistician , 58, 237-243. See: http://www.medicine.mcgill.ca/epidemiology/hanley/galton/ for source materials.   
Stigler, S. M. (1986). The History of Statistics: The Measurement of Uncertainty before 1900 . Cambridge, MA: Harvard University Press, Table 8.1   
Wachsmuth, A. W., Wilkinson L., Dallal G. E. (2003). Galton's bend: A previously undiscovered nonlinearity in Galton's family stature regression data. The American Statistician , 57, 190-192. https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf     See Also  
link{GaltonFamilies} ,  PearsonLee ,  galton in the psych    Examples    data(Galton) ########################################################################### # sunflower plot with regression line and data ellipses and lowess smooth ########################################################################### with(Galton, { sunflowerplot(parent,child, xlim=c(62,74), ylim=c(62,74)) reg <- lm(child ~ parent) abline(reg) lines(lowess(parent, child), col=""blue"", lwd=2) if(require(car)) { dataEllipse(parent,child, xlim=c(62,74), ylim=c(62,74), plot.points=FALSE) } })"
"HistData-GaltonFamilies","HistData","GaltonFamilies","Galton's data on the heights of parents and their children, by child",934,8,1,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/GaltonFamilies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/GaltonFamilies.html","GaltonFamilies R Documentation    Galton's data on the heights of parents and their children, by child    Description  
This data set lists the individual observations for 934 children in 205 families on which Galton (1886) based his cross-tabulation.  
In addition to the question of the relation between heights of parents and their offspring, for which this data is mainly famous, Galton had another purpose which the data in this form allows to address: Does marriage selection indicate a relationship between the heights of husbands and wives, a topic he called assortative mating ? Keen [p. 297-298](2010) provides a brief discussion of this topic.    Usage   data(GaltonFamilies)   Format  
A data frame with 934 observations on the following 8 variables.    family
family ID, a factor with levels 001 - 204   father
height of father   mother
height of mother   midparentHeight
mid-parent height, calculated as (father + 1.08*mother)/2   children
number of children in this family   childNum
number of this child within family. Children are listed in decreasing order of height for boys followed by girls   gender
child gender, a factor with levels female male   childHeight
height of child     Details  
Galton's notebook lists 963 children in 205 families ranging from 1-15 adult children children. Of these, 29 had non-numeric heights recorded and are not included here.   
Families are largely listed in descending order of fathers and mothers height.    Source  
Galton's notebook,  http://www.medicine.mcgill.ca/epidemiology/hanley/galton/notebook/ , transcribed by Beverley Shipley in 2001.    References  
Galton, F. (1886). Regression Towards Mediocrity in Hereditary Stature  Journal of the Anthropological Institute , 15, 246-263   
Hanley, J. A. (2004). ""Transmuting"" Women into Men: Galton's Family Data on Human Stature.  The American Statistician , 58, 237-243. See: http://www.medicine.mcgill.ca/epidemiology/hanley/galton/ for source materials.   
Keen, K. J. (2010). Graphics for Statistics and Data Analysis with R , Boca Raton: CRC Press,  https://www.unbc.ca/keen/graphics-for-statistics-and-data-analysis-with-r .   See Also  
Galton ,  PearsonLee     Examples    data(GaltonFamilies) str(GaltonFamilies) ## reproduce Fig 2 in Hanley (2004) library(car) scatterplot(childHeight ~ midparentHeight | gender, data=GaltonFamilies, ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78)) # multiply daughters' heights by 1.08 GF1 <- within(GaltonFamilies, {childHeight <- ifelse (gender==""female"", 1.08*childHeight, childHeight)} ) scatterplot(childHeight ~ midparentHeight | gender, data=GF1, ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78)) # add 5.2 to daughters' heights GF2 <- within(GaltonFamilies, {childHeight <- ifelse (gender==""female"", childHeight+5.2, childHeight)} ) scatterplot(childHeight ~ midparentHeight | gender, data=GF2, ellipse=TRUE, levels=0.68, legend.coords=list(x=64, y=78)) ######################################### # relationship between heights of parents ######################################### Parents <- subset(GaltonFamilies, !duplicated(GaltonFamilies$family)) with(Parents, { sunflowerplot(mother, father, rotate=TRUE, pch=16, xlab=""Mother height"", ylab=""Father height"") dataEllipse(mother, father, add=TRUE, plot.points=FALSE, center.pch=NULL, levels=0.68) abline(lm(father ~ mother), col=""red"", lwd=2) } )"
"HistData-Guerry","HistData","Guerry","Data from A.-M. Guerry, ""Essay on the Moral Statistics of France""",86,23,0,0,3,0,20,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Guerry.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Guerry.html","Guerry R Documentation    Data from A.-M. Guerry, ""Essay on the Moral Statistics of France""    Description  
Andre-Michel Guerry (1833) was the first to systematically collect and analyze social data on such things as crime, literacy and suicide with the view to determining social laws and the relations among these variables.   
The Guerry data frame comprises a collection of 'moral variables' on the 86 departments of France around 1830. A few additional variables have been added from other sources.    Usage   data(Guerry)   Format  
A data frame with 86 observations (the departments of France) on the following 23 variables.    dept
Department ID: Standard numbers for the departments, except for Corsica (200)   Region
Region of France ('N'='North', 'S'='South', 'E'='East', 'W'='West', 'C'='Central'). Corsica is coded as NA   Department
Department name: Departments are named according to usage in 1830, but without accents. A factor with levels Ain Aisne Allier ... Vosges Yonne   Crime_pers
Population per Crime against persons. Source: A2 (Compte general, 1825-1830)   Crime_prop
Population per Crime against property. Source: A2 (Compte general, 1825-1830)   Literacy
Percent Read & Write: Percent of military conscripts who can read and write. Source: A2   Donations
Donations to the poor. Source: A2 (Bulletin des lois)   Infants
Population per illegitimate birth. Source: A2 (Bureau des Longitudes, 1817-1821)   Suicides
Population per suicide. Source: A2 (Compte general, 1827-1830)   MainCity
Size of principal city ('1:Sm', '2:Med', '3:Lg'), used as a surrogate for population density. Large refers to the top 10, small to the bottom 10; all the rest are classed Medium. Source: A1. An ordered factor with levels 1:Sm < 2:Med < 3:Lg   Wealth
Per capita tax on personal property. A ranked index based on taxes on personal and movable property per inhabitant. Source: A1   Commerce
Commerce and Industry, measured by the rank of the number of patents / population. Source: A1   Clergy
Distribution of clergy, measured by the rank of the number of Catholic priests in active service / population. Source: A1 (Almanach officiel du clergy, 1829)   Crime_parents
Crimes against parents, measured by the rank of the ratio of crimes against parents to all crimes– Average for the years 1825-1830. Source: A1 (Compte general)   Infanticide
Infanticides per capita. A ranked ratio of number of infanticides to population– Average for the years 1825-1830. Source: A1 (Compte general)   Donation_clergy
Donations to the clergy. A ranked ratio of the number of bequests and donations inter vivios to population– Average for the years 1815-1824. Source: A1 (Bull. des lois, ordunn. d'autorisation)   Lottery
Per capita wager on Royal Lottery. Ranked ratio of the proceeds bet on the royal lottery to population— Average for the years 1822-1826. Source: A1 (Compte rendus par le ministre des finances)   Desertion
Military desertion, ratio of the number of young soldiers accused of desertion to the force of the military contingent, minus the deficit produced by the insufficiency of available billets– Average of the years 1825-1827. Source: A1 (Compte du ministere du guerre, 1829 etat V)   Instruction
Instruction. Ranks recorded from Guerry's map of Instruction. Note: this is inversely related to Literacy (as defined here)   Prostitutes
Prostitutes in Paris. Number of prostitutes registered in Paris from 1816 to 1834, classified by the department of their birth Source: Parent-Duchatelet (1836), De la prostitution en Paris   Distance
Distance to Paris (km). Distance of each department centroid to the centroid of the Seine (Paris) Source: calculated from department centroids   Area
Area (1000 km^2). Source: Angeville (1836)   Pop1831
1831 population. Population in 1831, taken from Angeville (1836), Essai sur la Statistique de la Population fran?ais , in 1000s     Details  
Note that most of the variables (e.g., Crime_pers ) are scaled so that 'more is better' morally.   
Values for the quantitative variables displayed on Guerry's maps were taken from Table A2 in the English translation of Guerry (1833) by Whitt and Reinking. Values for the ranked variables were taken from Table A1, with some corrections applied. The maximum is indicated by rank 1, and the minimum by rank 86.    Source  
Angeville, A. (1836). Essai sur la Statistique de la Population fran?aise Paris: F. Doufour.   
Guerry, A.-M. (1833). Essai sur la statistique morale de la France Paris: Crochard. English translation: Hugh P. Whitt and Victor W. Reinking, Lewiston, N.Y. : Edwin Mellen Press, 2002.   
Parent-Duchatelet, A. (1836). De la prostitution dans la ville de Paris , 3rd ed, 1857, p. 32, 36    References  
Dray, S. and Jombart, T. (2011). A Revisit Of Guerry's Data: Introducing Spatial Constraints In Multivariate Analysis. The Annals of Applied Statistics , Vol. 5, No. 4, 2278-2299. https://arxiv.org/pdf/1202.6485.pdf , DOI: 10.1214/10-AOAS356.   
Brunsdon, C. and Dykes, J. (2007). Geographically weighted visualization: interactive graphics for scale-varying exploratory analysis. Geographical Information Science Research Conference (GISRUK 07), NUI Maynooth, Ireland, April, 2007.   
Friendly, M. (2007). A.-M. Guerry's Moral Statistics of France: Challenges for Multivariable Spatial Analysis.  Statistical Science , 22, 368-399.   
Friendly, M. (2007). Data from A.-M. Guerry, Essay on the Moral Statistics of France (1833),  http://datavis.ca/gallery/guerry/guerrydat.html .    See Also  
The Guerry package for maps of France: gfrance  and related data.    Examples    data(Guerry) ## maybe str(Guerry) ; plot(Guerry) ..."
"HistData-HalleyLifeTable","HistData","HalleyLifeTable","Halley's Life Table",84,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/HalleyLifeTable.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/HalleyLifeTable.html","HalleyLifeTable R Documentation    Halley's Life Table    Description  
In 1693 the famous English astronomer Edmond Halley studied the birth and death records of the city of Breslau, which had been transmitted to the Royal Society by Caspar Neumann. He produced a life table showing the number of people surviving to any age from a cohort born the same year. He also used his table to compute the price of life annuities.    Usage   data(""HalleyLifeTable"")   Format  
A data frame with 84 observations on the following 4 variables.    age
a numeric vector   deaths
number of deaths, D_k , among people of age k, a numeric vector   number
size of the population, P_k surviving until this age, a numeric vector   ratio
the ratio P_{k+1}/P_k , the conditional probability of surviving until age k + 1 given that one had already reached age k, a numeric vector     Details  
Halley's table contained only age and number . For people aged over 84 years, Halley just noted that their total number was 107. This value is not included in the data set.   
The data from Breslau had a mean of 1,238 births per year: this is the value that Halley took for the size, P_0 of the population cohort at age 0. From the data, he could compute the annual mean  D_k of the number of deaths among people aged k for all k >= 0 . From this, he calculated the number P_{k+1} surviving one more year,   
P_{k+1} = P_k - D_k  
This method had the great advantage of not requiring a general census but only knowledge of the number of births and deaths and of the age at which people died during a few years.    Source  
N. Bacaer (2011), ""Halley's life table (1693)"", Ch 2, pp 5-10. In A Short History of Mathematical Population Dynamics , Springer-Verlag London, DOI 10.1007/978-0-85729-115-8_2. Data taken from Table 1.    References  
Halley, E. (1693). An estimate of the degrees of the mortality of mankind, drawn from curious tables of the births and funerals at the city of Breslau; with an attempt to ascertain the price of annuities upon lives. Philosophical Transactions of the Royal Society, London , 17, 596-610.   
The text of Halley's paper was found at  http://www.pierre-marteau.com/editions/1693-mortality.html     See Also  
Arbuthnot     Examples    data(HalleyLifeTable) # what was the estimated population of Breslau? sum(HalleyLifeTable$number) # plot survival vs. age plot(number ~ age, data=HalleyLifeTable, type=""h"", ylab=""Number surviving"") # population pyramid is transpose of this plot(age ~ number, data=HalleyLifeTable, type=""l"", xlab=""Number surviving"") with(HalleyLifeTable, segments(0, age, number, age, lwd=2)) # conditional probability of survival, one more year plot(ratio ~ age, data=HalleyLifeTable, ylab=""Probability survive one more year"")"
"HistData-Jevons","HistData","Jevons","W. Stanley Jevons' data on numerical discrimination",50,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Jevons.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Jevons.html","Jevons R Documentation    W. Stanley Jevons' data on numerical discrimination    Description  
In a remarkable brief note in Nature , 1871, W. Stanley Jevons described the results of an experiment he had conducted on himself to determine the limits of the number of objects an observer could comprehend immediately without counting them. This was an important philosophical question: How many objects can the mind embrace at once?   
He carried out 1027 trials in which he tossed an ""uncertain number"" of uniform black beans into a box and immediately attempted to estimate the number ""without the least hesitation"". His questions, procedure and analysis anticipated by 75 years one of the most influential papers in modern cognitive psychology by George Miller (1956), ""The magical number 7 plus or minus 2: Some limits on ..."" For Jevons, the magical number was 4.5, representing an empirical law of complete accuracy.    Usage   data(Jevons)   Format  
A frequency data frame with 50 observations on the following 4 variables.    actual
Actual number: a numeric vector   estimated
Estimated number: a numeric vector   frequency
Frequency of this combination of (actual, estimated): a numeric vector   error
actual - estimated : a numeric vector     Details  
The original data were presented in a two-way, 13 x 13 frequency table,  estimated (3:15) x actual (3:15).    Source  
Jevons, W. S. (1871). The Power of Numerical Discrimination, Nature , 1871, III (281-282)    References  
Miller, G. A. (1956). The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information,  Psychological Review , 63, 81-97, http://www.musanim.com/miller1956/     Examples    data(Jevons) # show as tables xtabs(frequency ~ estimated+actual, data=Jevons) xtabs(frequency ~ error+actual, data=Jevons) # show as sunflowerplot with regression line with(Jevons, sunflowerplot(actual, estimated, frequency, main=""Jevons data on numerical estimation"")) Jmod <-lm(estimated ~ actual, data=Jevons, weights=frequency) abline(Jmod) # show as balloonplots if (require(gplots)) { with(Jevons, balloonplot(actual, estimated, frequency, xlab=""actual"", ylab=""estimated"", main=""Jevons data on numerical estimation\nBubble area proportional to frequency"", text.size=0.8)) with(Jevons, balloonplot(actual, error, frequency, xlab=""actual"", ylab=""error"", main=""Jevons data on numerical estimation: Errors\nBubble area proportional to frequency"", text.size=0.8)) } # plot average error if(require(reshape)) { unJevons <- untable(Jevons, Jevons$frequency) str(unJevons) require(plyr) mean_error <- function(df) mean(df$error, na.rm=TRUE) Jmean <- ddply(unJevons, .(actual), mean_error) with(Jmean, plot(actual, V1, ylab='Mean error', xlab='Actual number', type='b', main='Jevons data')) abline(h=0) }"
"HistData-Langren.all","HistData","Langren.all","van Langren's Data on Longitude Distance between Toledo and Rome",61,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Langren.all.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Langren.all.html","Langren R Documentation    van Langren's Data on Longitude Distance between Toledo and Rome    Description  
Michael Florent van Langren (1598-1675) was a Dutch mathematician and astronomer, who served as a royal mathematician to King Phillip IV of Spain, and who worked on one of the most significant problems of his time— the accurate determination of longitude, particularly for navigation at sea.   
In order to convince the Spanish court of the seriousness of the problem (often resulting in great losses through ship wrecks), he prepared a 1-dimensional line graph, showing all the available estimates of the distance in longitude between Toledo and Rome, which showed large errors, for even this modest distance. This 1D line graph, from Langren (1644), is believed to be the first known graph of statistical data (Friendly etal., 2010). It provides a compelling example of the notions of statistical variability and bias.   
The data frame Langren1644 gives the estimates and other information derived from the previously known 1644 graph. It turns out that van Langren produced other versions of this graph, as early as 1628. The data frame Langren.all gives the estimates derived from all known versions of this graph.    Usage    data(Langren1644) data(Langren.all)    Format  
Langren1644 : A data frame with 12 observations on the following 9 variables, giving determinations of the distance in longitude between Toledo and Rome, from the 1644 graph.    Name
The name of the person giving a determination, a factor with levels A. Argelius ... T. Brahe   Longitude
Estimated value of the longitude distance between Toledo and Rome   Year
Year associated with this determination   Longname
A longer version of the Name , where appropriate; a factor with levels Andrea Argoli Christoph Clavius  Tycho Brahe   City
The principal city where this person worked; a factor with levels Alexandria Amsterdam Bamberg Bologna Frankfurt Hven Leuven Middelburg Nuremberg Padua Paris Rome   Country
The country where this person worked; a factor with levels Belgium Denmark Egypt Flanders France Germany Italy Italy   Latitude
Latitude of this City ; a numeric vector   Source
Likely source for this determination of Longitude; a factor with levels Astron Map   Gap
A numeric vector indicating whether the Longitude value is below or above the median    
Langren.all : A data frame with 61 observations on the following 4 variables, giving determinations of Longitude between Toledo and Rome from all known versions of van Langren's graph.    Author
Author of the graph, a factor with levels Langren Lelewel   Year
Year of publication   Name
The name of the person giving a determination, a factor with levels Algunos1 Algunos2  Apianus ... Schonerus   Longitude
Estimated value of the longitude distance between Toledo and Rome     Details  
In all the graphs, Toledo is implicitly at the origin and Rome is located relatively at the value of Longitude To judge correspondence with an actual map, the positions in (lat, long) are   
 toledo <- c(39.86, -4.03); rome <- c(41.89, 12.5)      Source  
The longitude values were digitized from images of the various graphs, which may be found on the Supplementary materials page for Friendly etal. (2009).    References  
Friendly, M., Valero-Mora, P. and Ulargui, J. I. (2010). The First (Known) Statistical Graph: Michael Florent van Langren and the ""Secret"" of Longitude.  The American Statistician , 64 (2), 185-191. Supplementary materials: http://datavis.ca/gallery/langren/ .  
Langren, M. F. van. (1644). La Verdadera Longitud por Mar y Tierra . Antwerp: (n.p.), 1644. English translation available at http://datavis.ca/gallery/langren/verdadera.pdf .   
Lelewel, J. (1851). Geographie du Moyen Age . Paris: Pilliet, 1851.    Examples    data(Langren1644) #################################################### # reproductions of Langren's graph overlaid on a map #################################################### if (require(jpeg, quietly=TRUE)) { gimage <- readJPEG(system.file(""images"", ""google-toledo-rome3.jpg"", package=""HistData"")) # NB: dimensions from readJPEG are y, x, colors gdim <- dim(gimage)[1:2] ylim <- c(1,gdim[1]) xlim <- c(1,gdim[2]) op <- par(bty=""n"", xaxt=""n"", yaxt=""n"", mar=c(2, 1, 1, 1) + 0.1) # NB: necessary to scale the plot to the pixel coordinates, and use asp=1 plot(xlim, ylim, xlim=xlim, ylim=ylim, type=""n"", ann=FALSE, asp=1 ) rasterImage(gimage, 1, 1, gdim[2], gdim[1]) # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner toledo.map <- c(131, 59) rome.map <- c(506, 119) # confirm locations of Toledo and Rome points(rbind(toledo.map, rome.map), cex=2) text(131, 95, ""Toledo"", cex=1.5) text(506, 104, ""Roma"", cex=1.5) # set a scale for translation of lat,long to pixel x,y scale <- data.frame(x=c(131, 856), y=c(52,52)) rownames(scale)=c(0,30) # translate from degrees longitude to pixels xlate <- function(x) { 131+x*726/30 } # draw an axis lines(scale) ticks <- xlate(seq(0,30,5)) segments(ticks, 52, ticks, 45) text(ticks, 40, seq(0,30,5)) text(xlate(8), 17, ""Grados de la Longitud"", cex=1.7) # label the observations with the names points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), pch=25, col=""blue"", bg=""blue"") text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), labels=Langren1644$Name, srt=90, adj=c(-.1, .5), cex=0.8) par(op) } ### Original implementation using ReadImages, now deprecated & shortly to be removed ## Not run: if (require(ReadImages)) { gimage <- read.jpeg(system.file(""images"", ""google-toledo-rome3.jpg"", package=""HistData"")) plot(gimage) # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner toledo.map <- c(130, 59) rome.map <- c(505, 119) # confirm locations of Toledo and Rome points(rbind(toledo.map, rome.map), cex=2) # set a scale for translation of lat,long to pixel x,y scale <- data.frame(x=c(130, 856), y=c(52,52)) rownames(scale)=c(0,30) lines(scale) xlate <- function(x) { 130+x*726/30 } points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), pch=25, col=""blue"") text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), labels=Langren1644$Name, srt=90, adj=c(0, 0.5), cex=0.8) } ## End(Not run) ### First attempt using ggplot2; temporarily abandonned. ## Not run: require(maps) require(ggplot2) require(reshape) require(plyr) require(scales) # set latitude to that of Toledo Langren1644$Latitude <- 39.68 # x/long y/lat bbox <- c( 38.186, -9.184, 43.692, 28.674 ) bbox <- matrix(bbox, 2, 2, byrow=TRUE) borders <- as.data.frame(map(""world"", plot = FALSE, xlim = expand_range(bbox[,2], 0.2), ylim = expand_range(bbox[,1], 0.2))[c(""x"", ""y"")]) data(world.cities) # get actual locations of Toledo & Rome cities <- subset(world.cities, name %in% c(""Rome"", ""Toledo"") & country.etc %in% c(""Spain"", ""Italy"")) colnames(cities)[4:5]<-c(""Latitude"", ""Longitude"") mplot <- ggplot(Langren1644, aes(Longitude, Latitude) ) + geom_path(aes(x, y), borders, colour = ""grey60"") + geom_point(y = 40) + geom_text(aes(label = Name), y = 40.1, angle = 90, hjust = 0, size = 3) mplot <- mplot + geom_segment(aes(x=-4.03, y=40, xend=30, yend=40)) mplot <- mplot + geom_point(data = cities, colour = ""red"", size = 2) + geom_text(data=cities, aes(label=name), color=""red"", size=3, vjust=-0.5) + coord_cartesian(xlim=bbox[,2], ylim=bbox[,1]) # make the plot have approximately aspect ratio = 1 windows(width=10, height=2) mplot ## End(Not run) ########################################### # show variation in estimates across graphs ########################################### library(lattice) graph <- paste(Langren.all$Author, Langren.all$Year) dotplot(Name ~ Longitude, data=Langren.all) dotplot( as.factor(Year) ~ Longitude, data=Langren.all, groups=Name, type=""o"") dotplot(Name ~ Longitude|graph, data=Langren.all, groups=graph) # why the gap? gap.mod <- glm(Gap ~ Year + Source + Latitude, family=binomial, data=Langren1644) anova(gap.mod, test=""Chisq"")"
"HistData-Langren1644","HistData","Langren1644","van Langren's Data on Longitude Distance between Toledo and Rome",12,9,2,0,5,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Langren1644.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Langren1644.html","Langren R Documentation    van Langren's Data on Longitude Distance between Toledo and Rome    Description  
Michael Florent van Langren (1598-1675) was a Dutch mathematician and astronomer, who served as a royal mathematician to King Phillip IV of Spain, and who worked on one of the most significant problems of his time— the accurate determination of longitude, particularly for navigation at sea.   
In order to convince the Spanish court of the seriousness of the problem (often resulting in great losses through ship wrecks), he prepared a 1-dimensional line graph, showing all the available estimates of the distance in longitude between Toledo and Rome, which showed large errors, for even this modest distance. This 1D line graph, from Langren (1644), is believed to be the first known graph of statistical data (Friendly etal., 2010). It provides a compelling example of the notions of statistical variability and bias.   
The data frame Langren1644 gives the estimates and other information derived from the previously known 1644 graph. It turns out that van Langren produced other versions of this graph, as early as 1628. The data frame Langren.all gives the estimates derived from all known versions of this graph.    Usage    data(Langren1644) data(Langren.all)    Format  
Langren1644 : A data frame with 12 observations on the following 9 variables, giving determinations of the distance in longitude between Toledo and Rome, from the 1644 graph.    Name
The name of the person giving a determination, a factor with levels A. Argelius ... T. Brahe   Longitude
Estimated value of the longitude distance between Toledo and Rome   Year
Year associated with this determination   Longname
A longer version of the Name , where appropriate; a factor with levels Andrea Argoli Christoph Clavius  Tycho Brahe   City
The principal city where this person worked; a factor with levels Alexandria Amsterdam Bamberg Bologna Frankfurt Hven Leuven Middelburg Nuremberg Padua Paris Rome   Country
The country where this person worked; a factor with levels Belgium Denmark Egypt Flanders France Germany Italy Italy   Latitude
Latitude of this City ; a numeric vector   Source
Likely source for this determination of Longitude; a factor with levels Astron Map   Gap
A numeric vector indicating whether the Longitude value is below or above the median    
Langren.all : A data frame with 61 observations on the following 4 variables, giving determinations of Longitude between Toledo and Rome from all known versions of van Langren's graph.    Author
Author of the graph, a factor with levels Langren Lelewel   Year
Year of publication   Name
The name of the person giving a determination, a factor with levels Algunos1 Algunos2  Apianus ... Schonerus   Longitude
Estimated value of the longitude distance between Toledo and Rome     Details  
In all the graphs, Toledo is implicitly at the origin and Rome is located relatively at the value of Longitude To judge correspondence with an actual map, the positions in (lat, long) are   
 toledo <- c(39.86, -4.03); rome <- c(41.89, 12.5)      Source  
The longitude values were digitized from images of the various graphs, which may be found on the Supplementary materials page for Friendly etal. (2009).    References  
Friendly, M., Valero-Mora, P. and Ulargui, J. I. (2010). The First (Known) Statistical Graph: Michael Florent van Langren and the ""Secret"" of Longitude.  The American Statistician , 64 (2), 185-191. Supplementary materials: http://datavis.ca/gallery/langren/ .  
Langren, M. F. van. (1644). La Verdadera Longitud por Mar y Tierra . Antwerp: (n.p.), 1644. English translation available at http://datavis.ca/gallery/langren/verdadera.pdf .   
Lelewel, J. (1851). Geographie du Moyen Age . Paris: Pilliet, 1851.    Examples    data(Langren1644) #################################################### # reproductions of Langren's graph overlaid on a map #################################################### if (require(jpeg, quietly=TRUE)) { gimage <- readJPEG(system.file(""images"", ""google-toledo-rome3.jpg"", package=""HistData"")) # NB: dimensions from readJPEG are y, x, colors gdim <- dim(gimage)[1:2] ylim <- c(1,gdim[1]) xlim <- c(1,gdim[2]) op <- par(bty=""n"", xaxt=""n"", yaxt=""n"", mar=c(2, 1, 1, 1) + 0.1) # NB: necessary to scale the plot to the pixel coordinates, and use asp=1 plot(xlim, ylim, xlim=xlim, ylim=ylim, type=""n"", ann=FALSE, asp=1 ) rasterImage(gimage, 1, 1, gdim[2], gdim[1]) # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner toledo.map <- c(131, 59) rome.map <- c(506, 119) # confirm locations of Toledo and Rome points(rbind(toledo.map, rome.map), cex=2) text(131, 95, ""Toledo"", cex=1.5) text(506, 104, ""Roma"", cex=1.5) # set a scale for translation of lat,long to pixel x,y scale <- data.frame(x=c(131, 856), y=c(52,52)) rownames(scale)=c(0,30) # translate from degrees longitude to pixels xlate <- function(x) { 131+x*726/30 } # draw an axis lines(scale) ticks <- xlate(seq(0,30,5)) segments(ticks, 52, ticks, 45) text(ticks, 40, seq(0,30,5)) text(xlate(8), 17, ""Grados de la Longitud"", cex=1.7) # label the observations with the names points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), pch=25, col=""blue"", bg=""blue"") text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), labels=Langren1644$Name, srt=90, adj=c(-.1, .5), cex=0.8) par(op) } ### Original implementation using ReadImages, now deprecated & shortly to be removed ## Not run: if (require(ReadImages)) { gimage <- read.jpeg(system.file(""images"", ""google-toledo-rome3.jpg"", package=""HistData"")) plot(gimage) # pixel coordinates of Toledo and Rome in the image, measured from the bottom left corner toledo.map <- c(130, 59) rome.map <- c(505, 119) # confirm locations of Toledo and Rome points(rbind(toledo.map, rome.map), cex=2) # set a scale for translation of lat,long to pixel x,y scale <- data.frame(x=c(130, 856), y=c(52,52)) rownames(scale)=c(0,30) lines(scale) xlate <- function(x) { 130+x*726/30 } points(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), pch=25, col=""blue"") text(x=xlate(Langren1644$Longitude), y=rep(57, nrow(Langren1644)), labels=Langren1644$Name, srt=90, adj=c(0, 0.5), cex=0.8) } ## End(Not run) ### First attempt using ggplot2; temporarily abandonned. ## Not run: require(maps) require(ggplot2) require(reshape) require(plyr) require(scales) # set latitude to that of Toledo Langren1644$Latitude <- 39.68 # x/long y/lat bbox <- c( 38.186, -9.184, 43.692, 28.674 ) bbox <- matrix(bbox, 2, 2, byrow=TRUE) borders <- as.data.frame(map(""world"", plot = FALSE, xlim = expand_range(bbox[,2], 0.2), ylim = expand_range(bbox[,1], 0.2))[c(""x"", ""y"")]) data(world.cities) # get actual locations of Toledo & Rome cities <- subset(world.cities, name %in% c(""Rome"", ""Toledo"") & country.etc %in% c(""Spain"", ""Italy"")) colnames(cities)[4:5]<-c(""Latitude"", ""Longitude"") mplot <- ggplot(Langren1644, aes(Longitude, Latitude) ) + geom_path(aes(x, y), borders, colour = ""grey60"") + geom_point(y = 40) + geom_text(aes(label = Name), y = 40.1, angle = 90, hjust = 0, size = 3) mplot <- mplot + geom_segment(aes(x=-4.03, y=40, xend=30, yend=40)) mplot <- mplot + geom_point(data = cities, colour = ""red"", size = 2) + geom_text(data=cities, aes(label=name), color=""red"", size=3, vjust=-0.5) + coord_cartesian(xlim=bbox[,2], ylim=bbox[,1]) # make the plot have approximately aspect ratio = 1 windows(width=10, height=2) mplot ## End(Not run) ########################################### # show variation in estimates across graphs ########################################### library(lattice) graph <- paste(Langren.all$Author, Langren.all$Year) dotplot(Name ~ Longitude, data=Langren.all) dotplot( as.factor(Year) ~ Longitude, data=Langren.all, groups=Name, type=""o"") dotplot(Name ~ Longitude|graph, data=Langren.all, groups=graph) # why the gap? gap.mod <- glm(Gap ~ Year + Source + Latitude, family=binomial, data=Langren1644) anova(gap.mod, test=""Chisq"")"
"HistData-Macdonell","HistData","Macdonell","Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)",924,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Macdonell.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Macdonell.html","Macdonell R Documentation    Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)    Description  
In the second issue of Biometrika , W. R. Macdonell (1902) published an extensive paper, On Criminal Anthropometry and the Identification of Criminals  in which he included numerous tables of physical characteristics 3000 non-habitual male criminals serving their sentences in England and Wales. His Table III (p. 216) recorded a bivariate frequency distribution of height by finger length. His main purpose was to show that Scotland Yard could have indexed their material more efficiently, and find a given profile more quickly.  
W. S. Gosset (aka ""Student"") used these data in two classic papers in 1908, in which he derived various characteristics of the sampling distributions of the mean, standard deviation and Pearson's r. He said, ""Before I had succeeded in solving my problem analytically, I had endeavoured to do so empirically."" Among his experiments, he randomly shuffled the 3000 observations from Macdonell's table, and then grouped them into samples of size 4, 8, ..., calculating the sample means, standard deviations and correlations for each sample.   Usage    data(Macdonell) data(MacdonellDF)    Format  
Macdonell : A frequency data frame with 924 observations on the following 3 variables giving the bivariate frequency distribution of height and finger .    height
lower class boundaries of height, in decimal ft.   finger
length of the left middle finger, in mm.   frequency
frequency of this combination of height and finger    
MacdonellDF : A data frame with 3000 observations on the following 2 variables.    height
a numeric vector   finger
a numeric vector     Details  
Class intervals for height in Macdonell's table were given in 1 in. ranges, from (4' 7"" 9/16 - 4' 8"" 9/16), to (6' 4"" 9/16 - 6' 5"" 9/16). The values of height are taken as the lower class boundaries.   
For convenience, the data frame MacdonellDF presents the same data, in expanded form, with each combination of height and finger replicated frequency times.    Source  
Macdonell, W. R. (1902). On Criminal Anthropometry and the Identification of Criminals.  Biometrika , 1(2), 177-227. doi: 10.1093/biomet/1.2.177    
The data used here were obtained from:   
Hanley, J. (2008). Macdonell data used by Student.  http://www.medicine.mcgill.ca/epidemiology/hanley/Student/     References  
Hanley, J. and Julien, M. and Moodie, E. (2008). Student's z, t, and s: What if Gosset had R?  The American Statistician , 62(1), 64-69.   
Gosset, W. S. [Student] (1908). Probable error of a mean.  Biometrika , 6(1), 1-25.  https://www.york.ac.uk/depts/maths/histstat/student.pdf    
Gosset, W. S. [Student] (1908). Probable error of a correlation coefficient.  Biometrika , 6, 302-310.    Examples    data(Macdonell) # display the frequency table xtabs(frequency ~ finger+round(height,3), data=Macdonell) ## Some examples by james.hanley@mcgill.ca October 16, 2011 ## http://www.biostat.mcgill.ca/hanley/ ## See: http://www.biostat.mcgill.ca/hanley/Student/ ############################################### ## naive contour plots of height and finger ## ############################################### # make a 22 x 42 table attach(Macdonell) ht <- unique(height) fi <- unique(finger) fr <- t(matrix(frequency, nrow=42)) detach(Macdonell) dev.new(width=10, height=5) # make plot double wide op <- par(mfrow=c(1,2),mar=c(0.5,0.5,0.5,0.5),oma=c(2,2,0,0)) dx <- 0.5/12 dy <- 0.5/12 plot(ht,ht,xlim=c(min(ht)-dx,max(ht)+dx), ylim=c(min(fi)-dy,max(fi)+dy), xlab="""", ylab="""", type=""n"" ) # unpack 3000 heights while looping though the frequencies heights <- c() for(i in 1:22) { for (j in 1:42) { f <- fr[i,j] if(f>0) heights <- c(heights,rep(ht[i],f)) if(f>0) text(ht[i], fi[j], toString(f), cex=0.4, col=""grey40"" ) } } text(4.65,13.5, ""Finger length (cm)"",adj=c(0,1), col=""black"") ; text(5.75,9.5, ""Height (feet)"", adj=c(0,1), col=""black"") ; text(6.1,11, ""Observed bin\nfrequencies"", adj=c(0.5,1), col=""grey40"",cex=0.85) ; # crude countour plot contour(ht, fi, fr, add=TRUE, drawlabels=FALSE, col=""grey60"") # smoother contour plot (Galton smoothed 2-D frequencies this way) # [Galton had experience with plotting isobars for meteorological data] # it was the smoothed plot that made him remember his 'conic sections' # and ask a mathematician to work out for him the iso-density # contours of a bivariate Gaussian distribution... dx <- 0.5/12; dy <- 0.05 ; # shifts caused by averaging plot(ht,ht,xlim=c(min(ht),max(ht)),ylim=c(min(fi),max(fi)), xlab="""", ylab="""", type=""n"" ) sm.fr <- matrix(rep(0,21*41),nrow <- 21) for(i in 1:21) { for (j in 1:41) { smooth.freq <- (1/4) * sum( fr[i:(i+1), j:(j+1)] ) sm.fr[i,j] <- smooth.freq if(smooth.freq > 0 ) text(ht[i]+dx, fi[j]+dy, sub(""^0."", ""."",toString(smooth.freq)), cex=0.4, col=""grey40"" ) } } contour(ht[1:21]+dx, fi[1:41]+dy, sm.fr, add=TRUE, drawlabels=FALSE, col=""grey60"") text(6.05,11, ""Smoothed bin\nfrequencies"", adj=c(0.5,1), col=""grey40"", cex=0.85) ; par(op) dev.new() # new default device ####################################### ## bivariate kernel density estimate ####################################### if(require(KernSmooth)) { MDest <- bkde2D(MacdonellDF, bandwidth=c(1/8, 1/8)) contour(x=MDest$x1, y=MDest$x2, z=MDest$fhat, xlab=""Height (feet)"", ylab=""Finger length (cm)"", col=""red"", lwd=2) with(MacdonellDF, points(jitter(height), jitter(finger), cex=0.5)) } ############################################################# ## sunflower plot of height and finger with data ellipses ## ############################################################# with(MacdonellDF, { sunflowerplot(height, finger, size=1/12, seg.col=""green3"", xlab=""Height (feet)"", ylab=""Finger length (cm)"") reg <- lm(finger ~ height) abline(reg, lwd=2) if(require(car)) { dataEllipse(height, finger, plot.points=FALSE, levels=c(.40, .68, .95)) } }) ############################################################ ## Sampling distributions of sample sd (s) and z=(ybar-mu)/s ############################################################ # note that Gosset used a divisor of n (not n-1) to get the sd. # He also used Sheppard's correction for the 'binning' or grouping. # with concatenated height measurements... mu <- mean(heights) ; sigma <- sqrt( 3000 * var(heights)/2999 ) c(mu,sigma) # 750 samples of size n=4 (as Gosset did) # see Student's z, t, and s: What if Gosset had R? # [Hanley J, Julien M, and Moodie E. The American Statistician, February 2008] # see also the photographs from Student's notebook ('Original small sample data and notes"") # under the link ""Gosset' 750 samples of size n=4"" # on website http://www.biostat.mcgill.ca/hanley/Student/ # and while there, look at the cover of the Notebook containing his yeast-cell counts # http://www.medicine.mcgill.ca/epidemiology/hanley/Student/750samplesOf4/Covers.JPG # (Biometrika 1907) and decide for yourself why Gosset, when forced to write under a # pen-name, might have taken the name he did! # PS: Can you figure out what the 750 pairs of numbers signify? # hint: look again at the numbers of rows and columns in Macdonell's (frequency) Table III. n <- 4 Nsamples <- 750 y.bar.values <- s.over.sigma.values <- z.values <- c() for (samp in 1:Nsamples) { y <- sample(heights,n) y.bar <- mean(y) s <- sqrt( (n/(n-1))*var(y) ) z <- (y.bar-mu)/s y.bar.values <- c(y.bar.values,y.bar) s.over.sigma.values <- c(s.over.sigma.values,s/sigma) z.values <- c(z.values,z) } op <- par(mfrow=c(2,2),mar=c(2.5,2.5,2.5,2.5),oma=c(2,2,0,0)) # sampling distributions hist(heights,breaks=seq(4.5,6.5,1/12), main=""Histogram of heights (N=3000)"") hist(y.bar.values, main=paste(""Histogram of y.bar (n="",n,"")"",sep="""")) hist(s.over.sigma.values,breaks=seq(0,4,0.1), main=paste(""Histogram of s/sigma (n="",n,"")"",sep="""")); z=seq(-5,5,0.25)+0.125 hist(z.values,breaks=z-0.125, main=""Histogram of z=(ybar-mu)/s"") # theoretical lines(z, 750*0.25*sqrt(n-1)*dt(sqrt(n-1)*z,3), col=""red"", lwd=1) par(op) ##################################################### ## Chisquare probability plot for bivariate normality ##################################################### mu <- colMeans(MacdonellDF) sigma <- var(MacdonellDF) Dsq <- mahalanobis(MacdonellDF, mu, sigma) Q <- qchisq(1:3000/3000, 2) plot(Q, sort(Dsq), xlab=""Chisquare (2) quantile"", ylab=""Squared distance"") abline(a=0, b=1, col=""red"", lwd=2)"
"HistData-MacdonellDF","HistData","MacdonellDF","Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)",3000,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/MacdonellDF.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/MacdonellDF.html","Macdonell R Documentation    Macdonell's Data on Height and Finger Length of Criminals, used by Gosset (1908)    Description  
In the second issue of Biometrika , W. R. Macdonell (1902) published an extensive paper, On Criminal Anthropometry and the Identification of Criminals  in which he included numerous tables of physical characteristics 3000 non-habitual male criminals serving their sentences in England and Wales. His Table III (p. 216) recorded a bivariate frequency distribution of height by finger length. His main purpose was to show that Scotland Yard could have indexed their material more efficiently, and find a given profile more quickly.  
W. S. Gosset (aka ""Student"") used these data in two classic papers in 1908, in which he derived various characteristics of the sampling distributions of the mean, standard deviation and Pearson's r. He said, ""Before I had succeeded in solving my problem analytically, I had endeavoured to do so empirically."" Among his experiments, he randomly shuffled the 3000 observations from Macdonell's table, and then grouped them into samples of size 4, 8, ..., calculating the sample means, standard deviations and correlations for each sample.   Usage    data(Macdonell) data(MacdonellDF)    Format  
Macdonell : A frequency data frame with 924 observations on the following 3 variables giving the bivariate frequency distribution of height and finger .    height
lower class boundaries of height, in decimal ft.   finger
length of the left middle finger, in mm.   frequency
frequency of this combination of height and finger    
MacdonellDF : A data frame with 3000 observations on the following 2 variables.    height
a numeric vector   finger
a numeric vector     Details  
Class intervals for height in Macdonell's table were given in 1 in. ranges, from (4' 7"" 9/16 - 4' 8"" 9/16), to (6' 4"" 9/16 - 6' 5"" 9/16). The values of height are taken as the lower class boundaries.   
For convenience, the data frame MacdonellDF presents the same data, in expanded form, with each combination of height and finger replicated frequency times.    Source  
Macdonell, W. R. (1902). On Criminal Anthropometry and the Identification of Criminals.  Biometrika , 1(2), 177-227. doi: 10.1093/biomet/1.2.177    
The data used here were obtained from:   
Hanley, J. (2008). Macdonell data used by Student.  http://www.medicine.mcgill.ca/epidemiology/hanley/Student/     References  
Hanley, J. and Julien, M. and Moodie, E. (2008). Student's z, t, and s: What if Gosset had R?  The American Statistician , 62(1), 64-69.   
Gosset, W. S. [Student] (1908). Probable error of a mean.  Biometrika , 6(1), 1-25.  https://www.york.ac.uk/depts/maths/histstat/student.pdf    
Gosset, W. S. [Student] (1908). Probable error of a correlation coefficient.  Biometrika , 6, 302-310.    Examples    data(Macdonell) # display the frequency table xtabs(frequency ~ finger+round(height,3), data=Macdonell) ## Some examples by james.hanley@mcgill.ca October 16, 2011 ## http://www.biostat.mcgill.ca/hanley/ ## See: http://www.biostat.mcgill.ca/hanley/Student/ ############################################### ## naive contour plots of height and finger ## ############################################### # make a 22 x 42 table attach(Macdonell) ht <- unique(height) fi <- unique(finger) fr <- t(matrix(frequency, nrow=42)) detach(Macdonell) dev.new(width=10, height=5) # make plot double wide op <- par(mfrow=c(1,2),mar=c(0.5,0.5,0.5,0.5),oma=c(2,2,0,0)) dx <- 0.5/12 dy <- 0.5/12 plot(ht,ht,xlim=c(min(ht)-dx,max(ht)+dx), ylim=c(min(fi)-dy,max(fi)+dy), xlab="""", ylab="""", type=""n"" ) # unpack 3000 heights while looping though the frequencies heights <- c() for(i in 1:22) { for (j in 1:42) { f <- fr[i,j] if(f>0) heights <- c(heights,rep(ht[i],f)) if(f>0) text(ht[i], fi[j], toString(f), cex=0.4, col=""grey40"" ) } } text(4.65,13.5, ""Finger length (cm)"",adj=c(0,1), col=""black"") ; text(5.75,9.5, ""Height (feet)"", adj=c(0,1), col=""black"") ; text(6.1,11, ""Observed bin\nfrequencies"", adj=c(0.5,1), col=""grey40"",cex=0.85) ; # crude countour plot contour(ht, fi, fr, add=TRUE, drawlabels=FALSE, col=""grey60"") # smoother contour plot (Galton smoothed 2-D frequencies this way) # [Galton had experience with plotting isobars for meteorological data] # it was the smoothed plot that made him remember his 'conic sections' # and ask a mathematician to work out for him the iso-density # contours of a bivariate Gaussian distribution... dx <- 0.5/12; dy <- 0.05 ; # shifts caused by averaging plot(ht,ht,xlim=c(min(ht),max(ht)),ylim=c(min(fi),max(fi)), xlab="""", ylab="""", type=""n"" ) sm.fr <- matrix(rep(0,21*41),nrow <- 21) for(i in 1:21) { for (j in 1:41) { smooth.freq <- (1/4) * sum( fr[i:(i+1), j:(j+1)] ) sm.fr[i,j] <- smooth.freq if(smooth.freq > 0 ) text(ht[i]+dx, fi[j]+dy, sub(""^0."", ""."",toString(smooth.freq)), cex=0.4, col=""grey40"" ) } } contour(ht[1:21]+dx, fi[1:41]+dy, sm.fr, add=TRUE, drawlabels=FALSE, col=""grey60"") text(6.05,11, ""Smoothed bin\nfrequencies"", adj=c(0.5,1), col=""grey40"", cex=0.85) ; par(op) dev.new() # new default device ####################################### ## bivariate kernel density estimate ####################################### if(require(KernSmooth)) { MDest <- bkde2D(MacdonellDF, bandwidth=c(1/8, 1/8)) contour(x=MDest$x1, y=MDest$x2, z=MDest$fhat, xlab=""Height (feet)"", ylab=""Finger length (cm)"", col=""red"", lwd=2) with(MacdonellDF, points(jitter(height), jitter(finger), cex=0.5)) } ############################################################# ## sunflower plot of height and finger with data ellipses ## ############################################################# with(MacdonellDF, { sunflowerplot(height, finger, size=1/12, seg.col=""green3"", xlab=""Height (feet)"", ylab=""Finger length (cm)"") reg <- lm(finger ~ height) abline(reg, lwd=2) if(require(car)) { dataEllipse(height, finger, plot.points=FALSE, levels=c(.40, .68, .95)) } }) ############################################################ ## Sampling distributions of sample sd (s) and z=(ybar-mu)/s ############################################################ # note that Gosset used a divisor of n (not n-1) to get the sd. # He also used Sheppard's correction for the 'binning' or grouping. # with concatenated height measurements... mu <- mean(heights) ; sigma <- sqrt( 3000 * var(heights)/2999 ) c(mu,sigma) # 750 samples of size n=4 (as Gosset did) # see Student's z, t, and s: What if Gosset had R? # [Hanley J, Julien M, and Moodie E. The American Statistician, February 2008] # see also the photographs from Student's notebook ('Original small sample data and notes"") # under the link ""Gosset' 750 samples of size n=4"" # on website http://www.biostat.mcgill.ca/hanley/Student/ # and while there, look at the cover of the Notebook containing his yeast-cell counts # http://www.medicine.mcgill.ca/epidemiology/hanley/Student/750samplesOf4/Covers.JPG # (Biometrika 1907) and decide for yourself why Gosset, when forced to write under a # pen-name, might have taken the name he did! # PS: Can you figure out what the 750 pairs of numbers signify? # hint: look again at the numbers of rows and columns in Macdonell's (frequency) Table III. n <- 4 Nsamples <- 750 y.bar.values <- s.over.sigma.values <- z.values <- c() for (samp in 1:Nsamples) { y <- sample(heights,n) y.bar <- mean(y) s <- sqrt( (n/(n-1))*var(y) ) z <- (y.bar-mu)/s y.bar.values <- c(y.bar.values,y.bar) s.over.sigma.values <- c(s.over.sigma.values,s/sigma) z.values <- c(z.values,z) } op <- par(mfrow=c(2,2),mar=c(2.5,2.5,2.5,2.5),oma=c(2,2,0,0)) # sampling distributions hist(heights,breaks=seq(4.5,6.5,1/12), main=""Histogram of heights (N=3000)"") hist(y.bar.values, main=paste(""Histogram of y.bar (n="",n,"")"",sep="""")) hist(s.over.sigma.values,breaks=seq(0,4,0.1), main=paste(""Histogram of s/sigma (n="",n,"")"",sep="""")); z=seq(-5,5,0.25)+0.125 hist(z.values,breaks=z-0.125, main=""Histogram of z=(ybar-mu)/s"") # theoretical lines(z, 750*0.25*sqrt(n-1)*dt(sqrt(n-1)*z,3), col=""red"", lwd=1) par(op) ##################################################### ## Chisquare probability plot for bivariate normality ##################################################### mu <- colMeans(MacdonellDF) sigma <- var(MacdonellDF) Dsq <- mahalanobis(MacdonellDF, mu, sigma) Q <- qchisq(1:3000/3000, 2) plot(Q, sort(Dsq), xlab=""Chisquare (2) quantile"", ylab=""Squared distance"") abline(a=0, b=1, col=""red"", lwd=2)"
"HistData-Michelson","HistData","Michelson","Michelson's Determinations of the Velocity of Light",100,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Michelson.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Michelson.html","Michelson R Documentation    Michelson's Determinations of the Velocity of Light    Description  
The data frame Michelson gives Albert Michelson's measurements of the velocity of light in air, made from June 5 to July 2, 1879, reported in Michelson (1882). The given values + 299,000 are Michelson's measurements in km/sec. The number of cases is 100 and the ""true"" value on this scale is 734.5.   
Stigler (1977) used these data to illustrate properties of robust estimators with real, historical data. For this purpose, he divided the 100 measurements into 5 sets of 20 each. These are contained in MichelsonSets .    Usage    data(Michelson) data(MichelsonSets)    Format  
Michelson : A data frame with 100 observations on the following variable, given in time order of data collection    velocity
a numeric vector    
MichelsonSets : A 20 x 5 matrix, with format int [1:20, 1:5] 850 850 1000 810 960 800 830 830 880 720 ... - attr(*, ""dimnames"")=List of 2 ..$ : NULL ..$ : chr [1:5] ""ds12"" ""ds13"" ""ds14"" ""ds15"" ...    Details  
The ""true"" value is taken to be 734.5, arrived at by taking the ""true"" speed of light in a vacuum to be 299,792.5 km/sec, and adjusting for the velocity in air.   
The data values are recorded in order, and so may also be taken as a time series.    Source  
Kyle Siegrist, ""Virtual Laboratories in Probability and Statistics"", http://www.math.uah.edu/stat/data/Michelson.html    
Stephen M. Stigler (1977), ""Do robust estimators work with real data?"", Annals of Statistics , 5, 1055-1098    References  
Michelson, A. A. (1882). ""Experimental determination of the velocity of light made at the United States Naval Academy, Anapolis"". Astronomical Papers , 1,109-145, U. S. Nautical Almanac Office.    See Also  
morley for these data in another format    Examples    data(Michelson) # density plot (default bandwidth & 0.6 * bw) plot(density(Michelson$velocity), xlab=""Speed of light - 299000 (km/s)"", main=""Density plots of Michelson data"") lines(density(Michelson$velocity, adjust=0.6), lty=2) rug(jitter(Michelson$velocity)) abline(v=mean(Michelson$velocity), col=""blue"") abline(v=734.5, col=""red"", lwd=2) text(mean(Michelson$velocity), .004, ""mean"", srt=90, pos=2) text(734.5, .004, ""true"", srt=90, pos=2) # index / time series plot plot(Michelson$velocity, type=""b"") abline(h=734.5, col=""red"", lwd=2) lines(lowess(Michelson$velocity), col=""blue"", lwd=2) # examine lag=1 differences plot(diff(Michelson$velocity), type=""b"") lines(lowess(diff(Michelson$velocity)), col=""blue"", lwd=2) # examine different data sets boxplot(MichelsonSets, ylab=""Velocity of light - 299000 (km/s)"", xlab=""Data set"") abline(h=734.5, col=""red"", lwd=2) # means and trimmed means (mn <-apply(MichelsonSets, 2, mean)) (tm <- apply(MichelsonSets, 2, mean, trim=.1)) points(1:5, mn) points(1:5+.05, tm, pch=16, col=""blue"")"
"HistData-MichelsonSets","HistData","MichelsonSets","Michelson's Determinations of the Velocity of Light",20,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/MichelsonSets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/MichelsonSets.html","Michelson R Documentation    Michelson's Determinations of the Velocity of Light    Description  
The data frame Michelson gives Albert Michelson's measurements of the velocity of light in air, made from June 5 to July 2, 1879, reported in Michelson (1882). The given values + 299,000 are Michelson's measurements in km/sec. The number of cases is 100 and the ""true"" value on this scale is 734.5.   
Stigler (1977) used these data to illustrate properties of robust estimators with real, historical data. For this purpose, he divided the 100 measurements into 5 sets of 20 each. These are contained in MichelsonSets .    Usage    data(Michelson) data(MichelsonSets)    Format  
Michelson : A data frame with 100 observations on the following variable, given in time order of data collection    velocity
a numeric vector    
MichelsonSets : A 20 x 5 matrix, with format int [1:20, 1:5] 850 850 1000 810 960 800 830 830 880 720 ... - attr(*, ""dimnames"")=List of 2 ..$ : NULL ..$ : chr [1:5] ""ds12"" ""ds13"" ""ds14"" ""ds15"" ...    Details  
The ""true"" value is taken to be 734.5, arrived at by taking the ""true"" speed of light in a vacuum to be 299,792.5 km/sec, and adjusting for the velocity in air.   
The data values are recorded in order, and so may also be taken as a time series.    Source  
Kyle Siegrist, ""Virtual Laboratories in Probability and Statistics"", http://www.math.uah.edu/stat/data/Michelson.html    
Stephen M. Stigler (1977), ""Do robust estimators work with real data?"", Annals of Statistics , 5, 1055-1098    References  
Michelson, A. A. (1882). ""Experimental determination of the velocity of light made at the United States Naval Academy, Anapolis"". Astronomical Papers , 1,109-145, U. S. Nautical Almanac Office.    See Also  
morley for these data in another format    Examples    data(Michelson) # density plot (default bandwidth & 0.6 * bw) plot(density(Michelson$velocity), xlab=""Speed of light - 299000 (km/s)"", main=""Density plots of Michelson data"") lines(density(Michelson$velocity, adjust=0.6), lty=2) rug(jitter(Michelson$velocity)) abline(v=mean(Michelson$velocity), col=""blue"") abline(v=734.5, col=""red"", lwd=2) text(mean(Michelson$velocity), .004, ""mean"", srt=90, pos=2) text(734.5, .004, ""true"", srt=90, pos=2) # index / time series plot plot(Michelson$velocity, type=""b"") abline(h=734.5, col=""red"", lwd=2) lines(lowess(Michelson$velocity), col=""blue"", lwd=2) # examine lag=1 differences plot(diff(Michelson$velocity), type=""b"") lines(lowess(diff(Michelson$velocity)), col=""blue"", lwd=2) # examine different data sets boxplot(MichelsonSets, ylab=""Velocity of light - 299000 (km/s)"", xlab=""Data set"") abline(h=734.5, col=""red"", lwd=2) # means and trimmed means (mn <-apply(MichelsonSets, 2, mean)) (tm <- apply(MichelsonSets, 2, mean, trim=.1)) points(1:5, mn) points(1:5+.05, tm, pch=16, col=""blue"")"
"HistData-Minard.cities","HistData","Minard.cities","Data from Minard's famous graphic map of Napoleon's march on Moscow",20,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Minard.cities.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Minard.cities.html","Minard R Documentation    Data from Minard's famous graphic map of Napoleon's march on Moscow    Description  
Charles Joseph Minard's graphic depiction of the fate of Napoleon's Grand Army in the Russian campaign of 1815 has been called the ""greatest statistical graphic ever drawn"" (Tufte, 1983). Friendly (2002) describes some background for this graphic, and presented it as Minard's Challenge: to reproduce it using modern statistical or graphic software, in a way that showed the elegance of some computer language to both describe and produce this graphic.    Usage    data(Minard.troops) data(Minard.cities) data(Minard.temp)    Format  
Minard.troops : A data frame with 51 observations on the following 5 variables giving the number of surviving troops.    long
Longitude   lat
Latitude   survivors
Number of surviving troops, a numeric vector   direction
a factor with levels A (""Advance"") R (""Retreat"")   group
a numeric vector    
Minard.cities : A data frame with 20 observations on the following 3 variables giving the locations of various places along the path of Napoleon's army.    long
Longitude   lat
Latitude   city
City name: a factor with levels Bobr Chjat ... Witebsk Wixma    
Minard.temp : A data frame with 9 observations on the following 4 variables, giving the temperature at various places along the march of retreat from Moscow.    long
Longitude   temp
Temperature   days
Number of days on the retreat march   date
a factor with levels Dec01 Dec06 Dec07 Nov09 Nov14 Nov28 Oct18 Oct24     Details  
date in Minard.temp should be made a real date in 1815.    Source  
https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/minard.txt     References  
Friendly, M. (2002). Visions and Re-visions of Charles Joseph Minard,  Journal of Educational and Behavioral Statistics , 27, No. 1, 31-51.   
Friendly, M. (2003). Re-Visions of Minard.  http://datavis.ca/gallery/re-minard.html     Examples    data(Minard.troops) data(Minard.cities) data(Minard.temp) ## Not run: #' ## Load required packages require(ggplot2) require(scales) require(gridExtra) #' ## plot path of troops, and another layer for city names plot_troops <- ggplot(Minard.troops, aes(long, lat)) + geom_path(aes(size = survivors, colour = direction, group = group), lineend = ""round"", linejoin = ""round"") plot_cities <- geom_text(aes(label = city), size = 4, data = Minard.cities) #' ## Combine these, and add scale information, labels, etc. #' Set the x-axis limits for longitude explicitly, to coincide with those for temperature breaks <- c(1, 2, 3) * 10^5 plot_minard <- plot_troops + plot_cities + scale_size(""Survivors"", range = c(1, 10), breaks = breaks, labels = scales::comma(breaks)) + scale_color_manual(""Direction"", values = c(""grey50"", ""red""), labels=c(""Advance"", ""Retreat"")) + coord_cartesian(xlim = c(24, 38)) + xlab(NULL) + ylab(""Latitude"") + ggtitle(""Napoleon's March on Moscow"") + theme_bw() + theme(legend.position=c(.8, .2), legend.box=""horizontal"") #' ## plot temperature vs. longitude, with labels for dates plot_temp <- ggplot(Minard.temp, aes(long, temp)) + geom_path(color=""grey"", size=1.5) + geom_point(size=2) + geom_text(aes(label=date)) + xlab(""Longitude"") + ylab(""Temperature"") + coord_cartesian(xlim = c(24, 38)) + theme_bw() #' The plot works best if we re-scale the plot window to an aspect ratio of ~ 2 x 1 # windows(width=10, height=5) #' Combine the two plots into one grid.arrange(plot_minard, plot_temp, nrow=2, heights=c(3,1)) ## End(Not run)"
"HistData-Minard.temp","HistData","Minard.temp","Data from Minard's famous graphic map of Napoleon's march on Moscow",9,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Minard.temp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Minard.temp.html","Minard R Documentation    Data from Minard's famous graphic map of Napoleon's march on Moscow    Description  
Charles Joseph Minard's graphic depiction of the fate of Napoleon's Grand Army in the Russian campaign of 1815 has been called the ""greatest statistical graphic ever drawn"" (Tufte, 1983). Friendly (2002) describes some background for this graphic, and presented it as Minard's Challenge: to reproduce it using modern statistical or graphic software, in a way that showed the elegance of some computer language to both describe and produce this graphic.    Usage    data(Minard.troops) data(Minard.cities) data(Minard.temp)    Format  
Minard.troops : A data frame with 51 observations on the following 5 variables giving the number of surviving troops.    long
Longitude   lat
Latitude   survivors
Number of surviving troops, a numeric vector   direction
a factor with levels A (""Advance"") R (""Retreat"")   group
a numeric vector    
Minard.cities : A data frame with 20 observations on the following 3 variables giving the locations of various places along the path of Napoleon's army.    long
Longitude   lat
Latitude   city
City name: a factor with levels Bobr Chjat ... Witebsk Wixma    
Minard.temp : A data frame with 9 observations on the following 4 variables, giving the temperature at various places along the march of retreat from Moscow.    long
Longitude   temp
Temperature   days
Number of days on the retreat march   date
a factor with levels Dec01 Dec06 Dec07 Nov09 Nov14 Nov28 Oct18 Oct24     Details  
date in Minard.temp should be made a real date in 1815.    Source  
https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/minard.txt     References  
Friendly, M. (2002). Visions and Re-visions of Charles Joseph Minard,  Journal of Educational and Behavioral Statistics , 27, No. 1, 31-51.   
Friendly, M. (2003). Re-Visions of Minard.  http://datavis.ca/gallery/re-minard.html     Examples    data(Minard.troops) data(Minard.cities) data(Minard.temp) ## Not run: #' ## Load required packages require(ggplot2) require(scales) require(gridExtra) #' ## plot path of troops, and another layer for city names plot_troops <- ggplot(Minard.troops, aes(long, lat)) + geom_path(aes(size = survivors, colour = direction, group = group), lineend = ""round"", linejoin = ""round"") plot_cities <- geom_text(aes(label = city), size = 4, data = Minard.cities) #' ## Combine these, and add scale information, labels, etc. #' Set the x-axis limits for longitude explicitly, to coincide with those for temperature breaks <- c(1, 2, 3) * 10^5 plot_minard <- plot_troops + plot_cities + scale_size(""Survivors"", range = c(1, 10), breaks = breaks, labels = scales::comma(breaks)) + scale_color_manual(""Direction"", values = c(""grey50"", ""red""), labels=c(""Advance"", ""Retreat"")) + coord_cartesian(xlim = c(24, 38)) + xlab(NULL) + ylab(""Latitude"") + ggtitle(""Napoleon's March on Moscow"") + theme_bw() + theme(legend.position=c(.8, .2), legend.box=""horizontal"") #' ## plot temperature vs. longitude, with labels for dates plot_temp <- ggplot(Minard.temp, aes(long, temp)) + geom_path(color=""grey"", size=1.5) + geom_point(size=2) + geom_text(aes(label=date)) + xlab(""Longitude"") + ylab(""Temperature"") + coord_cartesian(xlim = c(24, 38)) + theme_bw() #' The plot works best if we re-scale the plot window to an aspect ratio of ~ 2 x 1 # windows(width=10, height=5) #' Combine the two plots into one grid.arrange(plot_minard, plot_temp, nrow=2, heights=c(3,1)) ## End(Not run)"
"HistData-Minard.troops","HistData","Minard.troops","Data from Minard's famous graphic map of Napoleon's march on Moscow",51,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Minard.troops.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Minard.troops.html","Minard R Documentation    Data from Minard's famous graphic map of Napoleon's march on Moscow    Description  
Charles Joseph Minard's graphic depiction of the fate of Napoleon's Grand Army in the Russian campaign of 1815 has been called the ""greatest statistical graphic ever drawn"" (Tufte, 1983). Friendly (2002) describes some background for this graphic, and presented it as Minard's Challenge: to reproduce it using modern statistical or graphic software, in a way that showed the elegance of some computer language to both describe and produce this graphic.    Usage    data(Minard.troops) data(Minard.cities) data(Minard.temp)    Format  
Minard.troops : A data frame with 51 observations on the following 5 variables giving the number of surviving troops.    long
Longitude   lat
Latitude   survivors
Number of surviving troops, a numeric vector   direction
a factor with levels A (""Advance"") R (""Retreat"")   group
a numeric vector    
Minard.cities : A data frame with 20 observations on the following 3 variables giving the locations of various places along the path of Napoleon's army.    long
Longitude   lat
Latitude   city
City name: a factor with levels Bobr Chjat ... Witebsk Wixma    
Minard.temp : A data frame with 9 observations on the following 4 variables, giving the temperature at various places along the march of retreat from Moscow.    long
Longitude   temp
Temperature   days
Number of days on the retreat march   date
a factor with levels Dec01 Dec06 Dec07 Nov09 Nov14 Nov28 Oct18 Oct24     Details  
date in Minard.temp should be made a real date in 1815.    Source  
https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/minard.txt     References  
Friendly, M. (2002). Visions and Re-visions of Charles Joseph Minard,  Journal of Educational and Behavioral Statistics , 27, No. 1, 31-51.   
Friendly, M. (2003). Re-Visions of Minard.  http://datavis.ca/gallery/re-minard.html     Examples    data(Minard.troops) data(Minard.cities) data(Minard.temp) ## Not run: #' ## Load required packages require(ggplot2) require(scales) require(gridExtra) #' ## plot path of troops, and another layer for city names plot_troops <- ggplot(Minard.troops, aes(long, lat)) + geom_path(aes(size = survivors, colour = direction, group = group), lineend = ""round"", linejoin = ""round"") plot_cities <- geom_text(aes(label = city), size = 4, data = Minard.cities) #' ## Combine these, and add scale information, labels, etc. #' Set the x-axis limits for longitude explicitly, to coincide with those for temperature breaks <- c(1, 2, 3) * 10^5 plot_minard <- plot_troops + plot_cities + scale_size(""Survivors"", range = c(1, 10), breaks = breaks, labels = scales::comma(breaks)) + scale_color_manual(""Direction"", values = c(""grey50"", ""red""), labels=c(""Advance"", ""Retreat"")) + coord_cartesian(xlim = c(24, 38)) + xlab(NULL) + ylab(""Latitude"") + ggtitle(""Napoleon's March on Moscow"") + theme_bw() + theme(legend.position=c(.8, .2), legend.box=""horizontal"") #' ## plot temperature vs. longitude, with labels for dates plot_temp <- ggplot(Minard.temp, aes(long, temp)) + geom_path(color=""grey"", size=1.5) + geom_point(size=2) + geom_text(aes(label=date)) + xlab(""Longitude"") + ylab(""Temperature"") + coord_cartesian(xlim = c(24, 38)) + theme_bw() #' The plot works best if we re-scale the plot window to an aspect ratio of ~ 2 x 1 # windows(width=10, height=5) #' Combine the two plots into one grid.arrange(plot_minard, plot_temp, nrow=2, heights=c(3,1)) ## End(Not run)"
"HistData-Nightingale","HistData","Nightingale","Florence Nightingale's data on deaths from various causes in the Crimean War",24,10,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Nightingale.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Nightingale.html","Nightingale R Documentation    Florence Nightingale's data on deaths from various causes in the Crimean War    Description  
In the history of data visualization, Florence Nightingale is best remembered for her role as a social activist and her view that statistical data, presented in charts and diagrams, could be used as powerful arguments for medical reform.  
After witnessing deplorable sanitary conditions in the Crimea, she wrote several influential texts (Nightingale, 1858, 1859), including polar-area graphs (sometimes called ""Coxcombs"" or rose diagrams), showing the number of deaths in the Crimean from battle compared to disease or preventable causes that could be reduced by better battlefield nursing care.  
Her Diagram of the Causes of Mortality in the Army in the East  showed that most of the British soldiers who died during the Crimean War died of sickness rather than of wounds or other causes. It also showed that the death rate was higher in the first year of the war, before a Sanitary Commissioners arrived in March 1855 to improve hygiene in the camps and hospitals.    Usage   data(Nightingale)   Format  
A data frame with 24 observations on the following 10 variables.    Date
a Date, composed as as.Date(paste(Year, Month, 1, sep='-'), ""%Y-%b-%d"")   Month
Month of the Crimean War, an ordered factor   Year
Year of the Crimean War   Army
Estimated average monthly strength of the British army   Disease
Number of deaths from preventable or mitagable zymotic diseases   Wounds
Number of deaths directly from battle wounds   Other
Number of deaths from other causes   Disease.rate
Annual rate of deaths from preventable or mitagable zymotic diseases, per 1000   Wounds.rate
Annual rate of deaths directly from battle wounds, per 1000   Other.rate
Annual rate of deaths from other causes, per 1000     Details  
For a given cause of death, D , annual rates per 1000 are calculated as 12 * 1000 * D / Army , rounded to 1 decimal.   
The two panels of Nightingale's Coxcomb correspond to dates before and after March 1855    Source  
The data were obtained from:   
Pearson, M. and Short, I. (2007). Understanding Uncertainty: Mathematics of the Coxcomb.  http://understandinguncertainty.org/node/214 .    References  
Nightingale, F. (1858)  Notes on Matters Affecting the Health, Efficiency, and Hospital Administration of the British Army  Harrison and Sons, 1858   
Nightingale, F. (1859)  A Contribution to the Sanitary History of the British Army during the Late War with Russia  London: John W. Parker and Son.   
Small, H. (1998) Florence Nightingale's statistical diagrams  http://www.florence-nightingale-avenging-angel.co.uk/GraphicsPaper/Graphics.htm    
Pearson, M. and Short, I. (2008) Nightingale's Rose (flash animation).  http://understandinguncertainty.org/files/animations/Nightingale11/Nightingale1.html     Examples    data(Nightingale) # For some graphs, it is more convenient to reshape death rates to long format # keep only Date and death rates require(reshape) Night<- Nightingale[,c(1,8:10)] melted <- melt(Night, ""Date"") names(melted) <- c(""Date"", ""Cause"", ""Deaths"") melted$Cause <- sub(""\\.rate"", """", melted$Cause) melted$Regime <- ordered( rep(c(rep('Before', 12), rep('After', 12)), 3), levels=c('Before', 'After')) Night <- melted # subsets, to facilitate separate plotting Night1 <- subset(Night, Date < as.Date(""1855-04-01"")) Night2 <- subset(Night, Date >= as.Date(""1855-04-01"")) # sort according to Deaths in decreasing order, so counts are not obscured [thx: Monique Graf] Night1 <- Night1[order(Night1$Deaths, decreasing=TRUE),] Night2 <- Night2[order(Night2$Deaths, decreasing=TRUE),] # merge the two sorted files Night <- rbind(Night1, Night2) require(ggplot2) # Before plot cxc1 <- ggplot(Night1, aes(x = factor(Date), y=Deaths, fill = Cause)) + # do it as a stacked bar chart first geom_bar(width = 1, position=""identity"", stat=""identity"", color=""black"") + # set scale so area ~ Deaths scale_y_sqrt() # A coxcomb plot = bar chart + polar coordinates cxc1 + coord_polar(start=3*pi/2) + ggtitle(""Causes of Mortality in the Army in the East"") + xlab("""") # After plot cxc2 <- ggplot(Night2, aes(x = factor(Date), y=Deaths, fill = Cause)) + geom_bar(width = 1, position=""identity"", stat=""identity"", color=""black"") + scale_y_sqrt() cxc2 + coord_polar(start=3*pi/2) + ggtitle(""Causes of Mortality in the Army in the East"") + xlab("""") ## Not run: # do both together, with faceting cxc <- ggplot(Night, aes(x = factor(Date), y=Deaths, fill = Cause)) + geom_bar(width = 1, position=""identity"", stat=""identity"", color=""black"") + scale_y_sqrt() + facet_grid(. ~ Regime, scales=""free"", labeller=label_both) cxc + coord_polar(start=3*pi/2) + ggtitle(""Causes of Mortality in the Army in the East"") + xlab("""") ## End(Not run) ## What if she had made a set of line graphs? # these plots are best viewed with width ~ 2 * height colors <- c(""blue"", ""red"", ""black"") with(Nightingale, { plot(Date, Disease.rate, type=""n"", cex.lab=1.25, ylab=""Annual Death Rate"", xlab=""Date"", xaxt=""n"", main=""Causes of Mortality of the British Army in the East""); # background, to separate before, after rect(as.Date(""1854/4/1""), -10, as.Date(""1855/3/1""), 1.02*max(Disease.rate), col=gray(.90), border=""transparent""); text( as.Date(""1854/4/1""), .98*max(Disease.rate), ""Before Sanitary\nCommission"", pos=4); text( as.Date(""1855/4/1""), .98*max(Disease.rate), ""After Sanitary\nCommission"", pos=4); # plot the data points(Date, Disease.rate, type=""b"", col=colors[1], lwd=3); points(Date, Wounds.rate, type=""b"", col=colors[2], lwd=2); points(Date, Other.rate, type=""b"", col=colors[3], lwd=2) } ) # add custom Date axis and legend axis.Date(1, at=seq(as.Date(""1854/4/1""), as.Date(""1856/3/1""), ""3 months""), format=""%b %Y"") legend(as.Date(""1855/10/20""), 700, c(""Preventable disease"", ""Wounds and injuries"", ""Other""), col=colors, fill=colors, title=""Cause"", cex=1.25) # Alternatively, show each cause of death as percent of total Nightingale <- within(Nightingale, { Total <- Disease + Wounds + Other Disease.pct <- 100*Disease/Total Wounds.pct <- 100*Wounds/Total Other.pct <- 100*Other/Total }) colors <- c(""blue"", ""red"", ""black"") with(Nightingale, { plot(Date, Disease.pct, type=""n"", ylim=c(0,100), cex.lab=1.25, ylab=""Percent deaths"", xlab=""Date"", xaxt=""n"", main=""Percentage of Deaths by Cause""); # background, to separate before, after rect(as.Date(""1854/4/1""), -10, as.Date(""1855/3/1""), 1.02*max(Disease.rate), col=gray(.90), border=""transparent""); text( as.Date(""1854/4/1""), .98*max(Disease.pct), ""Before Sanitary\nCommission"", pos=4); text( as.Date(""1855/4/1""), .98*max(Disease.pct), ""After Sanitary\nCommission"", pos=4); # plot the data points(Date, Disease.pct, type=""b"", col=colors[1], lwd=3); points(Date, Wounds.pct, type=""b"", col=colors[2], lwd=2); points(Date, Other.pct, type=""b"", col=colors[3], lwd=2) } ) # add custom Date axis and legend axis.Date(1, at=seq(as.Date(""1854/4/1""), as.Date(""1856/3/1""), ""3 months""), format=""%b %Y"") legend(as.Date(""1854/8/20""), 60, c(""Preventable disease"", ""Wounds and injuries"", ""Other""), col=colors, fill=colors, title=""Cause"", cex=1.25)"
"HistData-OldMaps","HistData","OldMaps","Latitudes and Longitudes of 39 Points in 11 Old Maps",468,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/OldMaps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/OldMaps.html","OldMaps R Documentation    Latitudes and Longitudes of 39 Points in 11 Old Maps    Description  
The data set is concerned with the problem of aligning the coordinates of points read from old maps (1688 - 1818) of the Great Lakes area. 39 easily identifiable points were selected in the Great Lakes area, and their (lat, long) coordinates were recorded using a grid overlaid on each of 11 old maps, and using linear interpolation.   
It was conjectured that maps might be systematically in error in five key ways: (a) constant error in latitude; (b)constant error in longitude; (c) proportional error in latitude; (d)proportional error in longitude; (e) angular error from a non-zero difference between true North and the map's North.   
One challenge from these data is to produce useful analyses and graphical displays that relate to these characteristics or to other aspects of the data.    Usage   data(OldMaps)   Format  
A data frame with 468 observations on the following 6 variables, giving the latitude and longitude of 39 points recorded from 12 sources (Actual + 11 maps).    point
a numeric vector   col
Column in the table a numeric vector   name
Name of the map maker, using Actual for the true coordinates of the points. A factor with levels Actual  Arrowsmith Belin Cary Coronelli D'Anville} \code{Del'Isle Lattre Melish Mitchell Popple   year
Year of the map   lat
Latitude   long
Longitude     Details  
Some of the latitude and longitude values are inexplicably negative. It is probable that this is an error in type setting, because the table footnote says ""* denotes that interpolation accuracy is not good,"" yet no ""*""s appear in the body of the table.    Source  
Andrews, D. F., and Herzberg, A. M. (1985).  Data: A Collection of Problems from Many fields for the Student and Research Worker . New York: Springer, Table 10.1. The data were obtained from http://www.stat.duke.edu/courses/Spring01/sta114/data/Andrews/T10.1 .    Examples    data(OldMaps) ## maybe str(OldMaps) ; plot(OldMaps) ... with(OldMaps, plot(abs(long),abs(lat), pch=col, col=colors()[point]))"
"HistData-PearsonLee","HistData","PearsonLee","Pearson and Lee's data on the heights of parents and children classified by gender",746,6,2,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/PearsonLee.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/PearsonLee.html","PearsonLee R Documentation    Pearson and Lee's data on the heights of parents and children classified by gender    Description  
Wachsmuth et. al (2003) noticed that a loess smooth through Galton's data on heights of mid-parents and their offspring exhibited a slightly non-linear trend, and asked whether this might be due to Galton having pooled the heights of fathers and mothers and sons and daughters in constructing his tables and graphs.   
To answer this question, they used analogous data from English families at about the same time, tabulated by Karl Pearson and Alice Lee (1896, 1903), but where the heights of parents and children were each classified by gender of the parent.    Usage   data(PearsonLee)   Format  
A frequency data frame with 746 observations on the following 6 variables.    child
child height in inches, a numeric vector   parent
parent height in inches, a numeric vector   frequency
a numeric vector   gp
a factor with levels fd fs md ms   par
a factor with levels Father Mother   chl
a factor with levels Daughter Son     Details  
The variables gp , par and chl are provided to allow stratifying the data according to the gender of the father/mother and son/daughter.    Source  
Pearson, K. and Lee, A. (1896). Mathematical contributions to the theory of evolution. On telegony in man, etc. Proceedings of the Royal Society of London , 60 , 273-283.   
Pearson, K. and Lee, A. (1903). On the laws of inheritance in man: I. Inheritance of physical characters. Biometika , 2(4), 357-462. (Tables XXII, p. 415; XXV, p. 417; XXVIII, p. 419 and XXXI, p. 421.)    References  
Wachsmuth, A.W., Wilkinson L., Dallal G.E. (2003). Galton's bend: A previously undiscovered nonlinearity in Galton's family stature regression data. The American Statistician , 57, 190-192. https://www.cs.uic.edu/~wilkinson/Publications/galton.pdf     See Also  
Galton     Examples    data(PearsonLee) str(PearsonLee) with(PearsonLee, { lim <- c(55,80) xv <- seq(55,80, .5) sunflowerplot(parent,child, number=frequency, xlim=lim, ylim=lim, seg.col=""gray"", size=.1) abline(lm(child ~ parent, weights=frequency), col=""blue"", lwd=2) lines(xv, predict(loess(child ~ parent, weights=frequency), data.frame(parent=xv)), col=""blue"", lwd=2) # NB: dataEllipse doesn't take frequency into account if(require(car)) { dataEllipse(parent,child, xlim=lim, ylim=lim, plot.points=FALSE) } }) ## separate plots for combinations of (chl, par) # this doesn't quite work, because xyplot can't handle weights require(lattice) xyplot(child ~ parent|par+chl, data=PearsonLee, type=c(""p"", ""r"", ""smooth""), col.line=""red"") # Using ggplot [thx: Dennis Murphy] require(ggplot2) ggplot(PearsonLee, aes(x = parent, y = child, weight=frequency)) + geom_point(size = 1.5, position = position_jitter(width = 0.2)) + geom_smooth(method = lm, aes(weight = PearsonLee$frequency, colour = 'Linear'), se = FALSE, size = 1.5) + geom_smooth(aes(weight = PearsonLee$frequency, colour = 'Loess'), se = FALSE, size = 1.5) + facet_grid(chl ~ par) + scale_colour_manual(breaks = c('Linear', 'Loess'), values = c('green', 'red')) + theme(legend.position = c(0.14, 0.885), legend.background = element_rect(fill = 'white')) # inverse regression, as in Wachmuth et al. (2003) ggplot(PearsonLee, aes(x = child, y = parent, weight=frequency)) + geom_point(size = 1.5, position = position_jitter(width = 0.2)) + geom_smooth(method = lm, aes(weight = PearsonLee$frequency, colour = 'Linear'), se = FALSE, size = 1.5) + geom_smooth(aes(weight = PearsonLee$frequency, colour = 'Loess'), se = FALSE, size = 1.5) + facet_grid(chl ~ par) + scale_colour_manual(breaks = c('Linear', 'Loess'), values = c('green', 'red')) + theme(legend.position = c(0.14, 0.885), legend.background = element_rect(fill = 'white'))"
"HistData-PolioTrials","HistData","PolioTrials","Polio Field Trials Data",8,6,1,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/PolioTrials.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/PolioTrials.html","PolioTrials R Documentation    Polio Field Trials Data    Description  
The data frame PolioTrials gives the results of the 1954 field trials to test the Salk polio vaccine (named for the developer, Jonas Salk), conducted by the National Foundation for Infantile Paralysis (NFIP). It is adapted from data in the article by Francis et al. (1955). There were actually two clinical trials, corresponding to two statistical designs ( Experiment ), discussed by Brownlee (1955). The comparison of designs and results represented a milestone in the development of randomized clinical trials.   Usage   data(PolioTrials)   Format  
A data frame with 8 observations on the following 6 variables.    Experiment
a factor with levels ObservedControl RandomizedControl   Group
a factor with levels Controls Grade2NotInoculated IncompleteVaccinations NotInoculated Placebo Vaccinated   Population
the size of the population in each group in each experiment   Paralytic
the number of cases of paralytic polio observed in that group   NonParalytic
the number of cases of paralytic polio observed in that group   FalseReports
the number of cases initially reported as polio, but later determined not to be polio in that group     Details  
The data frame is in the form of a single table, but actually comprises the results of two separate field trials, given by Experiment . Each should be analyzed separately, because the designs differ markedly.   
The original design ( Experiment == ""ObservedControl"" ) called for vaccination of second-graders at selected schools in selected areas of the country (with the consent of the children's parents, of course). The Vaccinated second-graders formed the treatment group. The first and third-graders at the schools were not given the vaccination, and formed the Controls group.  
In the second design ( Experiment == ""RandomizedControl"" ) children were selected (again in various schools in various areas), all of whose parents consented to vaccination. The sample was randomly divided into treatment ( Group == ""Vaccinated"" ), given the real polio vaccination, and control groups ( Group == ""Placebo"" ), a placebo dose that looked just like the real vaccine. The experiment was also double blind: neither the parents of a child in the study nor the doctors treating the child knew which group the child belonged to.  
In both experiments, NotInnoculated refers to children who did not participate in the experiment.  IncompleteVaccinations refers to children who received one or two, but not all three administrations of the vaccine.    Source  
Kyle Siegrist, ""Virtual Laboratories in Probability and Statistics"", http://www.math.uah.edu/stat/data/Polio.html    
Thomas Francis, Robert Korn, et al. (1955). ""An Evaluation of the 1954 Poliomyelitis Vaccine Trials"", American Journal of Public Health , 45, (50 page supplement with a 63 page appendix).    References  
K. A. Brownlee (1955). ""Statistics of the 1954 Polio Vaccine Trials"", Journal of the American Statistical Association , 50, 1005-1013.    Examples    data(PolioTrials) ## maybe str(PolioTrials) ; plot(PolioTrials) ..."
"HistData-Prostitutes","HistData","Prostitutes","Parent-Duchatelet's time-series data on the number of prostitutes in Paris",516,5,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Prostitutes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Prostitutes.html","Prostitutes R Documentation    Parent-Duchatelet's time-series data on the number of prostitutes in Paris    Description  
A table indicating month by month, for the years 1812-1854, the number of prostitutes on the registers of the administration of the city of Paris.    Usage   data(Prostitutes)   Format  
A data frame with 516 observations on the following 5 variables.    Year
a numeric vector   month
a factor with levels Apr Aug Dec Feb Jan Jul Jun Mar May Nov Oct Sep   count
a numeric vector: number of prostitutes   mon
a numeric vector: numeric month   date
a Date     Details  
The data table was digitally scanned with OCR, and errors were corrected by comparing the yearly totals recorded in the table to the row sums of the scanned data.    Source  
Parent-Duchatelet, A. (1857), De la prostitution dans la ville de Paris , 3rd ed, p. 32, 36    Examples    data(Prostitutes) ## maybe str(Prostitutes) ; plot(Prostitutes) ..."
"HistData-Pyx","HistData","Pyx","Trial of the Pyx",72,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Pyx.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Pyx.html","Pyx R Documentation    Trial of the Pyx    Description  
Stigler (1997, 1999) recounts the history of one of the oldest continuous schemes of sampling inspection carried out by the Royal Mint in London for about eight centuries. The Trial of the Pyx was the final, ceremonial stage in a process designed to ensure that the weight and quality of gold and silver coins from the mint met the standards for coinage.  
At regular intervals, coins would be taken from production and deposited into a box called the Pyx. When a Trial of the Pyx was called, the contents of the Pyx would be counted, weighed and assayed for content, and the results would be compared with the standard set for the Royal Mint.  
The data frame Pyx gives the results for the year 1848 (Great Britain, 1848) in which 10,000 gold sovereigns were assayed. The coins in each bag were classified according to the deviation from the standard content of gold for each coin, called the Remedy, R = 123 * (12/5760) = .25625, in grains, for a single sovereign.   Usage   data(Pyx)   Format  
A frequency data frame with 72 observations on the following 4 variables giving the distribution of 10,000 sovereigns, classified according to the Bags in which they were collected and the Deviation from the standard weight.    Bags
an ordered factor with levels 1 and 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9 < 10   Group
an ordered factor with levels below std < near std < above std   Deviation
an ordered factor with levels Below -R < (-R to -.2) < (-.2 to -.l) < (-.1 to 0) < (0 to .l) < (.1 to .2) < (.2 to R) < Above R   count
number of sovereigns     Details  
Bags 1-4 were selected as ""near to standard"", bags 5-7 as below standard, bags 8-10 as above standard. This classification is reflected in Group .    Source  
Stigler, S. M. (1999).  Statistics on the Table . Cambridge, MA: Harvard University Press, table 21.1.    References  
Great Britain (1848). ""Report of the Commissioners Appointed to Inquire into the Constitution, Management and Expense of the Royal Mint."" In Vol 28 of House Documents for 1849 .   
Stigler, S. M. (1997). Eight Centuries of Sampling Inspection: The Trial of the Pyx  Journal of the American Statistical Association , 72(359), 493-500   Examples    data(Pyx) # display as table xtabs(count ~ Bags+Deviation, data=Pyx)"
"HistData-Quarrels","HistData","Quarrels","Statistics of Deadly Quarrels",779,84,50,0,64,0,20,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Quarrels.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Quarrels.html","Quarrels R Documentation    Statistics of Deadly Quarrels    Description  
The Statistics Of Deadly Quarrels by Lewis Fry Richardson (1960) is one of the earlier attempts at quantification of historical conflict behavior.  
The data set contains 779 dyadic deadly quarrels that cover a time period from 1809 to 1949. A quarrel consists of one pair of belligerents, and is identified by its beginning date and magnitude (log 10 of the number of deaths). Neither actor in a quarrel is identified by name.   
Because Richardson took a dyad of belligerents as his unit, a given war, such as World War I or World War II comprises multiple observations, for all pairs of belligerents. For example, there are forty-four pairs of belligerents coded for World War I.   
For each quarrel, the nominal variables include the type of quarrel, as well as political, cultural, and economic similarities and dissimilarities between the pair of combatants.    Usage   data(Quarrels)   Format  
A data frame with 779 observations on the following 84 variables.    ID
V84: Id sequence   year
V1: Begin date of quarrel   international
V2: Nation vs nation   colonial
V3: Nation vs colony   revolution
V4: Revolution or civil war   nat.grp
V5: Nation vs gp in other nation   grp.grpSame
V6: Grp vs grp (same nation)   grp.grpDif
V7: Grp vs grp (between nations)   numGroups
V8: Number groups against which fighting   months
V9: Number months fighting   pairs
V10: Number pairs in whole matrix   monthsPairs
V11: Num mons for all in matrix   logDeaths
V12: Log (killed) matrix   deaths
V13: Total killed for matrix   exchangeGoods
V14: Gp sent goods to other   obstacleGoods
V15: Gp puts obstacles to goods   intermarriageOK
V16: Present intermarriages   intermarriageBan
V17: Intermarriages banned   simBody
V18: Similar body characteristics   difBody
V19: Difference in body characteristics   simDress
V20: Similarity of customs (dress)   difDress
V21: Difference of customs (dress)   eqWealth
V22: Common level of wealth   difWealth
V23: Difference in wealth   simMariagCust
V24: Similar marriage cusomst   difMariagCust
V25: Different marriage customs   simRelig
V26: Similar religion or philosophy of life   difRelig
V27: Religion or philosophy felt different   philanthropy
V28: General philanthropy   restrictMigration
V29: Restricted immigrations   sameLanguage
V30: Common mother tongue   difLanguage
V31: Different languages   simArtSci
V32: Similar science, arts   travel
V33: Travel   ignorance
V34: Ignorant of other/both   simPersLiberty
V35: Personal liberty similar   difPersLiberty
V36: More personal liberty   sameGov
V37: Common government   sameGovYrs
V38: Years since common govt established   prevConflict
V39: Belligerents fought previously   prevConflictYrs
V40: Years since belligerents fought   chronicFighting
V41: Chronic fighting between belligerents   persFriendship
V42: Autocrats personal friends   persResentment
V43: Leaders personal resentment   difLegal
V44: Annoyingly different legal systems   nonintervention
V45: Policy of nonintervention   thirdParty
V46: Led by 3rd group to conflict   supportEnemy
V47: Supported others enemy   attackAlly
V48: Attacked ally of other   rivalsLand
V49: Rivals territory concess   rivalsTrade
V50: Rivals trade   churchPower
V51: Church civil power   noExtension
V52: Policy not extending term   territory
V53: Desired territory   habitation
V54: Wanted habitation   minerals
V55: Desired minerals   StrongHold
V56: Wanted strategic stronghold   taxation
V57: Taxed other   loot
V58: Wanted loot   objectedWar
V59: Objected to war   enjoyFight
V60: Enjoyed fighting   pride
V61: Elated by strong pride   overpopulated
V62: Insufficient land for population   fightForPay
V63: Fought only for pay   joinWinner
V64: Desired to join winners   otherDesiredWar
V65: Quarrel desired by other   propaganda3rd
V66: Issued of propaganda to third parties   protection
V67: Offered protection   sympathy
V68: Sympathized under control   debt
V69: Owed money to others   prevAllies
V70: Had fought as allies   yearsAllies
V71: Years since fought as allies   intermingled
V72: Had intermingled on territory   interbreeding
V73: Interbreeding between groups   propadanda
V74: Issued propaganda to other group   orderedObey
V75: Ordered other to obey   commerceOther
V76: Commercial enterprises   feltStronger
V77: Felt stronger   competeIntellect
V78: Competed successfully intellectual occ   insecureGovt
V79: Government insecure   prepWar
V80: Preparations for war   RegionalError
V81: Regional error measure   CasualtyError
V82: Casualty error measure   Auxiliaries
V83: Auxiliaries in service of nation at war     Details  
In the original data set obtained from ICPSR, variables were named V1 - V84 . These were renamed to make them more meaningful. V84 , renamed ID was moved to the first position, but otherwise the order of variables is the same.   
In many of the factor variables, 0 is used to indicate ""irrelevant to quarrel"". This refers to those relations that Richardson found absent or irrelevant to the particular quarrel, and did not subsequently mention.  
See the original codebook at  http://www.icpsr.umich.edu/cgi-bin/file?comp=none&study=5407&ds=1&file_id=652814  for details not contained here.    Source  
http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/05407     References  
Lewis F. Richardson, (1960).  The Statistics Of Deadly Quarrels . (Edited by Q. Wright and C. C. Lienau). Pittsburgh: Boxwood Press.  
Rummel, Rudolph J. (1967), ""Dimensions of Dyadic War, 1820-1952."" Journal of Conflict Resolution . 11, (2), 176 - 183.    Examples    data(Quarrels) str(Quarrels)"
"HistData-Snow.dates","HistData","Snow.dates","John Snow's Map and Data on the 1854 London Cholera Outbreak",44,3,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Snow.dates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.dates.html","Snow R Documentation    John Snow's Map and Data on the 1854 London Cholera Outbreak    Description  
The Snow data consists of the relevant 1854 London streets, the location of 578 deaths from cholera, and the position of 13 water pumps (wells) that can be used to re-create John Snow's map showing deaths from cholera in the area surrounding Broad Street, London in the 1854 outbreak. Another data frame provides boundaries of a tessellation of the map into Thiessen (Voronoi) regions which include all cholera deaths nearer to a given pump than to any other.   
The apocryphal story of the significance of Snow's map is that, by closing the Broad Street pump (by removing its handle), Dr. Snow stopped the epidemic, and demonstrated that cholera is a water borne disease. The method of contagion of cholera was not previously understood. Snow's map is the most famous and classical example in the field of medical cartography, even if it didn't happen exactly this way. (the apocryphal part is that the epidemic ended when the pump handle was removed.) At any rate, the map, together with various statistical annotations, is compelling because it points to the Broad Street pump as the source of the outbreak.    Usage    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.dates)    Format  
Snow.deaths : A data frame with 578 observations on the following 3 variables, giving the address of a person who died from cholera. When many points are associated with a single street address, they are ""stacked"" in a line away from the street so that they are more easily visualized. This is how they are displayed on John Snow's original map. The dates of the deaths are not individually recorded in this data set.    case
Sequential case number, in some arbitrary, randomized order   x
x coordinate   y
y coordinate    
Snow.pumps : A data frame with 13 observations on the following 4 variables, giving the locations of water pumps within the boundaries of the map.    pump
pump number   label
pump label: Briddle St Broad St ... Warwick   x
x coordinate   y
y coordinate    
Snow.streets : A data frame with 1241 observations on the following 4 variables, giving coordinates used to draw the 528 street segment lines within the boundaries of the map. The map is created by drawing lines connecting the n points in each street segment.    street
street segment number: 1:528   n
number of points in this street line segment   x
x coordinate   y
y coordinate    
Snow.polygons : A list of 13 data frames, giving the vertices of Thiessen (Voronoi) polygons containing each pump. Their boundaries define the area that is closest to each pump relative to all other pumps. They are mathematically defined by the perpendicular bisectors of the lines between all pumps. Each data frame contains:    x
x coordinate   y
y coordinate    
Snow.deaths2 : An alternative version of Snow.deaths correcting some possible duplicate and missing cases, as described in vignette(""Snow_deaths-duplicates"") .   
Snow.dates : A data frame of 44 observations and 3 variables from Table 1 of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 – Sept. 30, 1854. There are a total of 616 deaths represented in both columns attacks and deaths ; of these, the date of the attack is unknown for 45 cases.    Details  
The scale of the source map is approx. 1:2000. The (x, y) coordinate units are 100 meters, with an arbitrary origin.  
Of the data in the Snow.dates table, Snow says, “The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.”  
One limitation of these data sets is the lack of exact street addresses. Another is the lack of any data that would serve as a population denominator to allow for a comparison of mortality rates in the Broad Street pump area as opposed to others. See Koch (2000), Koch (2004), Koch \& Denike (2009) and Tufte (1999), p. 27-37, for further discussion.   Source  
Tobler, W. (1994). Snow's Cholera Map, http://www.ncgia.ucsb.edu/pubs/snow/snow.html ; data files were obtained from  http://ncgia.ucsb.edu/Publications/Software/cholera/ , but these sites seem to be down.   
The data in these files were first digitized in 1992 by Rusty Dodson of the NCGIA, Santa Barbara, from the map included in the book by John Snow: ""Snow on Cholera..."", London, Oxford University Press, 1936.   References  
Koch, T. (2000). Cartographies of Disease: Maps, Mapping, and Medicine . ESRI Press. ISBN: 9781589481206.   
Koch, T. (2004). The Map as Intent: Variations on the Theme of John Snow  Cartographica , 39 (4), 1-14.   
Koch, T. and Denike, K. (2009). Crediting his critics' concerns: Remaking John Snow's map of Broad Street cholera, 1854.  Social Science \& Medicine 69, 1246-1251.   
Snow, J. (1885). On the Mode of Communication of Cholera . London: John Churchill.  http://www.ph.ucla.edu/epi/snow/snowbook.html .   
Tufte, E. (1997). Visual Explanations . Cheshire, CT: Graphics Press.    See Also  
SnowMap     Examples    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.deaths) ## Plot deaths over time require(lubridate) clr <- ifelse(Snow.dates$date < mdy(""09/08/1854""), ""red"", ""darkgreen"") plot(deaths ~ date, data=Snow.dates, type=""h"", lwd=2, col=clr) points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr) text( mdy(""09/08/1854""), 40, ""Pump handle\nremoved Sept. 8"", pos=4) ## draw Snow's map and data SnowMap() # add polygons SnowMap(polygons=TRUE, main=""Snow's Cholera Map with Pump Polygons"") # zoom in a bit, and show density estimate SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE, main=""Snow's Cholera Map, Annotated"") ## re-do this the sp way... [thx: Stephane Dray] library(sp) # streets slist <- split(Snow.streets[,c(""x"",""y"")],as.factor(Snow.streets[,""street""])) Ll1 <- lapply(slist,Line) Lsl1 <- Lines(Ll1,""Street"") Snow.streets.sp <- SpatialLines(list(Lsl1)) plot(Snow.streets.sp, col=""gray"") title(main=""Snow's Cholera Map of London (sp)"") # deaths Snow.deaths.sp = SpatialPoints(Snow.deaths[,c(""x"",""y"")]) plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6) # pumps spp <- SpatialPoints(Snow.pumps[,c(""x"",""y"")]) Snow.pumps.sp <- SpatialPointsDataFrame(spp,Snow.pumps[,c(""x"",""y"")]) plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5) text(Snow.pumps[,c(""x"",""y"")], labels=Snow.pumps$label, pos=1, cex=0.8)"
"HistData-Snow.deaths","HistData","Snow.deaths","John Snow's Map and Data on the 1854 London Cholera Outbreak",578,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Snow.deaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.deaths.html","Snow R Documentation    John Snow's Map and Data on the 1854 London Cholera Outbreak    Description  
The Snow data consists of the relevant 1854 London streets, the location of 578 deaths from cholera, and the position of 13 water pumps (wells) that can be used to re-create John Snow's map showing deaths from cholera in the area surrounding Broad Street, London in the 1854 outbreak. Another data frame provides boundaries of a tessellation of the map into Thiessen (Voronoi) regions which include all cholera deaths nearer to a given pump than to any other.   
The apocryphal story of the significance of Snow's map is that, by closing the Broad Street pump (by removing its handle), Dr. Snow stopped the epidemic, and demonstrated that cholera is a water borne disease. The method of contagion of cholera was not previously understood. Snow's map is the most famous and classical example in the field of medical cartography, even if it didn't happen exactly this way. (the apocryphal part is that the epidemic ended when the pump handle was removed.) At any rate, the map, together with various statistical annotations, is compelling because it points to the Broad Street pump as the source of the outbreak.    Usage    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.dates)    Format  
Snow.deaths : A data frame with 578 observations on the following 3 variables, giving the address of a person who died from cholera. When many points are associated with a single street address, they are ""stacked"" in a line away from the street so that they are more easily visualized. This is how they are displayed on John Snow's original map. The dates of the deaths are not individually recorded in this data set.    case
Sequential case number, in some arbitrary, randomized order   x
x coordinate   y
y coordinate    
Snow.pumps : A data frame with 13 observations on the following 4 variables, giving the locations of water pumps within the boundaries of the map.    pump
pump number   label
pump label: Briddle St Broad St ... Warwick   x
x coordinate   y
y coordinate    
Snow.streets : A data frame with 1241 observations on the following 4 variables, giving coordinates used to draw the 528 street segment lines within the boundaries of the map. The map is created by drawing lines connecting the n points in each street segment.    street
street segment number: 1:528   n
number of points in this street line segment   x
x coordinate   y
y coordinate    
Snow.polygons : A list of 13 data frames, giving the vertices of Thiessen (Voronoi) polygons containing each pump. Their boundaries define the area that is closest to each pump relative to all other pumps. They are mathematically defined by the perpendicular bisectors of the lines between all pumps. Each data frame contains:    x
x coordinate   y
y coordinate    
Snow.deaths2 : An alternative version of Snow.deaths correcting some possible duplicate and missing cases, as described in vignette(""Snow_deaths-duplicates"") .   
Snow.dates : A data frame of 44 observations and 3 variables from Table 1 of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 – Sept. 30, 1854. There are a total of 616 deaths represented in both columns attacks and deaths ; of these, the date of the attack is unknown for 45 cases.    Details  
The scale of the source map is approx. 1:2000. The (x, y) coordinate units are 100 meters, with an arbitrary origin.  
Of the data in the Snow.dates table, Snow says, “The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.”  
One limitation of these data sets is the lack of exact street addresses. Another is the lack of any data that would serve as a population denominator to allow for a comparison of mortality rates in the Broad Street pump area as opposed to others. See Koch (2000), Koch (2004), Koch \& Denike (2009) and Tufte (1999), p. 27-37, for further discussion.   Source  
Tobler, W. (1994). Snow's Cholera Map, http://www.ncgia.ucsb.edu/pubs/snow/snow.html ; data files were obtained from  http://ncgia.ucsb.edu/Publications/Software/cholera/ , but these sites seem to be down.   
The data in these files were first digitized in 1992 by Rusty Dodson of the NCGIA, Santa Barbara, from the map included in the book by John Snow: ""Snow on Cholera..."", London, Oxford University Press, 1936.   References  
Koch, T. (2000). Cartographies of Disease: Maps, Mapping, and Medicine . ESRI Press. ISBN: 9781589481206.   
Koch, T. (2004). The Map as Intent: Variations on the Theme of John Snow  Cartographica , 39 (4), 1-14.   
Koch, T. and Denike, K. (2009). Crediting his critics' concerns: Remaking John Snow's map of Broad Street cholera, 1854.  Social Science \& Medicine 69, 1246-1251.   
Snow, J. (1885). On the Mode of Communication of Cholera . London: John Churchill.  http://www.ph.ucla.edu/epi/snow/snowbook.html .   
Tufte, E. (1997). Visual Explanations . Cheshire, CT: Graphics Press.    See Also  
SnowMap     Examples    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.deaths) ## Plot deaths over time require(lubridate) clr <- ifelse(Snow.dates$date < mdy(""09/08/1854""), ""red"", ""darkgreen"") plot(deaths ~ date, data=Snow.dates, type=""h"", lwd=2, col=clr) points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr) text( mdy(""09/08/1854""), 40, ""Pump handle\nremoved Sept. 8"", pos=4) ## draw Snow's map and data SnowMap() # add polygons SnowMap(polygons=TRUE, main=""Snow's Cholera Map with Pump Polygons"") # zoom in a bit, and show density estimate SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE, main=""Snow's Cholera Map, Annotated"") ## re-do this the sp way... [thx: Stephane Dray] library(sp) # streets slist <- split(Snow.streets[,c(""x"",""y"")],as.factor(Snow.streets[,""street""])) Ll1 <- lapply(slist,Line) Lsl1 <- Lines(Ll1,""Street"") Snow.streets.sp <- SpatialLines(list(Lsl1)) plot(Snow.streets.sp, col=""gray"") title(main=""Snow's Cholera Map of London (sp)"") # deaths Snow.deaths.sp = SpatialPoints(Snow.deaths[,c(""x"",""y"")]) plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6) # pumps spp <- SpatialPoints(Snow.pumps[,c(""x"",""y"")]) Snow.pumps.sp <- SpatialPointsDataFrame(spp,Snow.pumps[,c(""x"",""y"")]) plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5) text(Snow.pumps[,c(""x"",""y"")], labels=Snow.pumps$label, pos=1, cex=0.8)"
"HistData-Snow.deaths2","HistData","Snow.deaths2","John Snow's Map and Data on the 1854 London Cholera Outbreak",578,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Snow.deaths2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.deaths2.html","Snow R Documentation    John Snow's Map and Data on the 1854 London Cholera Outbreak    Description  
The Snow data consists of the relevant 1854 London streets, the location of 578 deaths from cholera, and the position of 13 water pumps (wells) that can be used to re-create John Snow's map showing deaths from cholera in the area surrounding Broad Street, London in the 1854 outbreak. Another data frame provides boundaries of a tessellation of the map into Thiessen (Voronoi) regions which include all cholera deaths nearer to a given pump than to any other.   
The apocryphal story of the significance of Snow's map is that, by closing the Broad Street pump (by removing its handle), Dr. Snow stopped the epidemic, and demonstrated that cholera is a water borne disease. The method of contagion of cholera was not previously understood. Snow's map is the most famous and classical example in the field of medical cartography, even if it didn't happen exactly this way. (the apocryphal part is that the epidemic ended when the pump handle was removed.) At any rate, the map, together with various statistical annotations, is compelling because it points to the Broad Street pump as the source of the outbreak.    Usage    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.dates)    Format  
Snow.deaths : A data frame with 578 observations on the following 3 variables, giving the address of a person who died from cholera. When many points are associated with a single street address, they are ""stacked"" in a line away from the street so that they are more easily visualized. This is how they are displayed on John Snow's original map. The dates of the deaths are not individually recorded in this data set.    case
Sequential case number, in some arbitrary, randomized order   x
x coordinate   y
y coordinate    
Snow.pumps : A data frame with 13 observations on the following 4 variables, giving the locations of water pumps within the boundaries of the map.    pump
pump number   label
pump label: Briddle St Broad St ... Warwick   x
x coordinate   y
y coordinate    
Snow.streets : A data frame with 1241 observations on the following 4 variables, giving coordinates used to draw the 528 street segment lines within the boundaries of the map. The map is created by drawing lines connecting the n points in each street segment.    street
street segment number: 1:528   n
number of points in this street line segment   x
x coordinate   y
y coordinate    
Snow.polygons : A list of 13 data frames, giving the vertices of Thiessen (Voronoi) polygons containing each pump. Their boundaries define the area that is closest to each pump relative to all other pumps. They are mathematically defined by the perpendicular bisectors of the lines between all pumps. Each data frame contains:    x
x coordinate   y
y coordinate    
Snow.deaths2 : An alternative version of Snow.deaths correcting some possible duplicate and missing cases, as described in vignette(""Snow_deaths-duplicates"") .   
Snow.dates : A data frame of 44 observations and 3 variables from Table 1 of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 – Sept. 30, 1854. There are a total of 616 deaths represented in both columns attacks and deaths ; of these, the date of the attack is unknown for 45 cases.    Details  
The scale of the source map is approx. 1:2000. The (x, y) coordinate units are 100 meters, with an arbitrary origin.  
Of the data in the Snow.dates table, Snow says, “The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.”  
One limitation of these data sets is the lack of exact street addresses. Another is the lack of any data that would serve as a population denominator to allow for a comparison of mortality rates in the Broad Street pump area as opposed to others. See Koch (2000), Koch (2004), Koch \& Denike (2009) and Tufte (1999), p. 27-37, for further discussion.   Source  
Tobler, W. (1994). Snow's Cholera Map, http://www.ncgia.ucsb.edu/pubs/snow/snow.html ; data files were obtained from  http://ncgia.ucsb.edu/Publications/Software/cholera/ , but these sites seem to be down.   
The data in these files were first digitized in 1992 by Rusty Dodson of the NCGIA, Santa Barbara, from the map included in the book by John Snow: ""Snow on Cholera..."", London, Oxford University Press, 1936.   References  
Koch, T. (2000). Cartographies of Disease: Maps, Mapping, and Medicine . ESRI Press. ISBN: 9781589481206.   
Koch, T. (2004). The Map as Intent: Variations on the Theme of John Snow  Cartographica , 39 (4), 1-14.   
Koch, T. and Denike, K. (2009). Crediting his critics' concerns: Remaking John Snow's map of Broad Street cholera, 1854.  Social Science \& Medicine 69, 1246-1251.   
Snow, J. (1885). On the Mode of Communication of Cholera . London: John Churchill.  http://www.ph.ucla.edu/epi/snow/snowbook.html .   
Tufte, E. (1997). Visual Explanations . Cheshire, CT: Graphics Press.    See Also  
SnowMap     Examples    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.deaths) ## Plot deaths over time require(lubridate) clr <- ifelse(Snow.dates$date < mdy(""09/08/1854""), ""red"", ""darkgreen"") plot(deaths ~ date, data=Snow.dates, type=""h"", lwd=2, col=clr) points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr) text( mdy(""09/08/1854""), 40, ""Pump handle\nremoved Sept. 8"", pos=4) ## draw Snow's map and data SnowMap() # add polygons SnowMap(polygons=TRUE, main=""Snow's Cholera Map with Pump Polygons"") # zoom in a bit, and show density estimate SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE, main=""Snow's Cholera Map, Annotated"") ## re-do this the sp way... [thx: Stephane Dray] library(sp) # streets slist <- split(Snow.streets[,c(""x"",""y"")],as.factor(Snow.streets[,""street""])) Ll1 <- lapply(slist,Line) Lsl1 <- Lines(Ll1,""Street"") Snow.streets.sp <- SpatialLines(list(Lsl1)) plot(Snow.streets.sp, col=""gray"") title(main=""Snow's Cholera Map of London (sp)"") # deaths Snow.deaths.sp = SpatialPoints(Snow.deaths[,c(""x"",""y"")]) plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6) # pumps spp <- SpatialPoints(Snow.pumps[,c(""x"",""y"")]) Snow.pumps.sp <- SpatialPointsDataFrame(spp,Snow.pumps[,c(""x"",""y"")]) plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5) text(Snow.pumps[,c(""x"",""y"")], labels=Snow.pumps$label, pos=1, cex=0.8)"
"HistData-Snow.pumps","HistData","Snow.pumps","John Snow's Map and Data on the 1854 London Cholera Outbreak",13,4,0,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Snow.pumps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.pumps.html","Snow R Documentation    John Snow's Map and Data on the 1854 London Cholera Outbreak    Description  
The Snow data consists of the relevant 1854 London streets, the location of 578 deaths from cholera, and the position of 13 water pumps (wells) that can be used to re-create John Snow's map showing deaths from cholera in the area surrounding Broad Street, London in the 1854 outbreak. Another data frame provides boundaries of a tessellation of the map into Thiessen (Voronoi) regions which include all cholera deaths nearer to a given pump than to any other.   
The apocryphal story of the significance of Snow's map is that, by closing the Broad Street pump (by removing its handle), Dr. Snow stopped the epidemic, and demonstrated that cholera is a water borne disease. The method of contagion of cholera was not previously understood. Snow's map is the most famous and classical example in the field of medical cartography, even if it didn't happen exactly this way. (the apocryphal part is that the epidemic ended when the pump handle was removed.) At any rate, the map, together with various statistical annotations, is compelling because it points to the Broad Street pump as the source of the outbreak.    Usage    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.dates)    Format  
Snow.deaths : A data frame with 578 observations on the following 3 variables, giving the address of a person who died from cholera. When many points are associated with a single street address, they are ""stacked"" in a line away from the street so that they are more easily visualized. This is how they are displayed on John Snow's original map. The dates of the deaths are not individually recorded in this data set.    case
Sequential case number, in some arbitrary, randomized order   x
x coordinate   y
y coordinate    
Snow.pumps : A data frame with 13 observations on the following 4 variables, giving the locations of water pumps within the boundaries of the map.    pump
pump number   label
pump label: Briddle St Broad St ... Warwick   x
x coordinate   y
y coordinate    
Snow.streets : A data frame with 1241 observations on the following 4 variables, giving coordinates used to draw the 528 street segment lines within the boundaries of the map. The map is created by drawing lines connecting the n points in each street segment.    street
street segment number: 1:528   n
number of points in this street line segment   x
x coordinate   y
y coordinate    
Snow.polygons : A list of 13 data frames, giving the vertices of Thiessen (Voronoi) polygons containing each pump. Their boundaries define the area that is closest to each pump relative to all other pumps. They are mathematically defined by the perpendicular bisectors of the lines between all pumps. Each data frame contains:    x
x coordinate   y
y coordinate    
Snow.deaths2 : An alternative version of Snow.deaths correcting some possible duplicate and missing cases, as described in vignette(""Snow_deaths-duplicates"") .   
Snow.dates : A data frame of 44 observations and 3 variables from Table 1 of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 – Sept. 30, 1854. There are a total of 616 deaths represented in both columns attacks and deaths ; of these, the date of the attack is unknown for 45 cases.    Details  
The scale of the source map is approx. 1:2000. The (x, y) coordinate units are 100 meters, with an arbitrary origin.  
Of the data in the Snow.dates table, Snow says, “The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.”  
One limitation of these data sets is the lack of exact street addresses. Another is the lack of any data that would serve as a population denominator to allow for a comparison of mortality rates in the Broad Street pump area as opposed to others. See Koch (2000), Koch (2004), Koch \& Denike (2009) and Tufte (1999), p. 27-37, for further discussion.   Source  
Tobler, W. (1994). Snow's Cholera Map, http://www.ncgia.ucsb.edu/pubs/snow/snow.html ; data files were obtained from  http://ncgia.ucsb.edu/Publications/Software/cholera/ , but these sites seem to be down.   
The data in these files were first digitized in 1992 by Rusty Dodson of the NCGIA, Santa Barbara, from the map included in the book by John Snow: ""Snow on Cholera..."", London, Oxford University Press, 1936.   References  
Koch, T. (2000). Cartographies of Disease: Maps, Mapping, and Medicine . ESRI Press. ISBN: 9781589481206.   
Koch, T. (2004). The Map as Intent: Variations on the Theme of John Snow  Cartographica , 39 (4), 1-14.   
Koch, T. and Denike, K. (2009). Crediting his critics' concerns: Remaking John Snow's map of Broad Street cholera, 1854.  Social Science \& Medicine 69, 1246-1251.   
Snow, J. (1885). On the Mode of Communication of Cholera . London: John Churchill.  http://www.ph.ucla.edu/epi/snow/snowbook.html .   
Tufte, E. (1997). Visual Explanations . Cheshire, CT: Graphics Press.    See Also  
SnowMap     Examples    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.deaths) ## Plot deaths over time require(lubridate) clr <- ifelse(Snow.dates$date < mdy(""09/08/1854""), ""red"", ""darkgreen"") plot(deaths ~ date, data=Snow.dates, type=""h"", lwd=2, col=clr) points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr) text( mdy(""09/08/1854""), 40, ""Pump handle\nremoved Sept. 8"", pos=4) ## draw Snow's map and data SnowMap() # add polygons SnowMap(polygons=TRUE, main=""Snow's Cholera Map with Pump Polygons"") # zoom in a bit, and show density estimate SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE, main=""Snow's Cholera Map, Annotated"") ## re-do this the sp way... [thx: Stephane Dray] library(sp) # streets slist <- split(Snow.streets[,c(""x"",""y"")],as.factor(Snow.streets[,""street""])) Ll1 <- lapply(slist,Line) Lsl1 <- Lines(Ll1,""Street"") Snow.streets.sp <- SpatialLines(list(Lsl1)) plot(Snow.streets.sp, col=""gray"") title(main=""Snow's Cholera Map of London (sp)"") # deaths Snow.deaths.sp = SpatialPoints(Snow.deaths[,c(""x"",""y"")]) plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6) # pumps spp <- SpatialPoints(Snow.pumps[,c(""x"",""y"")]) Snow.pumps.sp <- SpatialPointsDataFrame(spp,Snow.pumps[,c(""x"",""y"")]) plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5) text(Snow.pumps[,c(""x"",""y"")], labels=Snow.pumps$label, pos=1, cex=0.8)"
"HistData-Snow.streets","HistData","Snow.streets","John Snow's Map and Data on the 1854 London Cholera Outbreak",1241,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Snow.streets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Snow.streets.html","Snow R Documentation    John Snow's Map and Data on the 1854 London Cholera Outbreak    Description  
The Snow data consists of the relevant 1854 London streets, the location of 578 deaths from cholera, and the position of 13 water pumps (wells) that can be used to re-create John Snow's map showing deaths from cholera in the area surrounding Broad Street, London in the 1854 outbreak. Another data frame provides boundaries of a tessellation of the map into Thiessen (Voronoi) regions which include all cholera deaths nearer to a given pump than to any other.   
The apocryphal story of the significance of Snow's map is that, by closing the Broad Street pump (by removing its handle), Dr. Snow stopped the epidemic, and demonstrated that cholera is a water borne disease. The method of contagion of cholera was not previously understood. Snow's map is the most famous and classical example in the field of medical cartography, even if it didn't happen exactly this way. (the apocryphal part is that the epidemic ended when the pump handle was removed.) At any rate, the map, together with various statistical annotations, is compelling because it points to the Broad Street pump as the source of the outbreak.    Usage    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.dates)    Format  
Snow.deaths : A data frame with 578 observations on the following 3 variables, giving the address of a person who died from cholera. When many points are associated with a single street address, they are ""stacked"" in a line away from the street so that they are more easily visualized. This is how they are displayed on John Snow's original map. The dates of the deaths are not individually recorded in this data set.    case
Sequential case number, in some arbitrary, randomized order   x
x coordinate   y
y coordinate    
Snow.pumps : A data frame with 13 observations on the following 4 variables, giving the locations of water pumps within the boundaries of the map.    pump
pump number   label
pump label: Briddle St Broad St ... Warwick   x
x coordinate   y
y coordinate    
Snow.streets : A data frame with 1241 observations on the following 4 variables, giving coordinates used to draw the 528 street segment lines within the boundaries of the map. The map is created by drawing lines connecting the n points in each street segment.    street
street segment number: 1:528   n
number of points in this street line segment   x
x coordinate   y
y coordinate    
Snow.polygons : A list of 13 data frames, giving the vertices of Thiessen (Voronoi) polygons containing each pump. Their boundaries define the area that is closest to each pump relative to all other pumps. They are mathematically defined by the perpendicular bisectors of the lines between all pumps. Each data frame contains:    x
x coordinate   y
y coordinate    
Snow.deaths2 : An alternative version of Snow.deaths correcting some possible duplicate and missing cases, as described in vignette(""Snow_deaths-duplicates"") .   
Snow.dates : A data frame of 44 observations and 3 variables from Table 1 of Snow (1855), giving the number of fatal attacks and number of deaths by date from Aug. 19 – Sept. 30, 1854. There are a total of 616 deaths represented in both columns attacks and deaths ; of these, the date of the attack is unknown for 45 cases.    Details  
The scale of the source map is approx. 1:2000. The (x, y) coordinate units are 100 meters, with an arbitrary origin.  
Of the data in the Snow.dates table, Snow says, “The deaths in the above table are compiled from the sources mentioned above in describing the map; but some deaths which were omitted from the map on account of the number of the house not being known, are included in the table.”  
One limitation of these data sets is the lack of exact street addresses. Another is the lack of any data that would serve as a population denominator to allow for a comparison of mortality rates in the Broad Street pump area as opposed to others. See Koch (2000), Koch (2004), Koch \& Denike (2009) and Tufte (1999), p. 27-37, for further discussion.   Source  
Tobler, W. (1994). Snow's Cholera Map, http://www.ncgia.ucsb.edu/pubs/snow/snow.html ; data files were obtained from  http://ncgia.ucsb.edu/Publications/Software/cholera/ , but these sites seem to be down.   
The data in these files were first digitized in 1992 by Rusty Dodson of the NCGIA, Santa Barbara, from the map included in the book by John Snow: ""Snow on Cholera..."", London, Oxford University Press, 1936.   References  
Koch, T. (2000). Cartographies of Disease: Maps, Mapping, and Medicine . ESRI Press. ISBN: 9781589481206.   
Koch, T. (2004). The Map as Intent: Variations on the Theme of John Snow  Cartographica , 39 (4), 1-14.   
Koch, T. and Denike, K. (2009). Crediting his critics' concerns: Remaking John Snow's map of Broad Street cholera, 1854.  Social Science \& Medicine 69, 1246-1251.   
Snow, J. (1885). On the Mode of Communication of Cholera . London: John Churchill.  http://www.ph.ucla.edu/epi/snow/snowbook.html .   
Tufte, E. (1997). Visual Explanations . Cheshire, CT: Graphics Press.    See Also  
SnowMap     Examples    data(Snow.deaths) data(Snow.pumps) data(Snow.streets) data(Snow.polygons) data(Snow.deaths) ## Plot deaths over time require(lubridate) clr <- ifelse(Snow.dates$date < mdy(""09/08/1854""), ""red"", ""darkgreen"") plot(deaths ~ date, data=Snow.dates, type=""h"", lwd=2, col=clr) points(deaths ~ date, data=Snow.dates, cex=0.5, pch=16, col=clr) text( mdy(""09/08/1854""), 40, ""Pump handle\nremoved Sept. 8"", pos=4) ## draw Snow's map and data SnowMap() # add polygons SnowMap(polygons=TRUE, main=""Snow's Cholera Map with Pump Polygons"") # zoom in a bit, and show density estimate SnowMap(xlim=c(7.5,16.5), ylim=c(7,16), polygons=TRUE, density=TRUE, main=""Snow's Cholera Map, Annotated"") ## re-do this the sp way... [thx: Stephane Dray] library(sp) # streets slist <- split(Snow.streets[,c(""x"",""y"")],as.factor(Snow.streets[,""street""])) Ll1 <- lapply(slist,Line) Lsl1 <- Lines(Ll1,""Street"") Snow.streets.sp <- SpatialLines(list(Lsl1)) plot(Snow.streets.sp, col=""gray"") title(main=""Snow's Cholera Map of London (sp)"") # deaths Snow.deaths.sp = SpatialPoints(Snow.deaths[,c(""x"",""y"")]) plot(Snow.deaths.sp, add=TRUE, col ='red', pch=15, cex=0.6) # pumps spp <- SpatialPoints(Snow.pumps[,c(""x"",""y"")]) Snow.pumps.sp <- SpatialPointsDataFrame(spp,Snow.pumps[,c(""x"",""y"")]) plot(Snow.pumps.sp, add=TRUE, col='blue', pch=17, cex=1.5) text(Snow.pumps[,c(""x"",""y"")], labels=Snow.pumps$label, pos=1, cex=0.8)"
"HistData-Virginis","HistData","Virginis","John F. W. Herschel's Data on the Orbit of the Twin Stars gamma _Virginis_",18,6,0,2,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Virginis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Virginis.html","Virginis R Documentation    John F. W. Herschel's Data on the Orbit of the Twin Stars γ Virginis     Description  
In 1833 J. F. W. Herschel published two papers in the Memoirs of the Royal Astronomical Society  detailing his investigations of calculating the orbits of twin stars from observations of their relative position angle and angular distance.  
In the process, he invented the scatterplot, and the use of visual smoothing to obtain a reliable curve that surpassed the accuracy of individual observations (Friendly & Denis, 2005). His data on the recordings of the twin stars γ Virginis provide an accessible example of his methods.    Usage    data(""Virginis"") data(""Virginis.interp"")    Format  
Virgins : A data frame with 18 observations on the following 6 variables giving the measurements of position angle and angular distance between the central (brightest) star and its twin, recorded by various observers over more than 100 years.   year
year (""epoch"") of the observation, a decimal numeric vector   posangle
recorded position angle between the two stars, a numeric vector   distance
separation distance between the two stars, a numeric vector   weight
a subjective weight attributed to the accuracy of this observation, a numeric vector   notes
Herschel's notes on this observation, a character vector   authority
A simplified version of the notes giving just the attribution of authority of the observation, a character vector    
Virgins.interp : A data frame with 14 observations on the following 4 variables, giving the position angles and angular distance that Herschel interpolated from his smoothed curve.    year
year (""epoch"") of the observation, a decimal numeric vector   posangle
recorded position angle between the two stars, a numeric vector   distance
separation distance, calculated 1/sqrt(velocity)   velocity
angular velocity, calculated as the instantaneous slopes of tangents to the smoothed curve, a numeric vector     Details  
The data in Virginis come from the table on p. 35 of the “Micrometrical Measures” paper.  
The weight variable was assigned by the package author, reflecting Herschel's comments and for use in any weighted analysis.   
In the notes and authority variables, ""H"" refers to William Herschel (John's farther, the discoverer of the planet Uranus), ""h"" refers to John Herschel himself, and ""Sigma"" , rendered Σ in the table on p. 35 refers to Joseph Fraunhofer.   
The data in Virginis.interp come from Table 1 on p. 190 of the supplementary paper.    Source  
Herschel, J. F. W. III. Micrometrical Measures of 364 Double Stars with a 7-feet Equatorial Acromatic Telescope, taken at Slough, in the years 1828, 1829, and 1830 Memoirs of the Royal Astronomical Society , 1833, 5, 13-91.   
Herschel, J. F. W. On the Investigation of the Orbits of Revolving Double Stars: Being a Supplement to a Paper Entitled ""Micrometrical Measures of 364 Double Stars"" Memoirs of the Royal Astronomical Society , 1833, 5, 171-222.    References  
Friendly, M. & Denis, D. The early origins and development of the scatterplot.  Journal of the History of the Behavioral Sciences , 2005, 41, 103-130.    Examples    data(Virginis) data(Virginis.interp) # Herschel's interpolated curve plot(posangle ~ year, data=Virginis.interp, pch=15, type=""b"", col=""red"", cex=0.8, lwd=2, xlim=c(1710,1840), ylim=c(80, 170), ylab=""Position angle (deg.)"", xlab=""Year"", cex.lab=1.5) # The data points, and indication of their uncertainty points(posangle ~ year, data=Virginis, pch=16) points(posangle ~ year, data=Virginis, cex=weight/2)"
"HistData-Virginis.interp","HistData","Virginis.interp","John F. W. Herschel's Data on the Orbit of the Twin Stars gamma _Virginis_",14,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Virginis.interp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Virginis.interp.html","Virginis R Documentation    John F. W. Herschel's Data on the Orbit of the Twin Stars γ Virginis     Description  
In 1833 J. F. W. Herschel published two papers in the Memoirs of the Royal Astronomical Society  detailing his investigations of calculating the orbits of twin stars from observations of their relative position angle and angular distance.  
In the process, he invented the scatterplot, and the use of visual smoothing to obtain a reliable curve that surpassed the accuracy of individual observations (Friendly & Denis, 2005). His data on the recordings of the twin stars γ Virginis provide an accessible example of his methods.    Usage    data(""Virginis"") data(""Virginis.interp"")    Format  
Virgins : A data frame with 18 observations on the following 6 variables giving the measurements of position angle and angular distance between the central (brightest) star and its twin, recorded by various observers over more than 100 years.   year
year (""epoch"") of the observation, a decimal numeric vector   posangle
recorded position angle between the two stars, a numeric vector   distance
separation distance between the two stars, a numeric vector   weight
a subjective weight attributed to the accuracy of this observation, a numeric vector   notes
Herschel's notes on this observation, a character vector   authority
A simplified version of the notes giving just the attribution of authority of the observation, a character vector    
Virgins.interp : A data frame with 14 observations on the following 4 variables, giving the position angles and angular distance that Herschel interpolated from his smoothed curve.    year
year (""epoch"") of the observation, a decimal numeric vector   posangle
recorded position angle between the two stars, a numeric vector   distance
separation distance, calculated 1/sqrt(velocity)   velocity
angular velocity, calculated as the instantaneous slopes of tangents to the smoothed curve, a numeric vector     Details  
The data in Virginis come from the table on p. 35 of the “Micrometrical Measures” paper.  
The weight variable was assigned by the package author, reflecting Herschel's comments and for use in any weighted analysis.   
In the notes and authority variables, ""H"" refers to William Herschel (John's farther, the discoverer of the planet Uranus), ""h"" refers to John Herschel himself, and ""Sigma"" , rendered Σ in the table on p. 35 refers to Joseph Fraunhofer.   
The data in Virginis.interp come from Table 1 on p. 190 of the supplementary paper.    Source  
Herschel, J. F. W. III. Micrometrical Measures of 364 Double Stars with a 7-feet Equatorial Acromatic Telescope, taken at Slough, in the years 1828, 1829, and 1830 Memoirs of the Royal Astronomical Society , 1833, 5, 13-91.   
Herschel, J. F. W. On the Investigation of the Orbits of Revolving Double Stars: Being a Supplement to a Paper Entitled ""Micrometrical Measures of 364 Double Stars"" Memoirs of the Royal Astronomical Society , 1833, 5, 171-222.    References  
Friendly, M. & Denis, D. The early origins and development of the scatterplot.  Journal of the History of the Behavioral Sciences , 2005, 41, 103-130.    Examples    data(Virginis) data(Virginis.interp) # Herschel's interpolated curve plot(posangle ~ year, data=Virginis.interp, pch=15, type=""b"", col=""red"", cex=0.8, lwd=2, xlim=c(1710,1840), ylim=c(80, 170), ylab=""Position angle (deg.)"", xlab=""Year"", cex.lab=1.5) # The data points, and indication of their uncertainty points(posangle ~ year, data=Virginis, pch=16) points(posangle ~ year, data=Virginis, cex=weight/2)"
"HistData-Wheat","HistData","Wheat","Playfair's Data on Wages and the Price of Wheat",53,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Wheat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Wheat.html","Wheat R Documentation    Playfair's Data on Wages and the Price of Wheat    Description  
Playfair (1821) used a graph, showing parallel time-series of the price of wheat and the typical weekly wage for a ""good mechanic"" from 1565 to 1821 to argue that working men had never been as well-off in terms of purchasing power as they had become toward the end of this period.  
His graph is a classic in the history of data visualization, but commits the sin of showing two non-commensurable Y variables on different axes. Scatterplots of wages vs. price or plots of ratios (e.g., wages/price) are in some ways better, but both of these ideas were unknown in 1821.   
In this version, information on the reigns of British monarchs is provided in a separate data.frame, Wheat.monarch .    Usage    data(Wheat) data(Wheat.monarchs)    Format  
Wheat  A data frame with 53 observations on the following 3 variables.    Year
Year, in intervals of 5 from 1565 to 1821: a numeric vector   Wheat
Price of Wheat (Shillings/Quarter bushel): a numeric vector   Wages
Weekly wage (Shillings): a numeric vector    
Wheat.monarchs  A data frame with 12 observations on the following 4 variables.    name
Reigning monarch, a factor with levels Anne Charles I Charles II Cromwell Elizabeth George I George II George III George IV James I James II W&M   start
Starting year of reign, a numeric vector   end
Starting year of reign, a numeric vector   commonwealth
A binary variable indicating the period of the Commonwealth under Cromwell     Source  
Playfair, W. (1821). Letter on our Agricultural Distresses, Their Causes and Remedies . London: W. Sams, 1821   
Data values: originally digitized from http://datavis.ca/gallery/images/playfair-wheat1.gif  now taken from http://mbostock.github.io/protovis/ex/wheat.js     References  
Friendly, M. & Denis, D. (2005). The early origins and development of the scatterplot Journal of the History of the Behavioral Sciences , 41, 103-130.    Examples    data(Wheat) data(Wheat) # ------------------------------------ # Playfair's graph, largely reproduced # ------------------------------------ # convenience function to fill area under a curve down to a minimum value fillpoly <- function(x,y, low=min(y), ...) { n <- length(x) polygon( c(x, x[n], x[1]), c(y, low, low), ...) } # For best results, this graph should be viewed with width ~ 2 * height # Note use of type='s' to plot a step function for Wheat # and panel.first to provide a background grid() # The curve for Wages is plotted after the polygon below it is filled with(Wheat, { plot(Year, Wheat, type=""s"", ylim=c(0,105), ylab=""Price of the Quarter of Wheat (shillings)"", panel.first=grid(col=gray(.9), lty=1)) fillpoly(Year, Wages, low=0, col=""lightskyblue"", border=NA) lines(Year, Wages, lwd=3, col=""red"") }) # add some annotations text(1625,10, ""Weekly wages of a good mechanic"", cex=0.8, srt=3, col=""red"") # cartouche text(1650, 85, ""Chart"", cex=2, font=2) text(1650, 70, paste(""Shewing at One View"", ""The Price of the Quarter of Wheat"", ""& Wages of Labor by the Week"", ""from the Year 1565 to 1821"", ""by William Playfair"", sep=""\n""), font=3) # add the time series bars to show reigning monarchs # distinguish Cromwell visually, as Playfair did with(Wheat.monarchs, { y <- ifelse( !commonwealth & (!seq_along(start) %% 2), 102, 104) segments(start, y, end, y, col=""black"", lwd=7, lend=1) segments(start, y, end, y, col=ifelse(commonwealth, ""white"", NA), lwd=4, lend=1) text((start+end)/2, y-2, name, cex=0.5) }) # ----------------------------------------- # plot the labor cost of a quarter of wheat # ----------------------------------------- Wheat1 <- within(na.omit(Wheat), {Labor=Wheat/Wages}) with(Wheat1, { plot(Year, Labor, type='b', pch=16, cex=1.5, lwd=1.5, ylab=""Labor cost of a Quarter of Wheat (weeks)"", ylim=c(1,12.5)); lines(lowess(Year, Labor), col=""red"", lwd=2) }) # cartouche text(1740, 10, ""Chart"", cex=2, font=2) text(1740, 8.5, paste(""Shewing at One View"", ""The Work Required to Purchase"", ""One Quarter of Wheat"", sep=""\n""), cex=1.5, font=3) with(Wheat.monarchs, { y <- ifelse( !commonwealth & (!seq_along(start) %% 2), 12.3, 12.5) segments(start, y, end, y, col=""black"", lwd=7, lend=1) segments(start, y, end, y, col=ifelse(commonwealth, ""white"", NA), lwd=4, lend=1) text((start+end)/2, y-0.2, name, cex=0.5) })"
"HistData-Wheat.monarchs","HistData","Wheat.monarchs","Playfair's Data on Wages and the Price of Wheat",12,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Wheat.monarchs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Wheat.monarchs.html","Wheat R Documentation    Playfair's Data on Wages and the Price of Wheat    Description  
Playfair (1821) used a graph, showing parallel time-series of the price of wheat and the typical weekly wage for a ""good mechanic"" from 1565 to 1821 to argue that working men had never been as well-off in terms of purchasing power as they had become toward the end of this period.  
His graph is a classic in the history of data visualization, but commits the sin of showing two non-commensurable Y variables on different axes. Scatterplots of wages vs. price or plots of ratios (e.g., wages/price) are in some ways better, but both of these ideas were unknown in 1821.   
In this version, information on the reigns of British monarchs is provided in a separate data.frame, Wheat.monarch .    Usage    data(Wheat) data(Wheat.monarchs)    Format  
Wheat  A data frame with 53 observations on the following 3 variables.    Year
Year, in intervals of 5 from 1565 to 1821: a numeric vector   Wheat
Price of Wheat (Shillings/Quarter bushel): a numeric vector   Wages
Weekly wage (Shillings): a numeric vector    
Wheat.monarchs  A data frame with 12 observations on the following 4 variables.    name
Reigning monarch, a factor with levels Anne Charles I Charles II Cromwell Elizabeth George I George II George III George IV James I James II W&M   start
Starting year of reign, a numeric vector   end
Starting year of reign, a numeric vector   commonwealth
A binary variable indicating the period of the Commonwealth under Cromwell     Source  
Playfair, W. (1821). Letter on our Agricultural Distresses, Their Causes and Remedies . London: W. Sams, 1821   
Data values: originally digitized from http://datavis.ca/gallery/images/playfair-wheat1.gif  now taken from http://mbostock.github.io/protovis/ex/wheat.js     References  
Friendly, M. & Denis, D. (2005). The early origins and development of the scatterplot Journal of the History of the Behavioral Sciences , 41, 103-130.    Examples    data(Wheat) data(Wheat) # ------------------------------------ # Playfair's graph, largely reproduced # ------------------------------------ # convenience function to fill area under a curve down to a minimum value fillpoly <- function(x,y, low=min(y), ...) { n <- length(x) polygon( c(x, x[n], x[1]), c(y, low, low), ...) } # For best results, this graph should be viewed with width ~ 2 * height # Note use of type='s' to plot a step function for Wheat # and panel.first to provide a background grid() # The curve for Wages is plotted after the polygon below it is filled with(Wheat, { plot(Year, Wheat, type=""s"", ylim=c(0,105), ylab=""Price of the Quarter of Wheat (shillings)"", panel.first=grid(col=gray(.9), lty=1)) fillpoly(Year, Wages, low=0, col=""lightskyblue"", border=NA) lines(Year, Wages, lwd=3, col=""red"") }) # add some annotations text(1625,10, ""Weekly wages of a good mechanic"", cex=0.8, srt=3, col=""red"") # cartouche text(1650, 85, ""Chart"", cex=2, font=2) text(1650, 70, paste(""Shewing at One View"", ""The Price of the Quarter of Wheat"", ""& Wages of Labor by the Week"", ""from the Year 1565 to 1821"", ""by William Playfair"", sep=""\n""), font=3) # add the time series bars to show reigning monarchs # distinguish Cromwell visually, as Playfair did with(Wheat.monarchs, { y <- ifelse( !commonwealth & (!seq_along(start) %% 2), 102, 104) segments(start, y, end, y, col=""black"", lwd=7, lend=1) segments(start, y, end, y, col=ifelse(commonwealth, ""white"", NA), lwd=4, lend=1) text((start+end)/2, y-2, name, cex=0.5) }) # ----------------------------------------- # plot the labor cost of a quarter of wheat # ----------------------------------------- Wheat1 <- within(na.omit(Wheat), {Labor=Wheat/Wages}) with(Wheat1, { plot(Year, Labor, type='b', pch=16, cex=1.5, lwd=1.5, ylab=""Labor cost of a Quarter of Wheat (weeks)"", ylim=c(1,12.5)); lines(lowess(Year, Labor), col=""red"", lwd=2) }) # cartouche text(1740, 10, ""Chart"", cex=2, font=2) text(1740, 8.5, paste(""Shewing at One View"", ""The Work Required to Purchase"", ""One Quarter of Wheat"", sep=""\n""), cex=1.5, font=3) with(Wheat.monarchs, { y <- ifelse( !commonwealth & (!seq_along(start) %% 2), 12.3, 12.5) segments(start, y, end, y, col=""black"", lwd=7, lend=1) segments(start, y, end, y, col=ifelse(commonwealth, ""white"", NA), lwd=4, lend=1) text((start+end)/2, y-0.2, name, cex=0.5) })"
"HistData-Yeast","HistData","Yeast","Student's (1906) Yeast Cell Counts",36,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/Yeast.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/Yeast.html","Yeast R Documentation    Student's (1906) Yeast Cell Counts    Description  
Counts of the number of yeast cells were made each of 400 regions in a 20 x 20 grid on a microscope slide, comprising a 1 sq. mm. area. This experiment was repeated four times, giving samples A, B, C and D.   
Student (1906) used these data to investigate the errors in random sampling. He says ""there are two sources of error: (a) the drop taken may not be representative of the bulk of the liquid; (b) the distribution of the cells over the area which is examined is never exactly uniform, so that there is an 'error of random sampling.'""   
The data in the paper are provided in the form of discrete frequency distributions for the four samples. Each shows the frequency distribution squares containing a count of 0, 1, 2, ... yeast cells. These are combined here in Yeast . In addition, he gives a table (Table I) showing the actual number of yeast cells counted in the 20 x 20 grid for sample D, given here as YeastD.mat .    Usage    data(Yeast) data(YeastD.mat)    Format  
Yeast : A frequency data frame with 36 observations on the following 3 variables, giving the frequencies of   sample
Sample identifier, a factor with levels A B C D   count
The number of yeast cells counted in a square   freq
The number of squares with the given count    
YeastD.mat : A 20 x 20 matrix containing the count of yeast cells in each square for sample D.   Details  
Student considers the distribution of a total of Nm particles distributed over  N unit areas with an average of m particles per unit area. With uniform mixing, for a given particle, the probability of it falling on any one area is p = 1/N , and not falling on that area is q = 1 - 1/N . He derives the probability distribution of 0, 1, 2, 3, ... particles on a single unit area from the binomial expansion of (p + q)^{mN} .    Source  
D. J. Hand, F. Daly, D. Lunn, K. McConway and E. Ostrowski (1994). A Handbook of Small Data Sets . London: Chapman \& Hall. The data were originally found at: https://www2.stat.duke.edu/courses/Spring98/sta113/Data/Hand/yeast.dat    References  
""Student"" (1906) On the error of counting with a haemocytometer. Biometrika, 5, 351-360.  http://www.medicine.mcgill.ca/epidemiology/hanley/c626/Student_counting.pdf     Examples    data(Yeast) require(lattice) # basic bar charts # TODO: frequencies should start at 0, not 1. barchart(count~freq|sample, data=Yeast, ylab=""Number of Cells"", xlab=""Frequency"") barchart(freq~count|sample, data=Yeast, xlab=""Number of Cells"", ylab=""Frequency"", horizontal=FALSE, origin=0) # same, using xyplot xyplot(freq~count|sample, data=Yeast, xlab=""Number of Cells"", ylab=""Frequency"", horizontal=FALSE, origin=0, type=""h"", lwd=10)"
"HistData-YeastD.mat","HistData","YeastD.mat","Student's (1906) Yeast Cell Counts",20,20,0,0,0,0,20,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/YeastD.mat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/YeastD.mat.html","Yeast R Documentation    Student's (1906) Yeast Cell Counts    Description  
Counts of the number of yeast cells were made each of 400 regions in a 20 x 20 grid on a microscope slide, comprising a 1 sq. mm. area. This experiment was repeated four times, giving samples A, B, C and D.   
Student (1906) used these data to investigate the errors in random sampling. He says ""there are two sources of error: (a) the drop taken may not be representative of the bulk of the liquid; (b) the distribution of the cells over the area which is examined is never exactly uniform, so that there is an 'error of random sampling.'""   
The data in the paper are provided in the form of discrete frequency distributions for the four samples. Each shows the frequency distribution squares containing a count of 0, 1, 2, ... yeast cells. These are combined here in Yeast . In addition, he gives a table (Table I) showing the actual number of yeast cells counted in the 20 x 20 grid for sample D, given here as YeastD.mat .    Usage    data(Yeast) data(YeastD.mat)    Format  
Yeast : A frequency data frame with 36 observations on the following 3 variables, giving the frequencies of   sample
Sample identifier, a factor with levels A B C D   count
The number of yeast cells counted in a square   freq
The number of squares with the given count    
YeastD.mat : A 20 x 20 matrix containing the count of yeast cells in each square for sample D.   Details  
Student considers the distribution of a total of Nm particles distributed over  N unit areas with an average of m particles per unit area. With uniform mixing, for a given particle, the probability of it falling on any one area is p = 1/N , and not falling on that area is q = 1 - 1/N . He derives the probability distribution of 0, 1, 2, 3, ... particles on a single unit area from the binomial expansion of (p + q)^{mN} .    Source  
D. J. Hand, F. Daly, D. Lunn, K. McConway and E. Ostrowski (1994). A Handbook of Small Data Sets . London: Chapman \& Hall. The data were originally found at: https://www2.stat.duke.edu/courses/Spring98/sta113/Data/Hand/yeast.dat    References  
""Student"" (1906) On the error of counting with a haemocytometer. Biometrika, 5, 351-360.  http://www.medicine.mcgill.ca/epidemiology/hanley/c626/Student_counting.pdf     Examples    data(Yeast) require(lattice) # basic bar charts # TODO: frequencies should start at 0, not 1. barchart(count~freq|sample, data=Yeast, ylab=""Number of Cells"", xlab=""Frequency"") barchart(freq~count|sample, data=Yeast, xlab=""Number of Cells"", ylab=""Frequency"", horizontal=FALSE, origin=0) # same, using xyplot xyplot(freq~count|sample, data=Yeast, xlab=""Number of Cells"", ylab=""Frequency"", horizontal=FALSE, origin=0, type=""h"", lwd=10)"
"HistData-ZeaMays","HistData","ZeaMays","Darwin's Heights of Cross- and Self-fertilized Zea May Pairs",15,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HistData/ZeaMays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HistData/ZeaMays.html","ZeaMays R Documentation    Darwin's Heights of Cross- and Self-fertilized Zea May Pairs    Description  
Darwin (1876) studied the growth of pairs of zea may (aka corn) seedlings, one produced by cross-fertilization and the other produced by self-fertilization, but otherwise grown under identical conditions. His goal was to demonstrate the greater vigour of the cross-fertilized plants. The data recorded are the final height (inches, to the nearest 1/8th) of the plants in each pair.   
In the Design of Experiments , Fisher (1935) used these data to illustrate a paired t-test (well, a one-sample test on the mean difference, cross - self ). Later in the book (section 21), he used this data to illustrate an early example of a non-parametric permutation test, treating each paired difference as having (randomly) either a positive or negative sign.   Usage   data(ZeaMays)   Format  
A data frame with 15 observations on the following 4 variables.    pair
pair number, a numeric vector   pot
pot, a factor with levels 1 2 3 4   cross
height of cross fertilized plant, a numeric vector   self
height of self fertilized plant, a numeric vector   diff
cross - self for each pair     Details  
In addition to the standard paired t-test, several types of non-parametric tests can be contemplated:   
(a) Permutation test, where the values of, say self are permuted and diff=cross - self  is calculated for each permutation. There are 15! permutations, but a reasonably large number of random permutations would suffice. But this doesn't take the paired samples into account.   
(b) Permutation test based on assigning each abs(diff) a + or - sign, and calculating the mean(diff). There are 2^{15} such possible values. This is essentially what Fisher proposed. The p-value for the test is the proportion of absolute mean differences under such randomization which exceed the observed mean difference.   
(c) Wilcoxon signed rank test: tests the hypothesis that the median signed rank of the diff is zero, or that the distribution of diff is symmetric about 0, vs. a location shifted alternative.    Source  
Darwin, C. (1876). The Effect of Cross- and Self-fertilization in the Vegetable Kingdom , 2nd Ed. London: John Murray.   
Andrews, D. and Herzberg, A. (1985) Data: a collection of problems from many fields for the student and research worker . New York: Springer. Data retrieved from: https://www.stat.cmu.edu/StatDat/     References  
Fisher, R. A. (1935). The Design of Experiments . London: Oliver & Boyd.    See Also  
wilcox.test    
independence_test in the coin package, a general framework for conditional inference procedures (permutation tests)    Examples    data(ZeaMays) ################################## ## Some preliminary exploration ## ################################## boxplot(ZeaMays[,c(""cross"", ""self"")], ylab=""Height (in)"", xlab=""Fertilization"") # examine large individual diff/ces largediff <- subset(ZeaMays, abs(diff) > 2*sd(abs(diff))) with(largediff, segments(1, cross, 2, self, col=""red"")) # plot cross vs. self. NB: unusual trend and some unusual points with(ZeaMays, plot(self, cross, pch=16, cex=1.5)) abline(lm(cross ~ self, data=ZeaMays), col=""red"", lwd=2) # pot effects ? anova(lm(diff ~ pot, data=ZeaMays)) ############################## ## Tests of mean difference ## ############################## # Wilcoxon signed rank test # signed ranks: with(ZeaMays, sign(diff) * rank(abs(diff))) wilcox.test(ZeaMays$cross, ZeaMays$self, conf.int=TRUE, exact=FALSE) # t-tests with(ZeaMays, t.test(cross, self)) with(ZeaMays, t.test(diff)) mean(ZeaMays$diff) # complete permutation distribution of diff, for all 2^15 ways of assigning # one value to cross and the other to self (thx: Bert Gunter) N <- nrow(ZeaMays) allmeans <- as.matrix(expand.grid(as.data.frame( matrix(rep(c(-1,1),N), nr =2)))) %*% abs(ZeaMays$diff) / N # upper-tail p-value sum(allmeans > mean(ZeaMays$diff)) / 2^N # two-tailed p-value sum(abs(allmeans) > mean(ZeaMays$diff)) / 2^N hist(allmeans, breaks=64, xlab=""Mean difference, cross-self"", main=""Histogram of all mean differences"") abline(v=c(1, -1)*mean(ZeaMays$diff), col=""red"", lwd=2, lty=1:2) plot(density(allmeans), xlab=""Mean difference, cross-self"", main=""Density plot of all mean differences"") abline(v=c(1, -1)*mean(ZeaMays$diff), col=""red"", lwd=2, lty=1:2)"
"HLMdiag-ahd","HLMdiag","ahd","Methylprednisolone data",330,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HLMdiag/ahd.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HLMdiag/ahd.html","ahd R Documentation   Methylprednisolone data   Description  
Data from a longitudinal study examining the effectiveness of Methylprednisolone as a treatment for patients with severe alcoholic hepatitis. Subjects were randomly assigned to a treatment (31 received a placebo, 35 received the treatment) and serum bilirubin was measures each week for four weeks.    Usage    data(ahd)    Format  
A data frame with 330 observations on the following 5 variables:    treatment
The treatment a subject received - a factor. Levels are  placebo and treated .   subject
Subject ID - a factor.   week
Week of the study (0–4) - the time variable.   sbvalue
Serum bilirubin level (in μ mol/L).   baseline
A subject's serum bilirubin level at week 0.     Source  
Vonesh, E. F. and Chinchilli, V. M. (1997) Linear and Nonlinear Models for the Analysis of Repeated Measurements . Marcel Dekker, New York.    References  
Carithers, R. L., Herlong, H. F., Diehl, A. M., Shaw, E. W., Combes, B., Fallon, H. J. & Maddrey, W. C. (1989) Methylprednisolone therapy in patients with severe alcoholic hepatitis. Annals of Internal Medicine , 110 (9), 685–690."
"HLMdiag-autism","HLMdiag","autism","Autism data",604,7,3,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HLMdiag/autism.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HLMdiag/autism.html","autism R Documentation   Autism data   Description  
Data from a prospective longitudinal study following 214 children between the ages of 2 and 13 who were diagnosed with either autism spectrum disorder or non-spectrum developmental delays at age 2.    Usage    data(autism)    Format  
A data frame with 604 observation on the following 7 variables:    childid
Child ID.   sicdegp
Sequenced Inventory of Communication Development group (an assessment of expressive language development) - a factor. Levels are low , med , and high .   age2
Age (in years) centered around age 2 (age at diagnosis).   vsae
Vineland Socialization Age Equivalent   gender
Child's gender - a factor. Levels are male and female .   race
Child's race - a factor. Levels are white and nonwhite .   bestest2
Diagnosis at age 2 - a factor. Levels are autism and pdd (pervasive developmental disorder).     Source  
http://www-personal.umich.edu/~kwelch/     References  
Anderson, D. K., Lord, C., Risi, S., DiLavore, P. S., Shulman, C., Thurm, A., et al. (2007). Patterns of growth in verbal abilities among children with autism spectrum disorder. Journal of Consulting and Clinical Psychology , 75 (4), 594–604.  
Anderson, D. K., Oti, R. S., Lord, C., & Welch, K. (2009). Patterns of Growth in Adaptive Social Abilities Among Children with Autism Spectrum Disorders. Journal of Abnormal Child Psychology , 37 (7), 1019–1034."
"HLMdiag-radon","HLMdiag","radon","Radon data",919,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HLMdiag/radon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HLMdiag/radon.html","radon R Documentation   Radon data   Description  
Radon measurements of 919 owner-occupied homes in 85 counties of Minnesota.    Usage    data(radon)    Format  
A data frame with 919 observations on the following 5 variables:    log.radon
Radon measurement (in log pCi/L, i.e., log picoCurie per liter)   basement
Indicator for the level of the home at which the radon measurement was taken - 0 = basement, 1 = first floor.   uranium
Average county-level soil uranium content.   county
County ID.   county.name
County name - a factor.     Source  
http://www.stat.columbia.edu/~gelman/arm/software/     References  
Price, P. N., Nero, A. V. and Gelman, A. (1996) Bayesian prediction of mean indoor radon concentrations for Minnesota counties. Health Physics .  71 (6), 922–936.   
Gelman, A. and Hill, J. (2007) Data analysis using regression and multilevel/hierarchical models . Cambridge University Press."
"HLMdiag-wages","HLMdiag","wages","Wages for male high school dropouts",6402,15,3,0,3,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/HLMdiag/wages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HLMdiag/wages.html","wages R Documentation   Wages for male high school dropouts   Description  
Data on the labor-market experience of male high school dropouts.    Format  
A data frame with 6402 observations on the following 15 variables.    id
respondent id - a factor with 888 levels.   lnw
natural log of wages expressed in 1990 dollars.   exper
years of experience in the work force   ged
equals 1 if respondent has obtained a GED as of the time of survey, 0 otherwise   postexp
labor force participation since obtaining a GED (in years) - before a GED is earned postexp = 0, and on the day a GED is earned postexp = 0   black
factor - equals 1 if subject is black, 0 otherwise   hispanic
factor - equals 1 if subject is hispanic, 0 otherwise   hgc
highest grade completed - takes integers 6 through 12   hgc.9
hgc - 9, a centered version of hgc   uerate
local area unemployment rate for that year   ue.7 ue.centert1 ue.mean ue.person.cen ue1   Source  
These data are originally from the 1979 National Longitudinal Survey on Youth (NLSY79).   
Singer and Willett (2003) used these data for examples in chapter (insert info. here) and the data sets used can be found on the UCLA Statistical Computing website:  https://stats.idre.ucla.edu/other/examples/alda/    
Additionally the data were discussed by Cook and Swayne (2003) and the data can be found on the GGobi website:  http://ggobi.org/book.html .    References  
Singer, J. D. and Willett, J. B. (2003), Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence , New York: Oxford University Press.   
Cook, D. and Swayne, D. F. (2007), Interactive and Dynamic Graphics for Data Analysis with R and GGobi , Springer.    Examples    str(wages) summary(wages) ## Not run: library(lme4) lmer(lnw ~ exper + (exper | id), data = wages) ## End(Not run)"
"HSAUR-agefat","HSAUR","agefat","Total Body Composision Data",25,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/agefat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/agefat.html","agefat R Documentation   Total Body Composision Data   Description  
Age and body fat percentage of 25 normal adults.    Usage   data(""agefat"")   Format  
A data frame with 25 observations on the following 3 variables.    age
the age of the subject.   fat
the body fat percentage.   sex
a factor with levels female and male .     Details  
The data come from a study investigating a new methods of measuring body composition (see Mazess et al, 1984), and give the body fat percentage (percent fat), age and sex for 25 normal adults aged between 23 and 61 years. The questions of interest are how are age and percent fat related, and is there any evidence that the relationship is different for males and females.    Source  
R. B. Mazess, W. W. Peppler and M. Gibbons (1984), Total body composition by dual-photon (153Gd) absorptiometry. American Journal of Clinical Nutrition , 40 , 834–839.    Examples    data(""agefat"", package = ""HSAUR"") plot(fat ~ age, data = agefat)"
"HSAUR-aspirin","HSAUR","aspirin","Aspirin Data",7,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/aspirin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/aspirin.html","aspirin R Documentation   Aspirin Data   Description  
Efficacy of Aspirin in preventing death after a myocardial infarct.    Usage   data(""aspirin"")   Format  
A data frame with 7 observations on the following 4 variables.    dp
number of deaths after placebo.   tp
total number subjects treated with placebo.   da
number of deaths after Aspirin.   ta
total number of subjects treated with Aspirin.     Details  
The data were collected for a meta-analysis of the effectiveness of Aspirin (versus placebo) in preventing death after a myocardial infarction.   Source  
J. L. Fleiss (1993), The statistical basis of meta-analysis.  Statistical Methods in Medical Research 2 , 121–145.    Examples    data(""aspirin"", package = ""HSAUR"") aspirin"
"HSAUR-BCG","HSAUR","BCG","BCG Vaccine Data",13,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/BCG.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/BCG.html","BCG R Documentation   BCG Vaccine Data   Description  
A meta-analysis on the efficacy of BCG vaccination against tuberculosis (TB).    Usage   data(""BCG"")   Format  
A data frame with 13 observations on the following 7 variables.    Study
an identifier of the study.   BCGTB
the number of subjects suffering from TB after a BCG vaccination.   BCGVacc
the number of subjects with BCG vaccination.   NoVaccTB
the number of subjects suffering from TB without BCG vaccination.   NoVacc
the total number of subjects without BCG vaccination.   Latitude
geographic position of the place the study was undertaken.   Year
the year the study was undertaken.     Details  
Bacille Calmette Guerin (BCG) is the most widely used vaccination in the world. Developed in the 1930s and made of a live, weakened strain of Mycobacterium bovis, the BCG is the only vaccination available against tuberculosis today. Colditz et al. (1994) report data from 13 clinical trials of BCG vaccine each investigating its efficacy in the treatment of tuberculosis. The number of subjects suffering from TB with or without BCG vaccination are given here. In addition, the data contains the values of two other variables for each study, namely, the geographic latitude of the place where the study was undertaken and the year of publication. These two variables will be used to investigate and perhaps explain any heterogeneity among the studies.    Source  
G. A. Colditz, T. F. Brewer, C. S. Berkey, M. E. Wilson, E. Burdick, H. V. Fineberg and F. Mosteller (1994), Efficacy of BCG vaccine in the prevention of tuberculosis. Meta-analysis of the published literature. Journal of the American Medical Association , 271 (2), 698–702.    Examples    data(""BCG"", package = ""HSAUR"") boxplot(BCG$BCGTB/BCG$BCGVacc, BCG$NoVaccTB/BCG$NoVacc, names = c(""BCG Vaccination"", ""No Vaccination""), ylab = ""Percent BCG cases"")"
"HSAUR-birthdeathrates","HSAUR","birthdeathrates","Birth and Death Rates Data",69,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/birthdeathrates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/birthdeathrates.html","birthdeathrates R Documentation   Birth and Death Rates Data   Description  
Birth and death rates for 69 countries.    Usage   data(""birthdeathrates"")   Format  
A data frame with 69 observations on the following 2 variables.    birth
birth rate.   death
death rate.     Source  
J. A. Hartigan (1975), Clustering Algorithms . John Wiley & Sons, New York.    Examples    data(""birthdeathrates"", package = ""HSAUR"") plot(birthdeathrates)"
"HSAUR-bladdercancer","HSAUR","bladdercancer","Bladder Cancer Data",31,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/bladdercancer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/bladdercancer.html","bladdercancer R Documentation   Bladder Cancer Data   Description  
Data arise from 31 male patients who have been treated for superficial bladder cancer, and give the number of recurrent tumours during a particular time after the removal of the primary tumour, along with the size of the original tumour.    Usage   data(""bladdercancer"")   Format  
A data frame with 31 observations on the following 3 variables.    time
the duration.   tumorsize
a factor with levels <=3cm and >3cm .   number
number of recurrent tumours.     Details  
The aim is the estimate the effect of size of tumour on the number of recurrent tumours.    Source  
G. U. H. Seeber (1998), Poisson Regression. In: Encyclopedia of Biostatistics  (P. Armitage and T. Colton, eds), John Wiley \& Sons, Chichester.    Examples    data(""bladdercancer"", package = ""HSAUR"") mosaicplot(xtabs(~ number + tumorsize, data = bladdercancer))"
"HSAUR-BtheB","HSAUR","BtheB","Beat the Blues Data",100,8,3,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/BtheB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/BtheB.html","BtheB R Documentation   Beat the Blues Data   Description  
Data from a clinical trial of an interactive multimedia program called ‘Beat the Blues’.    Usage   data(""BtheB"")   Format  
A data frame with 100 observations of 100 patients on the following 8 variables.    drug
did the patient take anti-depressant drugs ( No or Yes ).   length
the length of the current episode of depression, a factor with levels <6m (less than six months) and >6m (more than six months).   treatment
treatment group, a factor with levels TAU (treatment as usual) and BtheB (Beat the Blues)   bdi.pre
Beck Depression Inventory II before treatment.   bdi.2m
Beck Depression Inventory II after two months.   bdi.4m
Beck Depression Inventory II after four months.   bdi.6m
Beck Depression Inventory II after six months.   bdi.8m
Beck Depression Inventory II after eight months.     Details  
Longitudinal data from a clinical trial of an interactive, multimedia program known as ""Beat the Blues"" designed to deliver cognitive behavioural therapy to depressed patients via a computer terminal. Patients with depression recruited in primary care were randomised to either the Beating the Blues program, or to ""Treatment as Usual (TAU)"".  
Note that the data are stored in the wide form, i.e., repeated measurments are represented by additional columns in the data frame.    Source  
J. Proudfoot, D. Goldberg and A. Mann (2003). Computerised, interactive, multimedia CBT reduced anxiety and depression in general practice: A RCT.  Psychological Medicine , 33 , 217–227.    Examples    data(""BtheB"", package = ""HSAUR"") layout(matrix(1:2, nrow = 1)) ylim <- range(BtheB[,grep(""bdi"", names(BtheB))], na.rm = TRUE) boxplot(subset(BtheB, treatment == ""TAU"")[,grep(""bdi"", names(BtheB))], main = ""Treated as usual"", ylab = ""BDI"", xlab = ""Time (in months)"", names = c(0, 2, 4, 6, 8), ylim = ylim) boxplot(subset(BtheB, treatment == ""BtheB"")[,grep(""bdi"", names(BtheB))], main = ""Beat the Blues"", ylab = ""BDI"", xlab = ""Time (in months)"", names = c(0, 2, 4, 6, 8), ylim = ylim)"
"HSAUR-clouds","HSAUR","clouds","Cloud Seeding Data",24,7,2,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/clouds.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/clouds.html","clouds R Documentation   Cloud Seeding Data   Description  
Data from an experiment investigating the use of massive amounts of silver iodide (100 to 1000 grams per cloud) in cloud seeding to increase rainfall.    Usage   data(""clouds"")   Format  
A data frame with 24 observations on the following 7 variables.    seeding
a factor indicating whether seeding action occured ( no  or yes ).   time
number of days after the first day of the experiment.   sne
suitability criterion.   cloudcover
the percentage cloud cover in the experimental area, measured using radar.   prewetness
the total rainfall in the target area one hour before seeding (in cubic metres times 1e+8 ).   echomotion
a factor showing whether the radar echo was  moving or stationary .   rainfall
the amount of rain in cubic metres times 1e+8 .     Details  
Weather modification, or cloud seeding, is the treatment of individual clouds or storm systems with various inorganic and organic materials in the hope of achieving an increase in rainfall. Introduction of such material into a cloud that contains supercooled water, that is, liquid water colder than zero Celsius, has the aim of inducing freezing, with the consequent ice particles growing at the expense of liquid droplets and becoming heavy enough to fall as rain from clouds that otherwise would produce none.   
The data available in cloud were collected in the summer of 1975 from an experiment to investigate the use of massive amounts of silver iodide 100 to 1000 grams per cloud) in cloud seeding to increase rainfall. In the experiment, which was conducted in an area of Florida, 24 days were judged suitable for seeding on the basis that a measured suitability criterion ( SNE ).    Source  
W. L. Woodley, J. Simpson, R. Biondini and J. Berkeley (1977), Rainfall results 1970-75: Florida area cumulus experiment.  Science 195 , 735–742.   
R. D. Cook and S. Weisberg (1980), Characterizations of an empirical influence function for detecting influential cases in regression. Technometrics 22 , 495–508.    Examples    data(""clouds"", package = ""HSAUR"") layout(matrix(1:2, nrow = 2)) boxplot(rainfall ~ seeding, data = clouds, ylab = ""Rainfall"") boxplot(rainfall ~ echomotion, data = clouds, ylab = ""Rainfall"")"
"HSAUR-CYGOB1","HSAUR","CYGOB1","CYG OB1 Star Cluster Data",47,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/CYGOB1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/CYGOB1.html","CYGOB1 R Documentation   CYG OB1 Star Cluster Data   Description  
Energy output and surface termperature for Star Cluster CYG OB1.    Usage   data(""CYGOB1"")   Format  
A data frame with 47 observations on the following 2 variables.    logst
log survface termperature of the star.   logli
log light intensity of the star.     Details  
The Hertzsprung-Russell (H-R) diagram forms the basis of the theory of stellar evolution. The diagram is essentially a plot of the energy output of stars plotted against their surface temperature. Data from the H-R diagram of Star Cluster CYG OB1, calibrated according to VanismaGreve1972 are given here.    Source  
F. Vanisma and J. P. De Greve (1972), Close binary systems before and after mass transfer. Astrophysics and Space Science ,  87 , 377–401.   
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""CYGOB1"", package = ""HSAUR"") plot(logst ~ logli, data = CYGOB1)"
"HSAUR-epilepsy","HSAUR","epilepsy","Epilepsy Data",236,6,1,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/epilepsy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/epilepsy.html","epilepsy R Documentation   Epilepsy Data   Description  
A randomised clinical trial investigating the effect of an anti-epileptic drug.    Usage   data(""epilepsy"")   Format  
A data frame with 236 observations on the following 6 variables.    treatment
the treatment group, a factor with levels placebo  and Progabide .   base
the number of seizures before the trial.   age
the age of the patient.   seizure.rate
the number of seizures (response variable).   period
treatment period, an ordered factor with levels  1 to 4 .   subject
the patient ID, a factor with levels 1 to  59 .     Details  
In this clinical trial, 59 patients suffering from epilepsy were randomized to groups receiving either the anti-epileptic drug Progabide or a placebo in addition to standard chemotherapy. The numbers of seizures suffered in each of four, two-week periods were recorded for each patient along with a baseline seizure count for the 8 weeks prior to being randomized to treatment and age. The main question of interest is whether taking progabide reduced the number of epileptic seizures compared with placebo.    Source  
P. F. Thall and S. C. Vail (1990), Some covariance models for longitudinal count data with overdispersion. Biometrics , 46 , 657–671.    Examples    data(""epilepsy"", package = ""HSAUR"") library(lattice) dotplot(I(seizure.rate / base) ~ period | subject, data = epilepsy, subset = treatment == ""Progabide"") dotplot(I(seizure.rate / base) ~ period | subject, data = epilepsy, subset = treatment == ""Progabide"")"
"HSAUR-Forbes2000","HSAUR","Forbes2000","The Forbes 2000 Ranking of the World's Biggest Companies (Year 2004)",2000,8,0,1,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/Forbes2000.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/Forbes2000.html","Forbes2000 R Documentation   The Forbes 2000 Ranking of the World's Biggest Companies (Year 2004)   Description  
The Forbes 2000 list is a ranking of the world's biggest companies, measured by sales, profits, assets and market value.    Usage   data(""Forbes2000"")   Format  
A data frame with 2000 observations on the following 8 variables.    rank
the ranking of the company.   name
the name of the company.   country
a factor giving the country the company is situated in.   category
a factor describing the products the company produces.   sales
the amount of sales of the company in billion USD.   profits
the profit of the company in billion USD.   assets
the assets of the company in billion USD.   marketvalue
the market value of the company in billion USD.     Source  
http://www.forbes.com , assessed on November 26th, 2004.    Examples    data(""Forbes2000"", package = ""HSAUR"") summary(Forbes2000) ### number of countries length(levels(Forbes2000$country)) ### number of industries length(levels(Forbes2000$category))"
"HSAUR-foster","HSAUR","foster","Foster Feeding Experiment",61,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/foster.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/foster.html","foster R Documentation   Foster Feeding Experiment   Description  
The data are from a foster feeding experiment with rat mothers and litters of four different genotypes. The measurement is the litter weight after a trial feeding period.    Usage   data(""foster"")   Format  
A data frame with 61 observations on the following 3 variables.    litgen
genotype of the litter, a factor with levels A , B , I , and J .   motgen
genotype of the mother, a factor with levels A , B , I , and J .   weight
the weight of the litter after a feeding period.     Details  
Here the interest lies in uncovering the effect of genotype of mother and litter on litter weight.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""foster"", package = ""HSAUR"") plot.design(foster)"
"HSAUR-GHQ","HSAUR","GHQ","General Health Questionnaire",22,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/GHQ.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/GHQ.html","GHQ R Documentation   General Health Questionnaire   Description  
Data from an psychiatric screening questionnaire   Usage   data(""GHQ"")   Format  
A data frame with 22 observations on the following 4 variables.    GHQ
the General Health Questionnaire score.   sex
a factor with levels female and male   cases
the number of diseased subjects.   non.cases
the number of healthy subjects.     Details  
The data arise from a study of a psychiatric screening questionnaire called the GHQ (General Health Questionnaire, see Goldberg, 1972). Here the main question of interest is to see how caseness is related to gender and GHQ score.    Source  
D. Goldberg (1972). The Detection of Psychiatric Illness by Questionnaire , Oxford University Press, Oxford, UK.    Examples    data(""GHQ"", package = ""HSAUR"") male <- subset(GHQ, sex == ""male"") female <- subset(GHQ, sex == ""female"") layout(matrix(1:2, ncol = 2)) barplot(t(as.matrix(male[,c(""cases"", ""non.cases"")])), main = ""Male"", xlab = ""GHC score"") barplot(t(as.matrix(male[,c(""cases"", ""non.cases"")])), main = ""Female"", xlab = ""GHC score"")"
"HSAUR-heptathlon","HSAUR","heptathlon","Olympic Heptathlon Seoul 1988",25,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/heptathlon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/heptathlon.html","heptathlon R Documentation   Olympic Heptathlon Seoul 1988   Description  
Results of the olympic heptathlon competition, Seoul, 1988.    Usage   data(""heptathlon"")   Format  
A data frame with 25 observations on the following 8 variables.    hurdles
results 100m hurdles.   highjump
results high jump.   shot
results shot.   run200m
results 200m race.   longjump
results long jump.   javelin
results javelin.   run800m
results 800m race.   score
total score.     Details  
The first combined Olympic event for women was the pentathlon, first held in Germany in 1928. Initially this consisted of the shot putt, long jump, 100m, high jump and javelin events held over two days. The pentathlon was first introduced into the Olympic Games in 1964, when it consisted of the 80m hurdles, shot, high jump, long jump and 200m. In 1977 the 200m was replaced by the 800m and from 1981 the IAAF brought in the seven-event heptathlon in place of the pentathlon, with day one containing the events-100m hurdles, shot, high jump, 200m and day two, the long jump, javelin and 800m. A scoring system is used to assign points to the results from each event and the winner is the woman who accumulates the most points over the two days. The event made its first Olympic appearance in 1984.   
In the 1988 Olympics held in Seoul, the heptathlon was won by one of the stars of women's athletics in the USA, Jackie Joyner-Kersee. The results for all 25 competitors are given here.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""heptathlon"", package = ""HSAUR"") plot(heptathlon)"
"HSAUR-Lanza","HSAUR","Lanza","Prevention of Gastointestinal Damages",198,3,1,0,3,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/Lanza.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/Lanza.html","Lanza R Documentation   Prevention of Gastointestinal Damages   Description  
Data from four randomised clinical trials on the prevention of gastointestinal damages by Misoprostol reported by Lanza et al. (1987, 1988a,b, 1989).    Usage   data(""Lanza"")   Format  
A data frame with 198 observations on the following 3 variables.    study
a factor with levels I , II ,  III , and IV describing the study number.   treatment
a factor with levels Misoprostol Placebo   classification
an ordered factor with levels 1 < 2 < 3 < 4 < 5  describing an ordered response variable.     Details  
The response variable is defined by the number of haemorrhages or erosions.   Source  
F. L. Lanza (1987), A double-blind study of prophylactic effect of misoprostol on lesions of gastric and duodenal mucosa induced by oral administration of tolmetin in healthy subjects. British Journal of Clinical Practice , May suppl, 91–101.   
F. L. Lanza, R. L. Aspinall, E. A. Swabb, R. E. Davis, M. F. Rack, A. Rubin (1988a), Double-blind, placebo-controlled endoscopic comparison of the mucosal protective effects of misoprostol versus cimetidine on tolmetin-induced mucosal injury to the stomach and duodenum. Gastroenterology , 95 (2), 289–294.   
F. L. Lanza, K. Peace, L. Gustitus, M. F. Rack, B. Dickson (1988b), A blinded endoscopic comparative study of misoprostol versus sucralfate and placebo in the prevention of aspirin-induced gastric and duodenal ulceration. American Journal of Gastroenterology ,  83 (2), 143–146.   
F. L. Lanza, D. Fakouhi, A. Rubin, R. E. Davis, M. F. Rack, C. Nissen, S. Geis (1989), A double-blind placebo-controlled comparison of the efficacy and safety of 50, 100, and 200 micrograms of misoprostol QID in the prevention of ibuprofen-induced gastric and duodenal mucosal lesions and symptoms. American Journal of Gastroenterology ,  84 (6), 633–636.    Examples    data(""Lanza"", package = ""HSAUR"") layout(matrix(1:4, nrow = 2)) pl <- tapply(1:nrow(Lanza), Lanza$study, function(indx) mosaicplot(table(Lanza[indx,""treatment""], Lanza[indx,""classification""]), main = """", shade = TRUE))"
"HSAUR-mastectomy","HSAUR","mastectomy","Survival Times after Mastectomy of Breast Cancer Patients",44,3,2,0,1,1,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/mastectomy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/mastectomy.html","mastectomy R Documentation   Survival Times after Mastectomy of Breast Cancer Patients   Description  
Survival times in months after mastectomy of women with breast cancer. The cancers are classified as having metastized or not based on a histochemical marker.   Usage   data(""mastectomy"")   Format  
A data frame with 42 observations on the following 3 variables.    time
survival times in months.   event
a logical indicating if the event was observed ( TRUE ) or if the survival time was censored ( FALSE ).   metastized
a factor at levels yes and no .     Source  
B. S. Everitt and S. Rabe-Hesketh (2001),  Analysing Medical Data using S-PLUS , Springer, New York, USA.    Examples    data(""mastectomy"", package = ""HSAUR"") table(mastectomy$metastized)"
"HSAUR-meteo","HSAUR","meteo","Meteorological Measurements for 11 Years",11,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/meteo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/meteo.html","meteo R Documentation   Meteorological Measurements for 11 Years   Description  
Several meteorological measurements for a period between 1920 and 1931.    Usage   data(""meteo"")   Format  
A data frame with 11 observations on the following 6 variables.    year
the years.   rainNovDec
rainfall in November and December (mm).   temp
average July temperature.   rainJuly
rainfall in July (mm).   radiation
radiation in July (millilitres of alcohol).   yield
average harvest yield (quintals per hectare).     Details  
Carry out a principal components analysis of both the covariance matrix and the correlation matrix of the data and compare the results. Which set of components leads to the most meaningful interpretation?   Source  
B. S. Everitt and G. Dunn (2001), Applied Multivariate Data Analysis , 2nd edition, Arnold, London.    Examples    data(""meteo"", package = ""HSAUR"") meteo"
"HSAUR-orallesions","HSAUR","orallesions","Oral Lesions in Rural India",24,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/orallesions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/orallesions.html","orallesions R Documentation   Oral Lesions in Rural India   Description  
The distribution of the oral lesion site found in house-to-house surveys in three geographic regions of rural India.    Usage   data(""orallesions"")   Format  
A two-way classification, see table .    Source  
Cyrus R. Mehta and Nitin R. Patel (2003), StatXact-6: Statistical Software for Exact Nonparametric Inference , Cytel Software Cooperation, Cambridge, USA.    Examples    data(""orallesions"", package = ""HSAUR"") mosaicplot(orallesions)"
"HSAUR-phosphate","HSAUR","phosphate","Phosphate Level Data",33,9,1,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/phosphate.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/phosphate.html","phosphate R Documentation   Phosphate Level Data   Description  
Plasma inorganic phosphate levels from 33 subjects.    Usage   data(""phosphate"")   Format  
A data frame with 33 observations on the following 9 variables.    group
a factor with levels control and  obese .   t0
baseline phosphate level    
,    t0.5
phosphate level after 1/2 an hour.   t1
phosphate level after one an hour.   t1.5
phosphate level after 1 1/2 hours.   t2
phosphate level after two hours.   t3
phosphate level after three hours.   t4
phosphate level after four hours.   t5
phosphate level after five hours.     Source  
C. S. Davis (2002), Statistical Methods for the Analysis of Repeated Measurements , Springer, New York.    Examples    data(""phosphate"", package = ""HSAUR"") plot(t0 ~ group, data = phosphate)"
"HSAUR-pistonrings","HSAUR","pistonrings","Piston Rings Failures",12,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/pistonrings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/pistonrings.html","pistonrings R Documentation   Piston Rings Failures   Description  
Number of failures of piston rings in three legs of four steam-driven compressors.   Usage   data(""pistonrings"")   Format  
A two-way classification, see table .    Details  
The data are given in form of a table . The table gives the number of piston-ring failures in each of three legs of four steam-driven compressors located in the same building. The compressors have identical design and are oriented in the same way. The question of interest is whether the two classification variables (compressor and leg) are independent.    Source  
S. J. Haberman (1973), The analysis of residuals in cross-classificed tables. Biometrics 29 , 205–220.    Examples    data(""pistonrings"", package = ""HSAUR"") mosaicplot(pistonrings)"
"HSAUR-planets","HSAUR","planets","Exoplanets Data",101,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/planets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/planets.html","planets R Documentation   Exoplanets Data   Description  
Data on planets outside the Solar System.    Usage   data(""planets"")   Format  
A data frame with 101 observations from 101 exoplanets on the following 3 variables.    mass
Jupiter mass of the planet.   period
period in earth days.   eccen
the radial eccentricity of the planet.     Details  
From the properties of the exoplanets found up to now it appears that the theory of planetary development constructed for the planets of the Solar System may need to be reformulated. The exoplanets are not at all like the nine local planets that we know so well. A first step in the process of understanding the exoplanets might be to try to classify them with respect to their known properties.    Source  
M. Mayor and P. Frei (2003). New Worlds in the Cosmos: The Discovery of Exoplanets . Cambridge University Press, Cambridge, UK.    Examples    data(""planets"", package = ""HSAUR"") require(""scatterplot3d"") scatterplot3d(log(planets$mass), log(planets$period), log(planets$eccen), type = ""h"", highlight.3d = TRUE, angle = 55, scale.y = 0.7, pch = 16)"
"HSAUR-plasma","HSAUR","plasma","Blood Screening Data",32,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/plasma.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/plasma.html","plasma R Documentation   Blood Screening Data   Description  
The erythrocyte sedimentation rate and measurements of two plasma proteins (fibrinogen and globulin).    Usage   data(""plasma"")   Format  
A data frame with 32 observations on the following 3 variables.    fibrinogen
the fibrinogen level in the blood.   globulin
the globulin level in the blood.   ESR
the erythrocyte sedimentation rate, either less or greater 20 mm / hour.     Details  
The erythrocyte sedimentation rate (ESR) is the rate at which red blood cells (erythrocytes) settle out of suspension in blood plasma, when measured under standard conditions. If the ESR increases when the level of certain proteins in the blood plasma rise in association with conditions such as rheumatic diseases, chronic infections and malignant diseases, its determination might be useful in screening blood samples taken form people suspected to being suffering from one of the conditions mentioned. The absolute value of the ESR is not of great importance rather it is whether it is less than 20mm/hr since lower values indicate a healthy individual.   
The question of interest is whether there is any association between the probability of an ESR reading greater than 20mm/hr and the levels of the two plasma proteins. If there is not then the determination of ESR would not be useful for diagnostic purposes.   Source  
D. Collett and A. A. Jemain (1985), Residuals, outliers and influential observations in regression analysis. Sains Malaysiana , 4 , 493–511.    Examples    data(""plasma"", package = ""HSAUR"") layout(matrix(1:2, ncol = 2)) boxplot(fibrinogen ~ ESR, data = plasma, varwidth = TRUE) boxplot(globulin ~ ESR, data = plasma, varwidth = TRUE)"
"HSAUR-polyps","HSAUR","polyps","Familial Andenomatous Polyposis",20,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/polyps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/polyps.html","polyps R Documentation   Familial Andenomatous Polyposis   Description  
Data from a placebo-controlled trial of a non-steroidal anti-inflammatory drug in the treatment of familial andenomatous polyposis (FAP).    Usage   data(""polyps"")   Format  
A data frame with 20 observations on the following 3 variables.    number
number of colonic polyps at 12 months.   treat
treatment arms of the trail, a factor with levels placebo and drug .   age
the age of the patient.     Details  
Giardiello et al. (1993) and Piantadosi (1997) describe the results of a placebo-controlled trial of a non-steroidal anti-inflammatory drug in the treatment of familial andenomatous polyposis (FAP). The trial was halted after a planned interim analysis had suggested compelling evidence in favour of the treatment. Here we are interested in assessing whether the number of colonic polyps at 12 months is related to treatment and age of patient.    Source  
F. M. Giardiello, S. R. Hamilton, A. J. Krush, S. Piantadosi, L. M. Hylind, P. Celano, S. V. Booker, C. R. Robinson and G. J. A. Offerhaus (1993), Treatment of colonic and rectal adenomas with sulindac in familial adenomatous polyposis. New England Journal of Medicine ,  328 (18), 1313–1316.   
S. Piantadosi (1997), Clinical Trials: A Methodologic Perspective . John Wiley \& Sons, New York.    Examples    data(""polyps"", package = ""HSAUR"") plot(number ~ age, data = polyps, pch = as.numeric(polyps$treat)) legend(40, 40, legend = levels(polyps$treat), pch = 1:2, bty = ""n"")"
"HSAUR-polyps3","HSAUR","polyps3","Familial Andenomatous Polyposis",22,5,2,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/polyps3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/polyps3.html","polyps3 R Documentation   Familial Andenomatous Polyposis   Description  
Data from a placebo-controlled trial of a non-steroidal anti-inflammatory drug in the treatment of familial andenomatous polyposis (FAP).    Usage   data(""polyps3"")   Format  
A data frame with 22 observations on the following 5 variables.    sex
a factor with levels female and male .   treatment
a factor with levels placebo and active .   baseline
the baseline number of polyps.   age
the age of the patient.   number3m
the number of polyps after three month.     Details  
The data arise from the same study as the polyps data. Here, the number of polyps after three months are given.    Source  
F. M. Giardiello, S. R. Hamilton, A. J. Krush, S. Piantadosi, L. M. Hylind, P. Celano, S. V. Booker, C. R. Robinson and G. J. A. Offerhaus (1993), Treatment of colonic and rectal adenomas with sulindac in familial adenomatous polyposis. New England Journal of Medicine ,  328 (18), 1313–1316.   
S. Piantadosi (1997), Clinical Trials: A Methodologic Perspective . John Wiley \& Sons, New York.    Examples    data(""polyps3"", package = ""HSAUR"") plot(number3m ~ age, data = polyps3, pch = as.numeric(polyps3$treatment)) legend(""topright"", legend = levels(polyps3$treatment), pch = 1:2, bty = ""n"")"
"HSAUR-pottery","HSAUR","pottery","Romano-British Pottery Data",45,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/pottery.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/pottery.html","pottery R Documentation   Romano-British Pottery Data   Description  
Chemical composition of Romano-British pottery.    Usage   data(""pottery"")   Format  
A data frame with 45 observations on the following 9 chemicals.    Al2O3
aluminium trioxide.   Fe2O3
iron trioxide.   MgO
magnesium oxide.   CaO
calcium oxide.   Na2O
natrium oxide.   K2O
calium oxide.   TiO2
titanium oxide.   MnO
mangan oxide.   BaO
barium oxide.     Details  
The data gives the chemical composition of specimens of Romano-British pottery, determined by atomic absorption spectrophotometry, for nine oxides.    Source  
A. Tubb and N. J. Parker and G. Nickless (1980), The analysis of Romano-British pottery by atomic absorption spectrophotometry. Archaeometry , 22 , 153–171.    Examples    data(""pottery"", package = ""HSAUR"") plot(pottery)"
"HSAUR-rearrests","HSAUR","rearrests","Rearrests of Juvenile Felons",4,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/rearrests.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/rearrests.html","rearrests R Documentation   Rearrests of Juvenile Felons   Description  
Rearrests of juventile felons by type of court in which they were tried.    Usage   data(""rearrests"")   Format  
A two-way classification, see table .    Details  
The data (taken from Agresti, 1996) arise from a sample of juveniles convicted of felony in Florida in 1987. Matched pairs were formed using criteria such as age and the number of previous offences. For each pair, one subject was handled in the juvenile court and the other was transferred to the adult court. Whether or not the juvenile was rearrested by the end of 1988 was then noted. Here the question of interest is whether the true proportions rearrested were identical for the adult and juvenile court assignments?    Source  
A. Agresti (1996). An Introduction to Categorical Data Analysis . Wiley, New York.    Examples    data(""rearrests"", package = ""HSAUR"") rearrests"
"HSAUR-respiratory","HSAUR","respiratory","Respiratory Illness Data",555,7,4,0,6,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/respiratory.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/respiratory.html","respiratory R Documentation   Respiratory Illness Data   Description  
The respiratory status of patients recruited for a randomised clinical multicenter trial.    Usage   data(""respiratory"")   Format  
A data frame with 555 observations on the following 7 variables.    centre
the study center, a factor with levels 1 and  2 .   treatment
the treatment arm, a factor with levels placebo  and treatment .   sex
a factor with levels female and male .   age
the age of the patient.   status
the respiratory status (response variable), a factor with levels poor and good .   month
the month, each patient was examined at months 0 , 1 , 2 , 3 and 4 .   subject
the patient ID, a factor with levels 1 to  111 .     Details  
In each of two centres, eligible patients were randomly assigned to active treatment or placebo. During the treatment, the respiratory status (categorised poor or good ) was determined at each of four, monthly visits. The trial recruited 111 participants (54 in the active group, 57 in the placebo group) and there were no missing data for either the responses or the covariates. The question of interest is to assess whether the treatment is effective and to estimate its effect.   
Note that the data are in long form, i.e, repeated measurments are stored as additional rows in the data frame.    Source  
C. S. Davis (1991), Semi-parametric and non-parametric methods for the analysis of repeated measurements with applications to clinical trials. Statistics in Medicine , 10 , 1959–1980.    Examples    data(""respiratory"", package = ""HSAUR"") mosaicplot(xtabs( ~ treatment + month + status, data = respiratory))"
"HSAUR-roomwidth","HSAUR","roomwidth","Students Estimates of Lecture Room Width",113,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/roomwidth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/roomwidth.html","roomwidth R Documentation   Students Estimates of Lecture Room Width   Description  
Lecture room width estimated by students in two different units.    Usage   data(""roomwidth"")   Format  
A data frame with 113 observations on the following 2 variables.    unit
a factor with levels feet and metres .   width
the estimated width of the lecture room.     Details  
Shortly after metric units of length were officially introduced in Australia, each of a group of 44 students was asked to guess, to the nearest metre, the width of the lecture hall in which they were sitting. Another group of 69 students in the same room was asked to guess the width in feet, to the nearest foot. The data were collected by Professor T. Lewis and are taken from Hand et al (1994). The main question is whether estimation in feet and in metres gives different results.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""roomwidth"", package = ""HSAUR"") convert <- ifelse(roomwidth$unit == ""feet"", 1, 3.28) boxplot(I(width * convert) ~ unit, data = roomwidth)"
"HSAUR-schizophrenia","HSAUR","schizophrenia","Age of Onset of Schizophrenia Data",251,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/schizophrenia.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/schizophrenia.html","schizophrenia R Documentation   Age of Onset of Schizophrenia Data   Description  
Data on sex differences in the age of onset of schizophrenia.    Usage   data(""schizophrenia"")   Format  
A data frame with 251 observations on the following 2 variables.    age
age at the time of diagnosis.   gender
a factor with levels female and male     Details  
A sex difference in the age of onset of schizophrenia was noted by Kraepelin (1919). Subsequently epidemiological studies of the disorder have consistently shown an earlier onset in men than in women. One model that has been suggested to explain this observed difference is know as the subtype model which postulates two type of schizophrenia, one characterised by early onset, typical symptoms and poor premorbid competence, and the other by late onset, atypical symptoms, and good premorbid competence. The early onset type is assumed to be largely a disorder of men and the late onset largely a disorder of women.    Source  
E. Kraepelin (1919), Dementia Praecox and Paraphrenia . Livingstone, Edinburgh.    Examples    data(""schizophrenia"", package = ""HSAUR"") boxplot(age ~ gender, data = schizophrenia)"
"HSAUR-schizophrenia2","HSAUR","schizophrenia2","Schizophrenia Data",220,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/schizophrenia2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/schizophrenia2.html","schizophrenia2 R Documentation   Schizophrenia Data   Description  
Though disorder and early onset of schizophrenia.    Usage   data(""schizophrenia2"")   Format  
A data frame with 220 observations on the following 4 variables.    subject
the patient ID, a factor with levels 1 to  44 .   onset
the time of onset of the disease, a factor with levels < 20 yrs and > 20 yrs .   disorder
whether thought disorder was absent or  present , the response variable.   month
month after hospitalisation.     Details  
The data were collected in a follow-up study of women patients with schizophrenia. The binary response recorded at 0, 2, 6, 8 and 10 months after hospitalisation was thought disorder (absent or present). The single covariate is the factor indicating whether a patient had suffered early or late onset of her condition (age of onset less than 20 years or age of onset 20 years or above). The question of interest is whether the course of the illness differs between patients with early and late onset?    Source  
Davis (2002), Statistical Methods for the Analysis of Repeated Measurements , Springer, New York.    Examples    data(""schizophrenia2"", package = ""HSAUR"") mosaicplot(xtabs( ~ onset + month + disorder, data = schizophrenia2))"
"HSAUR-schooldays","HSAUR","schooldays","Days not Spent at School",154,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/schooldays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/schooldays.html","schooldays R Documentation   Days not Spent at School   Description  
Data from a sociological study, the number of days absent from school is the response variable.    Usage   data(""schooldays"")   Format  
A data frame with 154 observations on the following 5 variables.    race
race of the child, a factor with levels aboriginal and non-aboriginal .   sex
the sex of the child, a factor with levels female and male .   school
the school type, a factor with levels F0 (primary), F1 (first), F2 (second) and F3 (third form).   learner
how good is the child in learning things, a factor with levels average and  slow .   absent
number of days absent from school.     Details  
The data arise from a sociological study of Australian Aboriginal and white children reported by Quine (1975).   
In this study, children of both sexes from four age groups (final grade in primary schools and first, second and third form in secondary school) and from two cultural groups were used. The children in age group were classified as slow or average learners. The response variable was the number of days absent from school during the school year. (Children who had suffered a serious illness during the years were excluded.)   Source  
S. Quine (1975), Achievement Orientation of Aboriginal and White Adolescents. Doctoral Dissertation, Australian National University, Canberra.    Examples    data(""schooldays"", package = ""HSAUR"") plot.design(schooldays)"
"HSAUR-skulls","HSAUR","skulls","Egyptian Skulls",150,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/skulls.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/skulls.html","skulls R Documentation   Egyptian Skulls   Description  
Measurements made on Egyptian skulls from five epochs.    Usage   data(""skulls"")   Format  
A data frame with 150 observations on the following 5 variables.    epoch
the epoch the skull as assigned to, a factor with levels c4000BC c3300BC ,  c1850BC , c200BC , and cAD150 , where the years are only given approximately, of course.   mb
maximum breaths of the skull.   bh
basibregmatic heights of the skull.   bl
basialiveolar length of the skull.   nh
nasal heights of the skull.     Details  
The question is whether the measurements change over time. Non-constant measurements of the skulls over time would indicate interbreeding with immigrant populations.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""skulls"", package = ""HSAUR"") means <- tapply(1:nrow(skulls), skulls$epoch, function(i) apply(skulls[i,colnames(skulls)[-1]], 2, mean)) means <- matrix(unlist(means), nrow = length(means), byrow = TRUE) colnames(means) <- colnames(skulls)[-1] rownames(means) <- levels(skulls$epoch) pairs(means, panel = function(x, y) { text(x, y, levels(skulls$epoch)) })"
"HSAUR-smoking","HSAUR","smoking","Nicotine Gum and Smoking Cessation",26,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/smoking.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/smoking.html","smoking R Documentation   Nicotine Gum and Smoking Cessation   Description  
Data from a meta-analysis on nicotine gum and smoking cessation    Usage   data(""smoking"")   Format  
A data frame with 26 observations (studies) on the following 4 variables.    qt
the number of treated subjetcs who stopped smoking.   tt
the totla number of treated subjects.   qc
the number of subjetcs who stopped smoking without being treated.   tc
the total number of subject not being treated.     Details  
Cigarette smoking is the leading cause of preventable death in the United States and kills more Americans than AIDS, alcohol, illegal drug use, car accidents, fires, murders and suicides combined. It has been estimated that 430,000 Americans die from smoking every year. Fighting tobacco use is, consequently, one of the major public health goals of our time and there are now many programs available designed to help smokers quit. One of the major aids used in these programs is nicotine chewing gum, which acts as a substitute oral activity and provides a source of nicotine that reduces the withdrawal symptoms experienced when smoking is stopped. But separate randomized clinical trials of nicotine gum have been largely inconclusive, leading Silagy (2003) to consider combining the results studies found from an extensive literature search. The results of these trials in terms of numbers of people in the treatment arm and the control arm who stopped smoking for at least 6 months after treatment are given here.   Source  
C. Silagy (2003), Nicotine replacement therapy for smoking cessation (Cochrane Review). The Cochrane Library ,  4 , John Wiley \& Sons, Chichester.    Examples    data(""smoking"", package = ""HSAUR"") boxplot(smoking$qt/smoking$tt, smoking$qc/smoking$tc, names = c(""Treated"", ""Control""), ylab = ""Percent Quitters"")"
"HSAUR-students","HSAUR","students","Student Risk Taking",35,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/students.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/students.html","students R Documentation   Student Risk Taking   Description  
Students were administered two parallel forms of a test after a random assignment to three different treatments.    Usage   data(""students"")   Format  
A data frame with 35 observations on the following 3 variables.    treatment
a factor with levels AA , C , and  NC .   low
the result of the first test.   high
the result of the second test.     Details  
The data arise from a large study of risk taking (Timm, 2002). Students were randomly assigned to three different treatments labelled AA, C and NC. Students were administered two parallel forms of a test called low and high . The aim is to carry out a test of the equality of the bivariate means of each treatment population.    Source  
N. H. Timm (2002), Applied Multivariate Analysis . Springer, New York.    Examples    data(""students"", package = ""HSAUR"") layout(matrix(1:2, ncol = 2)) boxplot(low ~ treatment, data = students, ylab = ""low"") boxplot(high ~ treatment, data = students, ylab = ""high"")"
"HSAUR-suicides","HSAUR","suicides","Crowd Baiting Behaviour and Suicides",4,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/suicides.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/suicides.html","suicides R Documentation   Crowd Baiting Behaviour and Suicides   Description  
Data from a study carried out to investigate the causes of jeering or baiting behaviour by a crowd when a person is threatening to commit suicide by jumping from a high building.    Usage   data(""suicides"")   Format  
A two-way classification, see table .    Source  
L. Mann (1981), The baiting crowd in episodes of threatened suicide.  Journal of Personality and Social Psychology , 41 , 703–709.    Examples    data(""suicides"", package = ""HSAUR"") mosaicplot(suicides)"
"HSAUR-toothpaste","HSAUR","toothpaste","Toothpaste Data",9,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/toothpaste.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/toothpaste.html","toothpaste R Documentation   Toothpaste Data   Description  
Meta-analysis of studies comparing two different toothpastes.    Usage   data(""toothpaste"")   Format  
A data frame with 9 observations on the following 7 variables.    Study
the identifier of the study.   nA
number of subjects using toothpaste A.   meanA
mean DMFS index of subjects using toothpaste A.   sdA
standard deviation of DMFS index of subjects using toothpaste A.   nB
number of subjects using toothpaste B.   meanB
mean DMFS index of subjects using toothpaste B.   sdB
standard deviation of DMFS index of subjects using toothpaste B.     Details  
The data are the results of nine randomised trials comparing two different toothpastes for the prevention of caries development. The outcomes in each trial was the change, from baseline, in the decayed, missing (due to caries) and filled surface dental index (DMFS).    Source  
B. S. Everitt and A. Pickles (2000), Statistical Aspects of the Design and Analysis of Clinical Trials , Imperial College Press, London.    Examples    data(""toothpaste"", package = ""HSAUR"") toothpaste"
"HSAUR-voting","HSAUR","voting","House of Representatives Voting Data",15,15,0,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/voting.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/voting.html","voting R Documentation   House of Representatives Voting Data   Description  
Voting results for 15 congressmen from New Jersey.    Usage   data(""voting"")   Format  
A 15 times 15 matrix.    Details  
Romesburg (1984) gives a set of data that shows the number of times 15 congressmen from New Jersey voted differently in the House of Representatives on 19 environmental bills. Abstentions are not recorded.    Source  
H. C. Romesburg (1984), Cluster Analysis for Researchers . Lifetime Learning Publications, Belmont, Canada.    Examples    data(""voting"", package = ""HSAUR"") require(""MASS"") voting_mds <- isoMDS(voting) plot(voting_mds$points[,1], voting_mds$points[,2], type = ""n"", xlab = ""Coordinate 1"", ylab = ""Coordinate 2"", xlim = range(voting_mds$points[,1])*1.2) text(voting_mds$points[,1], voting_mds$points[,2], labels = colnames(voting)) voting_sh <- Shepard(voting[lower.tri(voting)], voting_mds$points)"
"HSAUR-water","HSAUR","water","Mortality and Water Hardness",61,4,1,1,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/water.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/water.html","water R Documentation   Mortality and Water Hardness   Description  
The mortality and drinking water hardness for 61 cities in England and Wales.    Usage   data(""water"")   Format  
A data frame with 61 observations on the following 4 variables.    location
a factor with levels North and South indicating whether the town is as north as Derby.   town
the name of the town.   mortality
averaged annual mortality per 100.000 male inhabitants.   hardness
calcium concentration (in parts per million).     Details  
The data were collected in an investigation of environmental causes of disease. They show the annual mortality per 100,000 for males, averaged over the years 1958-1964, and the calcium concentration (in parts per million) in the drinking water for 61 large towns in England and Wales. The higher the calcium concentration, the harder the water. Towns at least as far north as Derby are identified in the table. Here there are several questions that might be of interest including, are mortality and water hardness related, and do either or both variables differ between northern and southern towns?    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""water"", package = ""HSAUR"") plot(mortality ~ hardness, data = water, col = as.numeric(water$location))"
"HSAUR-watervoles","HSAUR","watervoles","Water Voles Data",14,14,0,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/watervoles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/watervoles.html","watervoles R Documentation   Water Voles Data   Description  
Percentage incidence of the 13 characteristics of water voles in 14 areas.    Usage   data(""watervoles"")   Format  
A dissimilarity matrix for the following 14 variables, i.e, areas:  Surrey ,  Shropshire ,  Yorkshire ,  Perthshire ,  Aberdeen ,  Elean Gamhna ,  Alps ,  Yugoslavia ,  Germany ,  Norway ,  Pyrenees I ,  Pyrenees II ,  North Spain , and  South Spain .    Details  
Corbet et al. (1970) report a study of water voles (genus Arvicola) in which the aim was to compare British populations of these animals with those in Europe, to investigate whether more than one species might be present in Britain. The original data consisted of observations of the presence or absence of 13 characteristics in about 300 water vole skulls arising from six British populations and eight populations from the rest of Europe. The data are the percentage incidence of the 13 characteristics in each of the 14 samples of water vole skulls.    Source  
G. B. Corbet, J. Cummins, S. R. Hedges, W. J. Krzanowski (1970), The taxonomic structure of British water voles, genus Arvicola .  Journal of Zoology , 61 , 301–316.    Examples    data(""watervoles"", package = ""HSAUR"") watervoles"
"HSAUR-waves","HSAUR","waves","Electricity from Wave Power at Sea",18,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/waves.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/waves.html","waves R Documentation   Electricity from Wave Power at Sea   Description  
Measurements of root mean square bending moment by two different mooring methods.    Usage   data(""waves"")   Format  
A data frame with 18 observations on the following 2 variables.    method1
Root mean square bending moment in Newton metres, mooring method 1   method2
Root mean square bending moment in Newton metres, mooring method 2     Details  
In a design study for a device to generate electricity from wave power at sea, experiments were carried out on scale models in a wave tank to establish how the choice of mooring method for the system affected the bending stress produced in part of the device. The wave tank could simulate a wide range of sea states and the model system was subjected to the same sample of sea states with each of two mooring methods, one of which was considerably cheaper than the other. The question of interest is whether bending stress differs for the two mooring methods.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""waves"", package = ""HSAUR"") plot(method1 ~ method2, data = waves)"
"HSAUR-weightgain","HSAUR","weightgain","Gain in Weight of Rats",40,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/weightgain.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/weightgain.html","weightgain R Documentation   Gain in Weight of Rats   Description  
The data arise from an experiment to study the gain in weight of rats fed on four different diets, distinguished by amount of protein (low and high) and by source of protein (beef and cereal).    Usage   data(""weightgain"")   Format  
A data frame with 40 observations on the following 3 variables.    source
source of protein given, a factor with levels Beef  and Cereal .   type
amount of protein given, a factor with levels High  and Low .   weightgain
weigt gain in grams.     Details  
Ten rats are randomized to each of the four treatments. The question of interest is how diet affects weight gain.    Source  
D. J. Hand, F. Daly, A. D. Lunn, K. J. McConway and E. Ostrowski (1994).  A Handbook of Small Datasets , Chapman and Hall/CRC, London.    Examples    data(""weightgain"", package = ""HSAUR"") interaction.plot(weightgain$type, weightgain$source, weightgain$weightgain)"
"HSAUR-womensrole","HSAUR","womensrole","Womens Role in Society",42,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/womensrole.csv","https://vincentarelbundock.github.io/Rdatasets/doc/HSAUR/womensrole.html","womensrole R Documentation   Womens Role in Society   Description  
Data from a survey from 1974 / 1975 asking both female and male responders about their opinion on the statement: Women should take care of running their homes and leave running the country up to men.    Usage   data(""womensrole"")   Format  
A data frame with 42 observations on the following 4 variables.    education
years of education.   sex
a factor with levels Male and Female .   agree
number of subjects in agreement with the statement.   disagree
number of subjects in disagreement with the statement.     Details  
The data are from Haberman (1973) and also given in Collett (2003). The questions here are whether the response of men and women differ.    Source  
S. J. Haberman (1973), The analysis of residuals in cross-classificed tables. Biometrics , 29 , 205–220.   
D. Collett (2003), Modelling Binary Data . Chapman and Hall / CRC, London. 2nd edition.    Examples    data(""womensrole"", package = ""HSAUR"") summary(subset(womensrole, sex == ""Female"")) summary(subset(womensrole, sex == ""Male""))"
"hwde-IndianIrish","hwde","IndianIrish","Observed genotype frequencies at MN and S loci, for 2 populations",18,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/hwde/IndianIrish.csv","https://vincentarelbundock.github.io/Rdatasets/doc/hwde/IndianIrish.html","IndianIrish R Documentation   Observed genotype frequencies at MN and S loci, for 2 populations   Description  
The IndianIrish data frame has 18 rows and 4 columns. The data are genotype frequencies for two locations, for Xavante Indian and Irish populations respectively    Usage   data(IndianIrish)   Format  
This data frame contains the following columns:    Population
Factor with levels:  Indian and Irish   locus1
Factor with levels:  MM , MN and NN   locus2
Factor with levels:  SS , Ss and ss   Observed
a numeric vector giving the frequency for each category of the tale     Source  
Mourant et al (1977) and Huttley and Wilson (2000).    References  
1. Huttley, G.A. and Wilson, S.R. 2000. Testing for concordant equilibria between population samples. Genetics 156 , 2127-2135.
 2. Mourant, A.E., Kopec, A.C. and Domaniewska-Sobczak, K. 1976.  The Distribution of the Human Blood Groups and Other Polymorphisms.  Oxford University Press.
 3. Weir, B.S. 1996. Genetic Data Analysis II. Sinauer.    See Also  
hwde   Examples    data(IndianIrish) hwde(data=IndianIrish)"
"hwde-mendelABC","hwde","mendelABC","Mendel's F2 trifactorial data for seed shape (A: round or wrinkled), cotyledon color (B: albumen yellow or green), and seed coat color (C: grey-brown or white)",27,4,0,1,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/hwde/mendelABC.csv","https://vincentarelbundock.github.io/Rdatasets/doc/hwde/mendelABC.html","mendelABC R Documentation   Mendel's F2 trifactorial data for seed shape (A: round or wrinkled), cotyledon color (B: albumen yellow or green), and seed coat color (C: grey-brown or white)   Description  
The mendel3 data frame has 27 rows and 4 columns. Data are from Mendel (1886), and are reproduced in Fisher (1936) and Weir (1996).    Usage   data(mendelABC)   Format  
This data frame contains the following columns:    seedshape
Factor with levels:  AA , Aa and aa   cotylcolor
Factor with levels: BB , Bb and bb   coatcolor
Factor with levels:  CC , Cc and cc   Observed
a numeric vector that holds the frequencies.     Details  
The data are reviewed in detail in Fisher (1936). For a brief discussion, and references to work that revisits Fisher's conclusions, see Weir (1996).    Source  
Data are from Mendel (1886), and are reproduced in Fisher (1936) and Weir (1996).    References  
1. Fisher, R.A. 1936. Has Mendel's work been rediscovered?  Annals of Science 1 :115-137.   
2. Mendel, G. 1886. Versuche uber Pflanzen-Hybriden. Verhandlugen des Naturforschenden Vereines in Brunn 4 :3-47. (An English translation. with annotations, is available from http://www.esp.org/foundations/genetics/classical/gm-65.pdf  NB also the English translation by Royal Horticultural Society of London, reprinted in Peters, J.A. 1959. Classic Papers in Genetics.  Prentice-Hall.)   
3. Weir, B.S. 1996. Genetic Data Analysis II. Sinauer.    Examples    ## Lay table out as a 3D array, as in Fisher (1936) abc <- aperm(array(mendelABC[,4], dim=c(3,3,3)), c(1,3,2)) dimnames(abc) <- list(B=c('BB','Bb','bb'), A=c('AA','Aa','aa'), C=c('CC','Cc','cc')) abc ## Fit Hardy-Weinberg disequilibium model hwde(mendelABC, loci=c(""seedshape"",""cotylcolor"",""coatcolor""))"
"ISLR-Auto","ISLR","Auto","Auto Data Set",392,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Auto.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html","Auto R Documentation    Auto Data Set    Description  
Gas mileage, horsepower, and other information for 392 vehicles.   Usage   Auto   Format  
A data frame with 392 observations on the following 9 variables.    mpg
miles per gallon   cylinders
Number of cylinders between 4 and 8   displacement
Engine displacement (cu. inches)   horsepower
Engine horsepower   weight
Vehicle weight (lbs.)   acceleration
Time to accelerate from 0 to 60 mph (sec.)   year
Model year (modulo 100)   origin
Origin of car (1. American, 2. European, 3. Japanese)   name
Vehicle name    
The orginal data contained 408 observations but 16 observations with missing values were removed.   Source  
This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition.    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    pairs(Auto) attach(Auto) hist(mpg)"
"ISLR-Caravan","ISLR","Caravan","The Insurance Company (TIC) Benchmark",5822,86,6,0,1,0,85,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Caravan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Caravan.html","Caravan R Documentation   The Insurance Company (TIC) Benchmark    Description  
The data contains 5822 real customer records. Each record consists of 86 variables, containing sociodemographic data (variables 1-43) and product ownership (variables 44-86). The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Variable 86 ( Purchase ) indicates whether the customer purchased a caravan insurance policy. Further information on the individual variables can be obtained at http://www.liacs.nl/~putten/library/cc2000/data.html    Usage   Caravan   Format  
A data frame with 5822 observations on 86 variables.    Source  
The data was originally supplied by Sentient Machine Research and was used in the CoIL Challenge 2000.    References  
P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000. See http://www.liacs.nl/~putten/library/cc2000/
 P. van der Putten and M. van Someren. A Bias-Variance Analysis of a Real World Learning Problem: The CoIL Challenge 2000. Machine Learning, October 2004, vol. 57, iss. 1-2, pp. 177-195, Kluwer Academic Publishers
 James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Caravan) plot(Caravan$Purchase)"
"ISLR-Carseats","ISLR","Carseats","Sales of Child Car Seats",400,11,2,0,3,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Carseats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Carseats.html","Carseats R Documentation   Sales of Child Car Seats    Description  
A simulated data set containing sales of child car seats at 400 different stores.    Usage   Carseats   Format  
A data frame with 400 observations on the following 11 variables.    Sales
Unit sales (in thousands) at each location   CompPrice
Price charged by competitor at each location   Income
Community income level (in thousands of dollars)   Advertising
Local advertising budget for company at each location (in thousands of dollars)   Population
Population size in region (in thousands)   Price
Price company charges for car seats at each site   ShelveLoc
A factor with levels Bad , Good  and Medium indicating the quality of the shelving location for the car seats at each site   Age
Average age of the local population   Education
Education level at each location   Urban
A factor with levels No and Yes to indicate whether the store is in an urban or rural location   US
A factor with levels No and Yes to indicate whether the store is in the US or not     Source  
Simulated data    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Carseats) lm.fit=lm(Sales~Advertising+Price,data=Carseats)"
"ISLR-College","ISLR","College","U.S. News and World Report's College Data",777,18,1,0,1,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/College.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/College.html","College R Documentation   U.S. News and World Report's College Data    Description  
Statistics for a large number of US Colleges from the 1995 issue of US News and World Report.    Usage   College   Format  
A data frame with 777 observations on the following 18 variables.    Private
A factor with levels No and Yes  indicating private or public university   Apps
Number of applications received   Accept
Number of applications accepted   Enroll
Number of new students enrolled   Top10perc
Pct. new students from top 10% of H.S. class   Top25perc
Pct. new students from top 25% of H.S. class   F.Undergrad
Number of fulltime undergraduates   P.Undergrad
Number of parttime undergraduates   Outstate
Out-of-state tuition   Room.Board
Room and board costs   Books
Estimated book costs   Personal
Estimated personal spending   PhD
Pct. of faculty with Ph.D.'s   Terminal
Pct. of faculty with terminal degree   S.F.Ratio
Student/faculty ratio   perc.alumni
Pct. alumni who donate   Expend
Instructional expenditure per student   Grad.Rate
Graduation rate     Source  
This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the ASA Statistical Graphics Section's 1995 Data Analysis Exposition.    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(College) lm(Apps~Private+Accept,data=College)"
"ISLR-Credit","ISLR","Credit","Credit Card Balance Data",400,12,3,0,4,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Credit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Credit.html","Credit R Documentation   Credit Card Balance Data    Description  
A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.    Usage   Credit   Format  
A data frame with 10000 observations on the following 4 variables.    ID
Identification   Income
Income in $10,000's   Limit
Credit limit   Rating
Credit rating   Cards
Number of credit cards   Age
Age in years   Education
Number of years of education   Gender
A factor with levels Male and Female   Student
A factor with levels No and Yes  indicating whether the individual was a student   Married
A factor with levels No and Yes  indicating whether the individual was married   Ethnicity
A factor with levels African American , Asian , and Caucasian  indicating the individual's ethnicity   Balance
Average credit card balance in $.     Source  
Simulated data, with thanks to Albert Kim for pointing out that this was omitted, and supplying the data and man documentation page on Oct 19, 2017    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Credit) lm(Balance ~ Student + Limit, data=Credit)"
"ISLR-Default","ISLR","Default","Credit Card Default Data",10000,4,2,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Default.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Default.html","Default R Documentation   Credit Card Default Data    Description  
A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.    Usage   Default   Format  
A data frame with 10000 observations on the following 4 variables.    default
A factor with levels No and Yes  indicating whether the customer defaulted on their debt   student
A factor with levels No and Yes  indicating whether the customer is a student   balance
The average balance that the customer has remaining on their credit card after making their monthly payment   income
Income of customer     Source  
Simulated data    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Default) glm(default~student+balance+income,family=""binomial"",data=Default)"
"ISLR-Hitters","ISLR","Hitters","Baseball Data",322,20,3,0,3,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Hitters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Hitters.html","Hitters R Documentation   Baseball Data    Description  
Major League Baseball Data from the 1986 and 1987 seasons.    Usage   Hitters   Format  
A data frame with 322 observations of major league players on the following 20 variables.    AtBat
Number of times at bat in 1986   Hits
Number of hits in 1986   HmRun
Number of home runs in 1986   Runs
Number of runs in 1986   RBI
Number of runs batted in in 1986   Walks
Number of walks in 1986   Years
Number of years in the major leagues   CAtBat
Number of times at bat during his career   CHits
Number of hits during his career   CHmRun
Number of home runs during his career   CRuns
Number of runs during his career   CRBI
Number of runs batted in during his career   CWalks
Number of walks during his career   League
A factor with levels A and N  indicating player's league at the end of 1986   Division
A factor with levels E and W  indicating player's division at the end of 1986   PutOuts
Number of put outs in 1986   Assists
Number of assists in 1986   Errors
Number of errors in 1986   Salary
1987 annual salary on opening day in thousands of dollars   NewLeague
A factor with levels A and N  indicating player's league at the beginning of 1987     Source  
This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.   References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Hitters) lm(Salary~AtBat+Hits,data=Hitters)"
"ISLR-NCI60","ISLR","NCI60","NCI 60 Data",64,6831,0,1,0,0,6830,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/NCI60.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/NCI60.html","NCI60 R Documentation   NCI 60 Data    Description  
NCI microarray data. The data contains expression levels on 6830 genes from 64 cancer cell lines. Cancer type is also recorded.    Usage   NCI60   Format  
The format is a list containing two elements: data and  labs .   
data is a 64 by 6830 matrix of the expression values while  labs is a vector listing the cancer types for the 64 cell lines.    Source  
The data come from Ross et al. (Nat Genet., 2000). More information can be obtained at http://genome-www.stanford.edu/nci60/   References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    table(NCI60$labs)"
"ISLR-OJ","ISLR","OJ","Orange Juice Data",1070,18,4,0,2,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/OJ.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/OJ.html","OJ R Documentation   Orange Juice Data    Description  
The data contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. A number of characteristics of the customer and product are recorded.    Usage   OJ   Format  
A data frame with 1070 observations on the following 18 variables.    Purchase
A factor with levels CH and MM  indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice     WeekofPurchase
Week of purchase   StoreID
Store ID     PriceCH
Price charged for CH   PriceMM
Price charged for MM   DiscCH
Discount offered for CH   DiscMM
Discount offered for MM   SpecialCH
Indicator of special on CH   SpecialMM
Indicator of special on MM   LoyalCH
Customer brand loyalty for CH     SalePriceMM
Sale price for MM   SalePriceCH
Sale price for CH   PriceDiff
Sale price of MM less sale price of CH   Store7
A factor with levels No and Yes  indicating whether the sale is at Store 7   PctDiscMM
Percentage discount for MM   PctDiscCH
Percentage discount for CH   ListPriceDiff
List price of MM less list price of CH   STORE
Which of 5 possible stores the sale occured at     Source  
Stine, Robert A., Foster, Dean P., Waterman, Richard P. Business Analysis Using Regression (1998). Published by Springer.   References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(OJ) plot(OJ$Purchase,OJ$PriceCH)"
"ISLR-Portfolio","ISLR","Portfolio","Portfolio Data",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Portfolio.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Portfolio.html","Portfolio R Documentation   Portfolio Data    Description  
A simple simulated data set containing 100 returns for each of two assets, X and Y. The data is used to estimate the optimal fraction to invest in each asset to minimize investment risk of the combined portfolio. One can then use the Bootstrap to estimate the standard error of this estimate.    Usage   Portfolio   Format  
A data frame with 100 observations on the following 2 variables.    X
Returns for Asset X   Y
Returns for Asset Y     Source  
Simulated data    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Portfolio) attach(Portfolio) plot(X,Y)"
"ISLR-Smarket","ISLR","Smarket","S&P Stock Market Data",1250,9,1,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Smarket.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Smarket.html","Smarket R Documentation   S&P Stock Market Data    Description  
Daily percentage returns for the S&P 500 stock index between 2001 and 2005.   Usage   Smarket   Format  
A data frame with 1250 observations on the following 9 variables.    Year
The year that the observation was recorded   Lag1
Percentage return for previous day   Lag2
Percentage return for 2 days previous   Lag3
Percentage return for 3 days previous   Lag4
Percentage return for 4 days previous   Lag5
Percentage return for 5 days previous   Volume
Volume of shares traded (number of daily shares traded in billions)   Today
Percentage return for today   Direction
A factor with levels Down and  Up indicating whether the market had a positive or negative return on a given day     Source  
Raw values of the S&P 500 were obtained from Yahoo Finance and then converted to percentages and lagged.    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Smarket) lm(Today~Lag1+Lag2,data=Smarket)"
"ISLR-Wage","ISLR","Wage","Mid-Atlantic Wage Data",3000,11,3,0,7,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Wage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Wage.html","Wage R Documentation   Mid-Atlantic Wage Data    Description  
Wage and other data for a group of 3000 male workers in the Mid-Atlantic region.   Usage   Wage   Format  
A data frame with 3000 observations on the following 11 variables.    year
Year that wage information was recorded   age
Age of worker   maritl
A factor with levels 1. Never Married   2. Married 3. Widowed 4. Divorced and  5. Separated indicating marital status   race
A factor with levels 1. White   2. Black 3. Asian and 4. Other indicating race   education
A factor with levels 1. < HS Grad   2. HS Grad 3. Some College 4. College Grad  and 5. Advanced Degree indicating education level   region
Region of the country (mid-atlantic only)   jobclass
A factor with levels 1. Industrial and  2. Information indicating type of job   health
A factor with levels 1. <=Good and  2. >=Very Good indicating health level of worker   health_ins
A factor with levels 1. Yes and  2. No indicating whether worker has health insurance   logwage
Log of workers wage   wage
Workers raw wage     Source  
Data was manually assembled by Steve Miller, of Open BI (www.openbi.com), from the March 2011 Supplement to Current Population Survey data.   
http://thedataweb.rm.census.gov/TheDataWeb     References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Wage) lm(wage~year+age,data=Wage) ## maybe str(Wage) ; plot(Wage) ..."
"ISLR-Weekly","ISLR","Weekly","Weekly S&P Stock Market Data",1089,9,1,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Weekly.csv","https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Weekly.html","Weekly R Documentation   Weekly S&P Stock Market Data    Description  
Weekly percentage returns for the S&P 500 stock index between 1990 and 2010.   Usage   Weekly   Format  
A data frame with 1089 observations on the following 9 variables.    Year
The year that the observation was recorded   Lag1
Percentage return for previous week   Lag2
Percentage return for 2 weeks previous   Lag3
Percentage return for 3 weeks previous   Lag4
Percentage return for 4 weeks previous   Lag5
Percentage return for 5 weeks previous   Volume
Volume of shares traded (average number of daily shares traded in billions)   Today
Percentage return for this week   Direction
A factor with levels Down and  Up indicating whether the market had a positive or negative return on a given week     Source  
Raw values of the S&P 500 were obtained from Yahoo Finance and then converted to percentages and lagged.    References  
James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013)  An Introduction to Statistical Learning with applications in R ,  www.StatLearning.com , Springer-Verlag, New York    Examples    summary(Weekly) lm(Today~Lag1+Lag2,data=Weekly)"
"KMsurv-aids","KMsurv","aids","data from Section 1.19",295,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/aids.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/aids.html","aids R Documentation   data from Section 1.19   Description  
The aids data frame has 295 rows and 3 columns.    Format  
This data frame contains the following columns:    infect  
Infection time for AIDS, years    induct  
Induction time for AIDS, years    adult  
Indicator of adult (1=adult, 0=child)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Lagakos et al. Biometrika 68 (1981): 515-523.   Examples    data(aids)"
"KMsurv-alloauto","KMsurv","alloauto","data from Section 1.9",101,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/alloauto.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/alloauto.html","alloauto R Documentation   data from Section 1.9   Description  
The alloauto data frame has 90 rows and 5 columns.    Format  
This data frame contains the following columns:    time  
Time to death or relapse, months    type  
Type of transplant (1=allogeneic, 2=autologous)    delta  
Leukemia-free survival indicator (0=alive without relapse, 1=dead or relapse)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Kardaun Stat. Nederlandica 37 (1983), 103-126.    Examples    data(alloauto)"
"KMsurv-allograft","KMsurv","allograft","data from Exercise 13.1, p418",34,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/allograft.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/allograft.html","allograft R Documentation   data from Exercise 13.1, p418   Description  
The allograft data frame has 34 rows and 4 columns.    Format  
This data frame contains the following columns:    patient  
Patient    time  
Time to graft rejection, days    rejection  
Indicator of graft rejection (1=yes, 0=no)    match  
Good HLA skin match (1=yes, 0=no)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Batchelor and Hackett Lancet 2 (1970): 581-583.    Examples    data(allograft)"
"KMsurv-azt","KMsurv","azt","data from Exercise 4.7, p122",45,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/azt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/azt.html","azt R Documentation   data from Exercise 4.7, p122   Description  
The azt data frame has 45 rows and 4 columns.    Format  
This data frame contains the following columns:    patient  
Patient number    ageentry  
Age at entry into AZT study, months    age  
Age at death or censoring time, months    death  
Death indicator (1=dead, 0=alive)     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(azt)"
"KMsurv-baboon","KMsurv","baboon","data from Exercise 5.8, p147",152,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/baboon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/baboon.html","baboon R Documentation   data from Exercise 5.8, p147   Description  
The baboon data frame has 25 rows and 2 columns.    Format  
This data frame contains the following columns:    date  
Date (day/month/year)    time  
Descent time (military time)    observed  
Indicator of observed or not (1=observed, 0=not observed)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(baboon)"
"KMsurv-bcdeter","KMsurv","bcdeter","data from Section 1.18",95,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/bcdeter.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/bcdeter.html","bcdeter R Documentation   data from Section 1.18   Description  
The bcdeter data frame has 92 rows and 3 columns.    Format  
This data frame contains the following columns:    lower  
Lower limit of interval, months    upper  
Upper limit of interval, months    treat  
Treatment regimen (1=radiotherapy only, 2=radiotherapy + chemotherapy)     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Beadle et al Cancer 54 (1984):2911-2918.    Examples    data(bcdeter)"
"KMsurv-bfeed","KMsurv","bfeed","data from Section 1.14",927,10,5,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/bfeed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/bfeed.html","bfeed R Documentation   data from Section 1.14   Description  
The bfeed data frame has 927 rows and 10 columns.    Format  
This data frame contains the following columns:    duration  
Duration of breast feeding, weeks    delta  
Indicator of completed breast feeding (1=yes, 0=no)    race  
Race of mother (1=white, 2=black, 3=other)    poverty  
Mother in poverty (1=yes, 0=no)    smoke  
Mother smoked at birth of child (1=yes, 0=no)    alcohol  
Mother used alcohol at birth of child (1=yes, 0=no)    agemth  
Age of mother at birth of child    ybirth  
Year of birth    yschool  
Education level of mother (years of school)    pc3mth  
Prenatal care after 3rd month (1=yes, 0=no)     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.  National Longitudinal Survey of Youth Handbook The Ohio State University, 1995.    Examples    data(bfeed)"
"KMsurv-bmt","KMsurv","bmt","data from Section 1.3",137,22,12,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/bmt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/bmt.html","bmt R Documentation   data from Section 1.3   Description  
The bmt data frame has 137 rows and 22 columns.    Format  
This data frame contains the following columns:    group  
Disease Group 1-ALL, 2-AML Low Risk, 3-AML High Risk    t1  
Time To Death Or On Study Time    t2  
Disease Free Survival Time (Time To Relapse, Death Or End Of Study)    d1  
Death Indicator 1-Dead 0-Alive    d2  
Relapse Indicator 1-Relapsed, 0-Disease Free    d3  
Disease Free Survival Indicator 1-Dead Or Relapsed, 0-Alive Disease Free)    ta  
Time To Acute Graft-Versus-Host Disease    da  
Acute GVHD Indicator 1-Developed Acute GVHD 0-Never Developed Acute GVHD)    tc  
Time To Chronic Graft-Versus-Host Disease    dc  
Chronic GVHD Indicator 1-Developed Chronic GVHD 0-Never Developed Chronic GVHD   tp  
Time To Chronic Graft-Versus-Host Disease    dp  
Platelet Recovery Indicator 1-Platelets Returned To Normal, 0-Platelets Never Returned to Normal    z1  
Patient Age In Years    z2  
Donor Age In Years    z3  
Patient Sex: 1-Male, 0-Female    z4  
Donor Sex: 1-Male, 0-Female    z5  
Patient CMV Status: 1-CMV Positive, 0-CMV Negative    z6  
Donor CMV Status: 1-CMV Positive, 0-CMV Negative    z7  
Waiting Time to Transplant In Days    z8  
FAB: 1-FAB Grade 4 Or 5 and AML, 0-Otherwise    z9  
Hospital: 1-The Ohio State University, 2-Alferd , 3-St. Vincent, 4-Hahnemann    z10  
MTX Used as a Graft-Versus-Host- Prophylactic: 1-Yes 0-No      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(bmt)"
"KMsurv-bnct","KMsurv","bnct","data from Exercise 7.7, p223",30,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/bnct.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/bnct.html","bnct R Documentation   data from Exercise 7.7, p223   Description  
The bnct data frame has 34 rows and 3 columns.    Format  
This data frame contains the following columns:    trt  
Treatment (1=untreated, 2=radiated, 3=radiated + BPA)    time  
Death time or on-study time, days    death  
Death indicator (1=dead, 0=alive)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(bnct)"
"KMsurv-btrial","KMsurv","btrial","data from Section 1.5",45,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/btrial.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/btrial.html","btrial R Documentation   data from Section 1.5   Description  
The btrial data frame has 45 rows and 3 columns.    Format  
This data frame contains the following columns:    time  
Time to death or on-study time, months    death  
Death indicator (0=alive, 1=dead)   im  
Immunohistochemical response (1=negative, 2=positive)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Sedmak el al. Modern Pathology 2 (1989): 516-520.    Examples    data(btrial)"
"KMsurv-burn","KMsurv","burn","data from Section 1.6",154,18,12,0,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/burn.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/burn.html","burn R Documentation   data from Section 1.6   Description  
The burn data frame has 154 rows and 17 columns.    Format  
This data frame contains the following columns:    Obs  
Observation number    Z1  
Treatment: 0-routine bathing 1-Body cleansing    Z2  
Gender (0=male 1=female)    Z3  
Race: 0=nonwhite 1=white    Z4  
Percentage of total surface area burned    Z5  
Burn site indicator: head 1=yes, 0=no    Z6  
Burn site indicator: buttock 1=yes, 0=no    Z7  
Burn site indicator: trunk 1=yes, 0=no    Z8  
Burn site indicator: upper leg 1=yes, 0=no    Z9  
Burn site indicator: lower leg 1=yes, 0=no    Z10  
Burn site indicator: respiratory tract 1=yes, 0=no    Z11  
Type of burn: 1=chemical, 2=scald, 3=electric, 4=flame    T1  
Time to excision or on study time    D1  
Excision indicator: 1=yes 0=no    T2  
Time to prophylactic antibiotic treatment or on study time    D2  
Prophylactic antibiotic treatment: 1=yes 0=no    T3  
Time to straphylocous aureaus infection or on study time    D3  
Straphylocous aureaus infection: 1=yes 0=no      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Ichida et al. Stat. Med. 12 (1993): 301-310.    Examples    data(burn)"
"KMsurv-channing","KMsurv","channing","data from Section 1.16",462,6,2,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/channing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/channing.html","channing R Documentation   data from Section 1.16   Description  
The channing data frame has 462 rows and 6 columns.    Format  
This data frame contains the following columns:    obs  
Observation number    death  
Death status (1=dead, 0=alive)    ageentry  
Age of entry into retirement home, months    age  
Age of death or left retirement home, months    time  
Difference between the above two ages, months    gender  
Gender (1=male, 2=female)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Hyde Biometrika (1977), 225-230.    Examples    data(channing)"
"KMsurv-drug6mp","KMsurv","drug6mp","data from Section 1.2",21,5,2,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/drug6mp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/drug6mp.html","drug6mp R Documentation   data from Section 1.2   Description  
The drug6mp data frame has 21 rows and 5 columns.    Format  
This data frame contains the following columns:    pair  
pair number    remstat  
Remission status at randomization (1=partial, 2=complete)    t1  
Time to relapse for placebo patients, months   t2  
Time to relapse for 6-MP patients, months   relapse  
Relapse indicator (0=censored, 1=relapse) for 6-MP patients      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Freireich et al. (1963) Blood 21: 699-716.    Examples    data(drug6mp)"
"KMsurv-drughiv","KMsurv","drughiv","data from Exercise 7.6, p222",34,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/drughiv.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/drughiv.html","drughiv R Documentation   data from Exercise 7.6, p222   Description  
The drughiv data frame has 34 rows and 3 columns.    Format  
This data frame contains the following columns:    drug  
Drug combination (1=AZT + zalcitabine, 2=AZT + zalcitabine + saquinavir)    time  
Time after drug administration to CD4 count at a specified level, days    delta  
Indicator of CD4 count reaching specified level (1=yes, 0=no)     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(drughiv)"
"KMsurv-hodg","KMsurv","hodg","data from Section 1.10",43,6,3,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/hodg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/hodg.html","hodg R Documentation   data from Section 1.10   Description  
The hodg data frame has 43 rows and 6 columns.    Format  
This data frame contains the following columns:    gtype  
Graft type (1=allogenic, 2=autologous)    dtype  
Disease type (1=Non Hodgkin lymphoma, 2=Hodgkins disease)    time  
Time to death or relapse, days    delta  
Death/relapse indicator (0=alive, 1=dead)    score  
Karnofsky score    wtime  
Waiting time to transplant in months      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Avalos et al. Bone Marrow Transplantation 13(1993):133-138.    Examples    data(hodg)"
"KMsurv-kidney","KMsurv","kidney","data from Section 1.4",119,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/kidney.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/kidney.html","kidney R Documentation   data from Section 1.4   Description  
The kidney data frame has 119 rows and 3 columns.    Format  
This data frame contains the following columns:    time  
Time to infection, months   delta  
Infection indicator (0=no, 1=yes)    type  
Catheter placement (1=surgically, 2=percutaneously)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Nahman el at. J. Am Soc. Nephrology 3 (1992): 103-107.    Examples    data(kidney)"
"KMsurv-kidrecurr","KMsurv","kidrecurr","Data on 38 individuals using a kidney dialysis machine",38,10,6,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/kidrecurr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/kidrecurr.html","kidrecurr R Documentation   Data on 38 individuals using a kidney dialysis machine   Description  
Data on 38 individuals using a kidney dialysis machine See Problem 13.5.2    Usage   data(kidrecurr)   Format  
A data frame with 38 observations on the following 10 variables.    patient
Patient number   time1
Time one of recurrence of infection, days   infect1
Indicator infection one (1=yes, 0=no)   time2
Time two of recurrence of infection, days   infect2
Indicator infection two (1=yes, 0=no)   age
Patient's age   gender
Patient's gender   gn
Disease type GN (1=yes, 0=no)   an
Disease type AN (1=yes, 0=no)   pkd
Disease type PKD (1=yes, 0=no)     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. McGilchrist and Aisbett 47 (1991):461-466.    Examples    data(kidrecurr)"
"KMsurv-kidtran","KMsurv","kidtran","data from Section 1.7",863,6,3,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/kidtran.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/kidtran.html","kidtran R Documentation   data from Section 1.7   Description  
The kidtran data frame has 863 rows and 6 columns.    Format  
This data frame contains the following columns:    obs  
Observation number    time  
Time to death or on-study time    delta  
Death indicator (0=alive, 1=dead)    gender  
1=male, 2=female    race  
1=white, 2=black    age  
Age in years      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(kidtran)"
"KMsurv-larynx","KMsurv","larynx","data from Section 1.8",90,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/larynx.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/larynx.html","larynx R Documentation   data from Section 1.8   Description  
The larynx data frame has 90 rows and 5 columns.    Format  
This data frame contains the following columns:    stage  
Stage of disease (1=stage 1, 2=stage2, 3=stage 3, 4=stage 4)    time  
Time to death or on-study time, months    age  
Age at diagnosis of larynx cancer    diagyr  
Year of diagnosis of larynx cancer    delta  
Death indicator (0=alive, 1=dead)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Kardaun Stat. Nederlandica 37 (1983), 103-126.    Examples    data(larynx)"
"KMsurv-lung","KMsurv","lung","data from Exercise 4.4, p120",25,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/lung.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/lung.html","lung R Documentation   data from Exercise 4.4, p120   Description  
The lung data frame has 25 rows and 4 columns.    Format  
This data frame contains the following columns:    time  
Days to death    death  
Death indicator (1=dead), complete follow-up on all patients    time2  
Days to 3/31/80 or death (interim analysis)    death2  
Death indicator as of 3/31/80 (1=dead, 0=alive)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(lung)"
"KMsurv-pneumon","KMsurv","pneumon","data from Section 1.13",3470,15,4,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/pneumon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/pneumon.html","pneumon R Documentation   data from Section 1.13   Description  
The pneumon data frame has 3470 rows and 15 columns.    Format  
This data frame contains the following columns:    chldage  
Age child had pneumonia, months    hospital  
Indicator for hospitalization for pneumonia (1=yes, 0=no)    mthage  
Age of the mother, years    urban  
Urban environment for mother (1=yes, 0=no)    alcohol  
Alcohol use by mother during pregnancy (1=yes, 0=no)    smoke  
Cigarette use by mother during pregnancy (1=yes, 0=no)    region  
Region of the coutry (1=northeast, 2=north central, 3=south, 4=west)    poverty  
Mother at poverty level (1=yes, 0=no)    bweight  
Normal birthweight (>5.5 lbs.) (1=yes, 0=no)    race  
Race of the mother (1=white, 2=black, 3=other)    education  
Education of the mother, years of school    nsibs  
Number of siblings of the child    wmonth  
Month the child was weaned    sfmonth  
Month the child on solid food    agepn  
Age child in the hospital for pneumonia, months     Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.  National Longitudinal Survey of Youth Handbook The Ohio State University, 1995.    Examples    data(pneumon)"
"KMsurv-psych","KMsurv","psych","data from Section 1.15",26,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/psych.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/psych.html","psych R Documentation   data from Section 1.15   Description  
The psych data frame has 927 rows and 10 columns.    Format  
This data frame contains the following columns:    sex  
Patient sex (1=male, 2=female)    age  
Patient age    time  
Time to death or on-study time    death  
Death indicator (0=alive, 1=dead)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Woolsen Biometrics 37 (1981): 687-696.    Examples    data(psych)"
"KMsurv-rats","KMsurv","rats","data from Exercise 7.13, p225",150,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/rats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/rats.html","rats R Documentation   data from Exercise 7.13, p225   Description  
The rats data frame has 50 rows and 4 columns.    Format  
This data frame contains the following columns:    time  
Time to tumor development    tumor  
Indicator of tumor development (1=yes, 0=no)    trt  
Treatment (1=treated with drug, 0=given placebo)    litter  
Litter      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(rats)"
"KMsurv-std","KMsurv","std","data from Section 1.12",877,24,16,0,2,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/std.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/std.html","std R Documentation   data from Section 1.12   Description  
The std data frame has 877 rows and 3 columns.    Format  
This data frame contains the following columns:    obs  
Observation number    race  
Race (W=white, B=black)    marital  
Marital status (D=divorced / separated, M=married, S=single)    age  
AGE    yschool  
Years of schooling    iinfct  
Initial infection (1= gonorrhea, 2=chlamydia, 3=both)    npartner  
Number of partners    os12m  
Oral sex within 12 months (1=yes, 0=no)    os30d  
Oral sex within 30 days (1=yes, 0=no)    rs12m  
Rectal sex within 12 months (1=yes, 0=no)    rs30d  
Rectal sex within 30 days (1=yes, 0=no)    abdpain  
Presence of abdominal pain (1=yes, 0=no)    discharge  
Sign of discharge (1=yes, 0=no)    dysuria  
Sign of dysuria (1=yes, 0=no)    condom  
Condom use (1=always, 2=sometime, 3=never)    itch  
Sign of itch (1=yes, 0=no)    lesion  
Sign of lesion (1=yes, 0=no)    rash  
Sign of rash (1=yes, 0=no)    lymph  
Sign of lymph (1=yes, 0=no)    vagina  
Involvement vagina at exam (1=yes, 0=no)    dchexam  
Discharge at exam (1=yes, 0=no)    abnode  
Abnormal node at exam (1=yes, 0=no)    rinfct  
Reinfection (1=yes, 0=no)    time  
Time to reinfection      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(std)"
"KMsurv-stddiag","KMsurv","stddiag","data from Exercise 5.6, p146",25,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/stddiag.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/stddiag.html","stddiag R Documentation   data from Exercise 5.6, p146   Description  
The stddiag data frame has 25 rows and 2 columns.    Format  
This data frame contains the following columns:    encounter  
Months from 1/93 to encounter    diagnosed  
Months until STD diagnosed in the clinic      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(stddiag)"
"KMsurv-tongue","KMsurv","tongue","data from Section 1.11",80,3,2,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/tongue.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/tongue.html","tongue R Documentation   data from Section 1.11   Description  
The tongue data frame has 80 rows and 3 columns.    Format  
This data frame contains the following columns:    type  
Tumor DNA profile (1=Aneuploid Tumor, 2=Diploid Tumor)    time  
Time to death or on-study time, weeks    delta  
Death indicator (0=alive, 1=dead)      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer. Sickle-Santanello et al. Cytometry 9 (1988): 594-599.    Examples    data(tongue)"
"KMsurv-twins","KMsurv","twins","data from Exercise 7.14, p225",24,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/KMsurv/twins.csv","https://vincentarelbundock.github.io/Rdatasets/doc/KMsurv/twins.html","twins R Documentation   data from Exercise 7.14, p225   Description  
The twins data frame has 24 rows and 3 columns.    Format  
This data frame contains the following columns:    id  
Twin number    age  
Age of twin's death from CHD, months    death  
Death (male twin) from CHD indicator (1=dead from CHD, 0=alive or other cause of death)    gender  
1=male, 2=female      Source  
Klein and Moeschberger (1997) Survival Analysis Techniques for Censored and truncated data , Springer.    Examples    data(twins)"
"lattice-barley","lattice","barley","Yield data from a Minnesota barley trial",120,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/barley.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/barley.html","H_barley R Documentation   Yield data from a Minnesota barley trial   Description  
Total yield in bushels per acre for 10 varieties at 6 sites in each of two years.    Usage   barley   Format  
A data frame with 120 observations on the following 4 variables.    yield
Yield (averaged across three blocks) in bushels/acre.   variety
Factor with levels ""Svansota"" , ""No. 462"" ,  ""Manchuria"" , ""No. 475"" , ""Velvet"" ,  ""Peatland"" , ""Glabron"" , ""No. 457"" ,  ""Wisconsin No. 38"" , ""Trebi"" .   year
Factor with levels 1932 , 1931   site
Factor with 6 levels: ""Grand Rapids"" ,  ""Duluth"" , ""University Farm"" , ""Morris"" ,  ""Crookston"" , ""Waseca""     Details  
These data are yields in bushels per acre, of 10 varieties of barley grown in 1/40 acre plots at University Farm, St. Paul, and at the five branch experiment stations located at Waseca, Morris, Crookston, Grand Rapids, and Duluth (all in Minnesota). The varieties were grown in three randomized blocks at each of the six stations during 1931 and 1932, different land being used each year of the test.   
Immer et al. (1934) present the data for each Year*Site*Variety*Block. The data here is the average yield across the three blocks.   
Immer et al. (1934) refer (once) to the experiment as being conducted in 1930 and 1931, then later refer to it (repeatedly) as being conducted in 1931 and 1932. Later authors have continued the confusion.   
Cleveland (1993) suggests that the data for the Morris site may have had the years switched.    Author(s)  
Documentation contributed by Kevin Wright.    Source  
Immer, R. F., H. K. Hayes, and LeRoy Powers. (1934). Statistical Determination of Barley Varietal Adaptation. Journal of the American Society of Agronomy , 26 , 403–419.   
Wright, Kevin (2013). Revisiting Immer's Barley Data. The American Statistician , 67(3) , 129–133.    References  
Cleveland, William S. (1993) Visualizing Data . Hobart Press, Summit, New Jersey.   
Fisher, R. A. (1971) The Design of Experiments . Hafner, New York, 9th edition.    See Also  
immer in the MASS package for data from the same experiment (expressed as total yield for 3 blocks) for a subset of varieties.   Examples    # Graphic suggesting the Morris data switched the years 1931 and 1932 # Figure 1.1 from Cleveland dotplot(variety ~ yield | site, data = barley, groups = year, key = simpleKey(levels(barley$year), space = ""right""), xlab = ""Barley Yield (bushels/acre) "", aspect=0.5, layout = c(1,6), ylab=NULL)"
"lattice-environmental","lattice","environmental","Atmospheric environmental conditions in New York City",111,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/environmental.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/environmental.html","H_environmental R Documentation   Atmospheric environmental conditions in New York City   Description  
Daily measurements of ozone concentration, wind speed, temperature and solar radiation in New York City from May to September of 1973.    Usage   environmental   Format  
A data frame with 111 observations on the following 4 variables.    ozone
Average ozone concentration (of hourly measurements) of in parts per billion.   radiation
Solar radiation (from 08:00 to 12:00) in langleys.   temperature
Maximum daily emperature in degrees Fahrenheit.   wind
Average wind speed (at 07:00 and 10:00) in miles per hour.     Author(s)  
Documentation contributed by Kevin Wright.    Source  
Bruntz, S. M., W. S. Cleveland, B. Kleiner, and J. L. Warner. (1974). The Dependence of Ambient Ozone on Solar Radiation, Wind, Temperature, and Mixing Height. In Symposium on Atmospheric Diffusion and Air Pollution , pages 125–128. American Meterological Society, Boston.    References  
Cleveland, William S. (1993) Visualizing Data . Hobart Press, Summit, New Jersey.    Examples    # Scatter plot matrix with loess lines splom(~environmental, panel=function(x,y){ panel.xyplot(x,y) panel.loess(x,y) } ) # Conditioned plot similar to figure 5.3 from Cleveland attach(environmental) Temperature <- equal.count(temperature, 4, 1/2) Wind <- equal.count(wind, 4, 1/2) xyplot((ozone^(1/3)) ~ radiation | Temperature * Wind, aspect=1, prepanel = function(x, y) prepanel.loess(x, y, span = 1), panel = function(x, y){ panel.grid(h = 2, v = 2) panel.xyplot(x, y, cex = .5) panel.loess(x, y, span = 1) }, xlab = ""Solar radiation (langleys)"", ylab = ""Ozone (cube root ppb)"") detach() # Similar display using the coplot function with(environmental,{ coplot((ozone^.33) ~ radiation | temperature * wind, number=c(4,4), panel = function(x, y, ...) panel.smooth(x, y, span = .8, ...), xlab=""Solar radiation (langleys)"", ylab=""Ozone (cube root ppb)"") })"
"lattice-ethanol","lattice","ethanol","Engine exhaust fumes from burning ethanol",88,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/ethanol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/ethanol.html","H_ethanol R Documentation   Engine exhaust fumes from burning ethanol   Description  
Ethanol fuel was burned in a single-cylinder engine. For various settings of the engine compression and equivalence ratio, the emissions of nitrogen oxides were recorded.    Usage   ethanol   Format  
A data frame with 88 observations on the following 3 variables.    NOx
Concentration of nitrogen oxides (NO and NO2) in micrograms/J.   C
Compression ratio of the engine.   E
Equivalence ratio–a measure of the richness of the air and ethanol fuel mixture.     Author(s)  
Documentation contributed by Kevin Wright.    Source  
Brinkman, N.D. (1981) Ethanol Fuel—A Single-Cylinder Engine Study of Efficiency and Exhaust Emissions. SAE transactions ,  90 , 1410–1424.    References  
Cleveland, William S. (1993) Visualizing Data . Hobart Press, Summit, New Jersey.    Examples    ## Constructing panel functions on the fly EE <- equal.count(ethanol$E, number=9, overlap=1/4) xyplot(NOx ~ C | EE, data = ethanol, prepanel = function(x, y) prepanel.loess(x, y, span = 1), xlab = ""Compression ratio"", ylab = ""NOx (micrograms/J)"", panel = function(x, y) { panel.grid(h=-1, v= 2) panel.xyplot(x, y) panel.loess(x,y, span=1) }, aspect = ""xy"") # Wireframe loess surface fit. See Figure 4.61 from Cleveland. require(stats) with(ethanol, { eth.lo <- loess(NOx ~ C * E, span = 1/3, parametric = ""C"", drop.square = ""C"", family=""symmetric"") eth.marginal <- list(C = seq(min(C), max(C), length.out = 25), E = seq(min(E), max(E), length.out = 25)) eth.grid <- expand.grid(eth.marginal) eth.fit <- predict(eth.lo, eth.grid) wireframe(eth.fit ~ eth.grid$C * eth.grid$E, shade=TRUE, screen = list(z = 40, x = -60, y=0), distance = .1, xlab = ""C"", ylab = ""E"", zlab = ""NOx"") })"
"lattice-melanoma","lattice","melanoma","Melanoma skin cancer incidence",37,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/melanoma.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/melanoma.html","H_melanoma R Documentation   Melanoma skin cancer incidence   Description  
These data from the Connecticut Tumor Registry present age-adjusted numbers of melanoma skin-cancer incidences per 100,000 people in Connectict for the years from 1936 to 1972.    Usage   melanoma   Format  
A data frame with 37 observations on the following 2 variables.    year
Years 1936 to 1972.   incidence
Rate of melanoma cancer per 100,000 population.     Note  
This dataset is not related to the melanoma  dataset in the boot package with the same name.   
The S-PLUS 6.2 help for the melanoma data says that the incidence rate is per million , but this is not consistent with data found at the National Cancer Institute ( https://www.cancer.gov/ ).    Author(s)  
Documentation contributed by Kevin Wright.    Source  
Houghton, A., E. W. Munster, and M. V. Viola. (1978). Increased Incidence of Malignant Melanoma After Peaks of Sunspot Activity.  The Lancet , 8 , 759–760.    References  
Cleveland, William S. (1993) Visualizing Data . Hobart Press, Summit, New Jersey.    Examples    # Time-series plot. Figure 3.64 from Cleveland. xyplot(incidence ~ year, data = melanoma, aspect = ""xy"", panel = function(x, y) panel.xyplot(x, y, type=""o"", pch = 16), ylim = c(0, 6), xlab = ""Year"", ylab = ""Incidence"")"
"lattice-singer","lattice","singer","Heights of New York Choral Society singers",235,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/singer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/singer.html","H_singer R Documentation   Heights of New York Choral Society singers   Description  
Heights in inches of the singers in the New York Choral Society in 1979. The data are grouped according to voice part. The vocal range for each voice part increases in pitch according to the following order: Bass 2, Bass 1, Tenor 2, Tenor 1, Alto 2, Alto 1, Soprano 2, Soprano 1.    Usage   singer   Format  
A data frame with 235 observations on the following 2 variables.    height
Height in inches of the singers.   voice.part
(Unordered) factor with levels "" Bass 2 "", "" Bass 1 "", "" Tenor 2 "", "" Tenor 1 "", "" Alto 2 "", "" Alto 1 "", "" Soprano 2 "", "" Soprano 1 "".     Author(s)  
Documentation contributed by Kevin Wright.    Source  
Chambers, J.M., W. S. Cleveland, B. Kleiner, and P. A. Tukey. (1983).  Graphical Methods for Data Analysis . Chapman and Hall, New York.    References  
Cleveland, William S. (1993) Visualizing Data . Hobart Press, Summit, New Jersey.    Examples    # Separate histogram for each voice part (Figure 1.2 from Cleveland) histogram(~ height | voice.part, data = singer, aspect=1, layout = c(2, 4), nint=15, xlab = ""Height (inches)"") # Quantile-Quantile plot (Figure 2.11 from Cleveland) qqmath(~ height | voice.part, data=singer, aspect=1, layout=c(2,4), prepanel = prepanel.qqmathline, panel = function(x, ...) { panel.grid() panel.qqmathline(x, ...) panel.qqmath(x, ...) }, xlab = ""Unit Normal Quantile"", ylab=""Height (inches)"")"
"lattice-USMortality","lattice","USMortality","Mortality Rates in US by Cause and Gender",40,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/USMortality.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/USMortality.html","H_USMortality R Documentation   Mortality Rates in US by Cause and Gender   Description  
These datasets record mortality rates across all ages in the USA by cause of death, sex, and rural/urban status, 2011–2013. The two datasets represent the national aggregate rates and the region-wise rates for each administrative region under the Department of Health and Human Services (HHS).    Usage    USMortality USRegionalMortality    Format  
USRegionalMortality is a data frame with 400 observations on the following 6 variables.    Region
A factor specifying HHS Region. See details.   Status
A factor with levels Rural and Urban   Sex
A factor with levels Female and Male   Cause
Cause of death. A factor with levels  Alzheimers , Cancer , Cerebrovascular diseases ,  Diabetes , Flu and pneumonia , Heart disease ,  Lower respiratory , Nephritis , Suicide , and  Unintentional injuries   Rate
Age-adjusted death rate per 100,000 population   SE
Standard error for the rate    
USMortality is a data frame with 40 observations, containing the same variables with the exception of Region .    Details  
The region-wise data give estimated rates separately for each of 10 HHS regions. The location of the regional offices and their coverage area, available from  https://www.hhs.gov/about/agencies/iea/regional-offices/index.html , is given below.    HHS Region 01 - Boston:
Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont   HHS Region 02 - New York:
New Jersey, New York, Puerto Rico, and the Virgin Islands   HHS Region 03 - Philadelphia:
Delaware, District of Columbia, Maryland, Pennsylvania, Virginia, and West Virginia   HHS Region 04 - Atlanta:
Alabama, Florida, Georgia, Kentucky, Mississippi, North Carolina, South Carolina, and Tennessee   HHS Region 05 - Chicago:
Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin   HHS Region 06 - Dallas:
Arkansas, Louisiana, New Mexico, Oklahoma, and Texas   HHS Region 07 - Kansas City:
Iowa, Kansas, Missouri, and Nebraska   HHS Region 08 - Denver:
Colorado, Montana, North Dakota, South Dakota, Utah, and Wyoming   HHS Region 09 - San Francisco:
Arizona, California, Hawaii, Nevada, American Samoa, Commonwealth of the Northern Mariana Islands, Federated States of Micronesia, Guam, Marshall Islands, and Republic of Palau   HHS Region 10 - Seattle:
Alaska, Idaho, Oregon, and Washington     References  
Rural Health Reform Policy Research Center. _Exploring Rural and Urban Mortality Differences_, August 2015 Bethesda, MD. https://ruralhealth.und.edu/projects/health-reform-policy-research-center/rural-urban-mortality     Examples    dotplot(reorder(Cause, Rate) ~ Rate | Status, data = USMortality, groups = Sex, par.settings = simpleTheme(pch = 16), auto.key = list(columns = 2), scales = list(x = list(log = TRUE, equispaced.log = FALSE))) dotplot(reorder(Cause, Rate):Sex ~ Rate | Status, data = USRegionalMortality, groups = Sex, scales = list(x = list(log = TRUE, equispaced.log = FALSE)))"
"lattice-USRegionalMortality","lattice","USRegionalMortality","Mortality Rates in US by Cause and Gender",400,6,2,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lattice/USRegionalMortality.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lattice/USRegionalMortality.html","H_USMortality R Documentation   Mortality Rates in US by Cause and Gender   Description  
These datasets record mortality rates across all ages in the USA by cause of death, sex, and rural/urban status, 2011–2013. The two datasets represent the national aggregate rates and the region-wise rates for each administrative region under the Department of Health and Human Services (HHS).    Usage    USMortality USRegionalMortality    Format  
USRegionalMortality is a data frame with 400 observations on the following 6 variables.    Region
A factor specifying HHS Region. See details.   Status
A factor with levels Rural and Urban   Sex
A factor with levels Female and Male   Cause
Cause of death. A factor with levels  Alzheimers , Cancer , Cerebrovascular diseases ,  Diabetes , Flu and pneumonia , Heart disease ,  Lower respiratory , Nephritis , Suicide , and  Unintentional injuries   Rate
Age-adjusted death rate per 100,000 population   SE
Standard error for the rate    
USMortality is a data frame with 40 observations, containing the same variables with the exception of Region .    Details  
The region-wise data give estimated rates separately for each of 10 HHS regions. The location of the regional offices and their coverage area, available from  https://www.hhs.gov/about/agencies/iea/regional-offices/index.html , is given below.    HHS Region 01 - Boston:
Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont   HHS Region 02 - New York:
New Jersey, New York, Puerto Rico, and the Virgin Islands   HHS Region 03 - Philadelphia:
Delaware, District of Columbia, Maryland, Pennsylvania, Virginia, and West Virginia   HHS Region 04 - Atlanta:
Alabama, Florida, Georgia, Kentucky, Mississippi, North Carolina, South Carolina, and Tennessee   HHS Region 05 - Chicago:
Illinois, Indiana, Michigan, Minnesota, Ohio, and Wisconsin   HHS Region 06 - Dallas:
Arkansas, Louisiana, New Mexico, Oklahoma, and Texas   HHS Region 07 - Kansas City:
Iowa, Kansas, Missouri, and Nebraska   HHS Region 08 - Denver:
Colorado, Montana, North Dakota, South Dakota, Utah, and Wyoming   HHS Region 09 - San Francisco:
Arizona, California, Hawaii, Nevada, American Samoa, Commonwealth of the Northern Mariana Islands, Federated States of Micronesia, Guam, Marshall Islands, and Republic of Palau   HHS Region 10 - Seattle:
Alaska, Idaho, Oregon, and Washington     References  
Rural Health Reform Policy Research Center. _Exploring Rural and Urban Mortality Differences_, August 2015 Bethesda, MD. https://ruralhealth.und.edu/projects/health-reform-policy-research-center/rural-urban-mortality     Examples    dotplot(reorder(Cause, Rate) ~ Rate | Status, data = USMortality, groups = Sex, par.settings = simpleTheme(pch = 16), auto.key = list(columns = 2), scales = list(x = list(log = TRUE, equispaced.log = FALSE))) dotplot(reorder(Cause, Rate):Sex ~ Rate | Status, data = USRegionalMortality, groups = Sex, scales = list(x = list(log = TRUE, equispaced.log = FALSE)))"
"lme4-Arabidopsis","lme4","Arabidopsis","Arabidopsis clipping/fertilization data",625,8,3,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/Arabidopsis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/Arabidopsis.html","Arabidopsis R Documentation    Arabidopsis clipping/fertilization data    Description  
Data on genetic variation in responses to fertilization and simulated herbivory in Arabidopsis     Usage   data(""Arabidopsis"")   Format  
A data frame with 625 observations on the following 8 variables.    reg
region: a factor with 3 levels NL  (Netherlands), SP (Spain), SW (Sweden)   popu
population: a factor with the form n.R  representing a population in region R   gen
genotype: a factor with 24 (numeric-valued) levels   rack
a nuisance factor with 2 levels, one for each of two greenhouse racks   nutrient
fertilization treatment/nutrient level (1, minimal nutrients or 8, added nutrients)   amd
simulated herbivory or ""clipping"" (apical meristem damage): unclipped (baseline) or clipped   status
a nuisance factor for germination method ( Normal , Petri.Plate , or Transplant )   total.fruits
total fruit set per plant (integer)     Source  
From Josh Banta    References  
Joshua A. Banta, Martin H. H Stevens, and Massimo Pigliucci (2010) A comprehensive test of the 'limiting resources' framework applied to plant tolerance to apical meristem damage.  Oikos 119 (2), 359–369; doi: 10.1111/j.1600-0706.2009.17726.x     Examples    data(Arabidopsis) summary(Arabidopsis[,""total.fruits""]) table(gsub(""[0-9]."","""",levels(Arabidopsis[,""popu""]))) library(lattice) stripplot(log(total.fruits+1) ~ amd|nutrient, data = Arabidopsis, groups = gen, strip=strip.custom(strip.names=c(TRUE,TRUE)), type=c('p','a'), ## points and panel-average value -- ## see ?panel.xyplot scales=list(x=list(rot=90)), main=""Panel: nutrient, Color: genotype"")"
"lme4-cake","lme4","cake","Breakage Angle of Chocolate Cakes",270,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/cake.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/cake.html","cake R Documentation   Breakage Angle of Chocolate Cakes   Description  
Data on the breakage angle of chocolate cakes made with three different recipes and baked at six different temperatures. This is a split-plot design with the recipes being whole-units and the different temperatures being applied to sub-units (within replicates). The experimental notes suggest that the replicate numbering represents temporal ordering.    Format  
A data frame with 270 observations on the following 5 variables.    replicate
a factor with levels 1 to 15   recipe
a factor with levels A , B and C   temperature
an ordered factor with levels 175  < 185 < 195 < 205 < 215 < 225   angle
a numeric vector giving the angle at which the cake broke.   temp
numeric value of the baking temperature (degrees F).     Details  
The replicate factor is nested within the  recipe factor, and temperature is nested within replicate .    Source  
Original data were presented in Cook (1938), and reported in Cochran and Cox (1957, p. 300). Also cited in Lee, Nelder and Pawitan (2006).    References  
Cook, F. E. (1938) Chocolate cake, I. Optimum baking temperature . Master's Thesis, Iowa State College.   
Cochran, W. G., and Cox, G. M. (1957) Experimental designs , 2nd Ed. New York, John Wiley \& Sons.   
Lee, Y., Nelder, J. A., and Pawitan, Y. (2006)  Generalized linear models with random effects. Unified analysis via H-likelihood . Boca Raton, Chapman and Hall/CRC.    Examples    str(cake) ## 'temp' is continuous, 'temperature' an ordered factor with 6 levels (fm1 <- lmer(angle ~ recipe * temperature + (1|recipe:replicate), cake, REML= FALSE)) (fm2 <- lmer(angle ~ recipe + temperature + (1|recipe:replicate), cake, REML= FALSE)) (fm3 <- lmer(angle ~ recipe + temp + (1|recipe:replicate), cake, REML= FALSE)) ## and now ""choose"" : anova(fm3, fm2, fm1)"
"lme4-cbpp","lme4","cbpp","Contagious bovine pleuropneumonia",56,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/cbpp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/cbpp.html","cbpp R Documentation   Contagious bovine pleuropneumonia   Description  
Contagious bovine pleuropneumonia (CBPP) is a major disease of cattle in Africa, caused by a mycoplasma. This dataset describes the serological incidence of CBPP in zebu cattle during a follow-up survey implemented in 15 commercial herds located in the Boji district of Ethiopia. The goal of the survey was to study the within-herd spread of CBPP in newly infected herds. Blood samples were quarterly collected from all animals of these herds to determine their CBPP status. These data were used to compute the serological incidence of CBPP (new cases occurring during a given time period). Some data are missing (lost to follow-up).    Format  
A data frame with 56 observations on the following 4 variables.    herd
A factor identifying the herd (1 to 15).   incidence
The number of new serological cases for a given herd and time period.   size
A numeric vector describing herd size at the beginning of a given time period.   period
A factor with levels 1 to 4 .     Details  
Serological status was determined using a competitive enzyme-linked immuno-sorbent assay (cELISA).    Source  
Lesnoff, M., Laval, G., Bonnet, P., Abdicho, S., Workalemahu, A., Kifle, D., Peyraud, A., Lancelot, R., Thiaucourt, F. (2004) Within-herd spread of contagious bovine pleuropneumonia in Ethiopian highlands.  Preventive Veterinary Medicine 64 , 27–40.    Examples    ## response as a matrix (m1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), family = binomial, data = cbpp)) ## response as a vector of probabilities and usage of argument ""weights"" m1p <- glmer(incidence / size ~ period + (1 | herd), weights = size, family = binomial, data = cbpp) ## Confirm that these are equivalent: stopifnot(all.equal(fixef(m1), fixef(m1p), tolerance = 1e-5), all.equal(ranef(m1), ranef(m1p), tolerance = 1e-5)) ## GLMM with individual-level variability (accounting for overdispersion) cbpp$obs <- 1:nrow(cbpp) (m2 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd) + (1|obs), family = binomial, data = cbpp))"
"lme4-Dyestuff","lme4","Dyestuff","Yield of dyestuff by batch",30,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/Dyestuff.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/Dyestuff.html","Dyestuff R Documentation   Yield of dyestuff by batch   Description  
The Dyestuff data frame provides the yield of dyestuff (Naphthalene Black 12B) from 5 different preparations from each of 6 different batchs of an intermediate product (H-acid). The Dyestuff2 data were generated data in the same structure but with a large residual variance relative to the batch variance.    Format  
Data frames, each with 30 observations on the following 2 variables.    Batch
a factor indicating the batch of the intermediate product from which the preparation was created.   Yield
the yield of dyestuff from the preparation (grams of standard color).     Details  
The Dyestuff data are described in Davies and Goldsmith (1972) as coming from “an investigation to find out how much the variation from batch to batch in the quality of an intermediate product (H-acid) contributes to the variation in the yield of the dyestuff (Naphthalene Black 12B) made from it. In the experiment six samples of the intermediate, representing different batches of works manufacture, were obtained, and five preparations of the dyestuff were made in the laboratory from each sample. The equivalent yield of each preparation as grams of standard colour was determined by dye-trial.”   
The Dyestuff2 data are described in Box and Tiao (1973) as illustrating “ the case where between-batches mean square is less than the within-batches mean square. These data had to be constructed for although examples of this sort undoubtably occur in practice, they seem to be rarely published.”    Source  
O.L. Davies and P.L. Goldsmith (eds), Statistical Methods in Research and Production, 4th ed. , Oliver and Boyd, (1972), section 6.4   
G.E.P. Box and G.C. Tiao, Bayesian Inference in Statistical Analysis , Addison-Wesley, (1973), section 5.1.2    Examples    require(lattice) str(Dyestuff) dotplot(reorder(Batch, Yield) ~ Yield, Dyestuff, ylab = ""Batch"", jitter.y = TRUE, aspect = 0.3, type = c(""p"", ""a"")) dotplot(reorder(Batch, Yield) ~ Yield, Dyestuff2, ylab = ""Batch"", jitter.y = TRUE, aspect = 0.3, type = c(""p"", ""a"")) (fm1 <- lmer(Yield ~ 1|Batch, Dyestuff)) (fm2 <- lmer(Yield ~ 1|Batch, Dyestuff2))"
"lme4-Dyestuff2","lme4","Dyestuff2","Yield of dyestuff by batch",30,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/Dyestuff2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/Dyestuff2.html","Dyestuff R Documentation   Yield of dyestuff by batch   Description  
The Dyestuff data frame provides the yield of dyestuff (Naphthalene Black 12B) from 5 different preparations from each of 6 different batchs of an intermediate product (H-acid). The Dyestuff2 data were generated data in the same structure but with a large residual variance relative to the batch variance.    Format  
Data frames, each with 30 observations on the following 2 variables.    Batch
a factor indicating the batch of the intermediate product from which the preparation was created.   Yield
the yield of dyestuff from the preparation (grams of standard color).     Details  
The Dyestuff data are described in Davies and Goldsmith (1972) as coming from “an investigation to find out how much the variation from batch to batch in the quality of an intermediate product (H-acid) contributes to the variation in the yield of the dyestuff (Naphthalene Black 12B) made from it. In the experiment six samples of the intermediate, representing different batches of works manufacture, were obtained, and five preparations of the dyestuff were made in the laboratory from each sample. The equivalent yield of each preparation as grams of standard colour was determined by dye-trial.”   
The Dyestuff2 data are described in Box and Tiao (1973) as illustrating “ the case where between-batches mean square is less than the within-batches mean square. These data had to be constructed for although examples of this sort undoubtably occur in practice, they seem to be rarely published.”    Source  
O.L. Davies and P.L. Goldsmith (eds), Statistical Methods in Research and Production, 4th ed. , Oliver and Boyd, (1972), section 6.4   
G.E.P. Box and G.C. Tiao, Bayesian Inference in Statistical Analysis , Addison-Wesley, (1973), section 5.1.2    Examples    require(lattice) str(Dyestuff) dotplot(reorder(Batch, Yield) ~ Yield, Dyestuff, ylab = ""Batch"", jitter.y = TRUE, aspect = 0.3, type = c(""p"", ""a"")) dotplot(reorder(Batch, Yield) ~ Yield, Dyestuff2, ylab = ""Batch"", jitter.y = TRUE, aspect = 0.3, type = c(""p"", ""a"")) (fm1 <- lmer(Yield ~ 1|Batch, Dyestuff)) (fm2 <- lmer(Yield ~ 1|Batch, Dyestuff2))"
"lme4-grouseticks","lme4","grouseticks","Data on red grouse ticks from Elston et al. 2001",403,7,0,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/grouseticks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/grouseticks.html","grouseticks R Documentation    Data on red grouse ticks from Elston et al. 2001    Description  
Number of ticks on the heads of red grouse chicks sampled in the field ( grouseticks ) and an aggregated version ( grouseticks_agg ); see original source for more details    Usage   data(grouseticks)   Format   INDEX
(factor) chick number (observation level)   TICKS
number of ticks sampled   BROOD
(factor) brood number   HEIGHT
height above sea level (meters)   YEAR
year (-1900)   LOCATION
(factor) geographic location code   cHEIGHT
centered height, derived from HEIGHT   meanTICKS
mean number of ticks by brood   varTICKS
variance of number of ticks by brood     Details  
grouseticks_agg is just a brood-level aggregation of the data   Source  
Robert Moss, via David Elston    References  
Elston, D. A., R. Moss, T. Boulinier, C. Arrowsmith, and X. Lambin. 2001. ""Analysis of Aggregation, a Worked Example: Numbers of Ticks on Red Grouse Chicks."" Parasitology 122 (05): 563-569. doi:10.1017/S0031182001007740.  http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=82701 .    Examples    if (interactive()) { data(grouseticks) ## Figure 1a from Elston et al par(las=1,bty=""l"") tvec <- c(0,1,2,5,20,40,80) pvec <- c(4,1,3) with(grouseticks_agg,plot(1+meanTICKS~HEIGHT, pch=pvec[factor(YEAR)], log=""y"",axes=FALSE, xlab=""Altitude (m)"", ylab=""Brood mean ticks"")) axis(side=1) axis(side=2,at=tvec+1,label=tvec) box() abline(v=405,lty=2) ## Figure 1b with(grouseticks_agg,plot(varTICKS~meanTICKS, pch=4, xlab=""Brood mean ticks"", ylab=""Within-brood variance"")) curve(1*x,from=0,to=70,add=TRUE) ## Model fitting form <- TICKS~YEAR+HEIGHT+(1|BROOD)+(1|INDEX)+(1|LOCATION) (full_mod1 <- glmer(form, family=""poisson"",data=grouseticks)) }"
"lme4-InstEval","lme4","InstEval","University Lecture/Instructor Evaluations by Students at ETH",73421,7,1,0,6,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/InstEval.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/InstEval.html","InstEval R Documentation   University Lecture/Instructor Evaluations by Students at ETH   Description  
University lecture evaluations by students at ETH Zurich, anonymized for privacy protection. This is an interesting “medium” sized example of a  partially nested mixed effect model.    Format  
A data frame with 73421 observations on the following 7 variables.    s
a factor with levels 1:2972 denoting individual students.   d
a factor with 1128 levels from 1:2160 , denoting individual professors or lecturers.     studage
an ordered factor with levels 2 <  4 < 6 < 8 , denoting student's “age” measured in the semester number the student has been enrolled.   lectage
an ordered factor with 6 levels, 1 <  2 < ... < 6 , measuring how many semesters back the lecture rated had taken place.   service
a binary factor with levels 0 and  1 ; a lecture is a “service”, if held for a different department than the lecturer's main one.   dept
a factor with 14 levels from 1:15 , using a random code for the department of the lecture.   y
a numeric vector of ratings of lectures by the students, using the discrete scale 1:5 , with meanings of ‘poor’ to ‘very good’.    
Each observation is one student's rating for a specific lecture (of one lecturer, during one semester in the past).   Details  
The main goal of the survey is to find “the best liked prof”, according to the lectures given. Statistical analysis of such data has been the basis for a (student) jury selecting the final winners.   
The present data set has been anonymized and slightly simplified on purpose.    Examples    str(InstEval) head(InstEval, 16) xtabs(~ service + dept, InstEval)"
"lme4-Pastes","lme4","Pastes","Paste strength by batch and cask",60,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/Pastes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/Pastes.html","Pastes R Documentation   Paste strength by batch and cask   Description  
Strength of a chemical paste product; its quality depending on the delivery batch, and the cask within the delivery.    Format  
A data frame with 60 observations on the following 4 variables.    strength
paste strength.   batch
delivery batch from which the sample was sample. A factor with 10 levels: ‘A’ to ‘J’.   cask
cask within the delivery batch from which the sample was chosen. A factor with 3 levels: ‘a’ to ‘c’.   sample
the sample of paste whose strength was assayed, two assays per sample. A factor with 30 levels: ‘A:a’ to ‘J:c’.     Details  
The data are described in Davies and Goldsmith (1972) as coming from “ deliveries of a chemical paste product contained in casks where, in addition to sampling and testing errors, there are variations in quality between deliveries ... As a routine, three casks selected at random from each delivery were sampled and the samples were kept for reference. ... Ten of the delivery batches were sampled at random and two analytical tests carried out on each of the 30 samples”.    Source  
O.L. Davies and P.L. Goldsmith (eds), Statistical Methods in Research and Production, 4th ed. , Oliver and Boyd, (1972), section 6.5    Examples    str(Pastes) require(lattice) dotplot(cask ~ strength | reorder(batch, strength), Pastes, strip = FALSE, strip.left = TRUE, layout = c(1, 10), ylab = ""Cask within batch"", xlab = ""Paste strength"", jitter.y = TRUE) ## Modifying the factors to enhance the plot Pastes <- within(Pastes, batch <- reorder(batch, strength)) Pastes <- within(Pastes, sample <- reorder(reorder(sample, strength), as.numeric(batch))) dotplot(sample ~ strength | batch, Pastes, strip = FALSE, strip.left = TRUE, layout = c(1, 10), scales = list(y = list(relation = ""free"")), ylab = ""Sample within batch"", xlab = ""Paste strength"", jitter.y = TRUE) ## Four equivalent models differing only in specification (fm1 <- lmer(strength ~ (1|batch) + (1|sample), Pastes)) (fm2 <- lmer(strength ~ (1|batch/cask), Pastes)) (fm3 <- lmer(strength ~ (1|batch) + (1|batch:cask), Pastes)) (fm4 <- lmer(strength ~ (1|batch/sample), Pastes)) ## fm4 results in redundant labels on the sample:batch interaction head(ranef(fm4)[[1]]) ## compare to fm1 head(ranef(fm1)[[1]]) ## This model is different and NOT appropriate for these data (fm5 <- lmer(strength ~ (1|batch) + (1|cask), Pastes)) L <- getME(fm1, ""L"") Matrix::image(L, sub = ""Structure of random effects interaction in pastes model"")"
"lme4-Penicillin","lme4","Penicillin","Variation in penicillin testing",144,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/Penicillin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/Penicillin.html","Penicillin R Documentation   Variation in penicillin testing   Description  
Six samples of penicillin were tested using the B. subtilis plate method on each of 24 plates. The response is the diameter (mm) of the zone of inhibition of growth of the organism.    Format  
A data frame with 144 observations on the following 3 variables.    diameter
diameter (mm) of the zone of inhibition of the growth of the organism.   plate
assay plate. A factor with levels ‘a’ to ‘x’.   sample
penicillin sample. A factor with levels ‘A’ to ‘F’.     Details  
The data are described in Davies and Goldsmith (1972) as coming from an investigation to “assess the variability between samples of penicillin by the B. subtilis method. In this test method a bulk-inoculated nutrient agar medium is poured into a Petri dish of approximately 90 mm. diameter, known as a plate. When the medium has set, six small hollow cylinders or pots (about 4 mm. in diameter) are cemented onto the surface at equally spaced intervals. A few drops of the penicillin solutions to be compared are placed in the respective cylinders, and the whole plate is placed in an incubator for a given time. Penicillin diffuses from the pots into the agar, and this produces a clear circular zone of inhibition of growth of the organisms, which can be readily measured. The diameter of the zone is related in a known way to the concentration of penicillin in the solution.”    Source  
O.L. Davies and P.L. Goldsmith (eds), Statistical Methods in Research and Production, 4th ed. , Oliver and Boyd, (1972), section 6.6    Examples    str(Penicillin) require(lattice) dotplot(reorder(plate, diameter) ~ diameter, Penicillin, groups = sample, ylab = ""Plate"", xlab = ""Diameter of growth inhibition zone (mm)"", type = c(""p"", ""a""), auto.key = list(columns = 3, lines = TRUE, title = ""Penicillin sample"")) (fm1 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)) L <- getME(fm1, ""L"") Matrix::image(L, main = ""L"", sub = ""Penicillin: Structure of random effects interaction"")"
"lme4-sleepstudy","lme4","sleepstudy","Reaction times in a sleep deprivation study",180,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/sleepstudy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/sleepstudy.html","sleepstudy R Documentation   Reaction times in a sleep deprivation study   Description  
The average reaction time per day (in milliseconds) for subjects in a sleep deprivation study.   
Days 0-1 were adaptation and training (T1/T2), day 2 was baseline (B); sleep deprivation started after day 2.    Format  
A data frame with 180 observations on the following 3 variables.    Reaction
Average reaction time (ms)   Days
Number of days of sleep deprivation   Subject
Subject number on which the observation was made.     Details  
These data are from the study described in Belenky et al. (2003), for the most sleep-deprived group (3 hours time-in-bed) and for the first 10 days of the study, up to the recovery period. The original study analyzed speed (1/(reaction time)) and treated day as a categorical rather than a continuous predictor.    References  
Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research   12 , 1–12.    Examples    str(sleepstudy) require(lattice) xyplot(Reaction ~ Days | Subject, sleepstudy, type = c(""g"",""p"",""r""), index = function(x,y) coef(lm(y ~ x))[1], xlab = ""Days of sleep deprivation"", ylab = ""Average reaction time (ms)"", aspect = ""xy"") (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, subset=Days>=2)) ## independent model (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy, subset=Days>=2))"
"lme4-VerbAgg","lme4","VerbAgg","Verbal Aggression item responses",7584,9,4,0,8,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lme4/VerbAgg.html","VerbAgg R Documentation   Verbal Aggression item responses   Description  
These are the item responses to a questionaire on verbal aggression. These data are used throughout De Boeck and Wilson, Explanatory Item Response Models  (Springer, 2004) to illustrate various forms of item response models.    Format  
A data frame with 7584 observations on the following 13 variables.    Anger
the subject's Trait Anger score as measured on the State-Trait Anger Expression Inventory (STAXI)   Gender
the subject's gender - a factor with levels  M and F   item
the item on the questionaire, as a factor   resp
the subject's response to the item - an ordered factor with levels no < perhaps < yes   id
the subject identifier, as a factor   btype
behavior type - a factor with levels  curse , scold and shout   situ
situation type - a factor with levels  other and self indicating other-to-blame and self-to-blame   mode
behavior mode - a factor with levels want  and do   r2
dichotomous version of the response - a factor with levels N and Y     Source  
http://bear.soe.berkeley.edu/EIRM/     References  
De Boeck and Wilson (2004), Explanatory Item Response Models , Springer.    Examples    str(VerbAgg) ## Show how r2 := h(resp) is defined: with(VerbAgg, stopifnot( identical(r2, { r <- factor(resp, ordered=FALSE); levels(r) <- c(""N"",""Y"",""Y""); r}))) xtabs(~ item + resp, VerbAgg) xtabs(~ btype + resp, VerbAgg) round(100 * ftable(prop.table(xtabs(~ situ + mode + resp, VerbAgg), 1:2), 1)) person <- unique(subset(VerbAgg, select = c(id, Gender, Anger))) require(lattice) densityplot(~ Anger, person, groups = Gender, auto.key = list(columns = 2), xlab = ""Trait Anger score (STAXI)"") if(lme4:::testLevel() >= 3) { ## takes about 15 sec print(fmVA <- glmer(r2 ~ (Anger + Gender + btype + situ)^2 + (1|id) + (1|item), family = binomial, data = VerbAgg), corr=FALSE) } ## testLevel() >= 3 if (interactive()) { ## much faster but less accurate print(fmVA0 <- glmer(r2 ~ (Anger + Gender + btype + situ)^2 + (1|id) + (1|item), family = binomial, data = VerbAgg, nAGQ=0L), corr=FALSE) } ## interactive()"
"lmec-UTIdata","lmec","UTIdata","Data set for Unstructured Treatment Interruption Study",373,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/lmec/UTIdata.csv","https://vincentarelbundock.github.io/Rdatasets/doc/lmec/UTIdata.html","UTIdata R Documentation   Data set for Unstructured Treatment Interruption Study   Description  
Data set from a study of Unstructured Treatment Interruption in HIV-infected adolescents in four institutions in the US. The main outcome is the HIV-1 RNA viral load, which is subject to censoring below the lower limit of detection of the assay (50 copies/mL). The censored observations are indicated by the variable RNAcens   Usage   data(UTIdata)   Format  
A data frame with 373 observations on the following 5 variables.    Patid
patient ID   Days.after.TI
days after treatment interruption   Fup
follow-up months   RNA
viral load RNA   RNAcens
censoring indicator for viral load     References  
Saitoh, A., Foca, M, et al. (2008), Clinical outcome in perinatally acquired HIV-infected children and adolescents after unstructured treatment interruption, Pediatrics,121, e513-e521.    Examples    data(UTIdata) ## maybe str(UTIdata) ; plot(UTIdata) ..."
"MASS-abbey","MASS","abbey","Determinations of Nickel Content",31,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/abbey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/abbey.html","abbey R Documentation    Determinations of Nickel Content    Description  
A numeric vector of 31 determinations of nickel content (ppm) in a Canadian syenite rock.    Usage    abbey    Source  
S. Abbey (1988) Geostandards Newsletter 12 , 241.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-accdeaths","MASS","accdeaths","Accidental Deaths in the US 1973-1978",72,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/accdeaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/accdeaths.html","accdeaths R Documentation    Accidental Deaths in the US 1973-1978    Description  
A regular time series giving the monthly totals of accidental deaths in the USA.   Usage    accdeaths    Details  
The values for first six months of 1979 (p. 326) were  7798 7406 8363 8460 9217 9316 .    Source  
P. J. Brockwell and R. A. Davis (1991)  Time Series: Theory and Methods.  Springer, New York.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-Aids2","MASS","Aids2","Australian AIDS Survival Data",2843,7,2,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Aids2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Aids2.html","Aids2 R Documentation    Australian AIDS Survival Data    Description  
Data on patients diagnosed with AIDS in Australia before 1 July 1991.    Usage    Aids2    Format  
This data frame contains 2843 rows and the following columns:    state  
Grouped state of origin: ""NSW "" includes ACT and  ""other"" is WA, SA, NT and TAS.    sex  
Sex of patient.    diag
(Julian) date of diagnosis.   death  
(Julian) date of death or end of observation.    status  
""A"" (alive) or ""D"" (dead) at end of observation.    T.categ  
Reported transmission category.    age  
Age (years) at diagnosis.      Note  
This data set has been slightly jittered as a condition of its release, to ensure patient confidentiality.    Source  
Dr P. J. Solomon and the Australian National Centre in HIV Epidemiology and Clinical Research.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Animals","MASS","Animals","Brain and Body Weights for 28 Species",28,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Animals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Animals.html","Animals R Documentation    Brain and Body Weights for 28 Species    Description  
Average brain and body weights for 28 species of land animals.    Usage    Animals    Format   body  
body weight in kg.    brain  
brain weight in g.      Note  
The name Animals avoids conflicts with a system dataset  animals in S-PLUS 4.5 and later.    Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection.  Wiley, p. 57.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-anorexia","MASS","anorexia","Anorexia Data on Weight Change",72,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/anorexia.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/anorexia.html","anorexia R Documentation    Anorexia Data on Weight Change    Description  
The anorexia data frame has 72 rows and 3 columns. Weight change data for young female anorexia patients.    Usage    anorexia    Format  
This data frame contains the following columns:    Treat  
Factor of three levels: ""Cont"" (control), ""CBT""  (Cognitive Behavioural treatment) and ""FT"" (family treatment).    Prewt  
Weight of patient before study period, in lbs.    Postwt  
Weight of patient after study period, in lbs.      Source  
Hand, D. J., Daly, F., McConway, K., Lunn, D. and Ostrowski, E. eds (1993)  A Handbook of Small Data Sets.  Chapman & Hall, Data set 285 (p. 229)   
(Note that the original source mistakenly says that weights are in kg.)    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-bacteria","MASS","bacteria","Presence of Bacteria after Drug Treatments",220,6,3,0,5,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/bacteria.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/bacteria.html","bacteria R Documentation    Presence of Bacteria after Drug Treatments    Description  
Tests of the presence of the bacteria H. influenzae  in children with otitis media in the Northern Territory of Australia.    Usage    bacteria    Format  
This data frame has 220 rows and the following columns:    y
presence or absence: a factor with levels  n and y .   ap
active/placebo: a factor with levels a and p .   hilo
hi/low compliance: a factor with levels hi amd  lo .   week
numeric: week of test.   ID
subject ID: a factor.   trt
a factor with levels placebo , drug and  drug+ , a re-coding of ap and hilo .     Details  
Dr A. Leach tested the effects of a drug on 50 children with a history of otitis media in the Northern Territory of Australia. The children were randomized to the drug or the a placebo, and also to receive active encouragement to comply with taking the drug.   
The presence of H. influenzae was checked at weeks 0, 2, 4, 6 and 11: 30 of the checks were missing and are not included in this data frame.    Source  
Dr Amanda Leach via Mr James McBroom.    References  
Menzies School of Health Research 1999–2000 Annual Report. p.20.  http://www.menzies.edu.au/icms_docs/172302_2000_Annual_report.pdf .   
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    contrasts(bacteria$trt) <- structure(contr.sdif(3), dimnames = list(NULL, c(""drug"", ""encourage""))) ## fixed effects analyses summary(glm(y ~ trt * week, binomial, data = bacteria)) summary(glm(y ~ trt + week, binomial, data = bacteria)) summary(glm(y ~ trt + I(week > 2), binomial, data = bacteria)) # conditional random-effects analysis library(survival) bacteria$Time <- rep(1, nrow(bacteria)) coxph(Surv(Time, unclass(y)) ~ week + strata(ID), data = bacteria, method = ""exact"") coxph(Surv(Time, unclass(y)) ~ factor(week) + strata(ID), data = bacteria, method = ""exact"") coxph(Surv(Time, unclass(y)) ~ I(week > 2) + strata(ID), data = bacteria, method = ""exact"") # PQL glmm analysis library(nlme) summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID, family = binomial, data = bacteria))"
"MASS-beav1","MASS","beav1","Body Temperature Series of Beaver 1",114,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/beav1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/beav1.html","beav1 R Documentation    Body Temperature Series of Beaver 1    Description  
Reynolds (1994) describes a small part of a study of the long-term temperature dynamics of beaver Castor canadensis in north-central Wisconsin. Body temperature was measured by telemetry every 10 minutes for four females, but data from a one period of less than a day for each of two animals is used there.    Usage    beav1    Format  
The beav1 data frame has 114 rows and 4 columns. This data frame contains the following columns:    day  
Day of observation (in days since the beginning of 1990), December 12–13.    time  
Time of observation, in the form 0330 for 3.30am.    temp  
Measured body temperature in degrees Celsius.    activ  
Indicator of activity outside the retreat.      Note  
The observation at 22:20 is missing.    Source  
P. S. Reynolds (1994) Time-series analyses of beaver body temperatures. Chapter 11 of Lange, N., Ryan, L., Billard, L., Brillinger, D., Conquest, L. and Greenhouse, J. eds (1994) Case Studies in Biometry. New York: John Wiley and Sons.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
beav2     Examples    beav1 <- within(beav1, hours <- 24*(day-346) + trunc(time/100) + (time%%100)/60) plot(beav1$hours, beav1$temp, type=""l"", xlab=""time"", ylab=""temperature"", main=""Beaver 1"") usr <- par(""usr""); usr[3:4] <- c(-0.2, 8); par(usr=usr) lines(beav1$hours, beav1$activ, type=""s"", lty=2) temp <- ts(c(beav1$temp[1:82], NA, beav1$temp[83:114]), start = 9.5, frequency = 6) activ <- ts(c(beav1$activ[1:82], NA, beav1$activ[83:114]), start = 9.5, frequency = 6) acf(temp[1:53]) acf(temp[1:53], type = ""partial"") ar(temp[1:53]) act <- c(rep(0, 10), activ) X <- cbind(1, act = act[11:125], act1 = act[10:124], act2 = act[9:123], act3 = act[8:122]) alpha <- 0.80 stemp <- as.vector(temp - alpha*lag(temp, -1)) sX <- X[-1, ] - alpha * X[-115,] beav1.ls <- lm(stemp ~ -1 + sX, na.action = na.omit) summary(beav1.ls, cor = FALSE) rm(temp, activ)"
"MASS-beav2","MASS","beav2","Body Temperature Series of Beaver 2",100,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/beav2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/beav2.html","beav2 R Documentation    Body Temperature Series of Beaver 2    Description  
Reynolds (1994) describes a small part of a study of the long-term temperature dynamics of beaver Castor canadensis in north-central Wisconsin. Body temperature was measured by telemetry every 10 minutes for four females, but data from a one period of less than a day for each of two animals is used there.    Usage    beav2    Format  
The beav2 data frame has 100 rows and 4 columns. This data frame contains the following columns:    day  
Day of observation (in days since the beginning of 1990), November 3–4.    time  
Time of observation, in the form 0330 for 3.30am.    temp  
Measured body temperature in degrees Celsius.    activ  
Indicator of activity outside the retreat.      Source  
P. S. Reynolds (1994) Time-series analyses of beaver body temperatures. Chapter 11 of Lange, N., Ryan, L., Billard, L., Brillinger, D., Conquest, L. and Greenhouse, J. eds (1994)  Case Studies in Biometry. New York: John Wiley and Sons.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
beav1     Examples    attach(beav2) beav2$hours <- 24*(day-307) + trunc(time/100) + (time%%100)/60 plot(beav2$hours, beav2$temp, type = ""l"", xlab = ""time"", ylab = ""temperature"", main = ""Beaver 2"") usr <- par(""usr""); usr[3:4] <- c(-0.2, 8); par(usr = usr) lines(beav2$hours, beav2$activ, type = ""s"", lty = 2) temp <- ts(temp, start = 8+2/3, frequency = 6) activ <- ts(activ, start = 8+2/3, frequency = 6) acf(temp[activ == 0]); acf(temp[activ == 1]) # also look at PACFs ar(temp[activ == 0]); ar(temp[activ == 1]) arima(temp, order = c(1,0,0), xreg = activ) dreg <- cbind(sin = sin(2*pi*beav2$hours/24), cos = cos(2*pi*beav2$hours/24)) arima(temp, order = c(1,0,0), xreg = cbind(active=activ, dreg)) ## IGNORE_RDIFF_BEGIN library(nlme) # for gls and corAR1 beav2.gls <- gls(temp ~ activ, data = beav2, corr = corAR1(0.8), method = ""ML"") summary(beav2.gls) summary(update(beav2.gls, subset = 6:100)) detach(""beav2""); rm(temp, activ) ## IGNORE_RDIFF_END"
"MASS-biopsy","MASS","biopsy","Biopsy Data on Breast Cancer Patients",699,11,1,1,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/biopsy.html","biopsy R Documentation    Biopsy Data on Breast Cancer Patients    Description  
This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992; each of nine attributes has been scored on a scale of 1 to 10, and the outcome is also known. There are 699 rows and 11 columns.    Usage    biopsy    Format  
This data frame contains the following columns:    ID
sample code number (not unique).   V1
clump thickness.   V2
uniformity of cell size.   V3
uniformity of cell shape.   V4
marginal adhesion.   V5
single epithelial cell size.   V6
bare nuclei (16 values are missing).   V7
bland chromatin.   V8
normal nucleoli.   V9
mitoses.   class
""benign"" or ""malignant"" .     Source  
P. M. Murphy and D. W. Aha (1992). UCI Repository of machine learning databases. [Machine-readable data repository]. Irvine, CA: University of California, Department of Information and Computer Science.   
O. L. Mangasarian and W. H. Wolberg (1990) Cancer diagnosis via linear programming.  SIAM News 23 , pp 1 & 18.   
William H. Wolberg and O.L. Mangasarian (1990) Multisurface method of pattern separation for medical diagnosis applied to breast cytology.  Proceedings of the National Academy of Sciences, U.S.A.   87 , pp. 9193–9196.   
O. L. Mangasarian, R. Setiono and W.H. Wolberg (1990) Pattern recognition via linear programming: Theory and application to medical diagnosis. In  Large-scale Numerical Optimization  eds Thomas F. Coleman and Yuying Li, SIAM Publications, Philadelphia, pp 22–30.   
K. P. Bennett and O. L. Mangasarian (1992) Robust linear programming discrimination of two linearly inseparable sets.  Optimization Methods and Software   1 , pp. 23–34 (Gordon & Breach Science Publishers).    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-birthwt","MASS","birthwt","Risk Factors Associated with Low Infant Birth Weight",189,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/birthwt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/birthwt.html","birthwt R Documentation    Risk Factors Associated with Low Infant Birth Weight    Description  
The birthwt data frame has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986.    Usage    birthwt    Format  
This data frame contains the following columns:    low
indicator of birth weight less than 2.5 kg.   age
mother's age in years.   lwt
mother's weight in pounds at last menstrual period.   race
mother's race ( 1 = white, 2 = black,  3 = other).   smoke
smoking status during pregnancy.   ptl
number of previous premature labours.   ht
history of hypertension.   ui
presence of uterine irritability.   ftv
number of physician visits during the first trimester.   bwt
birth weight in grams.     Source  
Hosmer, D.W. and Lemeshow, S. (1989)  Applied Logistic Regression. New York: Wiley    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    bwt <- with(birthwt, { race <- factor(race, labels = c(""white"", ""black"", ""other"")) ptd <- factor(ptl > 0) ftv <- factor(ftv) levels(ftv)[-(1:2)] <- ""2+"" data.frame(low = factor(low), age, lwt, race, smoke = (smoke > 0), ptd, ht = (ht > 0), ui = (ui > 0), ftv) }) options(contrasts = c(""contr.treatment"", ""contr.poly"")) glm(low ~ ., binomial, bwt)"
"MASS-Boston","MASS","Boston","Housing Values in Suburbs of Boston",506,14,1,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Boston.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Boston.html","Boston R Documentation    Housing Values in Suburbs of Boston    Description  
The Boston data frame has 506 rows and 14 columns.    Usage    Boston    Format  
This data frame contains the following columns:    crim  
per capita crime rate by town.    zn  
proportion of residential land zoned for lots over 25,000 sq.ft.    indus  
proportion of non-retail business acres per town.    chas  
Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).    nox  
nitrogen oxides concentration (parts per 10 million).    rm  
average number of rooms per dwelling.    age  
proportion of owner-occupied units built prior to 1940.    dis  
weighted mean of distances to five Boston employment centres.    rad  
index of accessibility to radial highways.    tax  
full-value property-tax rate per \$10,000.    ptratio  
pupil-teacher ratio by town.    black  
1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.    lstat  
lower status of the population (percent).    medv  
median value of owner-occupied homes in \$1000s.      Source  
Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air.  J. Environ. Economics and Management   5 , 81–102.   
Belsley D.A., Kuh, E. and Welsch, R.E. (1980)  Regression Diagnostics. Identifying Influential Data and Sources of Collinearity.  New York: Wiley."
"MASS-cabbages","MASS","cabbages","Data from a cabbage field trial",60,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/cabbages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/cabbages.html","cabbages R Documentation    Data from a cabbage field trial    Description  
The cabbages data set has 60 observations and 4 variables    Usage    cabbages    Format  
This data frame contains the following columns:    Cult  
Factor giving the cultivar of the cabbage, two levels: c39  and c52 .    Date  
Factor specifying one of three planting dates: d16 ,  d20 or d21 .    HeadWt  
Weight of the cabbage head, presumably in kg.    VitC  
Ascorbic acid content, in undefined units.      Source  
Rawlings, J. O. (1988)  Applied Regression Analysis: A Research Tool.  Wadsworth and Brooks/Cole. Example 8.4, page 219. (Rawlings cites the original source as the files of the late Dr Gertrude M Cox.)    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-caith","MASS","caith","Colours of Eyes and Hair of People in Caithness",4,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/caith.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/caith.html","caith R Documentation    Colours of Eyes and Hair of People in Caithness    Description  
Data on the cross-classification of people in Caithness, Scotland, by eye and hair colour. The region of the UK is particularly interesting as there is a mixture of people of Nordic, Celtic and Anglo-Saxon origin.    Usage    caith    Format  
A 4 by 5 table with rows the eye colours (blue, light, medium, dark) and columns the hair colours (fair, red, medium, dark, black).    Source  
Fisher, R.A. (1940) The precision of discriminant functions.  Annals of Eugenics (London) 10 , 422–429.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    corresp(caith) dimnames(caith)[[2]] <- c(""F"", ""R"", ""M"", ""D"", ""B"") par(mfcol=c(1,3)) plot(corresp(caith, nf=2)); title(""symmetric"") plot(corresp(caith, nf=2), type=""rows""); title(""rows"") plot(corresp(caith, nf=2), type=""col""); title(""columns"") par(mfrow=c(1,1))"
"MASS-Cars93","MASS","Cars93","Data from 93 Cars on Sale in the USA in 1993",93,27,2,0,9,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Cars93.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Cars93.html","Cars93 R Documentation    Data from 93 Cars on Sale in the USA in 1993    Description  
The Cars93 data frame has 93 rows and 27 columns.    Usage    Cars93    Format  
This data frame contains the following columns:    Manufacturer  
Manufacturer.    Model  
Model.    Type  
Type: a factor with levels ""Small"" , ""Sporty"" ,  ""Compact"" , ""Midsize"" , ""Large"" and ""Van"" .    Min.Price  
Minimum Price (in \$1,000): price for a basic version.    Price  
Midrange Price (in \$1,000): average of Min.Price and  Max.Price .    Max.Price  
Maximum Price (in \$1,000): price for “a premium version”.    MPG.city  
City MPG (miles per US gallon by EPA rating).    MPG.highway  
Highway MPG.    AirBags  
Air Bags standard. Factor: none, driver only, or driver & passenger.    DriveTrain  
Drive train type: rear wheel, front wheel or 4WD; (factor).    Cylinders  
Number of cylinders (missing for Mazda RX-7, which has a rotary engine).    EngineSize  
Engine size (litres).    Horsepower  
Horsepower (maximum).    RPM  
RPM (revs per minute at maximum horsepower).    Rev.per.mile  
Engine revolutions per mile (in highest gear).    Man.trans.avail  
Is a manual transmission version available? (yes or no, Factor).    Fuel.tank.capacity  
Fuel tank capacity (US gallons).    Passengers  
Passenger capacity (persons)    Length  
Length (inches).    Wheelbase  
Wheelbase (inches).    Width  
Width (inches).    Turn.circle  
U-turn space (feet).    Rear.seat.room  
Rear seat room (inches) (missing for 2-seater vehicles).    Luggage.room  
Luggage capacity (cubic feet) (missing for vans).    Weight  
Weight (pounds).    Origin  
Of non-USA or USA company origins? (factor).    Make  
Combination of Manufacturer and Model (character).      Details  
Cars were selected at random from among 1993 passenger car models that were listed in both the Consumer Reports issue and the  PACE Buying Guide . Pickup trucks and Sport/Utility vehicles were eliminated due to incomplete information in the Consumer Reports  source. Duplicate models (e.g., Dodge Shadow and Plymouth Sundance) were listed at most once.   
Further description can be found in Lock (1993).    Source  
Lock, R. H. (1993) 1993 New Car Data.  Journal of Statistics Education   1 (1). doi: 10.1080/10691898.1993.11910459     References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-cats","MASS","cats","Anatomical Data from Domestic Cats",144,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/cats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/cats.html","cats R Documentation    Anatomical Data from Domestic Cats    Description  
The heart and body weights of samples of male and female cats used for  digitalis experiments. The cats were all adult, over 2 kg body weight.    Usage    cats    Format  
This data frame contains the following columns:    Sex  
sex: Factor with levels ""F"" and ""M"" .    Bwt  
body weight in kg.    Hwt  
heart weight in g.      Source  
R. A. Fisher (1947) The analysis of covariance method for the relation between a part and the whole, Biometrics 3 , 65–68.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-cement","MASS","cement","Heat Evolved by Setting Cements",13,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/cement.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/cement.html","cement R Documentation    Heat Evolved by Setting Cements    Description  
Experiment on the heat evolved in the setting of each of 13 cements.    Usage    cement    Format   x1, x2, x3, x4  
Proportions (%) of active ingredients.    y  
heat evolved in cals/gm.      Details  
Thirteen samples of Portland cement were set. For each sample, the percentages of the four main chemical ingredients was accurately measured. While the cement was setting the amount of heat evolved was also measured.    Source  
Woods, H., Steinour, H.H. and Starke, H.R. (1932) Effect of composition of Portland cement on heat evolved during hardening. Industrial Engineering and Chemistry , 24 , 1207–1214.    References  
Hald, A. (1957) Statistical Theory with Engineering Applications. Wiley, New York.    Examples    lm(y ~ x1 + x2 + x3 + x4, cement)"
"MASS-chem","MASS","chem","Copper in Wholemeal Flour",24,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/chem.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/chem.html","chem R Documentation    Copper in Wholemeal Flour    Description  
A numeric vector of 24 determinations of copper in wholemeal flour, in parts per million.    Usage    chem    Source  
Analytical Methods Committee (1989) Robust statistics – how not to reject outliers. The Analyst 114 , 1693–1702.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-coop","MASS","coop","Co-operative Trial in Analytical Chemistry",252,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/coop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/coop.html","coop R Documentation    Co-operative Trial in Analytical Chemistry    Description  
Seven specimens were sent to 6 laboratories in 3 separate batches and each analysed for Analyte. Each analysis was duplicated.    Usage    coop    Format  
This data frame contains the following columns:    Lab  
Laboratory, L1 , L2 , ..., L6 .    Spc  
Specimen, S1 , S2 , ..., S7 .    Bat  
Batch, B1 , B2 , B3 (nested within Spc/Lab ),    Conc  
Concentration of Analyte in g/kg .      Source  
Analytical Methods Committee (1987) Recommendations for the conduct and interpretation of co-operative trials,  The Analyst 112 , 679–686.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
chem , abbey ."
"MASS-cpus","MASS","cpus","Performance of Computer CPUs",209,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/cpus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/cpus.html","cpus R Documentation    Performance of Computer CPUs    Description  
A relative performance measure and characteristics of 209 CPUs.    Usage    cpus    Format  
The components are:    name  
manufacturer and model.    syct  
cycle time in nanoseconds.    mmin  
minimum main memory in kilobytes.    mmax  
maximum main memory in kilobytes.    cach  
cache size in kilobytes.    chmin  
minimum number of channels.    chmax  
maximum number of channels.    perf  
published performance on a benchmark mix relative to an IBM 370/158-3.    estperf  
estimated performance (by Ein-Dor & Feldmesser).      Source  
P. Ein-Dor and J. Feldmesser (1987) Attributes of the performance of central processing units: a relative performance prediction model.  Comm. ACM. 30 , 308–317.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-crabs","MASS","crabs","Morphological Measurements on Leptograpsus Crabs",200,8,2,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/crabs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/crabs.html","crabs R Documentation    Morphological Measurements on Leptograpsus Crabs    Description  
The crabs data frame has 200 rows and 8 columns, describing 5 morphological measurements on 50 crabs each of two colour forms and both sexes, of the species Leptograpsus variegatus collected at Fremantle, W. Australia.    Usage    crabs    Format  
This data frame contains the following columns:    sp  
species - ""B"" or ""O"" for blue or orange.    sex  
as it says.    index  
index 1:50 within each of the four groups.    FL  
frontal lobe size (mm).    RW  
rear width (mm).    CL  
carapace length (mm).    CW  
carapace width (mm).    BD  
body depth (mm).      Source  
Campbell, N.A. and Mahon, R.J. (1974) A multivariate study of variation in two species of rock crab of genus  Leptograpsus.   Australian Journal of Zoology 22 , 417–425.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Cushings","MASS","Cushings","Diagnostic Tests on Patients with Cushing's Syndrome",27,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Cushings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Cushings.html","Cushings R Documentation    Diagnostic Tests on Patients with Cushing's Syndrome    Description  
Cushing's syndrome is a hypertensive disorder associated with over-secretion of cortisol by the adrenal gland. The observations are urinary excretion rates of two steroid metabolites.    Usage    Cushings    Format  
The Cushings data frame has 27 rows and 3 columns:    Tetrahydrocortisone  
urinary excretion rate (mg/24hr) of Tetrahydrocortisone.    Pregnanetriol  
urinary excretion rate (mg/24hr) of Pregnanetriol.    Type  
underlying type of syndrome, coded a (adenoma) , b  (bilateral hyperplasia), c (carcinoma) or u for unknown.      Source  
J. Aitchison and I. R. Dunsmore (1975)  Statistical Prediction Analysis.  Cambridge University Press, Tables 11.1–3.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-DDT","MASS","DDT","DDT in Kale",15,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/DDT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/DDT.html","DDT R Documentation    DDT in Kale    Description  
A numeric vector of 15 measurements by different laboratories of the pesticide DDT in kale, in ppm (parts per million) using the multiple pesticide residue measurement.    Usage    DDT    Source  
C. E. Finsterwalder (1976) Collaborative study of an extension of the Mills et al  method for the determination of pesticide residues in food.  J. Off. Anal. Chem. 59 , 169–171   
R. G. Staudte and S. J. Sheather (1990)  Robust Estimation and Testing.  Wiley"
"MASS-deaths","MASS","deaths","Monthly Deaths from Lung Diseases in the UK",72,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/deaths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/deaths.html","deaths R Documentation    Monthly Deaths from Lung Diseases in the UK    Description  
A time series giving the monthly deaths from bronchitis, emphysema and asthma in the UK, 1974-1979, both sexes ( deaths ),    Usage    deaths    Source  
P. J. Diggle (1990)  Time Series: A Biostatistical Introduction.  Oxford, table A.3    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
This the same as dataset ldeaths in R 's datasets package."
"MASS-drivers","MASS","drivers","Deaths of Car Drivers in Great Britain 1969-84",192,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/drivers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/drivers.html","drivers R Documentation    Deaths of Car Drivers in Great Britain 1969-84    Description  
A regular time series giving the monthly totals of car drivers in Great Britain killed or seriously injured Jan 1969 to Dec 1984. Compulsory wearing of seat belts was introduced on 31 Jan 1983    Usage    drivers    Source  
Harvey, A.C. (1989)  Forecasting, Structural Time Series Models and the Kalman Filter.  Cambridge University Press, pp. 519–523.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-eagles","MASS","eagles","Foraging Ecology of Bald Eagles",8,5,3,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/eagles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/eagles.html","eagles R Documentation    Foraging Ecology of Bald Eagles    Description  
Knight and Skagen collected during a field study on the foraging behaviour of wintering Bald Eagles in Washington State, USA data concerning 160 attempts by one (pirating) Bald Eagle to steal a chum salmon from another (feeding) Bald Eagle.    Usage    eagles    Format  
The eagles data frame has 8 rows and 5 columns.    y  
Number of successful attempts.    n  
Total number of attempts.    P  
Size of pirating eagle ( L = large, S = small).    A  
Age of pirating eagle ( I = immature, A = adult).    V  
Size of victim eagle ( L = large, S = small).      Source  
Knight, R. L. and Skagen, S. K. (1988) Agonistic asymmetries and the foraging ecology of Bald Eagles.  Ecology 69 , 1188–1194.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer.    Examples    eagles.glm <- glm(cbind(y, n - y) ~ P*A + V, data = eagles, family = binomial) dropterm(eagles.glm) prof <- profile(eagles.glm) plot(prof) pairs(prof)"
"MASS-epil","MASS","epil","Seizure Counts for Epileptics",236,9,2,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/epil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/epil.html","epil R Documentation    Seizure Counts for Epileptics    Description  
Thall and Vail (1990) give a data set on two-week seizure counts for 59 epileptics. The number of seizures was recorded for a baseline period of 8 weeks, and then patients were randomly assigned to a treatment group or a control group. Counts were then recorded for four successive two-week periods. The subject's age is the only covariate.    Usage    epil    Format  
This data frame has 236 rows and the following 9 columns:    y  
the count for the 2-week period.    trt  
treatment, ""placebo"" or ""progabide"" .    base  
the counts in the baseline 8-week period.    age  
subject's age, in years.    V4  
0/1 indicator variable of period 4.    subject  
subject number, 1 to 59.    period  
period, 1 to 4.    lbase  
log-counts for the baseline period, centred to have zero mean.    lage  
log-ages, centred to have zero mean.      Source  
Thall, P. F. and Vail, S. C. (1990) Some covariance models for longitudinal count data with over-dispersion.  Biometrics 46 , 657–671.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth Edition. Springer.    Examples    summary(glm(y ~ lbase*trt + lage + V4, family = poisson, data = epil), cor = FALSE) epil2 <- epil[epil$period == 1, ] epil2[""period""] <- rep(0, 59); epil2[""y""] <- epil2[""base""] epil[""time""] <- 1; epil2[""time""] <- 4 epil2 <- rbind(epil, epil2) epil2$pred <- unclass(epil2$trt) * (epil2$period > 0) epil2$subject <- factor(epil2$subject) epil3 <- aggregate(epil2, list(epil2$subject, epil2$period > 0), function(x) if(is.numeric(x)) sum(x) else x[1]) epil3$pred <- factor(epil3$pred, labels = c(""base"", ""placebo"", ""drug"")) contrasts(epil3$pred) <- structure(contr.sdif(3), dimnames = list(NULL, c(""placebo-base"", ""drug-placebo""))) ## IGNORE_RDIFF_BEGIN summary(glm(y ~ pred + factor(subject) + offset(log(time)), family = poisson, data = epil3), cor = FALSE) ## IGNORE_RDIFF_END summary(glmmPQL(y ~ lbase*trt + lage + V4, random = ~ 1 | subject, family = poisson, data = epil)) summary(glmmPQL(y ~ pred, random = ~1 | subject, family = poisson, data = epil3))"
"MASS-farms","MASS","farms","Ecological Factors in Farm Management",20,4,0,0,4,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/farms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/farms.html","farms R Documentation    Ecological Factors in Farm Management    Description  
The farms data frame has 20 rows and 4 columns. The rows are farms on the Dutch island of Terschelling and the columns are factors describing the management of grassland.    Usage    farms    Format  
This data frame contains the following columns:    Mois  
Five levels of soil moisture – level 3 does not occur at these 20 farms.    Manag  
Grassland management type ( SF = standard,  BF = biological, HF = hobby farming,  NM = nature conservation).    Use  
Grassland use ( U1 = hay production, U2 = intermediate, U3 = grazing).    Manure  
Manure usage – classes C0 to C4 .      Source  
J.C. Gower and D.J. Hand (1996) Biplots . Chapman & Hall, Table 4.6.   
Quoted as from:
 R.H.G. Jongman, C.J.F. ter Braak and O.F.R. van Tongeren (1987)  Data Analysis in Community and Landscape Ecology.  PUDOC, Wageningen.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    farms.mca <- mca(farms, abbrev = TRUE) # Use levels as names eqscplot(farms.mca$cs, type = ""n"") text(farms.mca$rs, cex = 0.7) text(farms.mca$cs, labels = dimnames(farms.mca$cs)[[1]], cex = 0.7)"
"MASS-fgl","MASS","fgl","Measurements of Forensic Glass Fragments",214,10,0,0,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/fgl.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/fgl.html","fgl R Documentation    Measurements of Forensic Glass Fragments    Description  
The fgl data frame has 214 rows and 10 columns. It was collected by B. German on fragments of glass collected in forensic work.    Usage    fgl    Format  
This data frame contains the following columns:    RI  
refractive index; more precisely the refractive index is 1.518xxxx.   
The next 8 measurements are percentages by weight of oxides.    Na
sodium.   Mg
manganese.   Al
aluminium.   Si
silicon.   K
potassium.   Ca
calcium.   Ba
barium.   Fe
iron.   type  
The fragments were originally classed into seven types, one of which was absent in this dataset. The categories which occur are window float glass ( WinF : 70), window non-float glass ( WinNF : 76), vehicle window glass ( Veh : 17), containers ( Con : 13), tableware ( Tabl : 9) and vehicle headlamps ( Head : 29).      References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-forbes","MASS","forbes","Forbes' Data on Boiling Points in the Alps",17,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/forbes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/forbes.html","forbes R Documentation    Forbes' Data on Boiling Points in the Alps    Description  
A data frame with 17 observations on boiling point of water and barometric pressure in inches of mercury.    Usage    forbes    Format   bp  
boiling point (degrees Farenheit).    pres  
barometric pressure in inches of mercury.      Source  
A. C. Atkinson (1985) Plots, Transformations and Regression. Oxford.   
S. Weisberg (1980) Applied Linear Regression. Wiley."
"MASS-GAGurine","MASS","GAGurine","Level of GAG in Urine of Children",314,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/GAGurine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/GAGurine.html","GAGurine R Documentation    Level of GAG in Urine of Children    Description  
Data were collected on the concentration of a chemical GAG in the urine of 314 children aged from zero to seventeen years. The aim of the study was to produce a chart to help a paediatrican to assess if a child's GAG concentration is ‘normal’.    Usage    GAGurine    Format  
This data frame contains the following columns:    Age  
age of child in years.    GAG  
concentration of GAG (the units have been lost).      Source  
Mrs Susan Prosser, Paediatrics Department, University of Oxford, via Department of Statistics Consulting Service.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-galaxies","MASS","galaxies","Velocities for 82 Galaxies",82,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/galaxies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/galaxies.html","galaxies R Documentation    Velocities for 82 Galaxies    Description  
A numeric vector of velocities in km/sec of 82 galaxies from 6 well-separated conic sections of an unfilled survey of the Corona Borealis region. Multimodality in such surveys is evidence for voids and superclusters in the far universe.    Usage    galaxies    Note  
There is an 83rd measurement of 5607 km/sec in the Postman  et al. paper which is omitted in Roeder (1990) and from the dataset here.   
There is also a typo: this dataset has 78th observation 26690 which should be 26960.    Source  
Roeder, K. (1990) Density estimation with confidence sets exemplified by superclusters and voids in galaxies.  Journal of the American Statistical Association 85 , 617–624.   
Postman, M., Huchra, J. P. and Geller, M. J. (1986) Probes of large-scale structures in the Corona Borealis region.  Astronomical Journal 92 , 1238–1247.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    gal <- galaxies/1000 c(width.SJ(gal, method = ""dpi""), width.SJ(gal)) plot(x = c(0, 40), y = c(0, 0.3), type = ""n"", bty = ""l"", xlab = ""velocity of galaxy (1000km/s)"", ylab = ""density"") rug(gal) lines(density(gal, width = 3.25, n = 200), lty = 1) lines(density(gal, width = 2.56, n = 200), lty = 3)"
"MASS-gehan","MASS","gehan","Remission Times of Leukaemia Patients",42,4,2,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/gehan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/gehan.html","gehan R Documentation    Remission Times of Leukaemia Patients    Description  
A data frame from a trial of 42 leukaemia patients. Some were treated with the drug 6-mercaptopurine  and the rest are controls. The trial was designed as matched pairs, both withdrawn from the trial when either came out of remission.    Usage    gehan    Format  
This data frame contains the following columns:    pair  
label for pair.    time  
remission time in weeks.    cens  
censoring, 0/1.    treat  
treatment, control or 6-MP.      Source  
Cox, D. R. and Oakes, D. (1984) Analysis of Survival Data.  Chapman & Hall, p. 7. Taken from   
Gehan, E.A. (1965) A generalized Wilcoxon test for comparing arbitrarily single-censored samples.  Biometrika 52 , 203–233.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    library(survival) gehan.surv <- survfit(Surv(time, cens) ~ treat, data = gehan, conf.type = ""log-log"") summary(gehan.surv) survreg(Surv(time, cens) ~ factor(pair) + treat, gehan, dist = ""exponential"") summary(survreg(Surv(time, cens) ~ treat, gehan, dist = ""exponential"")) summary(survreg(Surv(time, cens) ~ treat, gehan)) gehan.cox <- coxph(Surv(time, cens) ~ treat, gehan) summary(gehan.cox)"
"MASS-genotype","MASS","genotype","Rat Genotype Data",61,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/genotype.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/genotype.html","genotype R Documentation    Rat Genotype Data    Description  
Data from a foster feeding experiment with rat mothers and litters of four different genotypes: A , B , I and J . Rat litters were separated from their natural mothers at birth and given to foster mothers to rear.    Usage    genotype    Format  
The data frame has the following components:    Litter  
genotype of the litter.    Mother  
genotype of the foster mother.    Wt  
Litter average weight gain of the litter, in grams at age 28 days. (The source states that the within-litter variability is negligible.)      Source  
Scheffe, H. (1959) The Analysis of Variance Wiley p. 140.   
Bailey, D. W. (1953)  The Inheritance of Maternal Influences on the Growth of the Rat.  Unpublished Ph.D. thesis, University of California. Table B of the Appendix.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-geyser","MASS","geyser","Old Faithful Geyser Data",299,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/geyser.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/geyser.html","geyser R Documentation   Old Faithful Geyser Data   Description  
A version of the eruptions data from the ‘Old Faithful’ geyser in Yellowstone National Park, Wyoming. This version comes from Azzalini and Bowman (1990) and is of continuous measurement from August 1 to August 15, 1985.   
Some nocturnal duration measurements were coded as 2, 3 or 4 minutes, having originally been described as ‘short’, ‘medium’ or ‘long’.    Usage    geyser    Format  
A data frame with 299 observations on 2 variables.   
  duration  numeric Eruption time in mins
  waiting  numeric Waiting time for this eruption
    Note  
The waiting time was incorrectly described as the time to the next eruption in the original files, and corrected for MASS  version 7.3-30.    References  
Azzalini, A. and Bowman, A. W. (1990) A look at some data on the Old Faithful geyser. Applied Statistics   39 , 357–365.   
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
faithful .   
CRAN package sm ."
"MASS-gilgais","MASS","gilgais","Line Transect of Soil in Gilgai Territory",365,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/gilgais.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/gilgais.html","gilgais R Documentation    Line Transect of Soil in Gilgai Territory    Description  
This dataset was collected on a line transect survey in gilgai territory in New South Wales, Australia. Gilgais are natural gentle depressions in otherwise flat land, and sometimes seem to be regularly distributed. The data collection was stimulated by the question: are these patterns reflected in soil properties? At each of 365 sampling locations on a linear grid of 4 meters spacing, samples were taken at depths 0-10 cm, 30-40 cm and 80-90 cm below the surface. pH, electrical conductivity and chloride content were measured on a 1:5 soil:water extract from each sample.    Usage    gilgais    Format  
This data frame contains the following columns:    pH00  
pH at depth 0–10 cm.    pH30  
pH at depth 30–40 cm.    pH80  
pH at depth 80–90 cm.    e00  
electrical conductivity in mS/cm (0–10 cm).    e30  
electrical conductivity in mS/cm (30–40 cm).    e80  
electrical conductivity in mS/cm (80–90 cm).    c00  
chloride content in ppm (0–10 cm).    c30  
chloride content in ppm (30–40 cm).    c80  
chloride content in ppm (80–90 cm).      Source  
Webster, R. (1977) Spectral analysis of gilgai soil.  Australian Journal of Soil Research 15 , 191–204.   
Laslett, G. M. (1989) Kriging and splines: An empirical comparison of their predictive performance in some applications (with discussion).  Journal of the American Statistical Association 89 , 319–409    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-hills","MASS","hills","Record Times in Scottish Hill Races",35,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/hills.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/hills.html","hills R Documentation    Record Times in Scottish Hill Races    Description  
The record times in 1984 for 35 Scottish hill races.    Usage    hills    Format  
The components are:    dist  
distance in miles (on the map).    climb  
total height gained during the route, in feet.    time  
record time in minutes.      Source  
A.C. Atkinson (1986) Comment: Aspects of diagnostic regression analysis.  Statistical Science 1 , 397–402.   
[A.C. Atkinson (1988) Transformations unmasked. Technometrics   30 , 311–318 “corrects” the time for Knock Hill from 78.65 to 18.65. It is unclear if this based on the original records.]    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-housing","MASS","housing","Frequency Table from a Copenhagen Housing Conditions Survey",72,5,1,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/housing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/housing.html","housing R Documentation    Frequency Table from a Copenhagen Housing Conditions Survey    Description  
The housing data frame has 72 rows and 5 variables.    Usage    housing    Format   Sat  
Satisfaction of householders with their present housing circumstances, (High, Medium or Low, ordered factor).    Infl  
Perceived degree of influence householders have on the management of the property (High, Medium, Low).    Type  
Type of rental accommodation, (Tower, Atrium, Apartment, Terrace).    Cont  
Contact residents are afforded with other residents, (Low, High).    Freq  
Frequencies: the numbers of residents in each class.      Source  
Madsen, M. (1976) Statistical analysis of multiple contingency tables. Two examples.  Scand. J. Statist. 3 , 97–106.   
Cox, D. R. and Snell, E. J. (1984)  Applied Statistics, Principles and Examples . Chapman & Hall.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    options(contrasts = c(""contr.treatment"", ""contr.poly"")) # Surrogate Poisson models house.glm0 <- glm(Freq ~ Infl*Type*Cont + Sat, family = poisson, data = housing) ## IGNORE_RDIFF_BEGIN summary(house.glm0, cor = FALSE) ## IGNORE_RDIFF_END addterm(house.glm0, ~. + Sat:(Infl+Type+Cont), test = ""Chisq"") house.glm1 <- update(house.glm0, . ~ . + Sat*(Infl+Type+Cont)) summary(house.glm1, cor = FALSE) 1 - pchisq(deviance(house.glm1), house.glm1$df.residual) dropterm(house.glm1, test = ""Chisq"") addterm(house.glm1, ~. + Sat:(Infl+Type+Cont)^2, test = ""Chisq"") hnames <- lapply(housing[, -5], levels) # omit Freq newData <- expand.grid(hnames) newData$Sat <- ordered(newData$Sat) house.pm <- predict(house.glm1, newData, type = ""response"") # poisson means house.pm <- matrix(house.pm, ncol = 3, byrow = TRUE, dimnames = list(NULL, hnames[[1]])) house.pr <- house.pm/drop(house.pm %*% rep(1, 3)) cbind(expand.grid(hnames[-1]), round(house.pr, 2)) # Iterative proportional scaling loglm(Freq ~ Infl*Type*Cont + Sat*(Infl+Type+Cont), data = housing) # multinomial model library(nnet) (house.mult<- multinom(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)) house.mult2 <- multinom(Sat ~ Infl*Type*Cont, weights = Freq, data = housing) anova(house.mult, house.mult2) house.pm <- predict(house.mult, expand.grid(hnames[-1]), type = ""probs"") cbind(expand.grid(hnames[-1]), round(house.pm, 2)) # proportional odds model house.cpr <- apply(house.pr, 1, cumsum) logit <- function(x) log(x/(1-x)) house.ld <- logit(house.cpr[2, ]) - logit(house.cpr[1, ]) (ratio <- sort(drop(house.ld))) mean(ratio) (house.plr <- polr(Sat ~ Infl + Type + Cont, data = housing, weights = Freq)) house.pr1 <- predict(house.plr, expand.grid(hnames[-1]), type = ""probs"") cbind(expand.grid(hnames[-1]), round(house.pr1, 2)) Fr <- matrix(housing$Freq, ncol = 3, byrow = TRUE) 2*sum(Fr*log(house.pr/house.pr1)) house.plr2 <- stepAIC(house.plr, ~.^2) house.plr2$anova"
"MASS-immer","MASS","immer","Yields from a Barley Field Trial",30,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/immer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/immer.html","immer R Documentation    Yields from a Barley Field Trial    Description  
The immer data frame has 30 rows and 4 columns. Five varieties of barley were grown in six locations in each of 1931 and 1932.    Usage    immer    Format  
This data frame contains the following columns:    Loc  
The location.    Var  
The variety of barley ( ""manchuria"" , ""svansota"" ,  ""velvet"" , ""trebi"" and ""peatland"" ).    Y1  
Yield in 1931.    Y2  
Yield in 1932.      Source  
Immer, F.R., Hayes, H.D. and LeRoy Powers (1934) Statistical determination of barley varietal adaptation.  Journal of the American Society for Agronomy   26 , 403–419.   
Fisher, R.A. (1947)  The Design of Experiments. 4th edition. Edinburgh: Oliver and Boyd.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer.    Examples    immer.aov <- aov(cbind(Y1,Y2) ~ Loc + Var, data = immer) summary(immer.aov) immer.aov <- aov((Y1+Y2)/2 ~ Var + Loc, data = immer) summary(immer.aov) model.tables(immer.aov, type = ""means"", se = TRUE, cterms = ""Var"")"
"MASS-Insurance","MASS","Insurance","Numbers of Car Insurance claims",64,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Insurance.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Insurance.html","Insurance R Documentation    Numbers of Car Insurance claims    Description  
The data given in data frame Insurance consist of the numbers of policyholders of an insurance company who were exposed to risk, and the numbers of car insurance claims made by those policyholders in the third quarter of 1973.    Usage    Insurance    Format  
This data frame contains the following columns:    District  
factor: district of residence of policyholder (1 to 4): 4 is major cities.    Group  
an ordered factor: group of car with levels <1 litre, 1–1.5 litre, 1.5–2 litre, >2 litre.    Age  
an ordered factor: the age of the insured in 4 groups labelled <25, 25–29, 30–35, >35.    Holders  
numbers of policyholders.    Claims  
numbers of claims      Source  
L. A. Baxter, S. M. Coutts and G. A. F. Ross (1980) Applications of linear models in motor insurance.  Proceedings of the 21st International Congress of Actuaries, Zurich  pp. 11–29.   
M. Aitkin, D. Anderson, B. Francis and J. Hinde (1989)  Statistical Modelling in GLIM.  Oxford University Press.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer.    Examples    ## main-effects fit as Poisson GLM with offset glm(Claims ~ District + Group + Age + offset(log(Holders)), data = Insurance, family = poisson) # same via loglm loglm(Claims ~ District + Group + Age + offset(log(Holders)), data = Insurance)"
"MASS-leuk","MASS","leuk","Survival Times and White Blood Counts for Leukaemia Patients",33,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/leuk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/leuk.html","leuk R Documentation    Survival Times and White Blood Counts for Leukaemia Patients    Description  
A data frame of data from 33 leukaemia patients.    Usage    leuk    Format  
A data frame with columns:    wbc  
white blood count.    ag  
a test result, ""present"" or ""absent"" .    time  
survival time in weeks.      Details  
Survival times are given for 33 patients who died from acute myelogenous leukaemia. Also measured was the patient's white blood cell count at the time of diagnosis. The patients were also factored into 2 groups according to the presence or absence of a morphologic characteristic of white blood cells. Patients termed AG positive were identified by the presence of Auer rods and/or significant granulation of the leukaemic cells in the bone marrow at the time of diagnosis.    Source  
Cox, D. R. and Oakes, D. (1984) Analysis of Survival Data . Chapman & Hall, p. 9.   
Taken from   
Feigl, P. & Zelen, M. (1965) Estimation of exponential survival probabilities with concomitant information.  Biometrics 21 , 826–838.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    library(survival) plot(survfit(Surv(time) ~ ag, data = leuk), lty = 2:3, col = 2:3) # now Cox models leuk.cox <- coxph(Surv(time) ~ ag + log(wbc), leuk) summary(leuk.cox)"
"MASS-mammals","MASS","mammals","Brain and Body Weights for 62 Species of Land Mammals",62,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/mammals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/mammals.html","mammals R Documentation    Brain and Body Weights for 62 Species of Land Mammals    Description  
A data frame with average brain and body weights for 62 species of land mammals.    Usage    mammals    Format   body  
body weight in kg.    brain  
brain weight in g.    name  
Common name of species. (Rock hyrax-a = Heterohyrax brucci , Rock hyrax-b = Procavia habessinic. .)      Source  
Weisberg, S. (1985)  Applied Linear Regression. 2nd edition. Wiley, pp. 144–5.   
Selected from: Allison, T. and Cicchetti, D. V. (1976) Sleep in mammals: ecological and constitutional correlates.  Science 194 , 732–734.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-mcycle","MASS","mcycle","Data from a Simulated Motorcycle Accident",133,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/mcycle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/mcycle.html","mcycle R Documentation    Data from a Simulated Motorcycle Accident    Description  
A data frame giving a series of measurements of head acceleration in a simulated motorcycle accident, used to test crash helmets.    Usage    mcycle    Format   times  
in milliseconds after impact.    accel  
in g.      Source  
Silverman, B. W. (1985) Some aspects of the spline smoothing approach to non-parametric curve fitting.  Journal of the Royal Statistical Society series B 47 , 1–52.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-Melanoma","MASS","Melanoma","Survival from Malignant Melanoma",205,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Melanoma.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Melanoma.html","Melanoma R Documentation    Survival from Malignant Melanoma    Description  
The Melanoma data frame has data on 205 patients in Denmark with malignant melanoma.    Usage    Melanoma    Format  
This data frame contains the following columns:    time  
survival time in days, possibly censored.    status  
1 died from melanoma, 2 alive, 3 dead from other causes.    sex  
1 = male, 0 = female.    age  
age in years.    year  
of operation.    thickness  
tumour thickness in mm.    ulcer  
1 = presence, 0 = absence.      Source  
P. K. Andersen, O. Borgan, R. D. Gill and N. Keiding (1993)  Statistical Models based on Counting Processes.  Springer."
"MASS-menarche","MASS","menarche","Age of Menarche in Warsaw",25,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/menarche.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/menarche.html","menarche R Documentation    Age of Menarche in Warsaw    Description  
Proportions of female children at various ages during adolescence who have reached menarche.    Usage    menarche    Format  
This data frame contains the following columns:    Age  
Average age of the group. (The groups are reasonably age homogeneous.)    Total  
Total number of children in the group.    Menarche  
Number who have reached menarche.      Source  
Milicer, H. and Szczotka, F. (1966) Age at Menarche in Warsaw girls in 1965.  Human Biology 38 , 199–203.   
The data are also given in
 Aranda-Ordaz, F.J. (1981) On two families of transformations to additivity for binary response data.  Biometrika 68 , 357–363.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    mprob <- glm(cbind(Menarche, Total - Menarche) ~ Age, binomial(link = probit), data = menarche)"
"MASS-michelson","MASS","michelson","Michelson's Speed of Light Data",100,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/michelson.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/michelson.html","michelson R Documentation    Michelson's Speed of Light Data    Description  
Measurements of the speed of light in air, made between 5th June and 2nd July, 1879. The data consists of five experiments, each consisting of 20 consecutive runs. The response is the speed of light in km/s, less 299000. The currently accepted value, on this scale of measurement, is 734.5.    Usage    michelson    Format  
The data frame contains the following components:    Expt  
The experiment number, from 1 to 5.    Run  
The run number within each experiment.    Speed  
Speed-of-light measurement.      Source  
A.J. Weekes (1986) A Genstat Primer. Edward Arnold.   
S. M. Stigler (1977) Do robust estimators work with real data?  Annals of Statistics 5 , 1055–1098.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-minn38","MASS","minn38","Minnesota High School Graduates of 1938",168,5,1,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/minn38.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/minn38.html","minn38 R Documentation    Minnesota High School Graduates of 1938    Description  
The Minnesota high school graduates of 1938 were classified according to four factors, described below. The minn38 data frame has 168 rows and 5 columns.    Usage    minn38    Format  
This data frame contains the following columns:    hs  
high school rank: ""L"" , ""M"" and ""U"" for lower, middle and upper third.    phs  
post high school status: Enrolled in college, ( ""C"" ), enrolled in non-collegiate school, ( ""N"" ), employed full-time, ( ""E"" ) and other, ( ""O"" ).    fol  
father's occupational level, (seven levels, ""F1"" , ""F2"" , ..., ""F7"" ).    sex  
sex: factor with levels ""F"" or ""M"" .    f  
frequency.      Source  
From R. L. Plackett, (1974) The Analysis of Categorical Data. London: Griffin   
who quotes the data from   
Hoyt, C. J., Krishnaiah, P. R. and Torrance, E. P. (1959) Analysis of complex contingency tables, J. Exp. Ed. 27 , 187–194."
"MASS-motors","MASS","motors","Accelerated Life Testing of Motorettes",40,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/motors.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/motors.html","motors R Documentation    Accelerated Life Testing of Motorettes    Description  
The motors data frame has 40 rows and 3 columns. It describes an accelerated life test at each of four temperatures of 10 motorettes, and has rather discrete times.    Usage    motors    Format  
This data frame contains the following columns:    temp  
the temperature (degrees C) of the test.    time  
the time in hours to failure or censoring at 8064 hours (= 336 days).    cens  
an indicator variable for death.      Source  
Kalbfleisch, J. D. and Prentice, R. L. (1980)  The Statistical Analysis of Failure Time Data.  New York: Wiley.   
taken from   
Nelson, W. D. and Hahn, G. J. (1972) Linear regression of a regression relationship from censored data. Part 1 – simple methods and their application.  Technometrics , 14 , 247–276.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    library(survival) plot(survfit(Surv(time, cens) ~ factor(temp), motors), conf.int = FALSE) # fit Weibull model motor.wei <- survreg(Surv(time, cens) ~ temp, motors) summary(motor.wei) # and predict at 130C unlist(predict(motor.wei, data.frame(temp=130), se.fit = TRUE)) motor.cox <- coxph(Surv(time, cens) ~ temp, motors) summary(motor.cox) # predict at temperature 200 plot(survfit(motor.cox, newdata = data.frame(temp=200), conf.type = ""log-log"")) summary( survfit(motor.cox, newdata = data.frame(temp=130)) )"
"MASS-muscle","MASS","muscle","Effect of Calcium Chloride on Muscle Contraction in Rat Hearts",60,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/muscle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/muscle.html","muscle R Documentation    Effect of Calcium Chloride on Muscle Contraction in Rat Hearts    Description  
The purpose of this experiment was to assess the influence of calcium in solution on the contraction of heart muscle in rats. The left auricle of 21 rat hearts was isolated and on several occasions a constant-length strip of tissue was electrically stimulated and dipped into various concentrations of calcium chloride solution, after which the shortening of the strip was accurately measured as the response.    Usage    muscle    Format  
This data frame contains the following columns:    Strip  
which heart muscle strip was used?    Conc  
concentration of calcium chloride solution, in multiples of 2.2 mM.    Length  
the change in length (shortening) of the strip, (allegedly) in mm.      Source  
Linder, A., Chakravarti, I. M. and Vuagnat, P. (1964) Fitting asymptotic regression curves with different asymptotes. In  Contributions to Statistics. Presented to Professor P. C. Mahalanobis on the occasion of his 70th birthday , ed. C. R. Rao, pp. 221–228. Oxford: Pergamon Press.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth Edition. Springer.    Examples    ## IGNORE_RDIFF_BEGIN A <- model.matrix(~ Strip - 1, data=muscle) rats.nls1 <- nls(log(Length) ~ cbind(A, rho^Conc), data = muscle, start = c(rho=0.1), algorithm=""plinear"") (B <- coef(rats.nls1)) st <- list(alpha = B[2:22], beta = B[23], rho = B[1]) (rats.nls2 <- nls(log(Length) ~ alpha[Strip] + beta*rho^Conc, data = muscle, start = st)) ## IGNORE_RDIFF_END Muscle <- with(muscle, { Muscle <- expand.grid(Conc = sort(unique(Conc)), Strip = levels(Strip)) Muscle$Yhat <- predict(rats.nls2, Muscle) Muscle <- cbind(Muscle, logLength = rep(as.numeric(NA), 126)) ind <- match(paste(Strip, Conc), paste(Muscle$Strip, Muscle$Conc)) Muscle$logLength[ind] <- log(Length) Muscle}) lattice::xyplot(Yhat ~ Conc | Strip, Muscle, as.table = TRUE, ylim = range(c(Muscle$Yhat, Muscle$logLength), na.rm = TRUE), subscripts = TRUE, xlab = ""Calcium Chloride concentration (mM)"", ylab = ""log(Length in mm)"", panel = function(x, y, subscripts, ...) { panel.xyplot(x, Muscle$logLength[subscripts], ...) llines(spline(x, y)) })"
"MASS-newcomb","MASS","newcomb","Newcomb's Measurements of the Passage Time of Light",66,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/newcomb.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/newcomb.html","newcomb R Documentation    Newcomb's Measurements of the Passage Time of Light    Description  
A numeric vector giving the ‘Third Series’ of measurements of the passage time of light recorded by Newcomb in 1882. The given values divided by 1000 plus 24.8 give the time in millionths of a second for light to traverse a known distance. The ‘true’ value is now considered to be 33.02.   
The dataset is given in the order in Staudte and Sheather. Stigler (1977, Table 5) gives the dataset as     28 26 33 24 34 -44 27 16 40 -2 29 22 24 21 25 30 23 29 31 19 24 20 36 32 36 28 25 21 28 29 37 25 28 26 30 32 36 26 30 22 36 23 27 27 28 27 31 27 26 33 26 32 32 24 39 28 24 25 32 25 29 27 28 29 16 23   
However, order is not relevant to its use as an example of robust estimation. (Thanks to Anthony Unwin for bringing this difference to our attention.)    Usage    newcomb    Source  
S. M. Stigler (1973) Simon Newcomb, Percy Daniell, and the history of robust estimation 1885–1920.  Journal of the American Statistical Association 68 , 872–879.   
S. M. Stigler (1977) Do robust estimators work with real data?  Annals of Statistics , 5 , 1055–1098.   
R. G. Staudte and S. J. Sheather (1990)  Robust Estimation and Testing. Wiley."
"MASS-nlschools","MASS","nlschools","Eighth-Grade Pupils in the Netherlands",2287,6,1,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/nlschools.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/nlschools.html","nlschools R Documentation    Eighth-Grade Pupils in the Netherlands    Description  
Snijders and Bosker (1999) use as a running example a study of 2287 eighth-grade pupils (aged about 11) in 132 classes in 131 schools in the Netherlands. Only the variables used in our examples are supplied.    Usage    nlschools    Format  
This data frame contains 2287 rows and the following columns:    lang  
language test score.    IQ  
verbal IQ.    class  
class ID.    GS  
class size: number of eighth-grade pupils recorded in the class (there may be others: see COMB , and some may have been omitted with missing values).    SES  
social-economic status of pupil's family.    COMB  
were the pupils taught in a multi-grade class ( 0/1 )? Classes which contained pupils from grades 7 and 8 are coded 1 , but only eighth-graders were tested.      Source  
Snijders, T. A. B. and Bosker, R. J. (1999)  Multilevel Analysis. An Introduction to Basic and Advanced Multilevel Modelling. London: Sage.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    nl1 <- within(nlschools, { IQave <- tapply(IQ, class, mean)[as.character(class)] IQ <- IQ - IQave }) cen <- c(""IQ"", ""IQave"", ""SES"") nl1[cen] <- scale(nl1[cen], center = TRUE, scale = FALSE) nl.lme <- nlme::lme(lang ~ IQ*COMB + IQave + SES, random = ~ IQ | class, data = nl1) ## IGNORE_RDIFF_BEGIN summary(nl.lme) ## IGNORE_RDIFF_END"
"MASS-npk","MASS","npk","Classical N, P, K Factorial Experiment",24,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/npk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/npk.html","npk R Documentation    Classical N, P, K Factorial Experiment    Description  
A classical N, P, K (nitrogen, phosphate, potassium) factorial experiment on the growth of peas conducted on 6 blocks. Each half of a fractional factorial design confounding the NPK interaction was used on 3 of the plots.    Usage    npk    Format  
The npk data frame has 24 rows and 5 columns:    block  
which block (label 1 to 6).    N  
indicator (0/1) for the application of nitrogen.    P  
indicator (0/1) for the application of phosphate.    K  
indicator (0/1) for the application of potassium.    yield  
Yield of peas, in pounds/plot (the plots were (1/70) acre).      Note  
This dataset is also contained in R 3.0.2 and later.    Source  
Imperial College, London, M.Sc. exercise sheet.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    options(contrasts = c(""contr.sum"", ""contr.poly"")) npk.aov <- aov(yield ~ block + N*P*K, npk) npk.aov summary(npk.aov) alias(npk.aov) coef(npk.aov) options(contrasts = c(""contr.treatment"", ""contr.poly"")) npk.aov1 <- aov(yield ~ block + N + K, data = npk) summary.lm(npk.aov1) se.contrast(npk.aov1, list(N==""0"", N==""1""), data = npk) ## IGNORE_RDIFF_BEGIN model.tables(npk.aov1, type = ""means"", se = TRUE) ## IGNORE_RDIFF_END"
"MASS-npr1","MASS","npr1","US Naval Petroleum Reserve No. 1 data",104,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/npr1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/npr1.html","npr1 R Documentation    US Naval Petroleum Reserve No. 1 data    Description  
Data on the locations, porosity and permeability (a measure of oil flow) on 104 oil wells in the US Naval Petroleum Reserve No. 1 in California.    Usage    npr1    Format  
This data frame contains the following columns:    x  
x coordinates, in miles (origin unspecified)..    y  
y coordinates, in miles.    perm  
permeability in milli-Darcies.    por  
porosity (%).      Source  
Maher, J.C., Carter, R.D. and Lantz, R.J. (1975) Petroleum geology of Naval Petroleum Reserve No. 1, Elk Hills, Kern County, California.  USGS Professional Paper 912 .    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-oats","MASS","oats","Data from an Oats Field Trial",72,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/oats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/oats.html","oats R Documentation    Data from an Oats Field Trial    Description  
The yield of oats from a split-plot field trial using three varieties and four levels of manurial treatment. The experiment was laid out in 6 blocks of 3 main plots, each split into 4 sub-plots. The varieties were applied to the main plots and the manurial treatments to the sub-plots.    Usage    oats    Format  
This data frame contains the following columns:    B  
Blocks, levels I, II, III, IV, V and VI.    V  
Varieties, 3 levels.    N  
Nitrogen (manurial) treatment, levels 0.0cwt, 0.2cwt, 0.4cwt and 0.6cwt, showing the application in cwt/acre.    Y  
Yields in 1/4lbs per sub-plot, each of area 1/80 acre.      Source  
Yates, F. (1935) Complex experiments,  Journal of the Royal Statistical Society Suppl.   2 , 181–247.   
Also given in Yates, F. (1970)  Experimental design: Selected papers of Frank Yates, C.B.E, F.R.S.  London: Griffin.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    oats$Nf <- ordered(oats$N, levels = sort(levels(oats$N))) oats.aov <- aov(Y ~ Nf*V + Error(B/V), data = oats, qr = TRUE) ## IGNORE_RDIFF_BEGIN summary(oats.aov) summary(oats.aov, split = list(Nf=list(L=1, Dev=2:3))) ## IGNORE_RDIFF_END par(mfrow = c(1,2), pty = ""s"") plot(fitted(oats.aov[[4]]), studres(oats.aov[[4]])) abline(h = 0, lty = 2) oats.pr <- proj(oats.aov) qqnorm(oats.pr[[4]][,""Residuals""], ylab = ""Stratum 4 residuals"") qqline(oats.pr[[4]][,""Residuals""]) par(mfrow = c(1,1), pty = ""m"") oats.aov2 <- aov(Y ~ N + V + Error(B/V), data = oats, qr = TRUE) model.tables(oats.aov2, type = ""means"", se = TRUE)"
"MASS-OME","MASS","OME","Tests of Auditory Perception in Children with OME",1097,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/OME.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/OME.html","OME R Documentation    Tests of Auditory Perception in Children with OME    Description  
Experiments were performed on children on their ability to differentiate a signal in broad-band noise. The noise was played from a pair of speakers and a signal was added to just one channel; the subject had to turn his/her head to the channel with the added signal. The signal was either coherent (the amplitude of the noise was increased for a period) or incoherent (independent noise was added for the same period to form the same increase in power).   
The threshold used in the original analysis was the stimulus loudness needs to get 75% correct responses. Some of the children had suffered from otitis media with effusion (OME).    Usage    OME    Format  
The OME data frame has 1129 rows and 7 columns:    ID  
Subject ID (1 to 99, with some IDs missing). A few subjects were measured at different ages.    OME  
""low"" or ""high"" or ""N/A"" (at ages other than 30 and 60 months).   Age  
Age of the subject (months).    Loud  
Loudness of stimulus, in decibels.    Noise  
Whether the signal in the stimulus was ""coherent"" or  ""incoherent"" .    Correct  
Number of correct responses from Trials trials.    Trials  
Number of trials performed.      Background  
The experiment was to study otitis media with effusion (OME), a very common childhood condition where the middle ear space, which is normally air-filled, becomes congested by a fluid. There is a concomitant fluctuating, conductive hearing loss which can result in various language, cognitive and social deficits. The term ‘binaural hearing’ is used to describe the listening conditions in which the brain is processing information from both ears at the same time. The brain computes differences in the intensity and/or timing of signals arriving at each ear which contributes to sound localisation and also to our ability to hear in background noise.   
Some years ago, it was found that children of 7–8 years with a history of significant OME had significantly worse binaural hearing than children without such a history, despite having equivalent sensitivity. The question remained as to whether it was the timing, the duration, or the degree of severity of the otitis media episodes during critical periods, which affected later binaural hearing. In an attempt to begin to answer this question, 95 children were monitored for the presence of effusion every month since birth. On the basis of OME experience in their first two years, the test population was split into one group of high OME prevalence and one of low prevalence.    Source  
Sarah Hogan, Dept of Physiology, University of Oxford, via Dept of Statistics Consulting Service    Examples    # Fit logistic curve from p = 0.5 to p = 1.0 fp1 <- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/scal)), c(""L75"", ""scal""), function(x,L75,scal)NULL) nls(Correct/Trials ~ fp1(Loud, L75, scal), data = OME, start = c(L75=45, scal=3)) nls(Correct/Trials ~ fp1(Loud, L75, scal), data = OME[OME$Noise == ""coherent"",], start=c(L75=45, scal=3)) nls(Correct/Trials ~ fp1(Loud, L75, scal), data = OME[OME$Noise == ""incoherent"",], start = c(L75=45, scal=3)) # individual fits for each experiment aa <- factor(OME$Age) ab <- 10*OME$ID + unclass(aa) ac <- unclass(factor(ab)) OME$UID <- as.vector(ac) OME$UIDn <- OME$UID + 0.1*(OME$Noise == ""incoherent"") rm(aa, ab, ac) OMEi <- OME library(nlme) fp2 <- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/2)), ""L75"", function(x,L75) NULL) dec <- getOption(""OutDec"") options(show.error.messages = FALSE, OutDec=""."") OMEi.nls <- nlsList(Correct/Trials ~ fp2(Loud, L75) | UIDn, data = OMEi, start = list(L75=45), control = list(maxiter=100)) options(show.error.messages = TRUE, OutDec=dec) tmp <- sapply(OMEi.nls, function(X) {if(is.null(X)) NA else as.vector(coef(X))}) OMEif <- data.frame(UID = round(as.numeric((names(tmp)))), Noise = rep(c(""coherent"", ""incoherent""), 110), L75 = as.vector(tmp), stringsAsFactors = TRUE) OMEif$Age <- OME$Age[match(OMEif$UID, OME$UID)] OMEif$OME <- OME$OME[match(OMEif$UID, OME$UID)] OMEif <- OMEif[OMEif$L75 > 30,] summary(lm(L75 ~ Noise/Age, data = OMEif, na.action = na.omit)) summary(lm(L75 ~ Noise/(Age + OME), data = OMEif, subset = (Age >= 30 & Age <= 60), na.action = na.omit), cor = FALSE) # Or fit by weighted least squares fpl75 <- deriv(~ sqrt(n)*(r/n - 0.5 - 0.5/(1 + exp(-(x-L75)/scal))), c(""L75"", ""scal""), function(r,n,x,L75,scal) NULL) nls(0 ~ fpl75(Correct, Trials, Loud, L75, scal), data = OME[OME$Noise == ""coherent"",], start = c(L75=45, scal=3)) nls(0 ~ fpl75(Correct, Trials, Loud, L75, scal), data = OME[OME$Noise == ""incoherent"",], start = c(L75=45, scal=3)) # Test to see if the curves shift with age fpl75age <- deriv(~sqrt(n)*(r/n - 0.5 - 0.5/(1 + exp(-(x-L75-slope*age)/scal))), c(""L75"", ""slope"", ""scal""), function(r,n,x,age,L75,slope,scal) NULL) OME.nls1 <- nls(0 ~ fpl75age(Correct, Trials, Loud, Age, L75, slope, scal), data = OME[OME$Noise == ""coherent"",], start = c(L75=45, slope=0, scal=2)) sqrt(diag(vcov(OME.nls1))) OME.nls2 <- nls(0 ~ fpl75age(Correct, Trials, Loud, Age, L75, slope, scal), data = OME[OME$Noise == ""incoherent"",], start = c(L75=45, slope=0, scal=2)) sqrt(diag(vcov(OME.nls2))) # Now allow random effects by using NLME OMEf <- OME[rep(1:nrow(OME), OME$Trials),] OMEf$Resp <- with(OME, rep(rep(c(1,0), length(Trials)), t(cbind(Correct, Trials-Correct)))) OMEf <- OMEf[, -match(c(""Correct"", ""Trials""), names(OMEf))] ## Not run: ## these fail in R on most platforms fp2 <- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/exp(lsc))), c(""L75"", ""lsc""), function(x, L75, lsc) NULL) try(summary(nlme(Resp ~ fp2(Loud, L75, lsc), fixed = list(L75 ~ Age, lsc ~ 1), random = L75 + lsc ~ 1 | UID, data = OMEf[OMEf$Noise == ""coherent"",], method = ""ML"", start = list(fixed=c(L75=c(48.7, -0.03), lsc=0.24)), verbose = TRUE))) try(summary(nlme(Resp ~ fp2(Loud, L75, lsc), fixed = list(L75 ~ Age, lsc ~ 1), random = L75 + lsc ~ 1 | UID, data = OMEf[OMEf$Noise == ""incoherent"",], method = ""ML"", start = list(fixed=c(L75=c(41.5, -0.1), lsc=0)), verbose = TRUE))) ## End(Not run)"
"MASS-painters","MASS","painters","The Painter's Data of de Piles",54,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/painters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/painters.html","painters R Documentation    The Painter's Data of de Piles    Description  
The subjective assessment, on a 0 to 20 integer scale, of 54 classical painters. The painters were assessed on four characteristics: composition, drawing, colour and expression. The data is due to the Eighteenth century art critic, de Piles.    Usage    painters    Format  
The row names of the data frame are the painters. The components are:    Composition  
Composition score.    Drawing  
Drawing score.    Colour  
Colour score.    Expression  
Expression score.    School  
The school to which a painter belongs, as indicated by a factor level code as follows:  ""A"" : Renaissance;  ""B"" : Mannerist;  ""C"" : Seicento;  ""D"" : Venetian;  ""E"" : Lombard;  ""F"" : Sixteenth Century;  ""G"" : Seventeenth Century;  ""H"" : French.      Source  
A. J. Weekes (1986)  A Genstat Primer. Edward Arnold.   
M. Davenport and G. Studdert-Kennedy (1972) The statistical analysis of aesthetic judgement: an exploration.  Applied Statistics 21 , 324–333.   
I. T. Jolliffe (1986)  Principal Component Analysis. Springer.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-petrol","MASS","petrol","N. L. Prater's Petrol Refinery Data",32,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/petrol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/petrol.html","petrol R Documentation    N. L. Prater's Petrol Refinery Data    Description  
The yield of a petroleum refining process with four covariates. The crude oil appears to come from only 10 distinct samples.   
These data were originally used by Prater (1956) to build an estimation equation for the yield of the refining process of crude oil to gasoline.    Usage    petrol    Format  
The variables are as follows    No  
crude oil sample identification label. (Factor.)    SG  
specific gravity, degrees API. (Constant within sample.)    VP  
vapour pressure in pounds per square inch. (Constant within sample.)    V10  
volatility of crude; ASTM 10% point. (Constant within sample.)    EP  
desired volatility of gasoline. (The end point. Varies within sample.)    Y  
yield as a percentage of crude.      Source  
N. H. Prater (1956) Estimate gasoline yields from crudes. Petroleum Refiner 35 , 236–238.   
This dataset is also given in D. J. Hand, F. Daly, K. McConway, D. Lunn and E. Ostrowski (eds) (1994)  A Handbook of Small Data Sets. Chapman & Hall.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    library(nlme) Petrol <- petrol Petrol[, 2:5] <- scale(as.matrix(Petrol[, 2:5]), scale = FALSE) pet3.lme <- lme(Y ~ SG + VP + V10 + EP, random = ~ 1 | No, data = Petrol) pet3.lme <- update(pet3.lme, method = ""ML"") pet4.lme <- update(pet3.lme, fixed = Y ~ V10 + EP) anova(pet4.lme, pet3.lme)"
"MASS-phones","MASS","phones","Belgium Phone Calls 1950-1973",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/phones.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/phones.html","Belgian-phones R Documentation    Belgium Phone Calls 1950-1973    Description  
A list object with the annual numbers of telephone calls, in Belgium. The components are:    year  
last two digits of the year.    calls  
number of telephone calls made (in millions of calls).      Usage    phones    Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression & Outlier Detection. Wiley.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Pima.te","MASS","Pima.te","Diabetes in Pima Indian Women",332,8,1,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Pima.te.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Pima.te.html","Pima.tr R Documentation    Diabetes in Pima Indian Women    Description  
A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin.    Usage    Pima.tr Pima.tr2 Pima.te    Format  
These data frames contains the following columns:    npreg  
number of pregnancies.    glu  
plasma glucose concentration in an oral glucose tolerance test.    bp  
diastolic blood pressure (mm Hg).    skin  
triceps skin fold thickness (mm).    bmi  
body mass index (weight in kg/(height in m) \^2 ).    ped  
diabetes pedigree function.    age  
age in years.    type  
Yes or No , for diabetic according to WHO criteria.      Details  
The training set Pima.tr contains a randomly selected set of 200 subjects, and Pima.te contains the remaining 332 subjects.  Pima.tr2 contains Pima.tr plus 100 subjects with missing values in the explanatory variables.    Source  
Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C. and Johannes, R. S. (1988) Using the ADAP learning algorithm to forecast the onset of  diabetes mellitus . In Proceedings of the Symposium on Computer Applications in Medical Care (Washington, 1988), ed. R. A. Greenes, pp. 261–265. Los Alamitos, CA: IEEE Computer Society Press.   
Ripley, B.D. (1996)  Pattern Recognition and Neural Networks.  Cambridge: Cambridge University Press."
"MASS-Pima.tr","MASS","Pima.tr","Diabetes in Pima Indian Women",200,8,1,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Pima.tr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Pima.tr.html","Pima.tr R Documentation    Diabetes in Pima Indian Women    Description  
A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin.    Usage    Pima.tr Pima.tr2 Pima.te    Format  
These data frames contains the following columns:    npreg  
number of pregnancies.    glu  
plasma glucose concentration in an oral glucose tolerance test.    bp  
diastolic blood pressure (mm Hg).    skin  
triceps skin fold thickness (mm).    bmi  
body mass index (weight in kg/(height in m) \^2 ).    ped  
diabetes pedigree function.    age  
age in years.    type  
Yes or No , for diabetic according to WHO criteria.      Details  
The training set Pima.tr contains a randomly selected set of 200 subjects, and Pima.te contains the remaining 332 subjects.  Pima.tr2 contains Pima.tr plus 100 subjects with missing values in the explanatory variables.    Source  
Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C. and Johannes, R. S. (1988) Using the ADAP learning algorithm to forecast the onset of  diabetes mellitus . In Proceedings of the Symposium on Computer Applications in Medical Care (Washington, 1988), ed. R. A. Greenes, pp. 261–265. Los Alamitos, CA: IEEE Computer Society Press.   
Ripley, B.D. (1996)  Pattern Recognition and Neural Networks.  Cambridge: Cambridge University Press."
"MASS-Pima.tr2","MASS","Pima.tr2","Diabetes in Pima Indian Women",300,8,1,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Pima.tr2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Pima.tr2.html","Pima.tr R Documentation    Diabetes in Pima Indian Women    Description  
A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin.    Usage    Pima.tr Pima.tr2 Pima.te    Format  
These data frames contains the following columns:    npreg  
number of pregnancies.    glu  
plasma glucose concentration in an oral glucose tolerance test.    bp  
diastolic blood pressure (mm Hg).    skin  
triceps skin fold thickness (mm).    bmi  
body mass index (weight in kg/(height in m) \^2 ).    ped  
diabetes pedigree function.    age  
age in years.    type  
Yes or No , for diabetic according to WHO criteria.      Details  
The training set Pima.tr contains a randomly selected set of 200 subjects, and Pima.te contains the remaining 332 subjects.  Pima.tr2 contains Pima.tr plus 100 subjects with missing values in the explanatory variables.    Source  
Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C. and Johannes, R. S. (1988) Using the ADAP learning algorithm to forecast the onset of  diabetes mellitus . In Proceedings of the Symposium on Computer Applications in Medical Care (Washington, 1988), ed. R. A. Greenes, pp. 261–265. Los Alamitos, CA: IEEE Computer Society Press.   
Ripley, B.D. (1996)  Pattern Recognition and Neural Networks.  Cambridge: Cambridge University Press."
"MASS-quine","MASS","quine","Absenteeism from School in Rural New South Wales",146,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/quine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/quine.html","quine R Documentation    Absenteeism from School in Rural New South Wales    Description  
The quine data frame has 146 rows and 5 columns. Children from Walgett, New South Wales, Australia, were classified by Culture, Age, Sex and Learner status and the number of days absent from school in a particular school year was recorded.    Usage    quine    Format  
This data frame contains the following columns:    Eth  
ethnic background: Aboriginal or Not, ( ""A"" or ""N"" ).    Sex  
sex: factor with levels ( ""F"" or ""M"" ).    Age  
age group: Primary ( ""F0"" ), or forms ""F1,""   ""F2"" or ""F3"" .    Lrn  
learner status: factor with levels Average or Slow learner, ( ""AL"" or  ""SL"" ).    Days  
days absent from school in the year.      Source  
S. Quine, quoted in Aitkin, M. (1978) The analysis of unbalanced cross classifications (with discussion).  Journal of the Royal Statistical Society series A 141 , 195–223.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Rabbit","MASS","Rabbit","Blood Pressure in Rabbits",60,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Rabbit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Rabbit.html","Rabbit R Documentation    Blood Pressure in Rabbits    Description  
Five rabbits were studied on two occasions, after treatment with saline (control) and after treatment with the 5-HT_3 antagonist MDL 72222. After each treatment ascending doses of phenylbiguanide were injected intravenously at 10 minute intervals and the responses of mean blood pressure measured. The goal was to test whether the cardiogenic chemoreflex elicited by phenylbiguanide depends on the activation of 5-HT_3 receptors.    Usage    Rabbit    Format  
This data frame contains 60 rows and the following variables:    BPchange  
change in blood pressure relative to the start of the experiment.    Dose  
dose of Phenylbiguanide in micrograms.    Run  
label of run ( ""C1"" to ""C5"" , then ""M1"" to ""M5"" ).    Treatment  
placebo or the 5-HT_3 antagonist MDL 72222.    Animal  
label of animal used ( ""R1"" to ""R5"" ).      Source  
J. Ludbrook (1994) Repeated measurements and multiple comparisons in cardiovascular research.  Cardiovascular Research   28 , 303–311.
 [The numerical data are not in the paper but were supplied by Professor Ludbrook]    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-road","MASS","road","Road Accident Deaths in US States",26,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/road.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/road.html","road R Documentation    Road Accident Deaths in US States    Description  
A data frame with the annual deaths in road accidents for half the US states.    Usage    road    Format  
Columns are:    state  
name.    deaths  
number of deaths.    drivers  
number of drivers (in 10,000s).    popden  
population density in people per square mile.    rural  
length of rural roads, in 1000s of miles.    temp  
average daily maximum temperature in January.    fuel  
fuel consumption in 10,000,000 US gallons per year.      Source  
Imperial College, London M.Sc. exercise"
"MASS-rotifer","MASS","rotifer","Numbers of Rotifers by Fluid Density",20,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/rotifer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/rotifer.html","rotifer R Documentation    Numbers of Rotifers by Fluid Density    Description  
The data give the numbers of rotifers falling out of suspension for different fluid densities. There are two species, pm   Polyartha major and kc , Keratella cochlearis and for each species the number falling out and the total number are given.    Usage    rotifer    Format   density  
specific density of fluid.    pm.y  
number falling out for P. major .    pm.total  
total number of P. major .    kc.y  
number falling out for K. cochlearis .    kc.tot  
total number of K. cochlearis .      Source  
D. Collett (1991) Modelling Binary Data. Chapman & Hall. p. 217"
"MASS-Rubber","MASS","Rubber","Accelerated Testing of Tyre Rubber",30,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Rubber.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Rubber.html","Rubber R Documentation    Accelerated Testing of Tyre Rubber    Description  
Data frame from accelerated testing of tyre rubber.    Usage    Rubber    Format   loss  
the abrasion loss in gm/hr.    hard  
the hardness in Shore units.    tens  
tensile strength in kg/sq m.      Source  
O.L. Davies (1947)  Statistical Methods in Research and Production.  Oliver and Boyd, Table 6.1 p. 119.   
O.L. Davies and P.L. Goldsmith (1972)  Statistical Methods in Research and Production.  4th edition, Longmans, Table 8.1 p. 239.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-ships","MASS","ships","Ships Damage Data",40,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/ships.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/ships.html","ships R Documentation    Ships Damage Data    Description  
Data frame giving the number of damage incidents and aggregate months of service by ship type, year of construction, and period of operation.    Usage    ships    Format   type  
type: ""A"" to ""E"" .    year  
year of construction: 1960–64, 65–69, 70–74, 75–79 (coded as ""60"" , ""65"" , ""70"" , ""75"" ).    period  
period of operation : 1960–74, 75–79.    service  
aggregate months of service.    incidents  
number of damage incidents.      Source  
P. McCullagh and J. A. Nelder, (1983),  Generalized Linear Models. Chapman & Hall, section 6.3.2, page 137"
"MASS-shoes","MASS","shoes","Shoe wear data of Box, Hunter and Hunter",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/shoes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/shoes.html","shoes R Documentation    Shoe wear data of Box, Hunter and Hunter    Description  
A list of two vectors, giving the wear of shoes of materials A and B for one foot each of ten boys.    Usage    shoes    Source  
G. E. P. Box, W. G. Hunter and J. S. Hunter (1978)  Statistics for Experimenters. Wiley, p. 100    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-shrimp","MASS","shrimp","Percentage of Shrimp in Shrimp Cocktail",18,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/shrimp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/shrimp.html","shrimp R Documentation    Percentage of Shrimp in Shrimp Cocktail    Description  
A numeric vector with 18 determinations by different laboratories of the amount (percentage of the declared total weight) of shrimp in shrimp cocktail.    Usage    shrimp    Source  
F. J. King and J. J. Ryan (1976) Collaborative study of the determination of the amount of shrimp in shrimp cocktail. J. Off. Anal. Chem. 59 , 644–649.   
R. G. Staudte and S. J. Sheather (1990)  Robust Estimation and Testing. Wiley."
"MASS-shuttle","MASS","shuttle","Space Shuttle Autolander Problem",256,7,5,0,7,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/shuttle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/shuttle.html","shuttle R Documentation    Space Shuttle Autolander Problem    Description  
The shuttle data frame has 256 rows and 7 columns. The first six columns are categorical variables giving example conditions; the seventh is the decision. The first 253 rows are the training set, the last 3 the test conditions.    Usage    shuttle    Format  
This data frame contains the following factor columns:    stability  
stable positioning or not ( stab / xstab ).    error  
size of error ( MM / SS / LX / XL ).    sign  
sign of error, positive or negative ( pp / nn ).    wind  
wind sign ( head / tail ).    magn  
wind strength ( Light / Medium / Strong /  Out of Range ).    vis  
visibility ( yes / no ).    use  
use the autolander or not. ( auto / noauto .)      Source  
D. Michie (1989) Problems of computer-aided concept formation. In  Applications of Expert Systems 2 , ed. J. R. Quinlan, Turing Institute Press / Addison-Wesley, pp. 310–333.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Sitka","MASS","Sitka","Growth Curves for Sitka Spruce Trees in 1988",395,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Sitka.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Sitka.html","Sitka R Documentation    Growth Curves for Sitka Spruce Trees in 1988    Description  
The Sitka data frame has 395 rows and 4 columns. It gives repeated measurements on the log-size of 79 Sitka spruce trees, 54 of which were grown in ozone-enriched chambers and 25 were controls. The size was measured five times in 1988, at roughly monthly intervals.    Usage    Sitka    Format  
This data frame contains the following columns:    size
measured size (height times diameter squared) of tree, on log scale.   Time
time of measurement in days since 1 January 1988.   tree
number of tree.   treat
either ""ozone"" for an ozone-enriched chamber or ""control"" .     Source  
P. J. Diggle, K.-Y. Liang and S. L. Zeger (1994)  Analysis of Longitudinal Data.  Clarendon Press, Oxford    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    See Also  
Sitka89 ."
"MASS-Sitka89","MASS","Sitka89","Growth Curves for Sitka Spruce Trees in 1989",632,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Sitka89.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Sitka89.html","Sitka89 R Documentation    Growth Curves for Sitka Spruce Trees in 1989    Description  
The Sitka89 data frame has 632 rows and 4 columns. It gives repeated measurements on the log-size of 79 Sitka spruce trees, 54 of which were grown in ozone-enriched chambers and 25 were controls. The size was measured eight times in 1989, at roughly monthly intervals.    Usage    Sitka89    Format  
This data frame contains the following columns:    size
measured size (height times diameter squared) of tree, on log scale.   Time
time of measurement in days since 1 January 1988.   tree
number of tree.   treat
either ""ozone"" for an ozone-enriched chamber or ""control"" .     Source  
P. J. Diggle, K.-Y. Liang and S. L. Zeger (1994)  Analysis of Longitudinal Data.  Clarendon Press, Oxford    See Also  
Sitka"
"MASS-Skye","MASS","Skye","AFM Compositions of Aphyric Skye Lavas",23,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Skye.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Skye.html","Skye R Documentation    AFM Compositions of Aphyric Skye Lavas    Description  
The Skye data frame has 23 rows and 3 columns.    Usage    Skye    Format  
This data frame contains the following columns:    A  
Percentage of sodium and potassium oxides.    F  
Percentage of iron oxide.    M  
Percentage of magnesium oxide.      Source  
R. N. Thompson, J. Esson and A. C. Duncan (1972) Major element chemical variation in the Eocene lavas of the Isle of Skye. J. Petrology , 13 , 219–253.    References  
J. Aitchison (1986)  The Statistical Analysis of Compositional Data.  Chapman and Hall, p.360.   
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    # ternary() is from the on-line answers. ternary <- function(X, pch = par(""pch""), lcex = 1, add = FALSE, ord = 1:3, ...) { X <- as.matrix(X) if(any(X < 0)) stop(""X must be non-negative"") s <- drop(X %*% rep(1, ncol(X))) if(any(s<=0)) stop(""each row of X must have a positive sum"") if(max(abs(s-1)) > 1e-6) { warning(""row(s) of X will be rescaled"") X <- X / s } X <- X[, ord] s3 <- sqrt(1/3) if(!add) { oldpty <- par(""pty"") on.exit(par(pty=oldpty)) par(pty=""s"") plot(c(-s3, s3), c(0.5-s3, 0.5+s3), type=""n"", axes=FALSE, xlab="""", ylab="""") polygon(c(0, -s3, s3), c(1, 0, 0), density=0) lab <- NULL if(!is.null(dn <- dimnames(X))) lab <- dn[[2]] if(length(lab) < 3) lab <- as.character(1:3) eps <- 0.05 * lcex text(c(0, s3+eps*0.7, -s3-eps*0.7), c(1+eps, -0.1*eps, -0.1*eps), lab, cex=lcex) } points((X[,2] - X[,3])*s3, X[,1], ...) } ternary(Skye/100, ord=c(1,3,2))"
"MASS-snails","MASS","snails","Snail Mortality Data",96,6,1,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/snails.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/snails.html","snails R Documentation    Snail Mortality Data    Description  
Groups of 20 snails were held for periods of 1, 2, 3 or 4 weeks in carefully controlled conditions of temperature and relative humidity. There were two species of snail, A and B, and the experiment was designed as a 4 by 3 by 4 by 2 completely randomized design. At the end of the exposure time the snails were tested to see if they had survived; the process itself is fatal for the animals. The object of the exercise was to model the probability of survival in terms of the stimulus variables, and in particular to test for differences between species.   
The data are unusual in that in most cases fatalities during the experiment were fairly small.    Usage    snails    Format  
The data frame contains the following components:    Species  
snail species A ( 1 ) or B ( 2 ).    Exposure  
exposure in weeks.    Rel.Hum  
relative humidity (4 levels).    Temp  
temperature, in degrees Celsius (3 levels).    Deaths  
number of deaths.    N  
number of snails exposed.      Source  
Zoology Department, The University of Adelaide.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-SP500","MASS","SP500","Returns of the Standard and Poors 500",2780,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/SP500.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/SP500.html","SP500 R Documentation    Returns of the Standard and Poors 500    Description  
Returns of the Standard and Poors 500 Index in the 1990's    Usage    SP500    Format  
A vector of returns of the Standard and Poors 500 index for all the trading days in 1990, 1991, ..., 1999.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-steam","MASS","steam","The Saturated Steam Pressure Data",14,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/steam.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/steam.html","steam R Documentation    The Saturated Steam Pressure Data    Description  
Temperature and pressure in a saturated steam driven experimental device.    Usage    steam    Format  
The data frame contains the following components:    Temp  
temperature, in degrees Celsius.    Press  
pressure, in Pascals.      Source  
N.R. Draper and H. Smith (1981)  Applied Regression Analysis. Wiley, pp. 518–9.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-stormer","MASS","stormer","The Stormer Viscometer Data",23,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/stormer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/stormer.html","stormer R Documentation    The Stormer Viscometer Data    Description  
The stormer viscometer measures the viscosity of a fluid by measuring the time taken for an inner cylinder in the mechanism to perform a fixed number of revolutions in response to an actuating weight. The viscometer is calibrated by measuring the time taken with varying weights while the mechanism is suspended in fluids of accurately known viscosity. The data comes from such a calibration, and theoretical considerations suggest a nonlinear relationship between time, weight and viscosity, of the form  Time = (B1*Viscosity)/(Weight - B2) + E  where B1 and B2  are unknown parameters to be estimated, and E is error.    Usage    stormer    Format  
The data frame contains the following components:    Viscosity  
viscosity of fluid.    Wt  
actuating weight.    Time  
time taken.      Source  
E. J. Williams (1959) Regression Analysis. Wiley.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-survey","MASS","survey","Student Survey Data",237,12,3,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/survey.html","survey R Documentation    Student Survey Data    Description  
This data frame contains the responses of 237 Statistics I students at the University of Adelaide to a number of questions.    Usage    survey    Format  
The components of the data frame are:    Sex  
The sex of the student. (Factor with levels ""Male"" and ""Female"" .)    Wr.Hnd  
span (distance from tip of thumb to tip of little finger of spread hand) of writing hand, in centimetres.    NW.Hnd  
span of non-writing hand.    W.Hnd  
writing hand of student. (Factor, with levels ""Left"" and ""Right"" .)    Fold  
“Fold your arms! Which is on top” (Factor, with levels  ""R on L"" , ""L on R"" , ""Neither"" .)    Pulse  
pulse rate of student (beats per minute).    Clap  
‘Clap your hands! Which hand is on top?’ (Factor, with levels  ""Right"" , ""Left"" , ""Neither"" .)    Exer  
how often the student exercises. (Factor, with levels ""Freq""  (frequently), ""Some"" , ""None"" .)    Smoke  
how much the student smokes. (Factor, levels ""Heavy"" ,  ""Regul"" (regularly), ""Occas"" (occasionally),  ""Never"" .)    Height  
height of the student in centimetres.    M.I  
whether the student expressed height in imperial (feet/inches) or metric (centimetres/metres) units. (Factor, levels  ""Metric"" , ""Imperial"" .)    Age  
age of the student in years.      References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-synth.te","MASS","synth.te","Synthetic Classification Problem",1000,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/synth.te.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/synth.te.html","synth.tr R Documentation    Synthetic Classification Problem    Description  
The synth.tr data frame has 250 rows and 3 columns. The synth.te data frame has 100 rows and 3 columns. It is intended that synth.tr be used from training and  synth.te for testing.    Usage    synth.tr synth.te    Format  
These data frames contains the following columns:    xs  
x-coordinate    ys  
y-coordinate    yc  
class, coded as 0 or 1.      Source  
Ripley, B.D. (1994) Neural networks and related methods for classification (with discussion).  Journal of the Royal Statistical Society series B   56 , 409–456.   
Ripley, B.D. (1996)  Pattern Recognition and Neural Networks.  Cambridge: Cambridge University Press."
"MASS-synth.tr","MASS","synth.tr","Synthetic Classification Problem",250,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/synth.tr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/synth.tr.html","synth.tr R Documentation    Synthetic Classification Problem    Description  
The synth.tr data frame has 250 rows and 3 columns. The synth.te data frame has 100 rows and 3 columns. It is intended that synth.tr be used from training and  synth.te for testing.    Usage    synth.tr synth.te    Format  
These data frames contains the following columns:    xs  
x-coordinate    ys  
y-coordinate    yc  
class, coded as 0 or 1.      Source  
Ripley, B.D. (1994) Neural networks and related methods for classification (with discussion).  Journal of the Royal Statistical Society series B   56 , 409–456.   
Ripley, B.D. (1996)  Pattern Recognition and Neural Networks.  Cambridge: Cambridge University Press."
"MASS-topo","MASS","topo","Spatial Topographic Data",52,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/topo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/topo.html","topo R Documentation    Spatial Topographic Data    Description  
The topo data frame has 52 rows and 3 columns, of topographic heights within a 310 feet square.    Usage    topo    Format  
This data frame contains the following columns:    x  
x coordinates (units of 50 feet)    y  
y coordinates (units of 50 feet)    z  
heights (feet)      Source  
Davis, J.C. (1973)  Statistics and Data Analysis in Geology.  Wiley.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-Traffic","MASS","Traffic","Effect of Swedish Speed Limits on Accidents",184,4,2,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Traffic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Traffic.html","Traffic R Documentation    Effect of Swedish Speed Limits on Accidents    Description  
An experiment was performed in Sweden in 1961–2 to assess the effect of a speed limit on the motorway accident rate. The experiment was conducted on 92 days in each year, matched so that day j in 1962 was comparable to day j in 1961. On some days the speed limit was in effect and enforced, while on other days there was no speed limit and cars tended to be driven faster. The speed limit days tended to be in contiguous blocks.    Usage    Traffic    Format  
This data frame contains the following columns:    year  
1961 or 1962.    day  
of year.    limit  
was there a speed limit?    y  
traffic accident count for that day.      Source  
Svensson, A. (1981) On the goodness-of-fit test for the multiplicative Poisson model.  Annals of Statistics, 9 , 697–704.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-UScereal","MASS","UScereal","Nutritional and Marketing Information on US Cereals",65,11,0,0,2,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/UScereal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/UScereal.html","UScereal R Documentation    Nutritional and Marketing Information on US Cereals    Description  
The UScereal data frame has 65 rows and 11 columns. The data come from the 1993 ASA Statistical Graphics Exposition, and are taken from the mandatory F&DA food label. The data have been normalized here to a portion of one American cup.    Usage    UScereal    Format  
This data frame contains the following columns:    mfr  
Manufacturer, represented by its first initial: G=General Mills, K=Kelloggs, N=Nabisco, P=Post, Q=Quaker Oats, R=Ralston Purina.    calories  
number of calories in one portion.    protein  
grams of protein in one portion.    fat  
grams of fat in one portion.    sodium  
milligrams of sodium in one portion.    fibre  
grams of dietary fibre in one portion.    carbo  
grams of complex carbohydrates in one portion.    sugars  
grams of sugars in one portion.    shelf  
display shelf (1, 2, or 3, counting from the floor).    potassium  
grams of potassium.    vitamins  
vitamins and minerals (none, enriched, or 100%).      Source  
The original data are available at  http://lib.stat.cmu.edu/datasets/1993.expo/ .    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-UScrime","MASS","UScrime","The Effect of Punishment Regimes on Crime Rates",47,16,1,0,0,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/UScrime.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/UScrime.html","UScrime R Documentation    The Effect of Punishment Regimes on Crime Rates    Description  
Criminologists are interested in the effect of punishment regimes on crime rates. This has been studied using aggregate data on 47 states of the USA for 1960 given in this data frame. The variables seem to have been re-scaled to convenient numbers.    Usage    UScrime    Format  
This data frame contains the following columns:    M  
percentage of males aged 14–24.    So  
indicator variable for a Southern state.    Ed  
mean years of schooling.    Po1  
police expenditure in 1960.    Po2  
police expenditure in 1959.    LF  
labour force participation rate.    M.F  
number of males per 1000 females.    Pop  
state population.    NW  
number of non-whites per 1000 people.    U1  
unemployment rate of urban males 14–24.    U2  
unemployment rate of urban males 35–39.    GDP  
gross domestic product per head.    Ineq  
income inequality.    Prob  
probability of imprisonment.    Time  
average time served in state prisons.    y  
rate of crimes in a particular category per head of population.      Source  
Ehrlich, I. (1973) Participation in illegitimate activities: a theoretical and empirical investigation.  Journal of Political Economy , 81 , 521–565.   
Vandaele, W. (1978) Participation in illegitimate activities: Ehrlich revisited. In Deterrence and Incapacitation , eds A. Blumstein, J. Cohen and D. Nagin, pp. 270–335. US National Academy of Sciences.    References  
Venables, W. N. and Ripley, B. D. (1999)  Modern Applied Statistics with S-PLUS. Third Edition. Springer."
"MASS-VA","MASS","VA","Veteran's Administration Lung Cancer Trial",137,8,3,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/VA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/VA.html","VA R Documentation    Veteran's Administration Lung Cancer Trial    Description  
Veteran's Administration lung cancer trial from Kalbfleisch & Prentice.    Usage    VA    Format  
A data frame with columns:    stime  
survival or follow-up time in days.    status  
dead or censored.    treat  
treatment: standard or test.    age  
patient's age in years.    Karn  
Karnofsky score of patient's performance on a scale of 0 to 100.    diag.time  
times since diagnosis in months at entry to trial.    cell  
one of four cell types.    prior  
prior therapy?      Source  
Kalbfleisch, J.D. and Prentice R.L. (1980)  The Statistical Analysis of Failure Time Data.  Wiley.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer."
"MASS-waders","MASS","waders","Counts of Waders at 15 Sites in South Africa",15,19,0,0,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/waders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/waders.html","waders R Documentation    Counts of Waders at 15 Sites in South Africa    Description  
The waders data frame has 15 rows and 19 columns. The entries are counts of waders in summer.    Usage    waders    Format  
This data frame contains the following columns (species)    S1  
Oystercatcher    S2  
White-fronted Plover    S3  
Kitt Lutz's Plover    S4  
Three-banded Plover    S5  
Grey Plover    S6  
Ringed Plover    S7  
Bar-tailed Godwit    S8  
Whimbrel    S9  
Marsh Sandpiper    S10  
Greenshank    S11  
Common Sandpiper    S12  
Turnstone    S13  
Knot    S14  
Sanderling    S15  
Little Stint    S16  
Curlew Sandpiper    S17  
Ruff    S18  
Avocet    S19  
Black-winged Stilt     
The rows are the sites:   
A = Namibia North coast
 B = Namibia North wetland
 C = Namibia South coast
 D = Namibia South wetland
 E = Cape North coast
 F = Cape North wetland
 G = Cape West coast
 H = Cape West wetland
 I = Cape South coast
 J= Cape South wetland
 K = Cape East coast
 L = Cape East wetland
 M = Transkei coast
 N = Natal coast
 O = Natal wetland    Source  
J.C. Gower and D.J. Hand (1996) Biplots  Chapman & Hall Table 9.1. Quoted as from:   
R.W. Summers, L.G. Underhill, D.J. Pearson and D.A. Scott (1987) Wader migration systems in south and eastern Africa and western Asia.  Wader Study Group Bulletin 49 Supplement, 15–34.    Examples    plot(corresp(waders, nf=2))"
"MASS-whiteside","MASS","whiteside","House Insulation: Whiteside's Data",56,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/whiteside.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/whiteside.html","whiteside R Documentation    House Insulation: Whiteside's Data    Description  
Mr Derek Whiteside of the UK Building Research Station recorded the weekly gas consumption and average external temperature at his own house in south-east England for two heating seasons, one of 26 weeks before, and one of 30 weeks after cavity-wall insulation was installed. The object of the exercise was to assess the effect of the insulation on gas consumption.    Usage    whiteside    Format  
The whiteside data frame has 56 rows and 3 columns.:    Insul  
A factor, before or after insulation.    Temp  
Purportedly the average outside temperature in degrees Celsius. (These values is far too low for any 56-week period in the 1960s in South-East England. It might be the weekly average of daily minima.)    Gas  
The weekly gas consumption in 1000s of cubic feet.      Source  
A data set collected in the 1960s by Mr Derek Whiteside of the UK Building Research Station. Reported by   
Hand, D. J., Daly, F., McConway, K., Lunn, D. and Ostrowski, E. eds (1993)  A Handbook of Small Data Sets.  Chapman & Hall, p. 69.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    require(lattice) xyplot(Gas ~ Temp | Insul, whiteside, panel = function(x, y, ...) { panel.xyplot(x, y, ...) panel.lmline(x, y, ...) }, xlab = ""Average external temperature (deg. C)"", ylab = ""Gas consumption (1000 cubic feet)"", aspect = ""xy"", strip = function(...) strip.default(..., style = 1)) gasB <- lm(Gas ~ Temp, whiteside, subset = Insul==""Before"") gasA <- update(gasB, subset = Insul==""After"") summary(gasB) summary(gasA) gasBA <- lm(Gas ~ Insul/Temp - 1, whiteside) summary(gasBA) gasQ <- lm(Gas ~ Insul/(Temp + I(Temp^2)) - 1, whiteside) coef(summary(gasQ)) gasPR <- lm(Gas ~ Insul + Temp, whiteside) anova(gasPR, gasBA) options(contrasts = c(""contr.treatment"", ""contr.poly"")) gasBA1 <- lm(Gas ~ Insul*Temp, whiteside) coef(summary(gasBA1))"
"MASS-wtloss","MASS","wtloss","Weight Loss Data from an Obese Patient",52,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/wtloss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/MASS/wtloss.html","wtloss R Documentation    Weight Loss Data from an Obese Patient    Description  
The data frame gives the weight, in kilograms, of an obese patient at 52 time points over an 8 month period of a weight rehabilitation programme.    Usage    wtloss    Format  
This data frame contains the following columns:    Days  
time in days since the start of the programme.    Weight  
weight in kilograms of the patient.      Source  
Dr T. Davies, Adelaide.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Fourth edition. Springer.    Examples    ## IGNORE_RDIFF_BEGIN wtloss.fm <- nls(Weight ~ b0 + b1*2^(-Days/th), data = wtloss, start = list(b0=90, b1=95, th=120)) wtloss.fm ## IGNORE_RDIFF_END plot(wtloss) with(wtloss, lines(Days, fitted(wtloss.fm)))"
"mediation-boundsdata","mediation","boundsdata","Example Data for the Design Functions",1000,7,6,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/boundsdata.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/boundsdata.html","boundsdata R Documentation   Example Data for the Design Functions   Description  
A random subsample of the simulated data used in Imai, Tingley, and Yamamoto (2012). The data contains 1000 rows and 7 columns with no missing values.    Usage    boundsdata    Format  
A data frame containing the following variables, which are interpreted as results from a hypothetical randomized trial. See the source for a full description.    out:
The binary outcome variable under the parallel design.   out.enc:
The binary outcome variable under the parallel encouragement design.   med:
The binary mediator under the parallel design.   med.enc:
The binary mediator under the parallel encouragement design.   ttt:
The binary treatment variable.   manip:
The design indicator, or the variable indicating whether the mediator is manipulated under the parallel design.   enc:
The trichotomous encouragement variable under the parallel encouragement design. Equals 0 if subject received no encouragement; 1 if encouraged for the mediator value of 1; and -1 if encouraged for the mediator value of 0.     Details  
Conditioning on 'manip' = 0 will simulate a randomized trial under the single experiment design, where 'out' and 'med' equal observed outcome and mediator values, respectively.   
Unconditionally, using 'out', 'med', 'ttt' and 'manip' will simulate an experiment under the parallel design.   
The 'out.enc' and 'med.enc' variables represent the outcome and mediator values observed when subjects received the encouragement indicated in 'enc'. Therefore, using 'out.enc', 'med.enc', 'ttt' and 'enc' will simulate an experiment under the parallel encouragement design.   
Note that all the observed responses are generated from an underlying distribution of potential outcomes and mediators (not shown in this dataset) satisfying the assumptions described in Imai, Tingley and Yamamoto (2012). The full simulation code is available as a companion replication archive for the article.    Source  
Imai, K., Tingley, D. and Yamamoto, T. (2012) Experimental Designs for Identifying Causal Mechanisms. Journal of the Royal Statistical Society, Series A (Statistics in Society)."
"mediation-CEDdata","mediation","CEDdata","Example Data for the Crossover Encouragement Design",2000,7,7,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/CEDdata.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/CEDdata.html","CEDdata R Documentation   Example Data for the Crossover Encouragement Design   Description  
A randomly generated dataset containing 2000 rows and 7 columns with no missing values.    Usage    CEDdata    Format  
A data frame containing the following variables, which are interpreted as results from a hypothetical randomized trial employing the crossover encouragement design.   T1:
The binary treatment indicator in the first stage.   M1:
The binary mediator variable recorded in the first stage.   Y1:
The binary outcome variable recorded in the first stage.   T2:
The binary treatment in the second stage. Equal to 1 - T1 by design.   Z:
The binary encouragement indicator for the second stage.   M2:
The binary mediator recorded in the second stage.   Y2:
The binary outcome recorded in the second stage.     Details  
Note that all the observed responses are generated from an underlying distribution of potential outcomes and mediators (not shown in this dataset) satisfying the assumptions described in Imai, Tingley and Yamamoto (2012).    Source  
Imai, K., Tingley, D. and Yamamoto, T. (2012) Experimental Designs for Identifying Causal Mechanisms. Journal of the Royal Statistical Society, Series A (Statistics in Society)."
"mediation-framing","mediation","framing","Brader, Valentino and Suhay (2008) Framing Experiment Data",265,15,6,0,5,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/framing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/framing.html","framing R Documentation   Brader, Valentino and Suhay (2008) Framing Experiment Data   Description  
The framing data contains 265 rows and 15 columns of data from a framing experiment conducted by Brader, Valentino and Suhay (2008).    Usage    framing    Format  
A data frame containing the following variables:   immigr:
A four-point scale measuring subjects' attitudes toward increased immigration. Larger values indicate more negative attitudes.   english:
A four-point scale indicating whether subjects favor or oppose a law making English the official language of the U.S.   cong_mesg:
Whether subjects requested sending an anti-immigration message to Congress on their behalf.   anti_info:
Whether subjects wanted to receive information from anti-immigration organizations.   tone:
1st treatment; whether the news story is framed positively or negatively.   eth:
2nd treatment; whether the news story features a Latino or European immigrant.   cond:
Four level measure recording joint treatment status of tone and eth.   treat:
Product of the two treatment variables. In the original study the authors only find this cell to be significant.   emo:
Measure of subjects' negative feeling during the experiment. A numeric scale ranging between 3 and 12 where 3 indicates the most negative feeling.   anx:
A four-point scale measuring subjects' anxiety about increased immigration.   p_harm:  
Subjects' perceived harm caused by increased immigration. A numeric scale between 2 and 8.   age:
Subjects' age.   educ:
Subjects' highest educational attainments.   gender:
Subjects' gender.   income:
Subjects' income, measured as a 19-point scale.     Source  
Brader, T., Valentino, N. and Suhay, E. (2008). What triggers public opposition to immigration? Anxiety, group cues, and immigration threat. American Journal of Political Science 52, 4, 959–978."
"mediation-jobs","mediation","jobs","JOBS II data",899,17,7,0,7,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/jobs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/jobs.html","jobs R Documentation   JOBS II data   Description  
Job Search Intervention Study (JOBS II). JOBS II is a randomized field experiment that investigates the efficacy of a job trainingintervention on unemployed workers. The program is designed to not only increase reemploymentamong the unemployed but also enhance the mental health of the job seekers. In the JOBS IIfield experiment, 1,801 unemployed workers received a pre-screening questionnaire and were thenrandomly assigned to treatment and control groups. Those in the treatment group participatedin job-skills workshops. In the workshops, respondents learned job-search skills and coping strategiesfor dealing with setbacks in the job-search process. Those in the control condition receiveda booklet describing job-search tips. In follow-up interviews, the two key outcome variables weremeasured; a continuous measure of depressive symptoms based on the Hopkins Symptom Checklist,and a binary variable, representing whether the respondent had become employed.    Usage    jobs    Format  
A data matrix with 899 rows and 17 columns, containing no missing values. The data are provided only for illustrative purposes and not for inference about program efficacy, for which the original data source should be consulted.   econ_hard:
Level of economic hardship pre-treatment with values from 1 to 5.   depress1:
Measure of depressive symptoms pre-treatment.   sex:
Indicator variable for sex. 1 = female   age:
Age in years.   occp:
Factor with seven categories for various occupations.   marital:
Factor with five categories for marital status.   nonwhite:
Indicator variable for race. 1 = nonwhite.   educ:
Factor with five categories for educational attainment.   income:
Factor with five categories for level of income.   job_seek:
A continuous scale measuring the level of job-search self-efficacy with values from 1 to 5. The mediator variable.   depress2:
Measure of depressive symptoms post-treatment.   work1:
Indicator variable for employment. 1 = employed.   job_dich:
The job_seek measure recoded into two categories of high and low. 1 = high job search self-efficacy.   job_disc:
The job_seek measure recoded into four categories from lowest to highest.   treat:
Indicator variable for whether participant was randomly selected for the JOBS II training program. 1 = assignment to participation.   comply:
Indicator variable for whether participant actually participated in the JOBS II program. 1 = participation.   control:
Indicator variable for whether participant was randomly selected to not participate in the JOBS II training program. 1 = non-participation.     Source  
The complete JOBS II data is available from the data archives at www.icpsr.umich.edu/    References  
Vinokur, A. and Schul, Y. (1997). Mastery and inoculation against setbacks as active ingredients in the jobs intervention for the unemployed. Journal of Consulting and Clinical Psychology 65(5):867-77."
"mediation-school","mediation","school","School-level data",568,5,2,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/school.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/school.html","school R Documentation   School-level data   Description  
The original data source is the Education Longitudinal Study of 2002. To deal with the issue on individually identifiable information, we generated hypothetical student-level data using a multiple imputation method. The Education Longitudinal Study of 2002 used a two-stage sample selection process. First, a national sample of schools was selected using stratified probability proportional to size (PPS), and school contacting resulted in 1,221 eligible public, Catholic, and other private schools from a population of approximately 27,000 schools containing 10th grade students. Of the eligible schools, 752 participated in the study. In the second stage of sample selection, a sample of approximately 26 sophomores, from within each of the participating public and private schools was selected. Each school was asked to provide a list of 10th grade students, and quality assurance (QA) checks were performed on each list that was received.    Usage    school    Format  
A data matrix with 568 rows and 5 columns, containing no missing values. The data are provided only for illustrative purposes and not for inference about education effectiveness, for which the original data source should be consulted.   SCH_ID:
School indicator.   coed:
Indicator variable for coeducation. 1 = coeducation.   smorale:
Measure of student morale in the school. 4 levels.   free:
Percent of 10th grade students receiving free lunch. 1 to 7 levels.   catholic:
Indicator variable for catholic school. 1 = catholic school.     Source  
The complete student-level data is available from the data archives at www.icpsr.umich.edu/    References  
United States Department of Education. National Center for Education Statistics"
"mediation-student","mediation","student","Hypothetical student-level data",9679,13,7,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/mediation/student.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mediation/student.html","student R Documentation   Hypothetical student-level data   Description  
The original data source is the Education Longitudinal Study of 2002. To deal with the issue on individually identifiable information, we generated hypothetical student-level data using a multiple imputation method. The Education Longitudinal Study of 2002 used a two-stage sample selection process. First, a national sample of schools was selected using stratified probability proportional to size (PPS), and school contacting resulted in 1,221 eligible public, Catholic, and other private schools from a population of approximately 27,000 schools containing 10th grade students. Of the eligible schools, 752 participated in the study. In the second stage of sample selection, a sample of approximately 26 sophomores, from within each of the participating public and private schools was selected. Each school was asked to provide a list of 10th grade students, and quality assurance (QA) checks were performed on each list that was received.    Usage    student    Format  
A data matrix with 9,679 rows and 17 columns, containing no missing values. The data are provided only for illustrative purposes and not for inference about education effectiveness, for which the original data source should be consulted.   SCH_ID:
School indicator.   fight:
Indicator variable for fight at school. 1 = fight.   attachment:
Indicator variable for attachment to school. 1 = like.   work:
Indicator variable for part-time job. 1 = work.   score:
Measure of math score.   late:
Frequency in which the student was late for school. 5 levels.   coed:
Indicator variable for coeducation. 1 = coeducation.   smorale:
Measure of student morale in the school. 4 levels.   gender:
Indicator variable for gender. 1 = female.   income:
Total family income. 13 levels.   free:
Percent of 10th grade students receiving free lunch. 1 to 7 levels.   pared:
Parents highest level of education. 8 levels   catholic:
Indicator variable for catholic school. 1 = catholic school.     Source  
The complete student-level data is available from the data archives at www.icpsr.umich.edu/    References  
United States Department of Education. National Center for Education Statistics"
"mi-CHAIN","mi","CHAIN","Subset of variables from the CHAIN project",532,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mi/CHAIN.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mi/CHAIN.html","CHAIN R Documentation    Subset of variables from the CHAIN project    Description  
The CHAIN project was a longitudinal cohort study of people living with HIV in New York City, which was recruited in 1994 from a large number of medical care and social service agencies serving HIV in New York City. This subset of data pertain to the sixth round of interviews.    Usage   data(CHAIN)   Format  
A data.frame with 532 observations on the following 8 variables.    log_virus  
log of self reported viral load level, where zero represents an undetectable level.    age  
age at time of the interview    income  
annual family income in 10 intervals    healthy  
a continuous scale of physical health with a theoretical range between 0 and 100 where better health is associated with higher scale values    mental  
a binary measure of poor mental health ( 1=Yes, 0=No )    damage  
ordered interval for the CD4 count, which is an indicator of how much damage HIV has caused to the immune system    treatment  
a three-level ordered variable: 0=Not currently taking HAART (Highly Active AntiretRoviral Therapy) 1=taking HAART but nonadherent, 2=taking HAART and adherent      Details  
A missing value in the log virus load level was assigned to individuals who either could not recall their viral load level, did not have a viral load test in the six month preceding the interview, or reported their viral loads as ""good"" or ""bad"".    Source  
http://cchps.columbia.edu/research.cfm    References  
Messeri P, Lee G, Abramson DA, Aidala A, Chiasson MA, Jones JD. (2003). “Antiretroviral therapy and declining AIDS mortality in New York City”.  Medical Care 41:512–521."
"mi-nlsyV","mi","nlsyV","National Longitudinal Survey of Youth Extract",400,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mi/nlsyV.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mi/nlsyV.html","nlsyV R Documentation    National Longitudinal Survey of Youth Extract    Description  
This dataset pertains to children and their families in the United States and is intended to illustrate missing data issues. Note that although the original data are longitudinal, this extract is not.    Usage   data(nlsyV)   Format  
A data frame with 400 randomly subsampled observations on the following 7 variables.    ppvtr.36
a numeric vector with data on the Peabody Picture Vocabulary Test (Revised) administered at 36 months   first
indicator for whether child was first-born   b.marr
indicator for whether mother was married when child was born   income
a numeric vector with data on family income in year after the child was born   momage
a numeric vector with data on the age of the mother when the child was born   momed
educational status of mother when child was born (1 = less than high school, 2 = high school graduate, 3 = some college, 4 = college graduate)   momrace
race of mother (1 = black, 2 = Hispanic, 3 = white)    
Note that momed would typically be an ordered factor while momrace  would typically be an unorderd factor but both are numeric in this  data.frame in order to illustrate the mechanism to change the type of a missing_variable     Source  
National Longitudinal Survey of Youth, 1997, http://www.bls.gov/nls/nlsy97.htm     Examples    data(nlsyV) summary(nlsyV)"
"mosaicData-Alcohol","mosaicData","Alcohol","Alcohol Consumption per Capita",411,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Alcohol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Alcohol.html","Alcohol R Documentation   Alcohol Consumption per Capita   Description  
These data provide per capita alcohol consumption values for many countries in 2005 and 2008. There are also a few countries for which there are data in other years.    Usage    data(Alcohol)    Format  
A data frame with 411 observations on the following variables.   

country country name   
year year   
alcohol estimated per capita alcohol consumption for adults (15+) in litres pure alcohol      Source  
Gapminder ( https://www.gapminder.org/data/ )    Examples    data(Alcohol) # There are only a few observations in years other than 2005 and 2008 subset(Alcohol, ! year %in% c(2005,2008))"
"mosaicData-Birthdays","mosaicData","Birthdays","US Births in 1969 - 1988",372864,7,0,1,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Birthdays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Birthdays.html","Birthdays R Documentation   US Births in 1969 - 1988   Description  
A day by day record of the number of births in each US State.    Usage    data(Birthdays)    Format  
A data frame with 374221 observations on the following variables.   

state state where child was born   
year year (1969-1988)   
month month (1-12)   
day day of month   
date date as a date object   
births number of births      Examples    data(Birthdays) if (require(mosaic)) { MI <- Birthdays %>% filter(state == ""MI"") gf_point(births ~ date, Birthdays, data = MI) gf_line(births ~ date, Birthdays, data = MI, color = ~ wday) gf_line(births ~ date, data = Birthdays %>% group_by(date) %>% summarise(births = sum(births))) }"
"mosaicData-Births","mosaicData","Births","US Births",7305,8,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Births.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Births.html","Births R Documentation   US Births   Description  
Number of births each day from 1968 to 1988    Usage    data(Births)    Format  
A data.frame with 7305 observations on the following 8 variables.   

date Date   
births Number of births on date (integer)   
wday Day of week (ordered factor)   
year Year (integer)   
month Month (integer)   
day_of_year Day of year (integer)   
day_of_month Day of month (integer)   
day_of_week Day of week (integer)      Details  
The number of births in Births78 is slightly lower than the number of births in this data set for the year 1978. See the examples.    Source  
Data source: National Vital Statistics System natality data, as provided by Google BigQuery and exported to csv Robert Kern ( http://www.mechanicalkern.com/static/birthdates-1968-1988.csv )    See Also  
Births2015 , Births .    Examples    data(Births) if(require(ggplot2)) { ggplot(data = Births, aes(x = date, y = births, colour = ~ wday)) + stat_smooth(se = FALSE, alpha = 0.8, geom = ""line"") ggplot(data = Births, aes(x = day_of_year, y = births, colour = ~ wday)) + geom_point(size = 0.4, alpha = 0.5) + stat_smooth(se = FALSE, geom = ""line"", alpha = 0.6, size = 1.5) if (require(dplyr)) { ggplot( data = bind_cols(Births %>% filter(year == 1978), Births78 %>% rename(births78 = births)), aes(x = births - births78) ) + geom_histogram(binwidth = 1) } }"
"mosaicData-Births2015","mosaicData","Births2015","US Births in 2015",365,8,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Births2015.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Births2015.html","Births2015 R Documentation   US Births in 2015   Description  
A day by day record of the number of births in the United States in 2015.    Usage    data(Births2015)    Format  
A data.frame with 365 observations on the following 8 variables.   

date Date   
births Number of births on date (integer)   
wday Day of week (ordered factor)   
year Year (integer)   
month Month (integer)   
day_of_year Day of year (integer)   
day_of_month Day of month (integer)   
day_of_week Day of week (integer)      Source  
Obtained from the National Center for Health Statistics, National Vital Statistics System, Natality, 2015 data.    See Also  
Births78 , Births     Examples    data(Births2015) if (require(ggformula)) { gf_point(births ~ date, data = Births2015) gf_point(births ~ date, data = Births2015, color = ~ wday) } if (require(dplyr)) { Births78 %>% group_by(wday) %>% summarise(births = sum(births)) %>% ungroup() %>% mutate(frac = births / sum(births)) Births2015 %>% group_by(wday) %>% summarise(births = sum(births)) %>% ungroup() %>% mutate(frac = births / sum(births)) }"
"mosaicData-Births78","mosaicData","Births78","US Births in 1978",365,8,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Births78.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Births78.html","Births78 R Documentation   US Births in 1978   Description  
A day by day record of the number of births in the United States in 1978.    Usage    data(Births78)    Format  
A data.frame with 365 observations on the following 8 variables.   

date Date   
births Number of births on date (integer)   
wday Day of week (ordered factor)   
year Year (integer)   
month Month (integer)   
day_of_year Day of year (integer)   
day_of_month Day of month (integer)   
day_of_week Day of week (integer)      See Also  
Births2015 , Births     Examples    data(Births78) if (require(ggformula)) { gf_point(births ~ date, data = Births78) gf_point(births ~ date, data = Births78, color = ~ wday) }"
"mosaicData-Cards","mosaicData","Cards","Standard Deck of Cards",52,1,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Cards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Cards.html","Cards R Documentation   Standard Deck of Cards   Description  
A character vector with two or three character representations of each card in a standard 52-card deck.    Usage    Cards    Details  
The 2 of clubs is represented as ""2C"", while the 10 of diamonds is ""10D"".    Examples    if (require(mosaic)) { deal(Cards, 13) # bridge hand deal(Cards, 5) # poker hand shuffle(Cards) # shuffled deck }"
"mosaicData-CoolingWater","mosaicData","CoolingWater","CoolingWater",222,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/CoolingWater.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/CoolingWater.html","CoolingWater R Documentation   CoolingWater   Description  
Temperature of a mug of water as it cools    Usage    data(CoolingWater)    Format  
A data frame with 222 observations of the following variables.   

time time in minutes   
temp temperature in Celsius      Details  
The water was poured into a mug and a temperature probe inserted into the water with a few seconds of the pour.    Source  
These data were collected Stan Wagon to help his mathematical modeling students explore Newton's Law of Cooling and the ways that the law is really only an approximation. More about Stan: http://stanwagon.com .    Examples    data(CoolingWater) if (require(ggformula)) { gf_point(temp ~ time, data = CoolingWater, alpha = 0.5) }"
"mosaicData-Countries","mosaicData","Countries","Countries",288,3,0,3,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Countries.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Countries.html","Countries R Documentation   Countries   Description  
A data frame containing country names as used by Gapminder and the maps  package to facilitate conversation between the two.    Usage    data(Countries)    Format  
A data frame with 258 observations on the following variables.   

worldmap region name http://mappinghacks.com/ data sets   
gapminder country name in Gapminder data sets   
maps region name in maps data sets      Details  
The ""countries"" in the maps data include several other geographic regions (bodies of water, islands belonging to other countries, Hawaii, etc.) that are not countries. Furthermore, the maps countries do not include many of the countries that have been created since ca. 2000. The mapping is therefore many-to-many, and also includes some NAs when there is no appropriate mapping. Bodies of water in the  maps data, for example, are not assigned a country in the Gapminder.    Examples    data(Countries) subset(Countries, maps==""Yugoslavia"") # Where has Yugoslavia gone? subset(Countries, is.na(gapminder)) # Things from maps with no Gapminder equivalent subset(Countries, is.na(maps)) # Things from Gapminder with no maps equivalent"
"mosaicData-CPS85","mosaicData","CPS85","Data from the 1985 Current Population Survey (CPS85)",534,11,6,0,7,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/CPS85.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/CPS85.html","CPS85 R Documentation   Data from the 1985 Current Population Survey (CPS85)   Description  
The Current Population Survey (CPS) is used to supplement census information between census years. These data consist of a random sample of persons from the CPS85, with information on wages and other characteristics of the workers, including sex, number of years of education, years of work experience, occupational status, region of residence and union membership.    Usage    data(CPS85)    Format  
A data frame with 534 observations on the following variables.   

wage wage (US dollars per hour)   
educ number of years of education   
race a factor with levels NW (nonwhite) or W (white)   
sex a factor with levels F M    
hispanic a factor with levels Hisp NH    
south a factor with levels NS S    
married a factor with levels Married Single    
exper number of years of work experience (inferred from age and  educ )   
union a factor with levels Not Union    
age age in years   
sector a factor with levels clerical const   manag manuf other prof sales service       Details  
Data are from 1985. The data file is recoded from the original, which had entirely numerical codes.    Source  
Data are from https://dasl.datadescription.com     References  
Berndt, ER. The Practice of Econometrics 1991. Addison-Wesley.    Examples    data(CPS85)"
"mosaicData-Dimes","mosaicData","Dimes","Weight of dimes",30,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Dimes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Dimes.html","Dimes R Documentation   Weight of dimes   Description  
Weights of a sample of dimes.    Usage    data(Dimes)    Format  
A data frame with 30 observations on the following 2 variables.   

mass mass of dime in grams   
year year the dime was minted      Details  
These data were collected on a sample taken from a large sack of dimes for the purpose of estimating the total number of dimes in the sack based on the weights of the individual dimes.    Source  
Data were collected by Michael Stob."
"mosaicData-Galton","mosaicData","Galton","Galton's dataset of parent and child heights",898,6,1,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Galton.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Galton.html","Galton R Documentation   Galton's dataset of parent and child heights   Description  
In the 1880's, Francis Galton was developing ways to quantify the heritability of traits. As part of this work, he collected data on the heights of adult children and their parents.    Usage    data(Galton)    Format  
A data frame with 898 observations on the following variables.   

family a factor with levels for each family   
father the father's height (in inches)   
mother the mother's height (in inches)   
sex the child's sex: F or M    
height the child's height as an adult (in inches)   
nkids the number of adult children in the family, or, at least, the number whose heights Galton recorded.      Details  
Entries were deleted for those children whose heights were not recorded numerically by Galton, who sometimes used entries such as ""tall"", ""short"", ""idiotic"", ""deformed"" and so on.    Source  
The data were transcribed by J.A. Hanley who has published them at  http://www.medicine.mcgill.ca/epidemiology/hanley/galton/     References  
""Transmuting"" women into men: Galton's family data on human stature. (2004)  The American Statistician , 58(3):237-243.    Examples    data(Galton)"
"mosaicData-Gestation","mosaicData","Gestation","Data from the Child Health and Development Studies",1236,23,0,12,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Gestation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Gestation.html","Gestation R Documentation   Data from the Child Health and Development Studies   Description  
Birth weight, date, and gestational period collected as part of the Child Health and Development Studies in 1961 and 1962. Information about the baby's parents — age, education, height, weight, and whether the mother smoked is also recorded.    Usage    data(Gestation)    Format  
A data frame with 1236 observations on the following variables.   

id identification number   
plurality all ""single fetus"" in this data set   
outcome all ""live birth"" (survived at least 28 days) in this data set   
date birth date where 1096=January 1, 1961   
gestation length of gestation (in days)   
wt birth weight (in ounces)   
parity total number of previous pregnancies (including fetal deaths and still births)   
race mother's race: ""asian"", ""black"", ""mex"", ""mixed"", or ""white""   
age mother's age in years at termination of pregnancy   
ed mother's education   
ht mother's height in inches to the last completed inch   
wt.1 mother's prepregnancy weight (in pounds)   
drace father's race   
dage father's age (in years)   
ded father's education   
dht father's height in inches to the last completed inch   
dwt father's weight (in pounds)   
marital marital status,   
inc family yearly income in $2500 increments   
smoke does mother smoke? (never, smokes now, until current pregnancy, once did, not now)   
time time since quitting smoking (never smoked, still smokes, during current preg, within 1 year, 1 to 2 years ago, 2 to 3 years ago, 3 to 4 years ago, 5 to 9 years ago, 10+ years ago, quit and don't know   
number number of cigarettes smoked per day for past and current smokers (never, 1-4, 5-9, 10-14, 15-19, 20-29, 30-39, 40-60, 60+, smoke but don't know)      Details  
The data were presented by Nolan and Speed to address the question of whether there is a link between maternal smoking and the baby's health for male births.    Source  
The book by Nolan and Speed describes the data in more detail and provides an Internet site for accessing them:  https://www.stat.berkeley.edu/users/statlabs/     References  
D Nolan and T Speed. Stat Labs: Mathematical Statistics Through Applications (2000), Springer-Verlag.    Examples    data(Gestation)"
"mosaicData-GoosePermits","mosaicData","GoosePermits","Goose Permit Study",11,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/GoosePermits.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/GoosePermits.html","GoosePermits R Documentation   Goose Permit Study   Description  
237 hunters were each offered one of 11 cash amounts (bids) ranging from $1 to $200 in return for their goose permits. Hunters returned either their permit or the cash.    Usage    data(GoosePermits)    Format  
A data.frame with 11 observations on the following 3 variables.   
itemcodebid amount offered for permit (US $) (numeric) itemcodekeep number of hunters who kept the permit and returned the cash (numeric) itemcodesell number of hunters who kept the cash and returned the permit (numeric)    Source  
Bishop and Heberlein. ""Measuring values of extramarket goods: are indirect measures biased?"". Amer. J. Agr. Econ. 61, 1979. Available at  https://onlinelibrary.wiley.com/doi/abs/10.2307/3180348     Examples    data(GoosePermits) goose.model <- glm( cbind(keep, sell) ~ log(bid), data = GoosePermits, family = binomial()) if (require(ggformula)) { y.hat <- makeFun(goose.model) gf_point( (keep/(keep+sell)) ~ bid, data = GoosePermits, ylim = c(0,1.05)) %>% gf_fun(y.hat(b) ~ b, add = TRUE, color = ""red"", alpha = 0.5) }"
"mosaicData-HeatX","mosaicData","HeatX","Data from a heat exchanger laboratory",6,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/HeatX.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/HeatX.html","HeatX R Documentation   Data from a heat exchanger laboratory   Description  
These data were collected by engineering students at Calvin College. The apparatus consists of concentric pipes insulated from the environment so that as nearly as can be managed the only heat exchange is between the hot and cold water.    Usage    data(HeatX)    Format  
A data frame with 6 observations on the following variables.   

trial trial number   
T.cold.in temperature (C) of the cold water as it enters the apparatus   
T.cold.out temperature (C) of the cold water as it leaves the apparatus   
m.cold flow rate (L/min) of the cold water   
T.hot.in temperature (C) of the hot water as it enters the apparatus   
T.hot.out temperature (C) of the hot water as it leaves the apparatus   
m.hot flow rate (L/min) of the hot water      Examples    # We can test for heat exchange with the environment by checking to see if the # heat gained by the cold water matches the heat lost by the hot water. C_p <- 4.182 / 60 # / 60 because measuring m in L/min HeatX2 <- dplyr::mutate(HeatX, Q.cold = m.cold * C_p * (T.cold.out - T.cold.in), Q.hot = m.hot * C_p * (T.hot.out- T.hot.in), Q.env = Q.cold + Q.hot ) if (require(ggformula)) { gf_jitter( """" ~ Q.env, data = HeatX2, alpha = 0.6, size = 4, width = 0, height = 0.1, seed = 123) %>% gf_labs(y = """") } if (require(mosaic)) { t.test( ~Q.env, data = HeatX2 ) }"
"mosaicData-HELPfull","mosaicData","HELPfull","Health Evaluation and Linkage to Primary Care",1472,788,329,0,6,0,782,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/HELPfull.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/HELPfull.html","HELPfull R Documentation   Health Evaluation and Linkage to Primary Care   Description  
The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.    Usage    data(HELPfull)    Format  
A data frame with 1472 observations on the following variables.   

ID Subject ID   
A10 Marital Status (1=Married, 2=Remarried, 3=Widowed, 4= Separated, 5=Divorced, 6=Never Married   
A11A Do you currently have a living mother? (0=No, 1= Yes   
A11B Do you currently have a living father? (0=No, 1=Yes   
A11C Do you currently have siblings? (0=No, 1=Yes   
A11D Do you currently have a partner (0=No, 1=Yes)   
A11E Do you currently have children? (0=No, 1=Yes)   
A12B_REC Hollingshead category (recode) (0=Cat 1,2,3, 1=Cat 4,5,6, 2=Cat 7,8,9)   
A12B Hollingshead categories (1=Major profess, 2=Lesser professional, 3=Minor professional, 4=Clerical/sales, 5=Skilled manual, 6=Semi-skilled, 7=Unskilled, 8= Homemaker, 9=No occupation)   
A13 Usual employment pattern in last 6 months (1=Full time, 2=Part time, 3=Student, 4=Unemployed, 5=Control envir)   
A14A Lived alone-last 6 months (0=No, 1=Yes)   
A14B Lived with a partner-last 6 months (0=No, 1=Yes   
A14C Lived with parent(s)-last 6 months (0=No, 1=Yes)   
A14D Lived with children-last 6 months (0=No, 1=Yes)   
A14E Lived with other family-last 6 months (0=No, 1=Yes   
A14F Lived with friend(s)-last 6 months (0=No, 1=Yes)   
A14G_T a factor with levels 1/2 WAY HOUSE 3/4 HOUSE ANCHOR INN ARMY ASSOCIATES BOARDERS BOYFRIENDS MOM CORRECTIONAL FACILIT CRACK HOUSE DEALER ENTRE FAMILIA FENWOOD GAVIN HSE GIRLFRIENDS DAUGHTE GIRLFRIENDS SON GIRLFRIENDS CHILDREN GIRLFRIENDS DAUGHTER GROUP HOME HALF-WAY HOUSE HALFWAY HOUSE HALFWAY HOUSES HALFWAY HSE HOLDING UNIT HOME BORDER HOMELESS HOMELESS SHELTER IN JAIL IN PROGRAMS INCARCERATED JAIL JAIL HALFWAY HOUSE JAIL, SHELTER JAIL, STREET JAIL/PROGRAM JAIL/SHELTER JAILS LANDLADY LANDLORD LODGING HOUSE MERIDIAN HOUSE NURSING HOME ON THE STREET PARTNERS MOTHER PARTNERS CHILD PARTNERS CHILDREN PRDGRAMS PRISON PROGRAM PROGRAM MTHP PROGRAM ROOMMATES PROGRAM SOBER HOUSE PROGRAM-RESIDENTIAL PROGRAM/HALFWAY HOUS PROGRAM/JAIL PROGRAM/SHELTER PROGRAM/SHELTERS PROGRAMS PROGRAMS SUBSTANCE PROGRAMS/SHELTER PROGRAMS/SHELTERS PROGRAMS/SHELTERS/DE PROJECT SOAR RESIDENTIAL FACILITY RESIDENTIAL PROGRAM ROOMING HOUSE ROOMING HOUSE (RELIG ROOMMATE ROOMMATES ROOMMATES AT TRANSIT RYAN HOUSE SALVATION ARMY SHELTER SHELTER/HALFWAY HSE SHELTER/HOTEL SHELTER/PROGRAM SHELTERS SHELTERS/HOSPITALS SHELTERS/JAIL SHELTERS/PROGRAMS SHELTERS/STREETS SOBER HOUSE SOBER HOUSING SOUTH BAY JAIL STEPSON STREET STREETS SUBSTANCE ABUSE TREA TRANSITIONAL HOUSE VA SHELTER    
A14G Lived w/ other-last 6 months (0=No, 1=Yes)   
A15A #nights in overnight shelter-last 6 months   
A15B # nights on street-last 6 months   
A15C # months in jail-last 6 months   
A16A # months in overnight shelter-last 5 years   
A16B # moths on street-last 5 years   
A16C # months in jail-last 5 years   
A17A Received SSI – past 6 months (0=No, 1=Yes)   
A17B Received SSDI – past 6 months (0=No, 1=Yes)   
A17C Received AFDC – past 6 months (0=No, 1=Yes)   
A17D Received EAEDC – past 6 months (0=No, 1=Yes)   
A17E Received WIC – past 6 months (0=No, 1=Yes)   
A17F Received unemployment benefits – past 6 months (0=No, 1=Yes)   
A17G Received Workman's Compensation – past 6 months (0=No, 1=Yes)   
A17H Received Child Support – past 6 months (0=No, 1=Yes)   
A17I_T a factor with levels DISABLED VETERAN EBT (FOOD STAMPS) EMERGENCY FOOD STAMP FOOD STAMP FOOD STAMPS FOOD STAMPS/VETERAN FOOD STAMPS/VETERANS INSURANCE SETTLEMENT PENSION CHECK SECTION 8 SERVICE CONNECTED DI SOCIAL SECURITY SSDI FOR SON SURVIVORS BENEFITS TEMPORARY DISABILITY VA BENEFITS-DISABILI VA COMPENSATION VA DISABILITY PENSIO VETERAN BENEFITS VETERANS SERVICES VETERANS AFFAIRS    
A17I Received other income – past 6 months (0=No, 1=Yes)   
A18_REC1 Most money made in 1 year (recode) (0=$19,000 or less, 1=$20,000-$49,000, 2=$50,000 or more)   
A18_REC2 Most money made-continuous recode   
A18 Most money made in any 1 year-last 5 years (1=<5000, 2=5000-10000, 3=11000-19000, 4=20000-29000, 5=30000-39000, 6=40000-49000, 7=50000+   
A1 Gender (1=Male, 2=Female)   
A9 Years of education completed   
ABUSE2 Type of abuse (0=No abuse, 1=Physical only, 2=Sexual only, 3=Physical and sexual)   
ABUSE3 Type of abuse (0=No abuse, 1=Physical only, 2=Sexual +/- physical (0=No, 1=Yes)   
ABUSE Abuse-physical or sexual (0=No abuse, 1=Family abuse, 2=Stranger only abuse)   
AGE Age in years   
ALCOHOL 1st/2nd drug of coice=Alcohol (0=No, 1=Yes)   
ALCQ_30 Total number drinks past 30 days   
ALONE6M Usually lived alone past 6 months (0=No, 1=Yes)   
ALT_TRT Alternative tratments (0=No, 1=Yes)   
ANYSUBSTATUS Used alcohol, heroin, or cocaine since leaving detox-6 months   
ANY_INS Did you have health insurance in past 6 months (0=No, 1=Yes)   
ANY_UTIL Any recent health utilization (0=No, 1=Yes)   
ANY_VIS_CUMUL Cumulative # visits to regular doctor's office   
ANY_VIS # visits to regular doctor's office–This time point   
B10 Any physcal/emotional problem interfere with social activities-last 4 weeks (1=All of the time, 2=Most of the time, 3=Some of the time, 4= A lttle of time, 5= None of the time)   
B11A I seem to get sick easier than other people (1=Definitely true, 2=Mostly True, 3=Don't know, 4=Mostly false, 5=Definitely false)   
B11B I am as healthy as anybody I know (1=Definitely true, 2=Mostly true, 3=Don't know, 4=Mostly false, 5=Definitely False)   
B11C I expect my health to get worse (1=Definitely true, 2=Mostly true, 3=Don't know, 3=Mostly false, 5=Definitely false)   
B11D My health is excellent (1=Definitely true, 2=Mostly true, 3=Don't know, 4=Mostly false, 5=Definitely false)   
B1 In general, how is your health (1=Excellent, 2=Very Good, 3=Good, 4=Fair, 5=Poor)   
B2 Compared to 1 year ago, how is your health now (1=Much better, 2=Somewhat better, 3=About the same, 4=Somewhat worse, 5=Much worse)   
B3A Does health limit you in vigorous activity (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3B Does your health limit you in moderate activity (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3C Does health limit you in lift/carry groceries (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3D Does health limit you in climb several stair flights (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3E Does health limit you in climb 1 stair flight (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3F Does health limit you in bend/kneel/stoop (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3G Does health limit you in walking >1 mile (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3H Does health limit you in walking sevral blocks (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3I Does health limit you in walking 1 block (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B3J Does health limit you in bathing/dressing self (1=Limited a lot, 2=Limited a little, 3=Not limited)   
B4A Cut down work/activity due to physical health-last 4 weeks (0=No, 1=Yes)   
B4B Accomplish less due to phys health-last 4 weeks (0=No, 1=Yes)   
B4C Lim wrk/act type due to phys health-last 4 weeks (0=No, 1=Yes)   
B4D Diff perf work due to phys health-last 4 weeks (0=No, 1=Yes)   
B5A Cut wrk/act time due to emot prbs-last 4 weeks (0=No, 1=Yes)   
B5B Accomplish ess due to emot probs-last 4 weeks (0=No, 1=Yes)   
B5C <carefl w/wrk/act due to em prb-last 4 weeks (0=No, 1=Yes)   
B6 Ext phys/em intf w/norm soc act-last 4 weeks (1=Not al all, 2=Slightly, 3=Moderately, 4=Quite a bit, 5=Extremely)   
B7 Amount of bodily pain – past 4 weeks (1=None, 2=Very mild, 3= Mild, 4=Moderate, 5= Severe, 6= Very severe)   
B8 Amount of pain interfering with normal work-last 4 weeks (1=Not at all, 2=A little bit, 3=Moderately, 4=Quite a bit, 5=Extremely   
B9A Did you feel full of pep – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9B Have you been nervous – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9C Felt nothing could cheer you-last 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9D Have you felt calm/peaceful – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9E Did you have a lot of energy – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9F Did you feel downhearted – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9G Did you feel worn out – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9H Have you been a happy pers – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
B9I Did you feel tired – past 4 weeks (1=All of the time, 2=Most of the time, 3 = Good bit of the time, 4=Some of the time, 5=A little of time, 6=None of the time)   
BIRTHPLC Where born (recode) (0=USA, 1=Foreign)   
BP SF-36 pain index (0-100)   
C1A Tolf by MD had seix, epil, convuls (0=No, 1=Yes)   
C1B Told by MD had asthma, emphysema, chr lung dis (0=No, 1=Yes)   
C1C Told by MD had MI (0=No, 1=Yes)   
C1D Told by MD had CHF (0=No, 1=Yes)   
C1E Told by MD had other heart dis (req med) (0=No, 1=Yes)   
C1F Told by MD had HBP (0=No, 1=Yes)   
C1G Told by MD had chronic liver disease (0=No, 1=Yes)   
C1H Told by MD had kidney failure (0=No, 1=Yes)   
C1I Told by MD had chronic art, osteoarth (0=No, 1=Yes)   
C1J Told by MD had peripheral neuropathy (0=No, 1=Yes)   
C1K Ever told by MD had cancer (0=No, 1=Yes)   
C1L Ever told by MD had diabetes (0=No, 1=Yes)   
C1M Ever told by MD had stroke (0=No, 1=Yes)   
C2A1 Have you ever had skin infections (0=No, 1=Yes)   
C2A2 Have you had skin infections – past 6 months (0=No, 1=Yes)   
C2B1 Have you ever had pneumonia (0=No, 1=Yes)   
C2B2 Have you had pneumonia – past 6 months (0=No, 1=Yes)   
C2C1 Have you ever had septic arthritis (0=No, 1=Yes)   
C2C2 Have you had septic arthritis – past 6 months (0=No, 1=Yes)   
C2D1 Have you ever had TB (0=No, 1=Yes)   
C2D2 Have you had TB-last 6 months (0=No, 1=Yes)   
C2E1 Have you ever had endocarditis (0=No, 1=Yes)   
C2E2 Have you had endocarditis – past 6 months (0=No, 1=Yes)   
C2F1 Have you ever had an ulcer (0=No, 1=Yes)   
C2F2 Have you had an ulcer – past 6 months (0=No, 1=Yes)   
C2G1 Have you ever had pancreatitis (0=No, 1=Yes)   
C2G2 Have you had pancreatitis – past 6 months (0=No, 1=Yes)   
C2H1 Ever had abdom pain req overnt hosp stay (0=No, 1=Yes)   
C2H2 Abdom pain req ovrnt hosp stay-last 6 months (0=No, 1=Yes)   
C2I1 Have you ever vomited blood (0=No, 1=Yes)   
C2I2 Have you vomited blood – past 6 months (0=No, 1=Yes)   
C2J1 Have you ever had hepatitis (0=No, 1=Yes)   
C2J2 Have you had hepatitis – past 6 months (0=No, 1=Yes)   
C2K1 Ever had blood clots in legs/lungs (0=No, 1=Yes)   
C2K2 Blood clots in legs/lungs – past 6 months (0=No, 1=Yes)   
C2L1 Have you ever had osteomyelitis (0=No, 1=Yes)   
C2L2 Have you had osteomyelitis – past 6 months (0=No, 1=Yes)   
C2M1 Chest pain using cocaine req ER/hosp (0=No, 1=Yes)   
C2M2 Chest pain using coc req ER/hosp-last 6 months (0=No, 1=Yes)   
C2N1 Have you ever had jaundice (0=No, 1=Yes)   
C2N2 Have you had jaundice – past 6 months (0=No, 1=Yes)   
C2O1 Lower back pain > 3 months req med attn (0=No, 1=Yes)   
C2O2 Lwr back pain >3 months req med attention-last 6 months (0=No, 1=Yes)   
C2P1 Ever had seizures or convulsions (0=No, 1=Yes)   
C2P2 Had seizures or convulsions – past 6 months (0=No, 1=Yes)   
C2Q1 Ever had drug/alcohol overdose requiring ER attention (0=No, 1=Yes)   
C2Q2 Drug/alcohol overdose req ER attn (0=No, 1=Yes)   
C2R1 Have you ever had a gunshot wound (0=No, 1=Yes)   
C2R2 Had a gunshot wound – past 6 months (0=No, 1=Yes)   
C2S1 Have you ever had a stab wound (0=No, 1=Yes)   
C2S2 Have you had a stab wound – past 6 months (0=No, 1=Yes)   
C2T1 Ever had accident/falls req med attn (0=No, 1=Yes)   
C2T2 Had accident/falls req med attn – past 6 months (0=No, 1=Yes)   
C2U1 Ever had fract/disloc to bones/joints (0=No, 1=Yes)   
C2U2 Fract/disloc to bones/joints – past 6 months (0=No, 1=Yes)   
C2V1 Ever had injury from traffic accident (0=No, 1=Yes)   
C2V2 Had injury from traffic accident – past 6 months (0=No, 1=Yes)   
C2W1 Have you ever had a head injury (0=No, 1=Yes)   
C2W2 Have you had a head injury – past 6 months (0=No, 1=Yes)   
C3A1 Have you ever had syphilis (0=No, 1=Yes)   
C3A2 # times had syphilis   
C3A3 Have you had syphilis in last 6 months (0=No, 1=Yes)   
C3B1 Have you ever had gonorrhea (0=No, 1=Yes)   
C3B2 # times had gonorrhea   
C3B3 Have you had gonorrhea in last 6 months (0=No, 1=Yes)   
C3C1 Have you ever had chlamydia (0=No, 1=Yes)   
C3C2 # of times had Chlamydia   
C3C3 Have you had chlamydia in last 6 months (0=No, 1=Yes)   
C3D Have you ever had genital warts (0=No, 1=Yes)   
C3E Have you ever had genital herpes (0=No, 1=Yes)   
C3F1 Have you ever had other STD's (not HIV) (0=No, 1=Yes)   
C3F2 # of times had other STD's (not HIV)   
C3F3 Had other STD's (not HIV)-last 6 months (0=No, 1=Yes)   
C3F_T a factor with levels 7 CRABS CRABS - TRICHONOMIS CRABS, HEP B DOESNT KNOW NAME HAS HAD ALL 3 ABC HEP B HEP B, TRICAMONAS HEP. B HEPATITIS B HEPATITS B TRICHAMONAS VAGINALA TRICHAMONIS TRICHOMONAS TRICHOMONIASIS TRICHOMONIS TRICHOMONIS VAGINITI TRICHOMORAS TRICHONOMIS    
C3G1 Have you ever been tested for HIV/AIDS (0=No, 1=Yes)   
C3G2 # times tested for HIV/AIDS   
C3G3 Have you been tested for HIV/AIDS-last 6 months (0=No, 1=Yes)   
C3G4 What was the result of last test (1=Positive, 2=Negative, 3=Refused, 4=Never got result, 5=Inconclusive   
C3H1 Have you ever had PID (0=No, 1=Yes)   
C3H2 # of times had PID   
C3H3 Have you had PID in last 6 months (0=No, 1=Yes)   
C3I Have you ever had a Pap smear (0=No, 1=Yes)   
C3J Have you had a Pap smear in last 3 years (0=No, 1=Yes)   
C3K_M How many months pregnant   
C3K Are you pregnant (0=No, 1=Yes)   
CESD_CUT CES-D score > 21 y/n (0=No, 1=Yes)   
CES_D CES-D score, measure of depressive symptoms, high scores are worse   
CHR_6M Chronic medical conds/HIV – past 6m y/n (0=No, 1=Yes)   
CHR_EVER Chronic medical conds/HIV-ever y/n (0=No, 1=Yes)   
CHR_SUM Sum chronic medical conds/HIV ever   
CNTRL InDUC-2L-Control score   
COC_HER 1st/2nd drug of choice=cocaine or heroine (0=No, 1=Yes)   
CUAD_C CUAD-Cocaine   
CUAD_H CUAD-Heroin   
CURPHYAB Current abuse-physical (0=No, 1=Yes)   
CURPHYSEXAB Curent abuse-physical or sexual (0=No abuse, 1=Physical only, 2=Sexual +/- physical)   
CURSEXAB Current abuse-sexual (0=No, 1=Yes)   
C_AU ASI-Composite score for alcohol use   
C_DU ASI-Composite score for drug use   
C_MS ASI-Composite medical status   
D1 $ of times hospitalized for med probs   
D2 Take prescription medicdation regularly for physical problem (0=No, 1=Yes)   
D3_REC Any medical problems past 30d y/n (0=No, 1=Yes)   
D3 # days had med probs-30 days bef detox   
D4_REC Bothered by medical problems y/n (0=No, 1=Yes)   
D4 How bother by med prob-30days bef detox (0=Not at all, 1=Slightly, 2=Moderately, 3=Considerably, 4=Extremely)   
D5_REC Medical trtmt is important y/n (0=No, 1=Yes)   
D5 How import is trtmnt for these med probs (0=Not at all, 1=Slightly, 2= Moderately, 3= Considerably, 4= Extremely   
DAYSANYSUB time (days) from baseline to first alcohol, heroin, or cocaine since leaving detox-6m   
DAYSDRINK Time (days) from baseline to first drink since leaving detox-6m   
DAYSLINK Time (days) to linkage to primary care within 12 months (by administrative record)   
DAYS_SINCE_BL # of days from baseline to current interview   
DAYS_SINCE_PREV # of days from previous to current interview   
DEAD a numeric vector   
DEC_AM SOCRATES-Ambivalence-Decile   
DEC_RE SOCRATES-Recognition-Decile   
DEC_TS SOCRATES-Taking steps-Decile   
DRINKSTATUS Drank alcohol since leaving detox-6m   
DRUGRISK RAB-Drug risk total   
E10A have you been to med clinic-last 6 months (0=No, 1=Yes)   
E10B1_R Mental health treatment past 6m y/n (0=No, 1=Yes)   
E10B1 # x visit ment health clin/prof-last 6 months   
E10B2_R Med clinic/private MD past 6m y/n (0=No, 1=Yes)   
E10B2 # x visited med clin/priv MD-last 6 months   
E10C19 Visited private MD-last 6 months (0=No, 1=Yes)   
E11A Did you stay ovrnite/+ in hosp-last 6 months (0=No, 1=Yes)   
E11B # times ovrnight/+ in hosp-last 6 months  
E11C Total # nights in hosp-last 6 months   
E12A Visited Hosp ER for med care – past 6 months (0=No, 1=Yes)   
E12B # times visited hosp ER-last 6 months   
E13 Tlt # visits to MDs-last 2 weeks bef detox   
E14A Recd trtmt from acupuncturist-last 6 months (0=No, 1=Yes)   
E14B Recd trtmt from chiropractor-last 6 months (0=No, 1=Yes)   
E14C Trtd by hol/herb/hom med prac-last 6 months (0=No, 1=Yes)   
E14D Recd trtmt from spirit healer-last 6 months (0=No, 1=Yes)   
E14E Have you had biofeedback-last 6 months (0=No, 1=Yes)   
E14F Have you underwent hypnosis-last 6 months (0=No, 1=Yes)   
E14G Received other treatment-last 6 months (0=No, 1=Yes)   
E15A Tried to get subst ab services-last 6 months (0=No, 1=Yes)   
E15B Always able to get subst ab servies (0=No, 1=Yes)   
E15C10 My insurance didn't cover services (0=No, 1=Yes)   
E15C11 There were no beds available at the prog (0=No, 1=Yes)   
E15C12 Other reason not get sub ab services (0=No, 1=Yes)   
E15C1 I could not pay for services (0=No, 1=Yes)   
E15C2 I did not know where to go for help (0=No, 1=Yes)   
E15C3 Couldn't get to services due to transp prob (0=No, 1=Yes)   
E15C4 The offie/clinic hrs were inconvenient (0=No, 1=Yes)   
E15C5 Didn't speak/understnd Englsh well enough (0=No, 1=Yes)   
E15C6 Afraid other might find out about prob (0=No, 1=Yes)   
E15C7 My substance abuse interfered (0=No, 1=Yes)   
E15C8 Didn't have someone to watch my children (0=No, 1=Yes)   
E15C9 I did not want to lose my job (0=No, 1=Yes)   
E16A10 I do not want to lose my job (0=No, 1=Yes)   
E16A11 My insurance doesn't cover charges (0=No, 1=Yes)   
E16A12 I do not feel I need a regular MD (0=No, 1=Yes)   
E16A13 Other reasons don't have regular MD (0=No, 1=Yes)   
E16A1 I cannot pay for services (0=No, 1=Yes)   
E16A2 I am not eligible for free care (0=No, 1=Yes)   
E16A3 I do not know where to go (0=No, 1=Yes)   
E16A4 Can't get to services due to trans prob (0=No, 1=Yes)   
E16A5 a numeric vectorOffice/clinic hours are inconvenient (0=No, 1=Yes)   
E16A6 I don't speak/understnd enough English (0=No, 1=Yes)   
E16A7 Afraid othrs find out about my health prob (0=No, 1=Yes)   
E16A8 My substance abuse interferes (0=No, 1=Yes)   
E16A9 I don't have someone to watch my children (0=No, 1=Yes)   
E16A_DD Barrier to regular MD: dislike docs/system (0=No, 1=Yes)   
E16A_IB Barrier to regular MD: internal barriers (0=No, 1=Yes)   
E16A_RT Barrier to regular MD: red tape (0=No, 1=Yes)   
E16A_TM Barrier to regular MD: time restrictions (0=No, 1=Yes)   
E18A I could not pay for services (0=No, 1=Yes)   
E18B I did not know where to go for help (0=No, 1=Yes)   
E18C Couldn't get to services due to transp prob (0=No, 1=Yes)   
E18D The office/clinic hrs were inconvenient (0=No, 1=Yes)   
E18F Afraid others might find out about prob (0=No, 1=Yes)   
E18G My substance abuse interfered (0=No, 1=Yes)   
E18H Didn't have someone to watch my children (0=No, 1=Yes)   
E18I I did not want to lose my job (0=No, 1=Yes)   
E18J My insurance didn't cover services (0=No, 1=Yes)   
E18K There were no beds available at the prog (0=No, 1=Yes)   
E18L I do not need substance abuse services (0=No, 1=Yes)   
E18M Other reason not get sub ab services (0=No, 1=Yes)   
E2A Detox prog for alcohol or drug prob-last 6 months (0=No, 1=Yes)   
E2B # times entered a detox prog-last 6 months   
E2C # nights ovrnight in detox prg-last 6 months   
E3A Holding unit for drug/alcohol prob-last 6 months (0=No, 1=Yes)   
E3B # times in holding unity=last 6 months   
E3C # total nights in holding unit-last 6 months   
E4A In halfway hse/resid facil-last 6 months (0=No, 1=Yes)   
E4B # times in hlfwy hse/res facil-last 6 months   
E4C Ttl nites in hlfwy hse/res fac-last 6 months   
E5A In day trtmt prg for alcohol/drug-last 6 months (0=No, 1=Yes)   
E5B Total # days in day trtmt prg-last 6 months   
E6 In methadone maintenance prg-last 6 months (0=No, 1=Yes)   
E7A Visit outpt prg subst ab couns-last 6 months (0=No, 1=Yes)   
E7B # visits outpt prg subst ab couns-last 6 months   
E8A1 Saw MD/H care worker regarding alcohol/drugs-last 6 months (0=No, 1=Yes)   
E8A2 Saw Prst/Min/Rabbi re alcohol/drugs-last 6 months (0=No, 1=Yes)   
E8A3 Employ Asst Prg for alcohol/drug prb-last 6 months (0=No, 1=Yes)   
E8A4 Oth source cnsl for alcohol/drug prb-last 6 months (0=No, 1=Yes)   
E9A AA/NA/slf-hlp for drug/alcohol/emot-last 6 months (0=No, 1=Yes)   
E9B How often attend AA/NA/slf-hlp-last 6 months (1=Daily, 2=2-3 Times/week, 3=Weekly, 4=Every 2 weeks, 5=Once/month   
EPI_6M2B Episodic(C2A-C2O)-6m y/n (0=No, 1=Yes)   
EPI_6M Episodic (C2A-C2O,C2R-C2U, STD)-6m y/n (0=No, 1=Yes)   
EPI_SUM Sum episodic (C2A-C2O, C2R-C2U, STD)-6m   
F1A Bothered by thngs not generally bothered by (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1B My appetite was poor (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1C Couldn't shake blues evn w/fam+frnds hlp (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1D Felt I was just as good as other people (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1E Had trouble keeping mind on what doing (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1F I felt depressed (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1G I felt everything I did was an effort (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1H I felt hopeful about the future (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1I I thought my life had been a failure (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1J I felt fearful (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1K My sleep was restless (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1L I was happy (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1M I talked less than usual (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1N I felt lonely (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1O People were unfriendly (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1P I enjoyed life (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1Q I had crying spells (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1R I felt sad (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1S I felt that people dislike me (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
F1T I could not get going (0=Rarely/never, 1=Some of the time, 2=Occas/moderately, 3=Most of the time)   
FAMABUSE Family abuse-physical or sexual (0=No, 1=Yes)   
FRML_SAT Formal substance abuse treatment y/n (0=No, 1=Yes)   
G1A_30 Diff contr viol beh-sig per last 30 days (0=No, 1=Yes)   
G1A Diff contr viol beh for sig time per evr (0=No, 1=Yes)   
G1B_30 Had thoughts of suicide-last 30 days (0=No, 1=Yes)   
G1B_REC Suicidal thoughts past 30 days y/n (0=No, 1=Yes)   
G1B Ever had thoughts of suicide (0=No, 1=Yes)   
G1C_30 Attempted suicide-last 30 days (0=No, 1=Yes)   
G1C Attempted suicide ever (0=No, 1=Yes)   
G1D_30 Prescr med for psy/emot prob-last 30 days (0=No, 1=Yes)   
G1D_REC Prescribed psych meds past 30 days y/n (0=No, 1=Yes)   
G1D Prescr med for pst/emot prob ever (0=No, 1=Yes)   
GH SF-36 general health perceptions (0-100)   
GOV_SUPP Received government support past 6 m (0=No, 1=Yes)   
GROUP Randomization Group (0=Control, 1=Clinic)   
H10_30 # days in last 30 bef detox used cannabis   
H10_LT # years regularly used cannabis   
H10_PRB Problem sub: marijuana, cannabis (0=No, 1=Yes)   
H10_RT Route of admin of cannabis (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H11_30 # days in last 30 bef detox used halluc   
H11_LT # years regularly used hallucinogens   
H11_PRB Problem sub: hallucinogens (0=No, 1=Yes)   
H11_RT Route of admin of hallucinogens (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H12_30 # days in last 30 bef detox used inhalant   
H12_LT # years regularly used inhalants   
H12_PRB Problem sub: inhalants (0=No, 1=Yes)   
H12_RT Route of admin of inhalants (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H13_30 # days used >1 sub/day-last 30 bef detox   
H13_LT # years regularly used >1 subst/day   
H13_RT Route of admin of >1 subst/day (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H14 According to interviewer, which substance is main problem (0=No problem, 1=Alcohol, 2=Alcohol to intox, 3=Heroin 4=Methadone, 5=Other opiate/analg, 6=Barbituates, 7=Sed/hyp/tranq, 8=Cocaine, 9=Amphetamines, 10=Marij/cannabis, 15=Alcohol and one or more drug, 16=More than one drug   
H15A # times had alcohol DTs   
H15B # times overdosed on drugs   
H16A $ spent on alcohol-last 30 days bef detox   
H16B $ spent on drugs-last 30 days bef detox   
H17A # days had alcohol prob-last 30 days bef det   
H17B # days had drug prob-last 30 days bef det   
H18A How troubled by alcohol probs-last 30 days (0=Not at all, 1=Slightly, 2=Moderately, 3=Considerably, 4=Extremely)   
H18B How troubled by drug probs-last 30 days (0=Not at all, 1=Slightly, 2=Moderately, 3=Considerably, 4=Extremely)   
H19A How import is treatment for alcohol problems now (0=Not at all, 1=Slightly, 2=Moderately, 3=Considerably, 4=Extremely)   
H19B How important is trtmnt for drug probs now (0=Not at all, 1=Slightly, 2=Moderately, 3=Considerably, 4=Extremely)   
H1_30 # days in past 30 bef detox used alcohol   
H1_LT # years regularly used alcohol   
H1_RT Route of administration use alcohol (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H2_30 #days in 3- bef detox use alcohol to intox   
H2_LT # years regularly used alcohol to intox   
H2_PRB Problem sub: alcohol to intox (0=No, 1=Yes)   
H2_RT Route of admin use alcohol to intox (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H3_30 # days in past 30 bef detox used heroin   
H3_LT # years regularly used heroin   
H3_PRB Problem sub: heroin (0=No, 1=Yes)   
H3_RT Route of administration of heroin (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H4_30 # days used methadone-last 30 bef detox   
H4_LT # years regularly used methadone   
H4_PRB Problem sub: methadone (0=No, 1=Yes)   
H4_RT Route of administration of methadone (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H5_30 # days used opiates/analg-last 30 bef detox   
H5_LT # years regularly used oth opiates/analg   
H5_PRB Problem sub: other opiates/analg (0=No, 1=Yes)   
H5_RT Route of admin of other opiates/analg (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H6_30 # days in past 30 before detox used barbiturates   
H6_LT # years regularly used barbiturates   
H6_PRB Problem sub: barbiturates (0=No, 1=Yes)   
H6_RT Route of admin of barbiturates (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H7_30 # days used sed/hyp/trnq-last 30 bef det   
H7_LT # years regularly used sed/hyp/trnq   
H7_PRB Problem sub: sedat/hyp/tranq (0=No, 1=Yes)   
H7_RT Route of admin of sed/hyp/trnq (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H8_30 # days in last 30 bef detox used cocaine   
H8_LT # years regularly used cocaine   
H8_PRB Problem sub: cocaine (0=No, 1=Yes)   
H8_RT Route of admin of cocaine (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
H9_30 # days in last 30 bef detox used amphet   
H9_LT # years regularly used amphetamines   
H9_PRB Problem sub: amphetamines (0=No, 1=Yes)   
H9_RT Route of admin of amphetamines (0=N/A. 1=Oral, 2=Nasal, 3=Smoking, 4=Non-IV injection, 5=IV)   
HOMELESS Homeless-shelter/street past 6 m (0=No, 1=Yes)   
HS_GRAD High school graduate (0=No, 1=Yes)   
HT Raw SF-36 health transition item   
I1 Avg # drinks in last 30 days bef detox   
I2 Most drank any 1 day in last 30 bef detox   
I3 On days used heroin, avg # bags used   
I4 Most bags heroin used any 1 day – 30 before det   
I5 Avg $ amt of heroin used per day   
I6A On days used cocaine, avg # bags used   
I6B On days used cocaine, avg # rocks used   
I7A Mst bgs cocaine use any 1 day-30 bef det   
I7B Mst rcks cocaine use any 1 day-30 bef det   
I8 Avg $ amt of cocaine used per day   
IMPUL2 Inventory of Drug Use Consequences InDUC-2L-Impulse control-Raw (w/0 M23)   
IMPUL Inventory of Drug Use Consequences InDUL-2L-Impulse control-Raw   
INDTOT2 InDUC-2L-Total drlnC-Raw- w/o M23 and M48   
INDTOT InDUC-2LTotal drlnC sore-Raw   
INTER InDUC-2L-Interpersonal-Raw   
INTRA InDUC-2L-Intrapersonal-Raw   
INT_TIME1 # of months from baseline to current interview   
INT_TIME2 # of months from previous to current interview   
J10A Get physically sick when stop using heroin (0=No, 1=Yes)   
J10B Ever use heroin to prevent getting sick (0=No, 1=Yes)   
J1 Evr don't stop using cocaine when should (0=No, 1=Yes)   
J2 Ever tried to cut down on cocaine (0=No, 1=Yes)   
J3 Does cocaine take up a lot of your time (0=No, 1=Yes)   
J4 Need use > cocaine to get some feeling (0=No, 1=Yes)   
J5A Get physically sick when stop using cocaine (0=No, 1=Yes)   
J5B Ever use cocaine to prevent getting sick (0=No, 1=Yes)   
J6 Ever don't stop using heroin when should (0=No, 1=Yes)   
J7 Ever tried to cut down on heroin (0=No, 1=Yes)   
J8 Does heroin take up a lot of your time (0=No, 1=Yes)   
J9 Need use > heroin to get some feeling (0=No, 1=Yes)   
JAIL_5YR Any jail time past 5 years y/n (0=No, 1=Yes)   
JAIL_MOS Total months in jail past 5 years  
K1 Do you currently smoke cigarettes (1=Yes-every day, 2=Yes-some days, 3=No-former smoker, 4=No-never>100 cigarettes   
K2 Avg # cigarettes smoked per day   
K3 Considering quitting cigarettes within next 6 months (0=No, 1=Yes)   
L10 Have had blkouts as result of drinkng (0=No, never, 1=Sometimes, 2=Often, 3=Alm evry time drink)   
L11 Do you carry bottle or keep close by (0=No, 1=Some of the time, 2=Most of the time)   
L12 After abstin end up drink heavily again (0=No, 1=Sometimes, 2=Almost evry time)   
L13 Passed out due to drinking-last 12 months (0=No, 1=Once, 2=More than once)   
L14 Had convuls following period of drinkng (0=No, 1=Once, 2=Several times)   
L15 Do you drink throughout the day (0=No, 1=Yes)   
L16 After drinkng heavily was thinkng unclear (0=No, 1=Yes, few hrs, 2=Yes,1-2 days, 3=Yes, many days)   
L17 D/t drinkng felt heart beat rapidly (0=No, 1=Once, 2=Several times)   
L18 Do you constntly think about drinkng/alcohol (0=No, 1=Yes)   
L19 D/t drinkng heard things not there (0=No, 1=Once, 2= Several times)   
L1 How often drink last time drank (1=To get high/less, 2=To get drunk, 3=To pass out)   
L20 Had weird/fright sensations when drinkng (0=No, 1=Once or twice, 2=Often)   
L21 When drinkng felt things rawl not there (0=No, 1=Once, 2=Several times)   
L22 With respect to blackouts (0=Never had one, 1=Had for <1hr, 2=Had several hrs, 3=Had for day/+)   
L23 Ever tried to cut down on drinking & failed (0=No, 1=Once, 2=Several times)   
L24 Do you gulp drinks (0=No, 1=Yes)   
L25 After taking 1 or 2 drinks can you stop (0=No, 1=Yes)   
L2 Often have hangovers Sun or Mon mornings (0=No, 1=Yes)   
L3 Have you had the shakes when sobering (0=No, 1=Sometimes, 2=Alm evry time drink)   
L4 Do you get physically sick as reslt of drinking (0=No, 1=Sometimes, 2=Alm evry time drink)   
L5 have you had the DTs (0=No, 1=Once, 2=Several times   
L6 When drink do you stumble/stagger/weave (0=No, 1=Sometimes, 2=Often)   
L7 D/t drinkng felt overly hot/sweaty (0=No, 1=Once, 2=Several times)   
L8 As result of drinkng saw thngs not there (0=No, 1=Once, 2=Several times)   
L9 Panic because fear not have drink if need it (0=No, 1=Yes)   
LINKSTATUS Linked to primary care within 12 months (by administrative record)   
M10 Using alcohol/1 drug caused > use othr drugs (0=No, 1=Yes)   
M11 I have been sick/vomited aft alcohol/drug use (0=No, 1=Yes)   
M12 I have been unhappy because of alcohol/drug use (0=No, 1=Yes)   
M13 Lost weight/eaten poorly due to alcohol/drug use (0=No, 1=Yes)   
M14 Fail to do what expected due to alcohol/drug use (0=No, 1=Yes)   
M15 Using alcohol/drugs has helped me to relax (0=No, 1=Yes)   
M16 Felt guilt/ashamed because of my alcohol drug use (0=No, 1=Yes)   
M17 Said/done emarras thngs when on alcohol/drug (0=No, 1=Yes)   
M18 Personality changed for worse on alcohol/drug (0=No, 1=Yes)   
M19 Taken foolish risk when using alcohol/drugs (0=No, 1=Yes)   
M1 Had hangover/felt bad aftr using alcohol/drugs (0=No, 1=Yes)   
M20 Gotten into trouble because of alcohol/drug use (0=No, 1=Yes)   
M21 Said cruel things while using alcohol/drugs (0=No, 1=Yes)   
M22 Done impuls thngs regret due to alcohol/drug use (0=No, 1=Yes)   
M23 Gotten in physical fights when use alcohol/drugs (0=No, 1=Yes)   
M24 My physical health was harmed by alcohol/drug use (0=No, 1=Yes)   
M25 Using alcohol/drug helped me have more + outlook (0=No, 1=Yes)   
M26 I have had money probs because of my alcohol/drug use (0=No, 1=Yes)   
M27 My love relat harmed due to my alcohol/drug use (0=No, 1=Yes)   
M28 Smoked tobacco more when using alcohol/drugs (0=No, 1=Yes)   
M29 My physical appearance harmed by alcohol/drug use (0=No, 1=Yes)   
M2 Felt bad about self because of alcohol/drug use (0=No, 1=Yes)   
M30 My family hurt because of my alcohol drug use (0=No, 1=Yes)   
M31 Close relationsp damaged due to alcohol/drug use (0=No, 1=Yes)   
M32 Spent time in jail because of my alcohol/drug use (0=No, 1=Yes)   
M33 My sex life suffered due to my alcohol/drug use (0=No, 1=Yes)   
M34 Lost interst in activity due to my alcohol/drug use (0=No, 1=Yes)   
M35 Soc life> enjoyable when using alcohol/drug (0=No, 1=Yes)   
M36 Spirit/moral life harmed by alcohol/drug use (0=No, 1=Yes)   
M37 Not had kind life want due to alcohol/drug use (0=No, 1=Yes)   
M38 My alcohol/drug use in way of personal growth (0=No, 1=Yes)   
M39 My alcohol/drug use damaged soc life/reputat (0=No, 1=Yes)   
M3 Missed days wrk/sch because of alcohol/drug use (0=No, 1=Yes)   
M40 Spent/lost too much $ because alcohol/drug use (0=No, 1=Yes)   
M41 Arrested for DUI of alcohol or oth drugs (0=No, 1=Yes)   
M42 Arrested for offenses rel to alcohol/drug use (0=No, 1=Yes)   
M43 Lost marriage/love relat due to alcohol/drug use (0=No, 1=Yes)   
M44 Susp/fired/left job/sch due to alcohol/drug use (0=No, 1=Yes)   
M45 I used drugs moderately w/o having probs (0=No, 1=Yes)   
M46 I have lost a friend due to my alcohol/drug use (0=No, 1=Yes)   
M47 Had an accident while using alcohol/drugs (0=No, 1=Yes)   
M48 Physically hurt/injured/burned when using alcohol/drugs (0=No, 1=Yes)   
M49 I injured someone while using alcohol/drugs (0=No, 1=Yes)   
M4 Fam/frinds worry/compl about alcohol/drug use (0=No, 1=Yes)   
M50 Damaged things/prop when using alcohol/drugs (0=No, 1=Yes)   
M5 I have enjoyed drinking/using drugs (0=No, 1=Yes)   
M6 Qual of work suffered because of alcohol/drug use (0=No, 1=Yes)   
M7 Parenting ability harmed by alcohol/drug use (0=No, 1=Yes)   
M8 Trouble sleeping/nightmares aftr alcohol/drugs (0=No, 1=Yes)   
M9 Driven motor veh while undr inf alcohol/drugs (0=No, 1=Yes)   
MAR_STAT Marital status (recode) (0=Married, 1=Not married)   
MCS Standardized mental component scale-00   
MD_LANG Lang prefer to speak to MD (recode) (0=English, 1=Other lang)   
MH SF-36 mental health index (0-100)   
MMSEC MMSEC   
N1A My friends give me the moral support I need (0=No, 1=Yes)   
N1B Most people closer to friends than I am (0=No, 1=Yes)   
N1C My friends enjoy hearing what I think (0=No, 1=Yes)   
N1D I rely on my friends for emot support (0=No, 1=Yes)   
N1E Friend go to when down w/o feel funny later (0=No, 1=Yes)   
N1F Frnds and I open re what thnk about things (0=No, 1=Yes)   
N1G My friends sensitive to my pers needs (0=No, 1=Yes)   
N1H My friends good at helping me solve probs (0=No, 1=Yes)   
N1I have deep sharing relat w/ a # of frnds (0=No, 1=Yes)   
N1J When confide in frnds makes me uncomfort (0=No, 1=Yes)   
N1K My friends seek me out for companionship (0=No, 1=Yes)   
N1L Not have as int relat w/frnds as others (0=No, 1=Yes)   
N1M Recent good idea how to do somethng frm frnd (0=No, 1=Yes)   
N1N I wish my friends were much different (0=No, 1=Yes)   
N2A My family gives me the moral support I need (0=No, 1=Yes)   
N2B Good ideas of how do/make thngs from fam (0=No, 1=Yes)   
N2C Most peop closer to their fam than I am (0=No, 1=Yes)   
N2D When confide make close fam membs uncomf (0=No, 1=Yes)   
N2E My fam enjoys hearing about what I think (0=No, 1=Yes)   
N2F Membs of my fam share many of my intrsts (0=No, 1=Yes)   
N2G I rely on my fam for emot support (0=No, 1=Yes)   
N2H Fam memb go to when down w/o feel funny (0=No, 1=Yes)   
N2I Fam and I open about what thnk about thngs (0=No, 1=Yes)   
N2J My fam is sensitive to my personal needs (0=No, 1=Yes)   
N2K Fam memb good at helping me solve probs (0=No, 1=Yes)   
N2L Have deep sharing relat w/# of fam membs (0=No, 1=Yes)   
N2M Makes me uncomf to confide in fam membs (0=No, 1=Yes)   
N2N I wish my family were much different (0=No, 1=Yes)   
NUM_BARR # of perceived barriers to linkage   
NUM_INTERVALS Number of 6-month intervals from previous to current interview   
O1A # people spend tx w/who drink alcohol (1=None, 2= A few, 3=About half, 4= Most, 5=All)   
O1B_REC Family/friends heavy drinkers y/n (0=No, 1=Yes)   
O1B # people spend tx w/who are heavy drinkrs (1=None, 2= A few, 3=About half, 4= Most, 5=All)   
O1C_REC Family/friends use drugs y/n (0=No, 1=Yes)   
O1C # people spend tx w/who use drugs (1=None, 2= A few, 3=About half, 4= Most, 5=All)   
O1D_REC Family/fiends support abst. y/n (0=No, 1=Yes)   
O1D # peop spend tx w/who supprt your abstin (1=None, 2= A few, 3=About half, 4= Most, 5=All)   
O2_REC Live-in partner drinks/drugs y/n (0=No, 1=Yes)   
O2 Does live-in part/spouse drink/use drugs (0=No, 1=Yes, 2=N/A)   
P1A Physical abuse/assault by family members/person I know (0=No, 1=Yes, 7=Not sure)   
P1B Age first physically assaulted by person I know   
P1C Physically assaulted by person I know-last 6 months (0=No, 1=Yes)   
P2A Physical abuse/assault by stranger (0=No, 1=Yes, 7=Not sure)   
P2B Age first physically assaulted by stranger   
P2C Physically assaulted by stranger-last 6 months (0=No, 1=Yes)   
P3 Using drugs/alcohol when physically assaulted (1=Don't know, 2=Never, 3=Some cases, 4=Most cases, 5=All cases, 9=Never assaulted)   
P4 Person who physically assaulted you was using alcohol/drugs (1=Don't know, 2=Never, 3=Some cases, 4=Most cases, 5=All cases, 9=Never assaulted)   
P5A Sexual abuse/assault by family member/person you know (0=No, 1= Yes, 7=Not sure)   
P5B Age first sexually assaulted by person you know   
P5C Sexually assaulted by person you know-last 6 months (0=No, 1=Yes)   
P6A Sexual abuse/assault by stranger (0=No, 1=Yes, 7=Not sure)   
P6B Age first sexually assaulted by stranger   
P6C Sexually assaulted by stranger-last 6 months (0=No, 1=Yes)   
P7 Using drugs/alcohol when sexually assaulted (1=Don't know, 2=Never, 3=Some cases, 4=Most cases, 5=All cases, 9=Never assaulted)   
P8 Person who sexually assaulted you using alcohol/drugs (1=Don't know, 2=Never, 3=Some cases, 4=Most cases, 5=All cases, 9=Never assaulted)   
PCP_ID a numeric vector   
PCS Standardized physical component scale-00   
PC_REC7 Primary cared received: Linked & # visits (0=Not linked, 1=Linked, 1 visit, 2=Linked, 2 visits, 3=Linked, 3 visits, 4=Linked, 4 visits, 5= Linked, 5 visits, 6=Linked, 6+visits)   
PC_REC Primary care received: Linked & # visits (0=Not linked, 1=Linked, 1 visit, 2=Linked, 2+ visits)   
PF SF-36 physical functioning (0-100)   
PHSXABUS Any abuse (0=No, 1=Yes)   
PHYABUSE Physical abuse-stranger or family (0=No, 1=Yes)   
PHYS2 InDUC-2L-Physical 9Raw (w/o M48)   
PHYS InDUC-2L-Physical-Raw   
POLYSUB Polysubstance abuser y/n (0=No, 1=Yes)   
PREV_TIME Previous interview time   
PRIMLANG First language (recode) (0=English, 1=Other lang)   
PRIMSUB2 First drug of choice (no marijuana) (0=None, 1=Alcohol, 2=Cocaine, 3=Heroin, 4=Barbituates, 5=Benzos, 6=Marijuana, 7=Methadone, 8=Opiates)   
PRIM_SUB First drug of choice (0=None, 1=Alcohol, 2=Cocaine, 3=Heroin, 4=Barbituates, 5=Benzos, 6=Marijuana, 7=Methadone, 8=Opiates)   
PSS_FA Perceived social support-family   
PSS_FR Perceived social support-friends   
Q10 How would you describe yourself (0=Straight, 1=Gay/bisexual)   
Q11 # men had sex w/in past 6 months (0=0 men, 1=1 man, 2=2-3 men, 3=4+ men   
Q12 # women had sex w/in past 6 months (0=0 women, 1=1woman, 2=2-3 women, 3=4+ women   
Q13 # times had sex In past 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q14 How often had sex to get drugs-last 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q15 How often given drugs to have sex-last 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q16 How often were you paid for sex-last 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q17 How often you pay pers for sex-last 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q18 How often use condoms during sex=last 6 months (0=No sex/always, 1=Most of the time, 2=Some of the time, 3=None of the time)   
Q19 Condoms are too much of a hassle to use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
Q1A Have you ever injected drugs (0=No, 1=Yes)   
Q1B Have you injected drugs-last 6 months (0=No, 1=Yes)   
Q20 Safer sex is always your responsibility (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
Q2 Have you shared needles/works-last 6 months (0=No/Not shot up, 3=Yes)   
Q3 # people shared needles w/past 6 months (0=No/Not shot up, 1=1 other person, 2=2-3 diff people, 3=4/+ diff people)   
Q4 How often been to shoot gall/hse-last 6 months (0=Never, 1=Few times or less, 2= Few times/month, 3= Once or more/week)   
Q5 How often been to crack house-last 6 months (0=Never, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q6 How often shared rinse-water-last 6 months (0=Nevr/Not shot up, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q7 How often shared a cooker-last 6 months (0=Nevr/Not shot up, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q8 How often shared a cotton-last 6 months (0=Nevr/Not shot up, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
Q9 How often use syringe to div drugs-last 6 months (0=Nevr/Not shot up, 1=Few times or less, 2=Few times/month, 3=Once or more/week)   
R1A I really want to change my alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1B Sometimes I wonder if I'm an alcohol/addict (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1C Id I don't change alcohol/drug probs will worsen (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1D I started making changes in alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1E Was using too much but managed to change (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1F I wonder if my alcohol/drug use hurting othrs (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1G I am a prob drinker or have drug prob (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1H Already doing thngs to change alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1I have changed use-trying to not slip back (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1J I have a serious problem w/ alcohol/drugs (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1K I wonder if I'm in control of alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1L My alcohol/drug use is causing a lot of harm (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1M Actively cutting down/stopping alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1N Want help to not go back to alcohol/drugs (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1O I know that I have an alcohol/drug problem (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1P I wonder if I use alcohol/drugs too much (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1Q I am an alcoholic or drug addict (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1R I am working hard to change alcohol/drug use (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
R1S Some changes-want help from going back (1=Strongly disagree, 2=Disagree, 3= Agree, 4=Strongly agree)   
RABSCALE RAB scale sore   
RACE2 Race (recode) (1=White, 2=Minority)   
RACE Race (recode) (1=Afr Amer/Black, 2=White, 3=Hispanic, 4=Other)   
RAWBP Raw SF-36 pain index   
RAWGH Raw SF-36 general health perceptions   
RAWMH Raw SF-36 mental health index   
RAWPF Raw SF-36 physical functioning   
RAWRE Raw SF-36 role-emotional   
RAWRP Raw SF-36 role-physical   
RAWSF Raw SF-36 social functioning   
RAWVT Raw SF-36 vitality   
RAW_ADS ADS score   
RAW_AM SOCRATES-Ambivalence-Raw   
RAW_RE SOCRATES-Recognition-Raw   
RAW_TS SOCRATES-Taking steps-Raw   
RCT_LINK Did subject link to primary care (RCT)–This time point (0=No, 1=Yes)   
REALM2 REALM score (dichotomous) (1=0-60, 2=61-66)   
REALM3 REALM score (categorical) (1=0-44), 2=45-60), 3=61-66)   
REALM REALM score   
REG_MD Did subject report having regular doctor–This time point (0=No, 1=Yes)   
RE SF-36 role-emotional (0-100)   
RP SF-36 role physical (0-100)   
S1A At interview pt obviously depressed/withdrawn (0=No, 1=Yes)   
S1B at interview pt obviously hostile (0=No, 1=Yes)   
S1C At interview patientt obviously anxious/nervous (0=No, 1=Yes)   
S1D Trouble with real tst/thght dis/par at interview (0=No, 1=Yes)   
S1E At interview pt trbl w/ compr/concen/rememb (0=No, 1=Yes)   
S1F At interview pt had suicidal thoughts (0=No, 1=Yes)   
SATREAT Any BSAS substance abuse this time point (0=No, 1=Yes)   
SECD_SUB Second drug of choice (0=None, 1=Alcohol, 3=Cocaine, 3=Heroine, 4=Barbituates, 5=Benzos, 6=Marijuana, 7=Methadone, 8=Opiates)   
SER_INJ Recent (6m) serious injury y/n (0=No, 1=Yes)   
SEXABUSE Sexual abuse-stranger or family (0=No, 1=Yes)   
SEXRISK RAB-Sex risk total   
SF SF-36 social functioning (0-100)   
SMOKER Current smoker (every/some days) y/n (0=No, 1=Yes)   
SR InDUC-2L-Social responsibility-Raw   
STD_6M Had an STD past 6m y/n (0=No, 1=Yes)   
STD_EVER Ever had an STD y/n (0=No, 1=Yes)   
STRABUSE Stranger abuse-physical or sexual (0=No, 1=Yes)   
T1B # days in row continued to drink   
T1C Longest period abstain-last 6 months (alcohol)   
T1 Have used alcohol since leaving River St. (0=No, 1=Yes)   
T2B # days in row continued to use heroin   
T2C Longest period abstain-last 6 months (heroin)   
T2 Have used heroin since leaving River St (0=No, 1=Yes)   
T3B # days in row continued to use cocaine   
T3C Longest period abstain-last 6 months (cocaine)   
T3 Have used cocaine since leaving River St (0=No, 1=Yes)   
TIME Interview time point   
TOTALRAB RAB-Total RAB sore   
U10A # times been to regular MDs office-pst 6 months   
U10B # times saw regular MD in office-pst 6 months   
U10C # times saw oth prof in office-pst 6 months   
U11 Rate convenience of MD office location (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U12 Rate hours MD office open for medical appointments (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U13 Usual wait for appointment when sick (unscheduled) (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U14 Time wait for appointment to start at MD office (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U15A DO you pay for any/all of MD visits (0=No, 1=Yes)   
U15B How rate amt of $ you pay for MD visits (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U16A Do you pay for any/all of prescript meds (0=No, 1=Yes)   
U16B Rate amt $ pay for meds/prescript trtmnts (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U17 Ever skip meds/trtmnts because too expensive (1=Yes, often, 2=Yes, occasionally, 3=No, never)   
U18A Ability to reach MC office by phone (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U18B Ability to speak to MD by phone if need (1=Very poor, 2=Poor, 3=Fair, 4=Good, 5=Very good, 6=Excellent)   
U19 How often see regular MD when have regular check-up (1=Always, 2=Almost always, 3=A lot of the time, 4=Some of the time, 5=Almost never, 6=Never)   
U1 It is important to have a regular MD (1=Strongly agree, 2=Agree, 3=Uncertain, 4=Disagree, 5=Strongly Disagree)   
U20 When sick + go to MD how often see regular MD (1=Always, 2=Almost always, 3=A lot of the time, 4=Some of the time, 5=Almost never, 6=Never)   
U21A How thorough MD exam to check health prb (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U21B How often question if MD diagnosis right (1=Always, 2=Almost always, 3=A lot of the time, 4=Some of the time, 5=Almost never, 6=Never)   
U22A Thoroughness of MD questions re symptoms (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U22B Attn MD gives to what you have to say (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U22C MD explanations of health problems/treatments need (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U22D MD instructions re symptom report/further care (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U22E MD advice in decisions about your care (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U23 How often leave MD office with unanswd quests (1=Always, 2=Almost always, 3=A lot of the time, 4=Some of the time, 5=Almost never, 6=Never)   
U24A Amount of time your MD spends with you (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U24B MDs patience w/ your questions/worries (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U24C MDs friendliness and warmth toward you (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U24D MDs caring and concern for you (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U24E MDs respect for you (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U25A Reg MD ever talked to you about smoking (0=No, 1=Yes)   
U25B Reg MD ever talked to you about alcohol use (0=No, 1=Yes)   
U25C Reg MD ever talk to you about seat belt use (0=No, 1=Yes)   
U25D Reg MD ever talked to you about diet (0=No, 1=Yes)   
U25E Reg Mdever talked to you about exercise (0=No, 1=Yes)   
U25F Reg MD ever talked to you about stress (0=No, 1=Yes)   
U25G Reg MD ever talked to you about safe sex (0=No, 1=Yes)   
U25H Reg MD ever talked to you about drug use (0=No, 1=Yes)   
U25I Reg MD ever talked to you about HIV testing (0=No, 1=Yes)   
U26A Cut/quit smoking because of MDs advice (0=No, 1=Yes)   
U26B Tried to drink less alcohol because of MD advice (0=No, 1=Yes)   
U26C Wore my seat belt more because of MDs advice (0=No, 1=Yes)   
U26D Changed diet because of MDs advice (0=No, 1=Yes)   
U26E Done more exercise because MDs advice (0=No, 1=Yes)   
U26F Relax/reduce stress because of MDs advice (0=No, 1=Yes)   
U26G Practiced safer sex because of MDs advice (0=No, 1=Yes)   
U26H Tried to cut down/quit drugs because MD advice (0=No, 1=Yes)""   
U26I Got HIV tested because of MDs advice (0=No, 1=Yes)""   
U27A I can tell my MD anything (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27B My MD pretends to know thngs if not sure (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27C I trust my MDs judgment re my med care (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27D My MD cares > about < costs than my health (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27E My MD always tell truth about my health (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27F My MD cares as much as I about my health (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U27G My MD would try to hide a mistake in trtmt (1=Strongly agree, 2= Agree, 3= Not sure, 4=Disagree, 5=Strongly disagree)""   
U28 How much to you trust this MD (0=Not at all, 1=1, 2=2, 3=3, 4=4, 5=5, 6=6, 7=7, 8=8, 9=9, 10=Completely)""   
U29A MDs knowledge of your entire med history (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)""   
U29B MD knowledge of your response-home/work/sch (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)""   
U29C MD knowledge of what worries you most-health (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)""   
U29D MDs knowledge of you as a person (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)""   
U2A I cannot pay for services (0=No, 1=Yes)   
U2B I am not eligible for free care (0=No, 1=Yes)   
U2C I do not know where to go (0=No, 1=Yes)   
U2D Can't get services due to transport probs (0=No, 1=Yes)   
U2E Office/clinic hours are inconvenient (0=No, 1=Yes)   
U2F I do not speak/understand English well (0=No, 1=Yes)   
U2G Afraid others discover health prb I have (0=No, 1=Yes)   
U2H My substance abuse interferes (0=No, 1=Yes)   
U2I I do not have a babysitter (0=No, 1=Yes)   
U2J I do not want to lose my job (0=No, 1=Yes)   
U2K My insurance does not cover services (0=No, 1=Yes)   
U2L Medical care is not important to me (0=No, 1=Yes)   
U2M I do not have time (0=No, 1=Yes)   
U2N Med staff do not treat me with respect (0=No, 1=Yes)   
U2O I do not trust my doctors or nurses (0=No, 1=Yes)   
U2P Often been unsatisfied w/my med care (0=No, 1=Yes)   
U2Q_T a factor with many levels   
U2Q Other reason hard to get regular med care (0=No, 1=Yes)   
U2R a factor with levels 7 A B C D E F G H I J K L M N O P Q    
U30 MD would know what want done if unconscious (1=Strongly agree, 2=Agree, 3=Not sure, 4= Disagree, 5=Strongly disagree)""   
U31 Oth MDs/RNs who play role in your care (0=No, 1=Yes)"" *   
U32A Their knowledge of you as a person (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U32B The quality of care they provide (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U32C Coordination between them and your regular MD (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U32D_T N/A, only my regular MD does this   
U32D Their explanation of your health prbs/trtmts need (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U33 Amt regular MD knows about care from others (1=Knows everything, 2=Knows almost everything, 3=Knows some things, 4=Knows very little, 5=Knows nothing)   
U34 Has MD ever recommended you see MD specialists (0=No, 1=Yes)   
U35A How helpful MD in deciding on specialist (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U35B How helpful MD getting appointment with specialist (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U35C MDs involvement when you trtd by specialist (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U35D MDs communication w/your specialists/oth MDs (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U35E MD help in explain what specialists said (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U35F Quality of specialists MD sent you to (1=Very poor, 2= Poor, 3=Fair, 4=Good, 5= Very good, 6= Excellent)   
U36 How many minutes to get to MDs office (1=<15, 2=16-30. 3=31-60, 4=More than 60)   
U37 When sick+call how long take to see you (1=Same day, 2=Next day, 3=In 2-3 days, 4=In 4-5 days, 5=in >5 days)   
U38 How many minutes late appointment usually begin (1=None, 2=<5 minutes, 3=6-10 minutes, 4=11-20 minutes, 5=21-30 minutes, 6=31-45 minutes, 7=>45 minutes)   
U39 How satisfied are you w/your regular MD (1=Completely satisfied, 2=Very satisfied, 3=Somewhat satisfied, 4=Neither, 5=Somewhat dissatisfied, 6=Very dissatisfied, 7=Completely dissatisfied)   
U3A Has MD evr talked to you about drug use (0=No, 1=Yes)   
U3B Has MD evr talked to you about alcohol use (0=No, 1=Yes)   
U4 Is there an MD you consider your regular MD (0=No, 1=Yes)   
U5 Have you seen any MDs in last 6 months (0=No, 1=Yes)   
U6A Would you go to this MD if med prb not emergency (0=No, 1=Yes)   
U6B Think one of these could be your regular MD (0=No, 1=Yes)   
U7A_T a factor with levels ARTHRITIS DOCTOR CHIROPRACTOR COCAINE STUDY DETOX DOCTOR DO EAR DOCTOR EAR SPECIALIST EAR, NOSE, & THROAT. EAR/NOSE/THROAT ENT FAMILY PHYSICIAN GENERAL MEDICINE GENERAL PRACTICE GENERAL PRACTITIONER GENERAL PRACTITIONER HEAD & NECK SPECIALIST HERBAL/HOMEOPATHIC/ACUPUNCTURE ID DOCTOR MAYBE GENERAL PRACTITIONER MEDICAL STUDENT NEUROLOGIST NURSE NURSE PRACTITIONER NURSE PRACTITIONER ONCOLOGIST PRENATAL PRIMARY PRIMARY CARE PRIMARY CARE PRIMARY CARE DOCTOR PRIMARY CARE THERAPIST UROLOGIST WOMENS CLINIC BMC    
U7A What type of MD is your regular MD/this MD (1=OB/GYN, 2=Family medicine, 3=Pediatrician, 4=Adolescent medicine, 5=Internal medicine, 6=AIDS doctor, 7=Asthma doctor, 8=Pulmonary doctor, 9=Cardiologist, 10=Gastroen)   
U8A Only saw this person once (=Only saw once)   
U8B Saw this person for < 6 months (1 = <6 months)   
U8C Saw this person for 6 months - 1 year (2=Between 6 months & 1 year)   
U8D Saw this person for 1-2 years (3 = 1-2 years)   
U8E Saw this person for 3-5 years (4 = 3-5 years)   
U8F Saw this person for more than 5 years (5 = >5 years)   
UNEMPLOY Usually unemployed last 6 months (0=No, 1=Yes)   
V1 Ever needed to drink much more to get effect (0=No, 1=Yes)   
V2 Evr find alcohol had < effect than once did (0=No, 1=Yes)   
VT SF-36 vitality 0-100)   
Z1 Breath Alcohol Concentration:1st test   
Z2 Breath Alcohol Concentration:2nd test      Details  
Eligible subjects were adults, who spoke Spanish or English, reported alcohol, heroin or cocaine as their first or second drug of choice, resided in proximity to the primary care clinic to which they would be referred or were homeless. Patients with established primary care relationships they planned to continue, significant dementia, specific plans to leave the Boston area that would prevent research participation, failure to provide contact information for tracking purposes, or pregnancy were excluded.   
Subjects were interviewed at baseline during their detoxification stay and follow-up interviews were undertaken every 6 months for 2 years. A variety of continuous, count, discrete, and survival time predictors and outcomes were collected at each of these five occasions.   
This dataset is a superset of the HELPmiss and HELPrct datasets which include far fewer variables. Full details of the survey instruments are available at the following link.    Source  
https://nhorton.people.amherst.edu/help/     References  
Samet JH, Larson MJ, Horton NJ, Doyle K, Winter M, and Saitz R. Linking alcohol and drug-dependent adults to primary medical care: A randomized controlled trial of a multi-disciplinary health intervention in a detoxification unit.  Addiction , 2003; 98(4):509-516.    See Also  
HELPrct , and HELPmiss .    Examples    data(HELPfull)"
"mosaicData-HELPmiss","mosaicData","HELPmiss","Health Evaluation and Linkage to Primary Care",470,28,8,0,9,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/HELPmiss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/HELPmiss.html","HELPmiss R Documentation   Health Evaluation and Linkage to Primary Care   Description  
The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.    Usage    data(HELPmiss)    Format  
Data frame with 470 observations on the following variables.   

age subject age at baseline (in years)   
anysub use of any substance post-detox: a factor with levels no yes    
cesd Center for Epidemiologic Studies Depression measure of depressive symptoms at baseline (higher scores indicate more symptoms)   
d1 lifetime number of hospitalizations for medical problems (measured at baseline)   
daysanysub time (in days) to first use of any substance post-detox   
dayslink time (in days) to linkage to primary care   
drugrisk Risk Assessment Battery drug risk scale at baseline   
e2b number of times in past 6 months entered a detox program (measured at baseline)   
female 0 for male, 1 for female   
sex a factor with levels male female    
g1b experienced serious thoughts of suicide in last 30 days (measured at baseline): a factor with levels no yes    
homeless housing status: a factor with levels housed homeless    
i1 average number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline)   
i2 maximum number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline)   
avg_drinks average number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline). Same as i1 .   
max_drinks maximum number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline). Same as i2 .   
id subject identifier   
indtot Inventory of Drug Use Consequences (InDUC) total score (measured at baseline)   
linkstatus post-detox linkage to primary care (0 = no, 1 = yes)   
link post-detox linkage to primary care: no yes    
mcs SF-36 Mental Component Score (measured at baseline, higher scores are better)   
pcs SF-36 Physical Component Score (measured at baseline, higher scores are better)   
pss_fr perceived social support by friends (measured at baseline)   
racegrp race/ethnicity: levels black hispanic other white    
satreat any BSAS substance abuse treatment at baseline: no yes    
sexrisk Risk Assessment Battery sex risk score (measured at baseline)   
substance primary substance of abuse: alcohol cocaine heroin    
treat randomized to HELP clinic: no yes       Details  
Eligible subjects were adults, who spoke Spanish or English, reported alcohol, heroin or cocaine as their first or second drug of choice, resided in proximity to the primary care clinic to which they would be referred or were homeless. Patients with established primary care relationships they planned to continue, significant dementia, specific plans to leave the Boston area that would prevent research participation, failure to provide contact information for tracking purposes, or pregnancy were excluded.   
Subjects were interviewed at baseline during their detoxification stay and follow-up interviews were undertaken every 6 months for 2 years. A variety of continuous, count, discrete, and survival time predictors and outcomes were collected at each of these five occasions.   
This dataset is a superset of the HELPrct data with 17 subjects with partially observed data on some of the baseline variables. This is a subset of the HELPfull data which includes 5 timepoints and many additional variables.    Source  
https://nhorton.people.amherst.edu/help/     References  
Samet JH, Larson MJ, Horton NJ, Doyle K, Winter M, and Saitz R. Linking alcohol and drug-dependent adults to primary medical care: A randomized controlled trial of a multi-disciplinary health intervention in a detoxification unit.  Addiction , 2003; 98(4):509-516.    See Also  
HELPrct , and HELPfull .    Examples    data(HELPmiss)"
"mosaicData-HELPrct","mosaicData","HELPrct","Health Evaluation and Linkage to Primary Care",453,30,10,0,9,0,21,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/HELPrct.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/HELPrct.html","HELPrct R Documentation   Health Evaluation and Linkage to Primary Care   Description  
The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care.    Usage    data(HELPrct)    Format  
Data frame with 453 observations on the following variables.   

age subject age at baseline (in years)   
anysub use of any substance post-detox: a factor with levels no yes    
cesd Center for Epidemiologic Studies Depression measure at baseline (high scores indicate more depressive symptoms)   
d1 lifetime number of hospitalizations for medical problems (measured at baseline)   
hospitalizations lifetime number of hospitalizations for medical problems (measured at baseline)   
daysanysub time (in days) to first use of any substance post-detox   
dayslink time (in days) to linkage to primary care   
drugrisk Risk Assessment Battery drug risk scale at baseline   
e2b number of times in past 6 months entered a detox program (measured at baseline)   
female 0 for male, 1 for female   
sex a factor with levels male female    
g1b experienced serious thoughts of suicide in last 30 days (measured at baseline): a factor with levels no yes    
homeless housing status: a factor with levels housed homeless    
i1 average number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline)   
i2 maximum number of drinks (standard units) consumed per day, in the past 30 days (measured at baseline)   
id subject identifier   
indtot Inventory of Drug Use Consequences (InDUC) total score (measured at baseline)   
linkstatus post-detox linkage to primary care (0 = no, 1 = yes)   
link post-detox linkage to primary care: no yes    
mcs SF-36 Mental Component Score (measured at baseline, lower scores indicate worse status)   
pcs SF-36 Physical Component Score (measured at baseline, lower scores indicate worse status)   
pss_fr perceived social support by friends (measured at baseline, higher scores indicate more support)   
racegrp race/ethnicity: levels black hispanic other white    
satreat any BSAS substance abuse treatment at baseline: no yes    
sexrisk Risk Assessment Battery sex risk score (measured at baseline)   
substance primary substance of abuse: alcohol cocaine heroin    
treat randomized to HELP clinic: no yes       Details  
Eligible subjects were adults, who spoke Spanish or English, reported alcohol, heroin or cocaine as their first or second drug of choice, resided in proximity to the primary care clinic to which they would be referred or were homeless. Patients with established primary care relationships they planned to continue, significant dementia, specific plans to leave the Boston area that would prevent research participation, failure to provide contact information for tracking purposes, or pregnancy were excluded.   
Subjects were interviewed at baseline during their detoxification stay and follow-up interviews were undertaken every 6 months for 2 years. A variety of continuous, count, discrete, and survival time predictors and outcomes were collected at each of these five occasions.   
This data set is a subset of the HELPmiss data set restricted to the 453 subjects who were fully observed on the  age , cesd , d1 ,  female , sex , g1b , homeless ,  i1 , i2 , indtot , mcs , pcs , pss_fr ,  racegrp , satreat , substance , treat , and sexrisk variables. (There is some missingness in the other variables.)  HELPmiss contains 17 additional subjects with partially observed data on some of these baseline variables. This is also a subset of the HELPfull data which includes 5 timepoints and many additional variables.    Note   The \code{HELPrct} data set was originally named \code{HELP} but has been renamed to avoid confusion with the \code{help} function.    Source  
https://nhorton.people.amherst.edu/help/     References  
Samet JH, Larson MJ, Horton NJ, Doyle K, Winter M, and Saitz R. Linking alcohol and drug-dependent adults to primary medical care: A randomized controlled trial of a multi-disciplinary health intervention in a detoxification unit.  Addiction , 2003; 98(4):509-516.    See Also  
HELPmiss , and HELPfull .    Examples    data(HELPrct)"
"mosaicData-KidsFeet","mosaicData","KidsFeet","Foot measurements in children",39,8,4,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/KidsFeet.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/KidsFeet.html","KidsFeet R Documentation   Foot measurements in children   Description  
These data were collected by a statistician, Mary C. Meyer, in a fourth grade classroom in Ann Arbor, MI, in October 1997. They are a convenience sample — the kids who were in the fourth grade.    Usage    data(KidsFeet)    Format  
A data frame with 39 observations on the following variables.   

name a factor with levels corresponding to the name of each child   
birthmonth the month of birth   
birthyear the year of birth   
length length of longer foot (in cm)   
width width of longer foot (in cm)   
sex a factor with levels B G    
biggerfoot a factor with levels L R    
domhand a factor with levels L R       Details  
Quoted from the source: ""From a very young age, shoes for boys tend to be wider than shoes for girls. Is this because boys have wider feet, or because it is assumed that girls, even in elementary school, are willing to sacrifice comfort for fashion? To assess the former, a statistician measures kids' feet.""    References  
Mary C. Meyer (2006) ""Wider Shoes for Wider Feet?""  Journal of Statistics Education 14(1),  http://jse.amstat.org/v14n1/datasets.meyer.html .    Examples    data(KidsFeet)"
"mosaicData-Marriage","mosaicData","Marriage","Marriage records",98,15,2,0,6,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Marriage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Marriage.html","Marriage R Documentation   Marriage records   Description  
Marriage records from the Mobile County, Alabama, probate court.    Usage    data(Marriage)    Format  
A data frame with 98 observations on the following variables.   

bookpageID a factor with levels for each book and page (unique identifier)   
appdate date on which the application was filed   
ceremonydate date of the ceremony   
delay number of days between the application and the ceremony   
officialTitle a factor with levels BISHOP CATHOLIC PRIEST CHIEF CLERK CIRCUIT JUDGE ELDER MARRIAGE OFFICIAL MINISTER PASTOR REVEREND    
person a factor with levels Bride Groom    
dob a factor with levels corresponding to the date of birth of the person   
age age of the person (in years)   
race a factor with levels American Indian Black Hispanic White    
prevcount the number of previous marriages of the person, as listed on the application   
prevconc the way the last marriage ended, as listed on the application   
hs the number of years of high school education, as listed on the application   
college the number of years College education, as listed on the application. Where no number was listed, this field was left blank, unless less than 12 years High School was reported, in which case it was entered as 0.   
dayOfBirth the day of birth, as a number from 1 to 365 counting from January 1   
sign the astrological sign, with levels Aquarius Aries Cancer Capricorn Gemini Leo Libra Pisces Sagittarius Scorpio Taurus Virgo       Details  
The calculation of the astrological sign may not correctly sort people directly on the borders between signs. This variable is not part of the original record.    Source  
The records were collected through http://www.mobilecounty.org/probatecourt/recordssearch.htm    Examples    data(Marriage)"
"mosaicData-Mites","mosaicData","Mites","Mites and Wilt Disease",47,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Mites.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Mites.html","Mites R Documentation   Mites and Wilt Disease   Description  
Data from an experiment to test whether exposure to mites protects against Wilt Disease in cotton plants.    Usage    data(Mites)    Format  
A data frame with 47 observations on the following variables.   

treatment a factor with levels mites and no mites    
outcome a factor with levels wilt and no wilt       Details  
Researchers suspected that attack of a plant by one organism induced resistance to subsequent attack by a different organism. Individually potted cotton plants were randomly allocated to two groups: infestation by spider mites or no infestation. After two weeks the mites were dutifully removed by a conscientious research assistant, and both groups were inoculated with Verticillium, a fungus that causes Wilt disease. More information can be found at https://www.causeweb.org/cause/webinar/activity/2010-01/ .    Source  
Statistics for the Life Sciences, Third Edition; Myra Samuels & Jeffrey Witmer (2003), page 409.    Examples    data(Mites) if (require(mosaic)) { tally(~ treatment + outcome, data=Mites) tally(~ outcome | treatment, format=""percent"", data=Mites) }"
"mosaicData-RailTrail","mosaicData","RailTrail","Volume of Users of a Rail Trail",90,11,5,1,0,1,9,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/RailTrail.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/RailTrail.html","RailTrail R Documentation   Volume of Users of a Rail Trail   Description  
The Pioneer Valley Planning Commission (PVPC) collected data north of Chestnut Street in Florence, MA for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.    Usage    data(RailTrail)    Format  
A data frame with 90 observations on the following variables.   

hightemp daily high temperature (in degrees Fahrenheit)   
lowtemp daily low temperature (in degrees Fahrenheit)   
avgtemp average of daily low and daily high temperature (in degrees Fahrenheit)   
spring indicator of whether the season was Spring   
summer indicator of whether the season was Summer   
fall indicator of whether the season was Fall   
cloudcover measure of cloud cover (in oktas)   
precip measure of precipitation (in inches)   
volume estimated number of trail users that day (number of breaks recorded)   
weekday logical indicator of whether the day was a non-holiday weekday   
dayType one of ""weekday"" or ""weekend""      Details  
There is a potential for error when two users trigger the infrared beam at exactly the same time since the counter would only logs one of the crossings. The collectors left the motion detector out during the winter, but because the counter drops data when the temperature falls below 14 degrees Fahrenheit, there is no data for the cold winter months.    Source  
Pioneer Valley Planning Commission    References  
http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf    Examples    data(RailTrail)"
"mosaicData-Riders","mosaicData","Riders","Volume of Users of a Massachusetts Rail Trail",90,12,2,0,3,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Riders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Riders.html","Riders R Documentation   Volume of Users of a Massachusetts Rail Trail   Description  
The Pioneer Valley Planning Commission (PVPC) collected data north of Chestnut Street in Florence, MA for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.    Usage    data(Riders)    Format  
A data frame with 90 observations on the following 12 variables.    date
date of data collection (POSIXct)   day
a factor with levels Monday , Tuesday , Wednesday ,  Thursday , Friday , Saturday , and Sunday .   highT
high temperature for the day (in degrees Fahrenheit)   lowT
low temperature for the day (in degrees Fahrenheit)   hi
shorter name for highT   lo
shorter name for lowT   precip
inches of precipitation   clouds
measure of cloud cover (in oktas)   riders
estimated number of trail crossings that day (number of breaks recorded)   ct
shorter name for riders   weekday
type of day: a factor with levels N (weekend or holiday)  Y (non-holiday weekday)   wday
shorter name for weekday     Details  
There is a potential for error when two users trigger the infrared beam at exactly the same time since the counter would only logs one of the crossings. The collectors left the motion detector out during the winter, but because the counter drops data when the temperature falls below 14 degrees Fahrenheit, there are no data for the coldest winter months.    Source  
Pioneer Valley Planning Commission, http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf    References  
""Rail trails and property values: Is there an association?"", Nicholas J. Horton and Ella Hartenian (Journal of Statistics Education, 2015), http://www.amstat.org/publications/jse/v23n2/horton.pdf    Examples    data(Riders) str(Riders)"
"mosaicData-SaratogaHouses","mosaicData","SaratogaHouses","Houses in Saratoga County (2006)",1728,16,3,0,6,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SaratogaHouses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SaratogaHouses.html","SaratogaHouses R Documentation   Houses in Saratoga County (2006)   Description  
Data on houses in Saratoga County, New York, USA in 2006    Usage    data(SaratogaHouses)    Format  
A data frame with 1728 observations on the following 16 variables.   

price price (US dollars)   
lotSize size of lot (acres)   
age age of house (years)   
landValue value of land (US dollars)   
livingArea living are (square feet)   
pctCollege percent of neighborhood that graduated college   
bedrooms number of bedrooms   
firplaces number of fireplaces   
bathrooms number of bathrooms (half bathrooms have no shower or tub)   
rooms number of rooms   
heating type of heating system   
fuel fuel used for heating   
sewer type of sewer system   
waterfront whether property includes waterfront   
newConstruction whether the property is a new construction   
centralAir whether the house has central air      Source  
Data collected by Candice Corvetti and used in the ""Stat 101"" case study ""How much is a Fireplace Worth"". See also  https://www.saratogacountyny.gov/departments/real-property-tax-service-agency/"
"mosaicData-SAT","mosaicData","SAT","State by State SAT data",50,8,0,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SAT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SAT.html","SAT R Documentation   State by State SAT data   Description  
SAT data assembled for a statistics education journal article on the link between SAT scores and measures of educational expenditures    Usage    data(SAT)    Format  
A data frame with 50 observations on the following variables.   

state a factor with names of each state   
expend expenditure per pupil in average daily attendance in public elementary and secondary schools, 1994-95 (in thousands of US dollars)   
ratio average pupil/teacher ratio in public elementary and secondary schools, Fall 1994   
salary estimated average annual salary of teachers in public elementary and secondary schools, 1994-95 (in thousands of US dollars)   
frac percentage of all eligible students taking the SAT, 1994-95   
verbal average verbal SAT score, 1994-95   
math average math SAT score, 1994-95   
sat average total SAT score, 1994-95      Source  
http://www.amstat.org/publications/jse/secure/v7n2/datasets.guber.cfm    References  
Deborah Lynn Guber, ""Getting what you pay for: the debate over equity in public school expenditures"" (1999), Journal of Statistics Education 7(2).    Examples    data(SAT) if (require(ggformula)) { gf_point(sat ~ expend, data = SAT, color = ""blue"", alpha = 0.5) %>% gf_lm() gf_text(sat ~ expend, data = SAT, label = ~ abbreviate(SAT$state, 3), inherit = FALSE) }"
"mosaicData-SnowGR","mosaicData","SnowGR","Snowfall data for Grand Rapids, MI",119,15,0,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SnowGR.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SnowGR.html","SnowGR R Documentation   Snowfall data for Grand Rapids, MI   Description  
Official snowfall data by month and season for Grand Rapids, MI, going back to 1893.    Usage    data(SnowGR)    Format  
A data frame with 119 observations of the following variables.   

SeasonStart Year in which season started (July is start of season)   
SeasonEnd Year in which season ended (June is end of season)   
Jul Inches of snow in July   
Aug Inches of snow in August   
Sep Inches of snow in September   
Oct Inches of snow in October   
Nov Inches of snow in November   
Dec Inches of snow in December   
Jan Inches of snow in January   
Feb Inches of snow in February   
Mar Inches of snow in March   
Apr Inches of snow in April   
May Inches of snow in May   
Jun Inches of snow in June   
Total Inches of snow for entire season (July-June)      Source  
These data were compiled by Laura Kapitula from data available from NOAA. The original URL used (http://www.crh.noaa.gov/grr/climate/data/grr/snowfall/) is no longer in service.    Examples    data(SnowGR) if (require(ggformula)) { df_stats(~ Total, data = SnowGR) gf_histogram( ~ Total, data = SnowGR) gf_point(Total ~ SeasonStart, data = SnowGR) %>% gf_smooth() if (require(tidyr) && require(dplyr)) { Snow2 <- SnowGR %>% pivot_longer(Jul:Total, names_to = ""month"", values_to = ""snowfall"") %>% filter(month != ""Total"") %>% mutate(month = factor(month, levels = unique(month))) gf_violin(snowfall ~ month, data = Snow2, scale = ""width"") } }"
"mosaicData-SwimRecords","mosaicData","SwimRecords","100 m Swimming World Records",62,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SwimRecords.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/SwimRecords.html","SwimRecords R Documentation   100 m Swimming World Records   Description  
World records for men and women over time from 1905 through 2004.    Usage    data(SwimRecords)    Format  
A data frame with 62 observations of the following variables.   

time time (in seconds) of the world record   
year Year in which the record was set   
sex a factor with levels M and F       Examples    data(SwimRecords) if (require(ggformula)) { gf_point(time ~ year, data = SwimRecords, color = ~ sex) }"
"mosaicData-TenMileRace","mosaicData","TenMileRace","Cherry Blossom Race",8636,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/TenMileRace.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/TenMileRace.html","TenMileRace R Documentation   Cherry Blossom Race   Description  
The Cherry Blossom 10 Mile Run is a road race held in Washington, D.C. in April each year. (The name comes from the famous cherry trees that are in bloom in April in Washington.) The results of this race are published. This data frame contains the results from the 2005 race.    Usage    data(TenMileRace)    Format  
A data frame with 8636 observations on the following variables.   

state State of residence of runner.   
time Official time from starting gun to finish line.   
net The recorded time (in seconds) from when the runner crossed the starting line to when the runner crossed the finish line. This is generally less than the official time because of the large number of runners in the race: it takes time to reach the starting line after the gun has gone off.   
age Age of runner in years.   
sex A factor with levels F M .      Examples    data(TenMileRace) if (require(ggformula)) { gf_point(net ~ age | sex, data = TenMileRace, color = ~sex, alpha = 0.1) %>% gf_density2d(color = ""gray40"") lm(net ~ age + sex, data = TenMileRace) }"
"mosaicData-Utilities","mosaicData","Utilities","Utility bills",117,12,0,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Utilities.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Utilities.html","Utilities R Documentation   Utility bills   Description  
Data from utility bills at a residence.  Utilities2 is a similar data set with some additional variables.    Usage    data(Utilities)    Format  
A data frame containing 117 observations for the following variables.   

month month (coded as a number)   
day day of month on which bill was calculated   
year year of bill   
temp average temperature (F) for billing period   
kwh electricity usage (kwh)   
ccf gas usage (ccf)   
thermsPerDay a numeric vector   
billingDays number of billing days in billing period   
totalbill total bill (in dollars)   
gasbill gas bill (in dollars)   
elecbill electric bill (in dollars)   
notes notes about the billing period      Source  
Daniel T. Kaplan, Statistical modeling: A fresh approach , 2009.    See Also  
Utilities2 .    Examples    data(Utilities) if (require(ggformula)) { gf_point(gasbill ~ temp, data = Utilities) }"
"mosaicData-Utilities2","mosaicData","Utilities2","Utility bills",117,19,0,0,1,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Utilities2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Utilities2.html","Utilities2 R Documentation   Utility bills   Description  
Data from utility bills at a private residence. This is an augmented version of Utilities .    Usage    data(Utilities2)    Format  
A data frame containing 117 observations for the following variables.   

month month (coded as a number)   
day day of month on which bill was calculated   
year year of bill   
temp average temperature (F) for billing period   
kwh electricity usage (kwh)   
ccf gas usage (ccf)   
thermsPerDay a numeric vector   
billingDays number of billing days in billing period   
totalbill total bill (in dollars)   
gasbill gas bill (in dollars)   
elecbill electric bill (in dollars)   
notes notes about the billing period   
ccfpday average gas usage per day ( Utilities2 only)   
kwhpday average electric usage per day ( Utilities2 only)   
gasbillpday gas bill divided by billing days ( Utilities2 only)   
elecbillpday electric bill divided by billing days a numeric vector ( Utilities2 only)   
totalbillpday total bill divided by billing days a numeric vector ( Utilities2 only)   
therms thermsPerDay * billingDays ( Utilities2 only)   
monthsSinceY2K months since 2000 ( Utilities2 only)      Source  
Daniel T. Kaplan, Statistical modeling: A fresh approach , 2009.    See Also  
Utilities .    Examples    data(Utilities2) if (require(ggformula)) { gf_point(gasbillpday ~ temp, data = Utilities2) }"
"mosaicData-Weather","mosaicData","Weather","Weather",3655,25,1,3,0,0,21,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Weather.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Weather.html","Weather R Documentation   Weather   Description  
2016-17 weather in several cities    Usage    data(Weather)    Format  
A data frame with weather-related variables for several world cities.    city
City name.   date
Date.   year
Numeric year.   month
Numeric month.   day
Numeric day.   high_temp, avg_temp, low_temp
High, average, and low temperature for the day in degrees F.   high_dewpt, avg_dewpt, low_dewpt
High, average, and low dew point for the day in degrees F.   high_humidity, avg_humidity, low_humidity
High, average, and low relative humidity.   high_hg, avg_hg, low_hg
High, average, and low sea level pressure in inches of mercury.   high_vis, avg_vis, low_vis
High, average, and low visability for the day in miles.   high_wind, avg_wind, low_wind
High, average, and low wind speed for the day in mph.   precip
Precipitation for the day – a character vale; T means ""trace amount"".   events
Character string naming weather events on the day (Rain, Fog, Snow, etc.)     Source  
These data were downloaded from WeatherUnderground in January 2018.    Examples    if (require(dplyr)) { Weather %>% group_by(city, year) %>% summarise( min_temp = min(low_temp), max_temp = max(high_temp) ) } if (require(ggformula)) { Weather %>% gf_linerange(low_temp + high_temp ~ date | city ~ ., color = ~ (high_temp + low_temp) / 2, show.legend = FALSE) %>% gf_refine(scale_color_gradientn(colors = rev(rainbow(5)))) }"
"mosaicData-Whickham","mosaicData","Whickham","Data from the Whickham survey",1314,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/Whickham.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mosaicData/Whickham.html","Whickham R Documentation   Data from the Whickham survey   Description  
Data on age, smoking, and mortality from a one-in-six survey of the electoral roll in Whickham, a mixed urban and rural district near Newcastle upon Tyne, in the UK. The survey was conducted in 1972-1974 to study heart disease and thyroid disease. A follow-up on those in the survey was conducted twenty years later.    Usage    data(Whickham)    Format  
A data frame with 1314 observations on women for the following variables.   

outcome survival status after 20 years: a factor with levels Alive Dead    
smoker smoking status at baseline: a factor with levels No Yes    
age age (in years) at the time of the first survey      Details  
This dataset contains a subset of the survey sample: women who were classified as current smokers or as never having smoked. The data were synthesized from the summary description tables given in the Appleton et al al paper.    References  
DR Appleton, JM French, MPJ Vanderpump. ""Ignoring a covariate: an example of Simpson's paradox"". (1996)  American Statistician , 50(4):340-341.    Examples    data(Whickham)"
"mstate-aidssi","mstate","aidssi","Data from the Amsterdam Cohort Studies on HIV infection and AIDS",329,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/aidssi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/aidssi.html","aidssi R Documentation   Data from the Amsterdam Cohort Studies on HIV infection and AIDS   Description  
These data sets give the times (in years) from HIV infection to AIDS, SI switch and death in 329 men who have sex with men (MSM). Data are from the period until combination anti-retroviral therapy became available (1996). For more background information on the cohort, ccr5 and SI, see Geskus  et al. (2000, 2003)    Format  
aidssi  
patnr: Patient identification number
 time: Time from HIV infection to first of SI appearance and AIDS, or last follow-up
status: Event indicator; 0 = censored, 1 = AIDS, 2 = SI appearance
cause: Failure cause; factor with levels ""event-free"", ""AIDS"", ""SI""
ccr5: CCR5 genotype; factor with levels ""WW"" (wild type allele on both chromosomes),
""WM"" (mutant allele on one chromosome)
 
aidssi2  
patnr: Patient identification number
entry.time: Time from HIV infection to cohort entry. Value is zero if HIV infection occurred while in follow-up.
aids.time: Time from HIV infection to AIDS, or last follow-up if AIDS was not observed
 aids.stat: Event indicator with respect to AIDS, with values 0 (censored) and 1 (AIDS)
si.time: Time from HIV infection to SI switch, or last follow-up if SI switch was not observed
si.stat:  Event indicator with respect to SI switch, with values 0 (no switch) and 1 (switch)
death.time: Time from HIV infection to death, or last follow-up if death was not observed
death.stat: Event indicator with respect to death; 0 = alive, 1 = dead
age.inf: Age at HIV infection
ccr5: CCR5 genotype; factor with levels ""WW"" (wild type allele on both chromosomes),
""WM"" (mutant allele on one chromosome)
  Details  
aidssi contains follow-up data until the first of AIDS and SI switch. It was used as example for the competing risks analyses in Putter, Fiocco, Geskus (2007) and in Geskus (2016).   
aidssi2 extends the aidssi data set in three ways. First, it considers events after the initial one. Second, it includes the entry times of the individuals that entered the study after HIV infection. Third, age at HIV infection has been added as extra covariable. Numbers differ slightly from the aidssi data set. Some individuals were diagnosed with AIDS only when they died and others had their last follow-up at AIDS diagnosis. In order to prevent two transitions to happen at the same time, their time to AIDS was shortened by 0.25 years. This data set was used as example for the multi-state analyses in Geskus (2016).    Source  
Geskus RB (2000). On the inclusion of prevalent cases in HIV/AIDS natural history studies through a marker-based estimate of time since seroconversion. Statistics in Medicine 19 , 1753–1769.   
Geskus RB, Miedema FA, Goudsmit J, Reiss P, Schuitemaker H, Coutinho RA (2003). Prediction of residual time to AIDS and death based on markers and cofactors. Journal of AIDS 32 , 514–521.    References  
Geskus, Ronald B. (2016). Data Analysis with Competing Risks and Intermediate States. CRC Press, Boca Raton.   
Putter H, Fiocco M, Geskus RB (2007). Tutorial in biostatistics: Competing risks and multi-state models. Statistics in Medicine 26 , 2389–2430."
"mstate-aidssi2","mstate","aidssi2","Data from the Amsterdam Cohort Studies on HIV infection and AIDS",329,10,4,0,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/aidssi2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/aidssi2.html","aidssi R Documentation   Data from the Amsterdam Cohort Studies on HIV infection and AIDS   Description  
These data sets give the times (in years) from HIV infection to AIDS, SI switch and death in 329 men who have sex with men (MSM). Data are from the period until combination anti-retroviral therapy became available (1996). For more background information on the cohort, ccr5 and SI, see Geskus  et al. (2000, 2003)    Format  
aidssi  
patnr: Patient identification number
 time: Time from HIV infection to first of SI appearance and AIDS, or last follow-up
status: Event indicator; 0 = censored, 1 = AIDS, 2 = SI appearance
cause: Failure cause; factor with levels ""event-free"", ""AIDS"", ""SI""
ccr5: CCR5 genotype; factor with levels ""WW"" (wild type allele on both chromosomes),
""WM"" (mutant allele on one chromosome)
 
aidssi2  
patnr: Patient identification number
entry.time: Time from HIV infection to cohort entry. Value is zero if HIV infection occurred while in follow-up.
aids.time: Time from HIV infection to AIDS, or last follow-up if AIDS was not observed
 aids.stat: Event indicator with respect to AIDS, with values 0 (censored) and 1 (AIDS)
si.time: Time from HIV infection to SI switch, or last follow-up if SI switch was not observed
si.stat:  Event indicator with respect to SI switch, with values 0 (no switch) and 1 (switch)
death.time: Time from HIV infection to death, or last follow-up if death was not observed
death.stat: Event indicator with respect to death; 0 = alive, 1 = dead
age.inf: Age at HIV infection
ccr5: CCR5 genotype; factor with levels ""WW"" (wild type allele on both chromosomes),
""WM"" (mutant allele on one chromosome)
  Details  
aidssi contains follow-up data until the first of AIDS and SI switch. It was used as example for the competing risks analyses in Putter, Fiocco, Geskus (2007) and in Geskus (2016).   
aidssi2 extends the aidssi data set in three ways. First, it considers events after the initial one. Second, it includes the entry times of the individuals that entered the study after HIV infection. Third, age at HIV infection has been added as extra covariable. Numbers differ slightly from the aidssi data set. Some individuals were diagnosed with AIDS only when they died and others had their last follow-up at AIDS diagnosis. In order to prevent two transitions to happen at the same time, their time to AIDS was shortened by 0.25 years. This data set was used as example for the multi-state analyses in Geskus (2016).    Source  
Geskus RB (2000). On the inclusion of prevalent cases in HIV/AIDS natural history studies through a marker-based estimate of time since seroconversion. Statistics in Medicine 19 , 1753–1769.   
Geskus RB, Miedema FA, Goudsmit J, Reiss P, Schuitemaker H, Coutinho RA (2003). Prediction of residual time to AIDS and death based on markers and cofactors. Journal of AIDS 32 , 514–521.    References  
Geskus, Ronald B. (2016). Data Analysis with Competing Risks and Intermediate States. CRC Press, Boca Raton.   
Putter H, Fiocco M, Geskus RB (2007). Tutorial in biostatistics: Competing risks and multi-state models. Statistics in Medicine 26 , 2389–2430."
"mstate-bmt","mstate","bmt","BMT data from Klein and Moeschberger",137,22,12,0,0,0,22,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/bmt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/bmt.html","bmt R Documentation   BMT data from Klein and Moeschberger   Description  
A data frame of 137 rows (patients) and 22 columns. The included variables are   group
Disease group; 1 = ALL, 2 = AML Low Risk, 3 = AML High Risk   t1
Time in days to death or last follow-up   t2
Disease-free survival time in days (time to relapse, death or last follow-up)   d1
Death indicator; 1 = dead, 0 = alive   d2
Relapse indicator; 1 = relapsed, 0 = disease-free   d3  
Disease-free survival indicator; 1 = dead or relapsed, 0 = alive and disease-free)   ta
Time in days to Acute Graft-versus-Host Disease (AGVHD)   da
Acute GVHD indicator; 1 = Acute GVHD, 0 = No Acute GVHD    tc
Time (days) to Chronic Graft-vrsus-Host Disease (CGVHD)   dc
Chronic GVHD indicator; 1 = Chronic GVHD, 0 = No Chronic GVHD   tp
Time (days) to platelet recovery   dp
Platelet recovery indicator; 1 = platelets returned to normal, 0 = platelets never returned to normal   z1
Patient age in years   z2
Donor age in years   z3
Patient sex; 1 = male, 0 = female   z4
Donor sex; 1 = male, 0 = female   z5
Patient CMV status; 1 = CMV positive, 0 = CMV negative   z6
Donor CMV status; 1 = CMV positive, 0 = CMV negative   z7
Waiting time to transplant in days   z8
FAB; 1 = FAB grade 4 or 5 and AML, 0 = Otherwise   z9
Hospital; 1 = The Ohio State University, 2 = Alferd , 3 = St. Vincent, 4 = Hahnemann   z10  
MTX used as a Graft-versus-Host prophylactic; 1 = yes, 0 = no     Format  
A data frame, see data.frame .    References  
Klein and Moeschberger (1997). Survival Analysis Techniques for Censored and Truncated Data , Springer, New York."
"mstate-ebmt1","mstate","ebmt1","Data from the European Society for Blood and Marrow Transplantation (EBMT)",1977,8,2,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/ebmt1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/ebmt1.html","EBMT year of relapse data R Documentation   Data from the European Society for Blood and Marrow Transplantation (EBMT)   Description  
A data frame of 1977 patients transplanted for CML. The included variables are   patid
Patient identification number   srv
Time in days from transplantation to death or last follow-up   srvstat
Survival status; 1 = death; 0 = censored   rel
Time in days from transplantation to relapse or last follow-up   relstat
Relapse status; 1 = relapsed; 0 = censored   yrel
Calendar year of relapse; factor with levels ""1993-1996"","" 1997-1999"", ""2000-""   age
Patient age at transplant (years)   score
Gratwohl score; factor with levels ""Low risk"", ""Medium risk"", ""High risk""     Format  
A data frame, see data.frame .    Source  
We acknowledge the European Society for Blood and Marrow Transplantation (EBMT) for making available these data. Disclaimer: these data were simplified for the purpose of illustration of the analysis of competing risks and multi-state models and do not reflect any real life situation. No clinical conclusions should be drawn from these data."
"mstate-ebmt2","mstate","ebmt2","Data from the European Society for Blood and Marrow Transplantation (EBMT)",8966,9,1,0,6,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/ebmt2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/ebmt2.html","EBMT cause of death data R Documentation   Data from the European Society for Blood and Marrow Transplantation (EBMT)   Description  
A data frame of 8966 patients transplanted at the EBMT. The included variables are   id
Patient identification number   time
Time in months from transplantation to death or last follow-up   status
Survival status; 0 = censored; 1,...,6 = death due to the following causes: Relapse (1), GvHD (2), Bacterial infections (3), Viral infections (4), Fungal infections (5), Other causes (6)   cod
Cause of death as factor with levels ""Alive"", ""Relapse"", ""GvHD"", ""Bacterial"", ""Viral"", ""Fungal"", ""Other""   dissub
Disease subclassification; factor with levels ""AML"", ""ALL"", ""CML""   match
Donor-recipient gender match; factor with levels ""No gender mismatch"", ""Gender mismatch""   tcd
T-cell depletion; factor with levels ""No TCD"", ""TCD"", ""Unknown""   year
Year of transplantation; factor with levels ""1985-1989"", ""1990-1994"", ""1995-1998""   age
Patient age at transplant; factor with levels ""<=20"", ""20-40"", "">40""     Format  
A data frame, see data.frame .    Source  
We acknowledge the European Society for Blood and Marrow Transplantation (EBMT) for making available these data. Disclaimer: these data were simplified for the purpose of illustration of the analysis of competing risks and multi-state models and do not reflect any real life situation. No clinical conclusions should be drawn from these data.    References  
Fiocco M, Putter H, van Houwelingen JC (2005). Reduced rank proportional hazards model for competing risks. Biostatistics   6 , 465–478."
"mstate-ebmt3","mstate","ebmt3","Data from the European Society for Blood and Marrow Transplantation (EBMT)",2204,9,4,0,4,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/ebmt3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/ebmt3.html","EBMT platelet recovery data R Documentation   Data from the European Society for Blood and Marrow Transplantation (EBMT)   Description  
A data frame of 2204 patients transplanted at the EBMT between 1995 and 1998. These data were used in Section 4 of the tutorial on competing risks and multi-state models (Putter, Fiocco & Geskus, 2007). The included variables are   id
Patient identification number   prtime
Time in days from transplantation to platelet recovery or last follow-up   prstat
Platelet recovery status; 1 = platelet recovery, 0 = censored   rfstime
Time in days from transplantation to relapse or death or last follow-up (relapse-free survival time)   rfsstat
Relapse-free survival status; 1 = relapsed or dead, 0 = censored   dissub
Disease subclassification; factor with levels ""AML"", ""ALL"", ""CML""   age
Patient age at transplant; factor with levels ""<=20"", ""20-40"", "">40""   drmatch
Donor-recipient gender match; factor with levels ""No gender mismatch"", ""Gender mismatch""   tcd
T-cell depletion; factor with levels ""No TCD"", ""TCD""     Format  
A data frame, see data.frame .    Source  
We acknowledge the European Society for Blood and Marrow Transplantation (EBMT) for making available these data. Disclaimer: these data were simplified for the purpose of illustration of the analysis of competing risks and multi-state models and do not reflect any real life situation. No clinical conclusions should be drawn from these data.    References  
Putter H, Fiocco M, Geskus RB (2007). Tutorial in biostatistics: Competing risks and multi-state models. Statistics in Medicine   26 , 2389–2430."
"mstate-ebmt4","mstate","ebmt4","Data from the European Society for Blood and Marrow Transplantation (EBMT)",2279,15,7,0,4,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/ebmt4.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/ebmt4.html","EBMT data R Documentation   Data from the European Society for Blood and Marrow Transplantation (EBMT)   Description  
A data frame of 2279 patients transplanted at the EBMT between 1985 and 1998. These data were used in Fiocco, Putter & van Houwelingen (2008), van Houwelingen & Putter (2008, 2012) and de Wreede, Fiocco & Putter (2011). The included variables are   id
Patient identification number   rec
Time in days from transplantation to recovery or last follow-up   rec.s
Recovery status; 1 = recovery, 0 = censored   ae
Time in days from transplantation to adverse event (AE) or last follow-up   ae.s
Adverse event status; 1 = adverse event, 0 = censored   recae
Time in days from transplantation to both recovery and AE or last follow-up   recae.s
Recovery and AE status; 1 = both recovery and AE, 0 = no recovery or no AE or censored   rel
Time in days from transplantation to relapse or last follow-up   rel.s
Relapse status; 1 = relapse, 0 = censored   srv
Time in days from transplantation to death or last follow-up   srv.s
Relapse status; 1 = dead, 0 = censored   year
Year of transplantation; factor with levels ""1985-1989"", ""1990-1994"", ""1995-1998""   agecl
Patient age at transplant; factor with levels ""<=20"", ""20-40"", "">40""   proph
Prophylaxis; factor with levels ""no"", ""yes""   match
Donor-recipient gender match; factor with levels ""no gender mismatch"", ""gender mismatch""     Format  
A data frame, see data.frame .    Source  
We acknowledge the European Society for Blood and Marrow Transplantation (EBMT) for making available these data. Disclaimer: these data were simplified for the purpose of illustration of the analysis of competing risks and multi-state models and do not reflect any real life situation. No clinical conclusions should be drawn from these data.    References  
Fiocco M, Putter H, van Houwelingen HC (2008). Reduced-rank proportional hazards regression and simulation-based prediction for multi-state models. Statistics in Medicine 27 , 4340–4358.   
van Houwelingen HC, Putter H (2008). Dynamic predicting by landmarking as an alternative for multi-state modeling: an application to acute lymphoid leukemia data. Lifetime Data Anal 14 , 447–463.   
van Houwelingen HC, Putter H (2012). Dynamic Prediction in Clinical Survival Analaysis. Chapman & Hall/CRC Press, Boca Raton.   
de Wreede LC, Fiocco M, and Putter H (2011). mstate: An R Package for the Analysis of Competing Risks and Multi-State Models. Journal of Statistical Software , Volume 38, Issue 7."
"mstate-prothr","mstate","prothr","Abnormal prothrombin levels in liver cirrhosis",2152,8,3,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/mstate/prothr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/mstate/prothr.html","Liver cirrhosis data R Documentation   Abnormal prothrombin levels in liver cirrhosis   Description  
A data frame of 488 liver cirrhosis patients from a randomized clinical trial concerning prednisone treatment in these patients. The dataset is in long format. The included variables are   id
Patient identification number   from
Starting state   to
Receiving state   trans
Transition number   Tstart
Starting time   Tstop
Transition time   status
Status variable; 1=transition, 0=censored   treat
Treatment; factor with levels ""Placebo"", ""Prednisone""     Format  
A data frame, see data.frame .    Details  
This data was kindly provided by Per Kragh Andersen. It was introduced in Andersen, Borgan, Gill & Keiding (1993), Example 1.3.12, and used as illustration for computation of transition probabilities in multi-state models, see Sections IV.4 (Example IV.4.4) and VII.2 (Example VII.2.10).    References  
Andersen PK, Borgan O, Gill RD, Keiding N (1993).  Statistical Models Based on Counting Processes . Springer, New York."
"multgee-arthritis","multgee","arthritis","Rheumatoid Arthritis Clinical Trial",906,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/multgee/arthritis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/multgee/arthritis.html","arthritis R Documentation   Rheumatoid Arthritis Clinical Trial   Description  
Rheumatoid self-assessment scores for 302 patients, measured on a five-level ordinal response scale at three follow-up times.    Usage    arthritis    Format  
A data frame with 906 observations on the following 7 variables:    id
Patient identifier variable.   y
Self-assessment score of rheumatoid arthritis measured on a five-level ordinal response scale.   sex
Coded as (1) for female and (2) for male.   age
Recorded at the baseline.   trt
Treatment group variable, coded as (1) for the placebo group and (2) for the drug group.   baseline
Self-assessment score of rheumatoid arthritis at the baseline.   time
Follow-up time recorded in months.     Source  
Lipsitz, S.R. and Kim, K. and Zhao, L. (1994) Analysis of repeated categorical data using generalized estimating equations. Statistics in Medicine , 13 , 1149–1163.    Examples    data(arthritis) str(arthritis)"
"multgee-housing","multgee","housing","Homeless Data",1448,4,1,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/multgee/housing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/multgee/housing.html","housing R Documentation   Homeless Data   Description  
Housing status for 362 severely mentally ill homeless subjects measured at baseline and at three follow-up times.    Usage    housing    Format  
A data frame with 1448 observations on the following 4 variables:    id
Subject identifier variable.   y
Housing status response, coded as (1) for street living, (2) for community living and (3) for independent housing.   time
Time recorded in months.   sec
Section 8 rent certificate indicator.     Source  
Hulrburt M.S., Wood, P.A. and Hough, R.L. (1996) Providing independent housing for the homeless mentally ill: a novel approach to evaluating longitudinal housing patterns. Journal of Community Psychology , 24 , 291–310.    Examples    data(housing) str(housing)"
"nycflights13-airlines","nycflights13","airlines","Airline names.",16,2,0,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airlines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/nycflights13/airlines.html","airlines R Documentation   Airline names.   Description  
Look up airline names from their carrier codes.    Usage    airlines    Format  
Data frame with columns    carrier
Two letter abbreviation.   name
Full name.     Source  
https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236     Examples    airlines"
"nycflights13-airports","nycflights13","airports","Airport metadata",1458,8,0,4,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/airports.csv","https://vincentarelbundock.github.io/Rdatasets/doc/nycflights13/airports.html","airports R Documentation   Airport metadata   Description  
Useful metadata about airports.    Usage    airports    Format  
A data frame with columns:    faa
FAA airport code.   name
Usual name of the aiport.   lat, lon
Location of airport.   alt
Altitude, in feet.   tz
Timezone offset from GMT.   dst
Daylight savings time zone. A = Standard US DST: starts on the second Sunday of March, ends on the first Sunday of November. U = unknown. N = no dst.   tzone
IANA time zone, as determined by GeoNames webservice.     Source  
https://openflights.org/data.html , downloaded 2014-06-27    Examples    airports if (require(""dplyr"")) { airports %>% rename(dest = faa) %>% semi_join(flights) flights %>% anti_join(airports %>% rename(dest = faa)) airports %>% rename(origin = faa) %>% semi_join(flights) }"
"nycflights13-flights","nycflights13","flights","Flights data",336776,19,0,4,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/flights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/nycflights13/flights.html","flights R Documentation   Flights data   Description  
On-time data for all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013.    Usage    flights    Format  
Data frame with columns    year, month, day
Date of departure.   dep_time, arr_time
Actual departure and arrival times (format HHMM or HMM), local tz.   sched_dep_time, sched_arr_time
Scheduled departure and arrival times (format HHMM or HMM), local tz.   dep_delay, arr_delay
Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.   carrier
Two letter carrier abbreviation. See airlines  to get name.   flight
Flight number.   tailnum
Plane tail number. See planes for additional metadata.   origin, dest
Origin and destination. See airports for additional metadata.   air_time
Amount of time spent in the air, in minutes.   distance
Distance between airports, in miles.   hour, minute
Time of scheduled departure broken into hour and minutes.   time_hour
Scheduled date and hour of the flight as a POSIXct date. Along with origin , can be used to join flights data to weather data.     Source  
RITA, Bureau of transportation statistics,  https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236"
"nycflights13-planes","nycflights13","planes","Plane metadata.",3322,9,0,5,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/planes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/nycflights13/planes.html","planes R Documentation   Plane metadata.   Description  
Plane metadata for all plane tailnumbers found in the FAA aircraft registry. American Airways (AA) and Envoy Air (MQ) report fleet numbers rather than tail numbers so can't be matched.    Usage    planes    Format  
A data frame with columns:    tailnum
Tail number.   year
Year manufactured.   type
Type of plane.   manufacturer, model
Manufacturer and model.   engines, seats
Number of engines and seats.   speed
Average cruising speed in mph.   engine
Type of engine.     Source  
FAA Aircraft registry,  https://www.faa.gov/licenses_certificates/aircraft_certification/aircraft_registry/releasable_aircraft_download/     Examples    planes if (require(""dplyr"")) { # Flights that don't have plane metadata flights %>% anti_join(planes, ""tailnum"") }"
"nycflights13-weather","nycflights13","weather","Hourly weather data",26115,15,0,1,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/nycflights13/weather.csv","https://vincentarelbundock.github.io/Rdatasets/doc/nycflights13/weather.html","weather R Documentation   Hourly weather data   Description  
Hourly meterological data for LGA, JFK and EWR.    Usage    weather    Format  
A data frame with columns:    origin
Weather station. Named origin to facilitate merging with  flights data.   year, month, day, hour
Time of recording.   temp, dewp
Temperature and dewpoint in F.   humid
Relative humidity.   wind_dir, wind_speed, wind_gust
Wind direction (in degrees), speed and gust speed (in mph).   precip
Precipitation, in inches.   pressure
Sea level pressure in millibars.   visib
Visibility in miles.   time_hour
Date and hour of the recording as a POSIXct date.     Source  
ASOS download from Iowa Environmental Mesonet,  https://mesonet.agron.iastate.edu/request/download.phtml ."
"openintro-absenteeism","openintro","absenteeism","Absenteeism from school in New South Wales",146,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/absenteeism.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/absenteeism.html","absenteeism R Documentation   Absenteeism from school in New South Wales   Description  
Researchers interested in the relationship between absenteeism from school and certain demographic characteristics of children collected data from 146 randomly sampled students in rural New South Wales, Australia, in a particular school year.    Usage    absenteeism    Format  
A data frame with 146 observations on the following 5 variables.    eth
Ethnicity, representing Aboriginal ( A ) or not ( N ).   sex
Gender.   age
Age bucket.   lrn
Learner status, with average learner ( AL ) and slow learner ( SL ).   days
Number of days absent.     Source  
Venables WN, Ripley BD. 2002. Modern Applied Statistics with S. Fourth Edition. New York: Springer.   
Data can also be found in the R MASS package under the data set name  quine .    Examples    library(ggplot2) ggplot(absenteeism, aes(x = eth, y = days)) + geom_boxplot() + coord_flip()"
"openintro-acs12","openintro","acs12","American Community Survey, 2012",2000,13,5,0,9,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/acs12.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/acs12.html","acs12 R Documentation   American Community Survey, 2012   Description  
Results from the US Census American Community Survey, 2012.    Usage    acs12    Format  
A data frame with 2000 observations on the following 13 variables.    income
Annual income.   employment
Employment status.   hrs_work
Hours worked per week.   race
Race.   age
Age, in years.   gender
Gender.   citizen
Whether the person is a U.S. citizen.   time_to_work
Travel time to work, in minutes.   lang
Language spoken at home.   married
Whether the person is married.   edu
Education level.   disability
Whether the person is disabled.   birth_qrtr
The quarter of the year that the person was born, e.g. Jan thru Mar .     Source  
https://www.census.gov/programs-surveys/acs     Examples    library(dplyr) library(ggplot2) library(broom) # employed only acs12_emp <- acs12 %>% filter( age >= 30, age <= 60, employment == ""employed"", income > 0 ) # linear model ggplot(acs12_emp, mapping = aes(x = age, y = income)) + geom_point() + geom_smooth(method = ""lm"") lm(income ~ age, data = acs12_emp) %>% tidy() # log-transormed model ggplot(acs12_emp, mapping = aes(x = age, y = log(income))) + geom_point() + geom_smooth(method = ""lm"") lm(log(income) ~ age, data = acs12_emp) %>% tidy()"
"openintro-age_at_mar","openintro","age_at_mar","Age at first marriage of 5,534 US women.",5534,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/age_at_mar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/age_at_mar.html","age_at_mar R Documentation   Age at first marriage of 5,534 US women.   Description  
Age at first marriage of 5,534 US women who responded to the National Survey of Family Growth (NSFG) conducted by the CDC in the 2006 and 2010 cycle.    Usage    age_at_mar    Format  
A data frame with 5,534 observations and 1 variable.    age
Age a first marriage.     Source  
National Survey of Family Growth, 2006-2010 cycle,  https://www.cdc.gov/nchs/nsfg/nsfg_2006_2010_puf.htm .    Examples    library(ggplot2) ggplot(age_at_mar, mapping = aes(x = age)) + geom_histogram(binwidth = 3) + labs(x = ""Age"", y = ""Count"", title = ""Age at first marriage, US Women"", subtitle = ""Source: National Survey of Family Growth Survey, 2006 - 2010"")"
"openintro-ames","openintro","ames","Housing prices in Ames, Iowa",2930,82,3,0,43,0,39,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ames.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ames.html","ames R Documentation   Housing prices in Ames, Iowa   Description  
Data set contains information from the Ames Assessor's Office used in computing assessed values for individual residential properties sold in Ames, IA from 2006 to 2010. See here  for detailed variable descriptions.    Usage    ames    Format  
A tbl_df with with 2930 rows and 82 variables:    Order
Observation number.   PID
Parcel identification number - can be used with city web site for parcel review.   area
Above grade (ground) living area square feet.   price
Sale price in USD.   MS.SubClass
Identifies the type of dwelling involved in the sale.   MS.Zoning
Identifies the general zoning classification of the sale.   Lot.Frontage
Linear feet of street connected to property.   Lot.Area
Lot size in square feet.   Street
Type of road access to property.   Alley
Type of alley access to property.   Lot.Shape
General shape of property.   Land.Contour
Flatness of the property.   Utilities
Type of utilities available.   Lot.Config
Lot configuration.   Land.Slope
Slope of property.   Neighborhood
Physical locations within Ames city limits (map available).   Condition.1
Proximity to various conditions.   Condition.2
Proximity to various conditions (if more than one is present).   Bldg.Type
Type of dwelling.   House.Style
Style of dwelling.   Overall.Qual
Rates the overall material and finish of the house.   Overall.Cond
Rates the overall condition of the house.   Year.Built
Original construction date.   Year.Remod.Add
Remodel date (same as construction date if no remodeling or additions).   Roof.Style
Type of roof.   Roof.Matl
Roof material.   Exterior.1st
Exterior covering on house.   Exterior.2nd
Exterior covering on house (if more than one material).   Mas.Vnr.Type
Masonry veneer type.   Mas.Vnr.Area
Masonry veneer area in square feet.   Exter.Qual
Evaluates the quality of the material on the exterior.   Exter.Cond
Evaluates the present condition of the material on the exterior.   Foundation
Type of foundation.   Bsmt.Qual
Evaluates the height of the basement.   Bsmt.Cond
Evaluates the general condition of the basement.   Bsmt.Exposure
Refers to walkout or garden level walls.   BsmtFin.Type.1
Rating of basement finished area.   BsmtFin.SF.1
Type 1 finished square feet.   BsmtFin.Type.2
Rating of basement finished area (if multiple types).   BsmtFin.SF.2
Type 2 finished square feet.   Bsmt.Unf.SF
Unfinished square feet of basement area.   Total.Bsmt.SF
Total square feet of basement area.   Heating
Type of heating.   Heating.QC
Heating quality and condition.   Central.Air
Central air conditioning.   Electrical
Electrical system.   X1st.Flr.SF
First Floor square feet.   X2nd.Flr.SF
Second floor square feet.   Low.Qual.Fin.SF
Low quality finished square feet (all floors).   Bsmt.Full.Bath
Basement full bathrooms.   Bsmt.Half.Bath
Basement half bathrooms.   Full.Bath
Full bathrooms above grade.   Half.Bath
Half baths above grade.   Bedroom.AbvGr
Bedrooms above grade (does NOT include basement bedrooms).   Kitchen.AbvGr
Kitchens above grade.   Kitchen.Qual
Kitchen quality.   TotRms.AbvGrd
Total rooms above grade (does not include bathrooms).   Functional
Home functionality (Assume typical unless deductions are warranted).   Fireplaces
Number of fireplaces.   Fireplace.Qu
Fireplace quality.   Garage.Type
Garage location.   Garage.Yr.Blt
Year garage was built.   Garage.Finish
Interior finish of the garage.   Garage.Cars
Size of garage in car capacity.   Garage.Area
Size of garage in square feet.   Garage.Qual
Garage quality.   Garage.Cond
Garage condition.   Paved.Drive
Paved driveway.   Wood.Deck.SF
Wood deck area in square feet.   Open.Porch.SF
Open porch area in square feet.   Enclosed.Porch
Enclosed porch area in square feet.   X3Ssn.Porch
Three season porch area in square feet.   Screen.Porch
Screen porch area in square feet.   Pool.Area
Pool area in square feet.   Pool.QC
Pool quality.   Fence
Fence quality.   Misc.Feature
Miscellaneous feature not covered in other categories.   Misc.Val
Dollar value of miscellaneous feature.   Mo.Sold
Month Sold (MM).   Yr.Sold
Year Sold (YYYY).   Sale.Type
Type of sale.   Sale.Condition
Condition of sale.     Source  
De Cock, Dean. ""Ames, Iowa: Alternative to the Boston housing data as an end of semester regression project."" Journal of Statistics Education 19.3 (2011)."
"openintro-ami_occurrences","openintro","ami_occurrences","Acute Myocardial Infarction (Heart Attack) Events",365,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ami_occurrences.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ami_occurrences.html","ami_occurrences R Documentation   Acute Myocardial Infarction (Heart Attack) Events   Description  
This data set is simulated but contains realistic occurrences of AMI in NY City.    Usage    ami_occurrences    Format  
A data frame with 365 observations on the following variable.    ami
Number of daily occurrences of heart attacks in NY City.     Examples    library(ggplot2) ggplot(ami_occurrences, mapping = aes(x = ami)) + geom_bar() + labs(x = ""Acute Myocardial Infarction events"", y = ""Count"", title = ""Acute Myocardial Infarction events in NYC"")"
"openintro-antibiotics","openintro","antibiotics","Pre-existing conditions in 92 children",92,1,0,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/antibiotics.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/antibiotics.html","antibiotics R Documentation   Pre-existing conditions in 92 children   Description  
Pre-existing medical conditions of 92 children involved in a study on the optimal duration of antibiotic use in treatment of tracheitis, which is an upper respiratory infection.    Usage    antibiotics    Format  
A data frame with 92 observations, each representing a child, on the following variable.    condition
Pre-existing medical condition.     Examples    library(ggplot2) ggplot(antibiotics, aes(x = condition)) + geom_bar() + labs(x = ""Conidition"", y = ""Count"", title = ""Pre-existing coniditions of children"", subtitle = ""in antibiotic use study"") + coord_flip()"
"openintro-arbuthnot","openintro","arbuthnot","Male and female births in London",82,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/arbuthnot.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/arbuthnot.html","arbuthnot R Documentation   Male and female births in London   Description  
Arbuthnot's data describes male and female christenings (births) for London from 1629-1710.    Usage    arbuthnot    Format  
A tbl_df with with 82 rows and 3 variables:    year
year, ranging from 1629 to 1710   boys
number of male christenings (births)   girls
number of female christenings (births)     Details  
John Arbuthnot (1710) used these time series data to carry out the first known significance test. During every one of the 82 years, there were more male christenings than female christenings. As Arbuthnot wondered, we might also wonder if this could be due to chance, or whether it meant the birth ratio was not actually 1:1.    Source  
These data are excerpted from the Arbuthnot data set in the  HistData package.    Examples    library(ggplot2) library(tidyr) # All births ggplot(arbuthnot, aes(x = year, y = boys + girls, group = 1)) + geom_line() # Boys and girls arbuthnot %>% pivot_longer(cols = -year, names_to = ""sex"", values_to = ""n"") %>% ggplot(aes(x = year, y = n, color = sex, group = sex)) + geom_line()"
"openintro-ask","openintro","ask","How important is it to ask pointed questions?",219,3,1,3,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ask.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ask.html","ask R Documentation   How important is it to ask pointed questions?   Description  
In this experiment, each individual was asked to be a seller of an iPod (a product commonly used to store music on before smart phones...). They participant received $10 + 5% of the sale price for participating. The iPod they were selling had frozen twice in the past inexplicably but otherwise worked fine. The prospective buyer starts off and then asks one of three final questions, depending on the seller's treatment group.    Usage    ask    Format  
A data frame with 219 observations on the following 3 variables.    question_class
The type of question:  general , pos_assumption , and neg_assumption .   question
The question corresponding to the  question.class   response
The classified response from the seller, either disclose or hide .     Details  
The three possible questions:   

General: What can you tell me about it?   
Positive Assumption: It doesn't have any problems, does it?   
Negative Assumption: What problems does it have?     
The outcome variable is whether or not the participant discloses or hides the problem with the iPod.    Source  
Minson JA, Ruedy NE, Schweitzer ME. There is such a thing as a stupid question: Question disclosure in strategic communication.    Examples    library(dplyr) library(ggplot2) # Distribution of responses based on question type ask %>% count(question_class, response) # Visualize relative frequencies of responses based on question type ggplot(ask, aes(x = question_class, fill = response)) + geom_bar(position = ""fill"") # Perform chi-square test (test <- chisq.test(table(ask$question_class, ask$response))) # Check the test's assumption around sufficient expected observations # per table cell. test$expected"
"openintro-association","openintro","association","Simulated data for association plots",121,15,0,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/association.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/association.html","association R Documentation   Simulated data for association plots   Description  
Simulated data set.    Usage    association    Format  
A data frame with 121 observations on the following 4 variables.    x1
a numeric vector   x2
a numeric vector   x3
a numeric vector   y1
a numeric vector   y2
a numeric vector   y3
a numeric vector   y4
a numeric vector   y5
a numeric vector   y6
a numeric vector   y7
a numeric vector   y8
a numeric vector   y9
a numeric vector   y10
a numeric vector   y11
a numeric vector   y12
a numeric vector     Examples    library(ggplot2) ggplot(association, aes(x = x1, y = y1)) + geom_point() ggplot(association, aes(x = x2, y = y4)) + geom_point() ggplot(association, aes(x = x3, y = y7)) + geom_point()"
"openintro-assortive_mating","openintro","assortive_mating","Eye color of couples",204,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/assortive_mating.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/assortive_mating.html","assortive_mating R Documentation   Eye color of couples   Description  
Colors of the eye colors of male and female partners.    Usage    assortive_mating    Format  
A data frame with 204 observations on the following 2 variables.    self_male
a factor with levels blue , brown , and green   partner_female
a factor with blue , brown , and green     Source  
B. Laeng et al. Why do blue-eyed men prefer women with the same eye color? In: Behavioral Ecology and Sociobiology 61.3 (2007), pp. 371-384.    Examples    data(assortive_mating) table(assortive_mating)"
"openintro-avandia","openintro","avandia","Cardiovascular problems for two types of Diabetes medicines",227571,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/avandia.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/avandia.html","avandia R Documentation   Cardiovascular problems for two types of Diabetes medicines   Description  
A comparison of cardiovascular problems for Rosiglitazone and Pioglitazone.    Usage    avandia    Format  
A data frame with 227571 observations on the following 2 variables.    treatment
a factor with levels Pioglitazone and  Rosiglitazone   cardiovascular_problems
a factor with levels no and  yes     Source  
D.J. Graham et al. Risk of acute myocardial infarction, stroke, heart failure, and death in elderly Medicare patients treated with rosiglitazone or pioglitazone. In: JAMA 304.4 (2010), p. 411. issn: 0098-7484.    Examples    table(avandia)"
"openintro-babies","openintro","babies","The Child Health and Development Studies",1236,8,2,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/babies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/babies.html","babies R Documentation   The Child Health and Development Studies   Description  
The Child Health and Development Studies investigate a range of topics. One study, in particular, considered all pregnancies between 1960 and 1967 among women in the Kaiser Foundation Health Plan in the San Francisco East Bay area. We do not have ideal provenance for these data. For a better documented and more recent dataset on a similar topic with similar variables, see births14. Additionally, Gestation dataset in the  mosaicData  package also contains similar data.    Usage    babies    Format  
A data frame with 1236 rows and 8 variables:    case
id number   bwt
birthweight, in ounces   gestation
length of gestation, in days   parity
binary indicator for a first pregnancy (0 = first pregnancy)   age
mother's age in years   height
mother's height in inches   weight
mother's weight in pounds   smoke
binary indicator for whether the mother smokes     Source  
These data come from Child Health and Development Studies."
"openintro-babies_crawl","openintro","babies_crawl","Crawling age",12,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/babies_crawl.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/babies_crawl.html","babies_crawl R Documentation   Crawling age   Description  
Crawling age of babies along with the average outdoor temperature at 6 months of age.    Usage    babies_crawl    Format  
A data frame with 12 observations on the following 5 variables.    birth_month
A factor with levels corresponding to months   avg_crawling_age
a numeric vector   sd
a numeric vector   n
a numeric vector   temperature
a numeric vector     Source  
J.B. Benson. Season of birth and onset of locomotion: Theoretical and methodological implications. In: Infant behavior and development 16.1 (1993), pp. 69-81. issn: 0163-6383.    Examples    library(ggplot2) ggplot(babies_crawl, aes(x = temperature, y = avg_crawling_age)) + geom_point() + labs(x = ""Temperature"", y = ""Average crawling age"")"
"openintro-bac","openintro","bac","Beer and blood alcohol content",16,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/bac.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/bac.html","bac R Documentation   Beer and blood alcohol content   Description  
Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer.    Usage    bac    Format  
A data frame with 16 observations on the following 3 variables.    student
a numeric vector   beers
a numeric vector   bac
a numeric vector     Source  
J. Malkevitch and L.M. Lesser. For All Practical Purposes: Mathematical Literacy in Today's World. WH Freeman & Co, 2008.    Examples    library(ggplot2) ggplot(bac, aes(x = beers, y = bac)) + geom_point() + labs(x = ""Number of beers"", y = ""Blood alcohol content"")"
"openintro-ball_bearing","openintro","ball_bearing","Lifespan of ball bearings",75,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ball_bearing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ball_bearing.html","ball_bearing R Documentation   Lifespan of ball bearings   Description  
A simulated data set on lifespan of ball bearings.    Usage    ball_bearing    Format  
A data frame with 75 observations on the following variable.    life_span
Lifespan of ball bearings (in hours).     Source  
Simulated data.    Examples    library(ggplot2) ggplot(ball_bearing, aes(x = life_span)) + geom_histogram(binwidth = 1) qqnorm(ball_bearing$life_span)"
"openintro-bdims","openintro","bdims","Body measurements of 507 physically active individuals.",507,25,1,0,0,0,25,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/bdims.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/bdims.html","bdims R Documentation   Body measurements of 507 physically active individuals.   Description  
Body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender, are given for 507 physically active individuals - 247 men and 260 women. These data can be used to provide statistics students practice in the art of data analysis. Such analyses range from simple descriptive displays to more complicated multivariate analyses such as multiple regression and discriminant analysis.    Usage    bdims    Format  
A data frame with 507 observations on the following 25 variables.    bia_di
A numerical vector, respondent's biacromial diameter in centimeters.   bii_di
A numerical vector, respondent's biiliac diameter (pelvic breadth) in centimeters.   bit_di
A numerical vector, respondent's bitrochanteric diameter in centimeters.   che_de
A numerical vector, respondent's chest depth in centimeters, measured between spine and sternum at nipple level, mid-expiration.   che_di
A numerical vector, respondent's chest diameter in centimeters, measured at nipple level, mid-expiration.   elb_di
A numerical vector, respondent's elbow diameter in centimeters, measured as sum of two elbows.   wri_di
A numerical vector, respondent's wrist diameter in centimeters, measured as sum of two wrists.   kne_di
A numerical vector, respondent's knee diameter in centimeters, measured as sum of two knees.   ank_di
A numerical vector, respondent's ankle diameter in centimeters, measured as sum of two ankles.   sho_gi
A numerical vector, respondent's shoulder girth in centimeters, measured over deltoid muscles.   che_gi
A numerical vector, respondent's chest girth in centimeters, measured at nipple line in males and just above breast tissue in females, mid-expiration.   wai_gi
A numerical vector, respondent's waist girth in centimeters, measured at the narrowest part of torso below the rib cage as average of contracted and relaxed position.   nav_gi
A numerical vector, respondent's navel (abdominal) girth in centimeters, measured at umbilicus and iliac crest using iliac crest as a landmark.   hip_gi
A numerical vector, respondent's hip girth in centimeters, measured at at level of bitrochanteric diameter.   thi_gi
A numerical vector, respondent's thigh girth in centimeters, measured below gluteal fold as the average of right and left girths.   bic_gi
A numerical vector, respondent's bicep girth in centimeters, measured when flexed as the average of right and left girths.   for_gi
A numerical vector, respondent's forearm girth in centimeters, measured when extended, palm up as the average of right and left girths.   kne_gi
A numerical vector, respondent's knee diameter in centimeters, measured as sum of two knees.   cal_gi
A numerical vector, respondent's calf maximum girth in centimeters, measured as average of right and left girths.   ank_gi
A numerical vector, respondent's ankle minimum girth in centimeters, measured as average of right and left girths.   wri_gi
A numerical vector, respondent's wrist minimum girth in centimeters, measured as average of right and left girths.   age
A numerical vector, respondent's age in years.   wgt
A numerical vector, respondent's weight in kilograms.   hgt
A numerical vector, respondent's height in centimeters.   sex
A categorical vector, 1 if the respondent is male, 0 if female.     Source  
Heinz G, Peterson LJ, Johnson RW, Kerk CJ. 2003. Exploring Relationships in Body Dimensions. Journal of Statistics Education 11(2).    Examples    library(ggplot2) ggplot(bdims, aes(x = hgt)) + geom_histogram(binwidth = 5) ggplot(bdims, aes(x = hgt, y = wgt)) + geom_point() + labs(x = ""Height"", y = ""Weight"") ggplot(bdims, aes(x = hgt, y = sho_gi)) + geom_point() + labs(x = ""Height"", y = ""Shoulder girth"") ggplot(bdims, aes(x = hgt, y = hip_gi)) + geom_point() + labs(x = ""Height"", y = ""Hip girth"")"
"openintro-biontech_adolescents","openintro","biontech_adolescents","Efficacy of Pfizer-BioNTech COVID-19 vaccine on adolescents",2260,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/biontech_adolescents.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/biontech_adolescents.html","biontech_adolescents R Documentation   Efficacy of Pfizer-BioNTech COVID-19 vaccine on adolescents   Description  
On March 31, 2021, Pfizer and BioNTech announced that ""in a Phase 3 trial in adolescents 12 to 15 years of age with or without prior evidence of SARS-CoV-2 infection, the Pfizer-BioNTech COVID-19 vaccine BNT162b2 demonstrated 100% efficacy and robust antibody responses, exceeding those recorded earlier in vaccinated participants aged 16 to 25 years old, and was well tolerated."" These results are from a Phase 3 trial in 2,260 adolescents 12 to 15 years of age in the United States. In the trial, 18 cases of COVID-19 were observed in the placebo group (n = 1,129) versus none in the vaccinated group (n = 1,131).    Usage    biontech_adolescents    Format  
A data frame with 2260 observations on the following 2 variables.    group
Study group: vaccine (Pfizer-BioNTech COVID-19 vaccine administered) or placebo .   outcome
Study outcome: COVID-19 or no COVID-19 .     Source  
""Pfizer-Biontech Announce Positive Topline Results Of Pivotal Covid-19 Vaccine Study In Adolescents"" . March 21, 2021. (Retrieved April 25, 2021.)    Examples    library(dplyr) library(ggplot2) biontech_adolescents %>% count(group, outcome) ggplot(biontech_adolescents, aes(y = group, fill = outcome)) + geom_bar()"
"openintro-birds","openintro","birds","Aircraft-Wildlife Collisions",19302,17,0,2,11,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/birds.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/birds.html","birds R Documentation   Aircraft-Wildlife Collisions   Description  
A collection of all collisions between aircraft in wildlife that were reported to the US Federal Aviation Administration between 1990 and 1997, with details on the circumstances of the collision.    Usage    birds    Format  
A data frame with 19302 observations on the following 17 variables.    opid
Three letter identification code for the operator (carrier) of the aircraft.   operator
Name of the aircraft operator.   atype
Make and model of aircraft.   remarks
Verbal remarks regarding the collision.   phase_of_flt
Phase of the flight during which the collision occurred: Approach , Climb , Descent , En Route , Landing Roll , Parked , Take-off run , Taxi .   ac_mass
Mass of the aircraft classified as 2250 kg or less (1), 2251-5700 kg (2), 5701-27000 kg (3), 27001-272000 kg (4), above 272000 kg (5).   num_engs
Number of engines on the aircraft.   date
Date of the collision (MM/DD/YYYY).   time_of_day
Light conditions: Dawn , Day , Dusk , Night .   state
Two letter abbreviation of the US state in which the collision occurred.   height
Feet above ground level.   speed
Knots (indicated air speed).   effect
Effect on flight: Aborted Take-off , Engine Shut Down , None , Other , Precautionary Landing .   sky
Type of cloud cover, if any: No Cloud , Overcast , Some Cloud .   species
Common name for bird or other wildlife.   birds_seen
Number of birds/wildlife seen by pilot: 1 , 2-10 , 11-100 , Over 100 .   birds_struck
Number of birds/wildlife struck: 0 , 1 , 2-10 , 11-100 , Over 100 .     Details  
The FAA National Wildlife Strike Database contains strike reports that are voluntarily reported to the FAA by pilots, airlines, airports and others. Current research indicates that only about 20\ Wildlife strike reporting is not uniform as some organizations have more robust voluntary reporting procedures. Because of variations in reporting, users are cautioned that the comparisons between individual airports or airlines may be misleading.    Source  
Aircraft Wildlife Strike Data: Search Tool - FAA Wildlife Strike Database. Available at https://dev.socrata.com/foundry/datahub.transportation.gov/jhay-dgxy . Retrieval date: Feb 4, 2012.    Examples    library(dplyr) library(ggplot2) library(forcats) library(tidyr) # Phase of the flight during which the collision occurred, tabular birds %>% count(phase_of_flt, sort = TRUE) # Phase of the flight during which the collision occurred, barplot ggplot(birds, aes(y = fct_infreq(phase_of_flt))) + geom_bar() + labs(x = ""Phase of flight"") # Height summary statistics summary(birds$height) # Phase of flight vs. effect of crash birds %>% drop_na(phase_of_flt, effect) %>% ggplot(aes(y = phase_of_flt, fill = effect)) + geom_bar(position = ""fill"") + labs(x = ""Proportion"", y = ""Phase of flight"", fill = ""Effect"")"
"openintro-births","openintro","births","North Carolina births, 100 cases",150,9,3,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/births.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/births.html","births R Documentation   North Carolina births, 100 cases   Description  
Data on a random sample of 100 births for babies in North Carolina where the mother was not a smoker and another 50 where the mother was a smoker.    Usage    births    Format  
A data frame with 150 observations on the following 14 variables.    f_age
Father's age.   m_age
Mother's age.   weeks
Weeks at which the mother gave birth.   premature
Indicates whether the baby was premature or not.   visits
Number of hospital visits.   gained
Weight gained by mother.   weight
Birth weight of the baby.   sex_baby
Gender of the baby.   smoke
Whether or not the mother was a smoker.     Source  
Birth records released by North Carolina in 2004.    See Also  
We do not have ideal provenance for these data. For a better documented and more recent dataset on a similar topic with similar variables, see births14. Additionally, ncbirths also contains similar data.    Examples    library(ggplot2) ggplot(births, aes(x = smoke, y = weight)) + geom_boxplot()"
"openintro-births14","openintro","births14","US births",1000,13,7,7,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/births14.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/births14.html","births14 R Documentation   US births   Description  
Every year, the US releases to the public a large data set containing information on births recorded in the country. This data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from the data set released in 2014.    Usage    births14    Format  
A data frame with 1,000 observations on the following 13 variables.    fage
Father's age in years.   mage
Mother's age in years.   mature
Maturity status of mother.   weeks
Length of pregnancy in weeks.   premie
Whether the birth was classified as premature (premie) or full-term.   visits
Number of hospital visits during pregnancy.   gained
Weight gained by mother during pregnancy in pounds.   weight
Weight of the baby at birth in pounds.   lowbirthweight
Whether baby was classified as low birthweight ( low ) or not ( not low ).   sex
Sex of the baby, female or male .   habit
Status of the mother as a nonsmoker or a smoker .   marital
Whether mother is married or not married at birth.   whitemom
Whether mom is white or not white .     Source  
United States Department of Health and Human Services. Centers for Disease Control and Prevention. National Center for Health Statistics. Natality Detail File, 2014 United States. Inter-university Consortium for Political and Social Research, 2016-10-07. doi: 10.3886/ICPSR36461.v1 .    Examples    library(ggplot2) ggplot(births14, aes(x = habit, y = weight)) + geom_boxplot() + labs(x = ""Smoking status of mother"", y = ""Birth weight of baby (in lbs)"") ggplot(births14, aes(x = whitemom, y = visits)) + geom_boxplot() + labs(x = ""Mother's race"", y = ""Number of doctor visits during pregnancy"") ggplot(births14, aes(x = mature, y = gained)) + geom_boxplot() + labs(x = ""Mother's age category"", y = ""Weight gained during pregnancy"")"
"openintro-books","openintro","books","Sample of books on a shelf",95,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/books.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/books.html","books R Documentation   Sample of books on a shelf   Description  
Simulated data set.    Usage    books    Format  
A data frame with 95 observations on the following 2 variables.    type
a factor with levels fiction and nonfiction   format
a factor with levels hardcover and paperback     Examples    table(books)"
"openintro-burger","openintro","burger","Burger preferences",500,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/burger.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/burger.html","burger R Documentation   Burger preferences   Description  
Sample burger place preferences versus gender.    Usage    burger    Format  
A data frame with 500 observations on the following 2 variables.    best_burger_place
Burger place.   gender
a factor with levels Female and Male     Source  
SurveyUSA, Results of SurveyUSA News Poll #17718, data collected on December 2, 2010.    Examples    table(burger)"
"openintro-cancer_in_dogs","openintro","cancer_in_dogs","Cancer in dogs",1436,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cancer_in_dogs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cancer_in_dogs.html","cancer_in_dogs R Documentation   Cancer in dogs   Description  
A study in 1994 examined 491 dogs that had developed cancer and 945 dogs as a control group to determine whether there is an increased risk of cancer in dogs that are exposed to the herbicide 2,4-Dichlorophenoxyacetic acid (2,4-D).    Usage    cancer_in_dogs    Format  
A data frame with 1436 observations on the following 2 variables.    order
a factor with levels 2,4-D and no 2,4-D   response
a factor with levels cancer and no cancer     Source  
Hayes HM, Tarone RE, Cantor KP, Jessen CR, McCurnin DM, and Richardson RC. 1991. Case- Control Study of Canine Malignant Lymphoma: Positive Association With Dog Owner's Use of 2, 4- Dichlorophenoxyacetic Acid Herbicides. Journal of the National Cancer Institute 83(17):1226-1231.    Examples    table(cancer_in_dogs)"
"openintro-cards","openintro","cards","Deck of cards",52,4,2,0,3,1,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cards.html","cards R Documentation   Deck of cards   Description  
All the cards in a standard deck.    Usage    cards    Format  
A data frame with 52 observations on the following 4 variables.    value
a factor with levels 10 2 3 4   5 6 7 8 9 A J K   Q   color
a factor with levels black red   suit
a factor with levels Club Diamond Heart Spade   face
a logical vector     Examples    table(cards$value) table(cards$color) table(cards$suit) table(cards$face) table(cards$suit, cards$face)"
"openintro-cars93","openintro","cars93","cars93",54,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cars93.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cars93.html","cars93 R Documentation   cars93   Description  
A data frame with 54 rows and 6 columns. This data is a subset of the  Cars93 data set from the MASS package.    Usage    cars93    Format  
A data frame with 54 observations on the following 6 variables.    type
The vehicle type with levels large , midsize , and small .   price
Vehicle price (USD).   mpg_city
Vehicle mileage in city (miles per gallon).   drive_train
Vehicle drive train with levels 4WD , front , and rear .   passengers
The vehicle passenger capacity.   weight
Vehicle weight (lbs).     Details  
These cars represent a random sample for 1993 models that were in both  Consumer Reports and PACE Buying Guide . Only vehicles of type  small , midsize , and large were include.   
Further description can be found in Lock (1993). Use the URL  http://jse.amstat.org/v1n1/datasets.lock.html .    Source  
Lock, R. H. (1993) 1993 New Car Data. Journal of Statistics Education 1(1).    Examples    library(ggplot2) # Vehicle price by type ggplot(cars93, aes(x = price)) + geom_histogram(binwidth = 5) + facet_wrap(~type) # Vehicle price vs. weight ggplot(cars93, aes(x = weight, y = price)) + geom_point() # Milleage vs. weight ggplot(cars93, aes(x = weight, y = mpg_city)) + geom_point() + geom_smooth()"
"openintro-cchousing","openintro","cchousing","Community college housing (simulated data)",75,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cchousing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cchousing.html","cchousing R Documentation   Community college housing (simulated data)   Description  
These are simulated data and intended to represent housing prices of students at a community college.    Usage    cchousing    Format  
A data frame with 75 observations on the following variable.    price
Monthly housing price, simulated.     Examples    hist(cchousing$price)"
"openintro-census","openintro","census","Random sample of 2000 U.S. Census Data",500,8,1,0,4,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/census.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/census.html","census R Documentation   Random sample of 2000 U.S. Census Data   Description  
A random sample of 500 observations from the 2000 U.S. Census Data.    Usage    census    Format  
A data frame with 500 observations on the following 8 variables.    census_year
Census Year.   state_fips_code
Name of state.   total_family_income
Total family income (in U.S. dollars).   age
Age.   sex
Sex with levels Female and Male .   race_general
Race with levels American Indian or Alaska Native , Black , Chinese , Japanese , Other Asian or Pacific Islander , Two major races , White and Other .   marital_status
Marital status with levels Divorced , Married/spouse absent , Married/spouse present , Never married/single , Separated and Widowed .   total_personal_income
Total personal income (in U.S. dollars).     Source  
http://factfinder.census.gov     Examples    library(dplyr) library(ggplot2) census %>% filter(total_family_income > 0) %>% ggplot(aes(x = total_family_income)) + geom_histogram(binwidth = 25000)"
"openintro-cherry","openintro","cherry","Summary information for 31 cherry trees",31,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cherry.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cherry.html","cherry R Documentation   Summary information for 31 cherry trees   Description  
Researchers wanting to understand the relationship between these variables for black cherry trees collected data from 31 trees in the Allegheny National Forest, Pennsylvania.    Usage    cherry    Format  
A data frame with 31 observations on the following 3 variables.    diam
diameter in inches (at 54 inches above ground)   height
height is measured in feet   volume
volume in cubic feet     Source  
D.J. Hand. A handbook of small data sets. Chapman & Hall/CRC, 1994.    Examples    library(ggplot2) library(broom) ggplot(cherry, aes(x = diam, y = volume)) + geom_point() + geom_smooth(method = ""lm"") mod <- lm(volume ~ diam + height, cherry) tidy(mod)"
"openintro-china","openintro","china","Child care hours",9788,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/china.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/china.html","china R Documentation   Child care hours   Description  
The China Health and Nutrition Survey aims to examine the effects of the health, nutrition, and family planning policies and programs implemented by national and local governments.    Usage    china    Format  
A data frame with 9788 observations on the following 3 variables.    gender
a numeric vector   edu
a numeric vector   child_care
a numeric vector     Source  
UNC Carolina Population Center, China Health and Nutrition Survey, 2006.    Examples    summary(china)"
"openintro-cia_factbook","openintro","cia_factbook","CIA Factbook Details on Countries",259,11,0,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cia_factbook.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cia_factbook.html","cia_factbook R Documentation   CIA Factbook Details on Countries   Description  
Country-level statistics from the US Central Intelligence Agency (CIA).    Usage    cia_factbook    Format  
A data frame with 259 observations on the following 11 variables.    country
Country name.   area
Land area, in square kilometers. (1 square kilometer is 0.386 square miles   birth_rate
Birth rate, in births per 1,000 people.   death_rate
Death rate, in deaths per 1,000 people.   infant_mortality_rate
Infant mortality, in deaths per 1,000 live births.   internet_users
Total number of internet users.   life_exp_at_birth
Live expectancy at birth, in years.   maternal_mortality_rate
Number of female deaths per 100,000 live births where the death is related to pregnancy or birth.   net_migration_rate
Net migration rate.   population
Total population.   population_growth_rate
Population growth rate.     Source  
CIA Factbook, Country Comparisons, 2014.  https://www.cia.gov/the-world-factbook/references/guide-to-country-comparisons/     Examples    library(dplyr) library(ggplot2) cia_factbook_iup <- cia_factbook %>% mutate(internet_users_percent = 100 * internet_users / population) ggplot(cia_factbook_iup, aes(x = internet_users_percent, y = life_exp_at_birth)) + geom_point() + labs(x = ""Percentage of internet users"", y = ""Life expectancy at birth"")"
"openintro-classdata","openintro","classdata","Simulated class data",164,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/classdata.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/classdata.html","classdata R Documentation   Simulated class data   Description  
This data is simulated and is meant to represent students scores from three different lectures who were all given the same exam.    Usage    classdata    Format  
A data frame with 164 observations on the following 2 variables.    m1
Represents a first midterm score.   lecture
Three classes: a , b , and c .     References  
OpenIntro Statistics, Chapter 8.    Examples    anova(lm(m1 ~ lecture, classdata))"
"openintro-cle_sac","openintro","cle_sac","Cleveland and Sacramento",500,8,3,0,5,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cle_sac.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cle_sac.html","cle_sac R Documentation   Cleveland and Sacramento   Description  
Data on a sample of 500 people from the Cleveland, OH and Sacramento, CA metro areas.    Usage    cle_sac    Format  
A data frame with 500 observations representing people on the following 8 variables.    year
Year the data was collected.   state
State where person resides.   city
City.   age
Age of the person.   sex
Gender.   race
Ethnicity.   marital_status
Marital status.   personal_income
Personal income.     Examples    library(ggplot2) ggplot(cle_sac, aes(x = personal_income)) + geom_histogram(binwidth = 20000) + facet_wrap(~city)"
"openintro-climate70","openintro","climate70","Temperature Summary Data, Geography Limited",197,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/climate70.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/climate70.html","climate70 R Documentation   Temperature Summary Data, Geography Limited   Description  
A random set of monitoring locations were taken from NOAA data that had both years of interest (1948 and 2018) as well as data for both summary metrics of interest (dx70 and dx90, which are described below).    Usage    climate70    Format  
A data frame with 197 observations on the following 7 variables.    station
Station ID.   latitude
Latitude of the station.   longitude
Longitude of the station.   dx70_1948
Number of days above 70 degrees in 1948.   dx70_2018
Number of days above 70 degrees in 2018.   dx90_1948
Number of days above 90 degrees in 1948.   dx90_2018
Number of days above 90 degrees in 2018.     Details  
Please keep in mind that these are two annual snapshots, and a complete analysis would consider much more than two years of data and much additional information for those years.    Source  
https://www.ncdc.noaa.gov/cdo-web/datasets , retrieved 2019-04-24.    Examples    # Data sampled are from the US, Europe, and Australia. # This geographic limitation may be due to the particular # years considered, since locations without both 1948 and # 2018 were discarded for this (simple) data set. plot(climate70$longitude, climate70$latitude) plot(climate70$dx70_1948, climate70$dx70_2018) abline(0, 1, lty = 2) plot(climate70$dx90_1948, climate70$dx90_2018) abline(0, 1, lty = 2) hist(climate70$dx70_2018 - climate70$dx70_1948) hist(climate70$dx90_2018 - climate70$dx90_1948) t.test(climate70$dx70_2018 - climate70$dx70_1948) t.test(climate70$dx90_2018 - climate70$dx90_1948)"
"openintro-coast_starlight","openintro","coast_starlight","Coast Starlight Amtrak train",16,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/coast_starlight.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/coast_starlight.html","coast_starlight R Documentation   Coast Starlight Amtrak train   Description  
Travel times and distances.    Usage    coast_starlight    Format  
A data frame with 16 observations on the following 3 variables.    station
Station.   dist
Distance.   travel_time
Travel time.     Examples    library(ggplot2) ggplot(coast_starlight, aes(x = dist, y = travel_time)) + geom_point()"
"openintro-COL","openintro","COL","OpenIntro Statistics colors",7,13,0,13,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/COL.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/COL.html","COL R Documentation   OpenIntro Statistics colors   Description  
These are the core colors used for the OpenIntro Statistics textbook. The blue, green, yellow, and red colors are also gray-scaled, meaning no changes are required when printing black and white copies.    Usage    COL    Format  
A 7-by-13 matrix of 7 colors with thirteen fading scales: blue, green, yellow, red, black, gray, and light gray.    Source  
Colors selected by OpenIntro's in-house graphic designer,  Meenal Patel .    Examples    plot(1:7, 7:1, col = COL, pch = 19, cex = 6, xlab = """", ylab = """", xlim = c(0.5,7.5), ylim = c(-2.5,8), axes = FALSE) text(1:7, 7:1+0.7, paste(""COL["", 1:7, ""]"", sep = """"), cex = 0.9) points(1:7, 7:1-0.7, col = COL[,2], pch = 19, cex = 6) points(1:7, 7:1-1.4, col = COL[,3], pch = 19, cex = 6) points(1:7, 7:1-2.1, col = COL[,4], pch = 19, cex = 6)"
"openintro-corr_match","openintro","corr_match","Sample data sets for correlation problems",121,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/corr_match.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/corr_match.html","corr_match R Documentation   Sample data sets for correlation problems   Description  
Simulated data.    Usage    corr_match    Format  
A data frame with 121 observations on the following 9 variables.    x
a numeric vector   y1
a numeric vector   y2
a numeric vector   y3
a numeric vector   y4
a numeric vector   y5
a numeric vector   y6
a numeric vector   y7
a numeric vector   y8
a numeric vector     Source  
Simulated data set.    Examples    library(ggplot2) ggplot(corr_match, aes(x = x, y = y1)) + geom_point() cor(corr_match$x, corr_match$y1)"
"openintro-country_iso","openintro","country_iso","Country ISO information",249,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/country_iso.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/country_iso.html","country_iso R Documentation   Country ISO information   Description  
Country International Organization for Standardization (ISO) information.    Usage    country_iso    Format  
A data frame with 249 observations on the following 4 variables.    country_code
Two-letter ISO country code.   country_name
Country name.   year
Year the two-letter ISO country code was assigned.   top_level_domain
op-level domain name.     Source  
Wikipedia, retrieved 2018-11-18.  https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2     Examples    country_iso"
"openintro-cpr","openintro","cpr","CPR data set",90,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cpr.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cpr.html","cpr R Documentation   CPR data set   Description  
These patients were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours.    Usage    cpr    Format  
A data frame with 90 observations on the following 2 variables.    group
a factor with levels control and treatment   outcome
a factor with levels died and survived     Source  
Efficacy and safety of thrombolytic therapy after initially unsuccessful cardiopulmonary resuscitation: a prospective clinical trial, by Bottiger et al., The Lancet, 2001.    Examples    table(cpr)"
"openintro-cpu","openintro","cpu","CPU's Released between 2010 and 2020.",875,12,1,4,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/cpu.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/cpu.html","cpu R Documentation   CPU's Released between 2010 and 2020.   Description  
Data on computer processors released between 2010 and 2020.    Usage    cpu    Format  
A data frame with 875 rows and 12 variables.    company
Manufacturer of the CPU.   name
Model name of the processor.   codename
Name given by manufacturer to all chips with this architecture.   cores
Number of compute cores per processor.   threads
The number of threads represents the number of simultaneous calculations that can be ongoing in the processor.   base_clock
Base speed for the CPU in GHz.   boost_clock
Single-core max speed for the CPU in GHz.   socket
Specifies the type of connection to the motherboard.   process
Size of the process node used in production in nm.   l3_cache
Size of the level 3 cache on the processor in MB.   tdp
Total draw power of the processor.   released
Date which the processor was released to the public.     Source  
TechPowerUp CPU Database .    Examples    library(ggplot2) # CPU base speed ggplot(cpu, aes(x = company, y = base_clock)) + geom_boxplot() + labs( x = ""Company"", y = ""Base Clock (GHz)"", title = ""CPU base speed"" ) # Process node size vs. boost speed ggplot(cpu, aes(x = process, y = boost_clock)) + geom_point() + labs( x = ""Process node size (nm)"", y = ""Boost Clock (GHz)"", title = ""Process node size vs. boost speed"" )"
"openintro-credits","openintro","credits","College credits.",100,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/credits.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/credits.html","credits R Documentation   College credits.   Description  
A simulated data set of number of credits taken by college students each semester.    Usage    credits    Format  
A data frame with 100 observations on the following variable.    credits
Number of credits.     Source  
Simulated data.    Examples    library(ggplot2) ggplot(credits, aes(x = credits)) + geom_histogram(binwidth = 1)"
"openintro-daycare_fines","openintro","daycare_fines","Daycare fines",200,7,1,1,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/daycare_fines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/daycare_fines.html","daycare_fines R Documentation   Daycare fines   Description  
Researchers tested the deterrence hypothesis which predicts that the introduction of a penalty will reduce the occurrence of the behavior subject to the fine, with the condition that the fine leaves everything else unchanged by instituting a fine for late pickup at daycare centers. For this study, they worked with 10 volunteer daycare centers that did not originally impose a fine to parents for picking up their kids late. They randomly selected 6 of these daycare centers and instituted a monetary fine (of a considerable amount) for picking up children late and then removed it. In the remaining 4 daycare centers no fine was introduced. The study period was divided into four: before the fine (weeks 1–4), the first 4 weeks with the fine (weeks 5-8), the entire period with the fine (weeks 5–16), and the after fine period (weeks 17-20). Throughout the study, the number of kids who were picked up late was recorded each week for each daycare. The study found that the number of late-coming parents increased significantly when the fine was introduced, and no reduction occurred after the fine was removed.    Usage    daycare_fines    Format  
A data frame with 200 observations on the following 7 variables.    center
Daycare center id.   group
Study group: test (fine instituted) or control (no fine).   children
Number of children at daycare center.   week
Week of study.   late_pickups
Number of late pickups for a given week and daycare center.   study_period_4
Period of study, divided into 4 periods:  before fine , first 4 weeks with fine , last 8 weeks with fine , after fine   study_period_3
Period of study, divided into 4 periods:  before fine , with fine , after fine     Source  
Gneezy, Uri, and Aldo Rustichini. ""A fine is a price."" The Journal of Legal Studies 29, no. 1 (2000): 1-17.    Examples    library(dplyr) library(tidyr) library(ggplot2) # The following tables roughly match results presented in Table 2 of the source article # The results are only off by rounding for some of the weeks daycare_fines %>% group_by(center, study_period_4) %>% summarise(avg_late_pickups = mean(late_pickups), .groups = ""drop"") %>% pivot_wider(names_from = study_period_4, values_from = avg_late_pickups) daycare_fines %>% group_by(center, study_period_3) %>% summarise(avg_late_pickups = mean(late_pickups), .groups = ""drop"") %>% pivot_wider(names_from = study_period_3, values_from = avg_late_pickups) # The following plot matches Figure 1 of the source article daycare_fines %>% group_by(week, group) %>% summarise(avg_late_pickups = mean(late_pickups), .groups = ""drop"") %>% ggplot(aes(x = week, y = avg_late_pickups, group = group, color = group)) + geom_point() + geom_line()"
"openintro-diabetes2","openintro","diabetes2","Type 2 Diabetes Clinical Trial for Patients 10-17 Years Old",699,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/diabetes2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/diabetes2.html","diabetes2 R Documentation   Type 2 Diabetes Clinical Trial for Patients 10-17 Years Old   Description  
Three treatments were compared to test their relative efficacy (effectiveness) in treating Type 2 Diabetes in patients aged 10-17 who were being treated with metformin. The primary outcome was lack of glycemic control (or not); lacking glycemic control means the patient still needed insulin, which is not the preferred outcome for a patient.    Usage    diabetes2    Format  
A data frame with 699 observations on the following 2 variables.    treatment
The treatment the patient received.   outcome
Whether there patient still needs insulin ( failure ) or met a basic positive outcome bar ( success ).     Details  
Each of the 699 patients in the experiment were randomized to one of the following treatments: (1) continued treatment with metformin (coded as met ), (2) formin combined with rosiglitazone (coded as  rosi ), or or (3) a lifestyle-intervention program (coded as  lifestyle ).    Source  
Zeitler P, et al. 2012. A Clinical Trial to Maintain Glycemic Control in Youth with Type 2 Diabetes. N Engl J Med.    Examples    lapply(diabetes2, table) (cont.table <- table(diabetes2)) (m <- chisq.test(cont.table)) m$expected"
"openintro-dream","openintro","dream","Survey on views of the DREAM Act",910,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/dream.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/dream.html","dream R Documentation   Survey on views of the DREAM Act   Description  
A SurveyUSA poll.    Usage    dream    Format  
A data frame with 910 observations on the following 2 variables.    ideology
a factor with levels Conservative Liberal Moderate   stance
a factor with levels No Not sure Yes     Source  
SurveyUSA, News Poll #18927, data collected Jan 27-29, 2012.    Examples    table(dream)"
"openintro-drone_blades","openintro","drone_blades","Quadcopter Drone Blades",2000,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/drone_blades.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/drone_blades.html","drone_blades R Documentation   Quadcopter Drone Blades   Description  
Quality control data set for quadcopter drone blades, where this data has been made up for an example.    Usage    drone_blades    Format  
A data frame with 2000 observations on the following 2 variables.    supplier
The supplier for the blade.   inspection
The inspection conclusion.     References  
OpenIntro Statistics, Third Edition and Fourth Edition.    Examples    library(dplyr) drone_blades %>% count(supplier, inspection)"
"openintro-drug_use","openintro","drug_use","Drug use of students and parents",445,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/drug_use.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/drug_use.html","drug_use R Documentation   Drug use of students and parents   Description  
Summary of 445 student-parent pairs.    Usage    drug_use    Format  
A data frame with 445 observations on the following 2 variables.    student
a factor with levels not uses   parents
a factor with levels not used     Source  
Ellis GJ and Stone LH. 1979. Marijuana Use in College: An Evaluation of a Modeling Explanation. Youth and Society 10:323-334.    Examples    table(drug_use)"
"openintro-duke_forest","openintro","duke_forest","Sale prices of houses in Duke Forest, Durham, NC",98,13,1,6,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/duke_forest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/duke_forest.html","duke_forest R Documentation   Sale prices of houses in Duke Forest, Durham, NC   Description  
Data on houses that were recently sold in the Duke Forest neighborhood of Durham, NC in November 2020.    Usage    duke_forest    Format  
A data frame with 98 rows and 13 variables.    address
Address of house.   price
Sale price, in USD.   bed
Number of bedrooms.   bath
Number of bathrooms.   area
Area of home, in square feet.   type
Type of home (all are Single Family).   year_built
Year the home was built.   heating
Heating sytem.   cooling
Cooling system ( other or central ).   parking
Type of parking available and number of parking spaces.   lot
Area of the entire property, in acres.   hoa
If the home belongs to an Home Owners Association, the associted fee ( NA otherwise).   url
URL of the listing.     Source  
Data were collected from Zillow.com in November 2020.    Examples    library(ggplot2) # Number of bedrooms and price ggplot(duke_forest, aes(x = as.factor(bed), y = price)) + geom_boxplot() + labs( x = ""Number of bedrooms"", y = ""Sale price (USD)"", title = ""Homes for sale in Duke Forest, Durham, NC"", subtitle = ""Data are from November 2020"" ) # Area and price ggplot(duke_forest, aes(x = area, y = price)) + geom_point() + labs( x = ""Area (square feet)"", y = ""Sale price (USD)"", title = ""Homes for sale in Duke Forest, Durham, NC"", subtitle = ""Data are from November 2020"" )"
"openintro-earthquakes","openintro","earthquakes","Earthquakes",123,7,0,3,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/earthquakes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/earthquakes.html","earthquakes R Documentation   Earthquakes   Description  
Select set of notable earthquakes from 1900 to 1999.    Usage    earthquakes    Format  
A data frame with 123 rows and 7 variables.    year
Year the earthquake took place.   month
Month the earthquake took place.   day
Day the earthquake took place   richter
Magnitude of earthquake using the Richter Scale.   area
City or geographic location of earthquakes.   region
Country or countries if the earthquake occurred on a border.   deaths
Approximate number of deaths caused by earthquake     Source  
World Almanac and Book of Facts: 2011.    Examples    library(ggplot2) ggplot(earthquakes, aes(x = richter, y = deaths))+ geom_point() ggplot(earthquakes, aes(x = log(deaths)))+ geom_histogram()"
"openintro-ebola_survey","openintro","ebola_survey","Survey on Ebola quarantine",1042,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ebola_survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ebola_survey.html","ebola_survey R Documentation   Survey on Ebola quarantine   Description  
In New York City on October 23rd, 2014, a doctor who had recently been treating Ebola patients in Guinea went to the hospital with a slight fever and was subsequently diagnosed with Ebola. Soon thereafter, an NBC 4 New York/The Wall Street Journal/Marist Poll asked New Yorkers whether they favored a ""mandatory 21-day quarantine for anyone who has come in contact with an Ebola patient"". This poll included responses of 1,042 New York adults between October 26th and 28th, 2014.    Usage    ebola_survey    Format  
A data frame with 1042 observations on the following variable.    quarantine
Indicates whether the respondent is in favor or  against the mandatory quarantine.     Source  
Poll ID NY141026 on maristpoll.marist.edu.    Examples    table(ebola_survey)"
"openintro-elmhurst","openintro","elmhurst","Elmhurst College gift aid",50,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/elmhurst.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/elmhurst.html","elmhurst R Documentation   Elmhurst College gift aid   Description  
A random sample of 50 students gift aid for students at Elmhurst College.    Usage    elmhurst    Format  
A data frame with 50 observations on the following 3 variables.    family_income
Family income of the student.   gift_aid
Gift aid, in $1000s.   price_paid
Price paid by the student (tuition - gift aid).     Source  
These data were sampled from a table of data for all freshman from the 2011 class at Elmhurst College that accompanied an article titled What Students Really Pay to Go to College published online by The Chronicle of Higher Education:  https://www.chronicle.com/article/what-students-really-pay-to-go-to-college/ .    Examples    library(ggplot2) library(broom) ggplot(elmhurst, aes(x = family_income, y = gift_aid)) + geom_point() + geom_smooth(method = ""lm"") mod <- lm(gift_aid ~ family_income, data = elmhurst) tidy(mod)"
"openintro-email","openintro","email","Data frame representing information about a collection of emails",3921,21,10,0,9,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/email.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/email.html","email R Documentation   Data frame representing information about a collection of emails   Description  
These data represent incoming emails for the first three months of 2012 for an email account (see Source).    Usage    email    Format  
A email ( email_sent ) data frame has 3921 (1252) observations on the following 21 variables.    spam
Indicator for whether the email was spam.   to_multiple
Indicator for whether the email was addressed to more than one recipient.   from
Whether the message was listed as from anyone (this is usually set by default for regular outgoing email).   cc
Number of people cc'ed.   sent_email
Indicator for whether the sender had been sent an email in the last 30 days.   time
Time at which email was sent.   image
The number of images attached.   attach
The number of attached files.   dollar
The number of times a dollar sign or the word “dollar” appeared in the email.   winner
Indicates whether “winner” appeared in the email.   inherit
The number of times “inherit” (or an extension, such as “inheritance”) appeared in the email.   viagra
The number of times “viagra” appeared in the email.   password
The number of times “password” appeared in the email.   num_char
The number of characters in the email, in thousands.   line_breaks
The number of line breaks in the email (does not count text wrapping).   format
Indicates whether the email was written using HTML (e.g. may have included bolding or active links).   re_subj
Whether the subject started with “Re:”, “RE:”, “re:”, or “rE:”   exclaim_subj
Whether there was an exclamation point in the subject.   urgent_subj
Whether the word “urgent” was in the email subject.   exclaim_mess
The number of exclamation points in the email message.   number
Factor variable saying whether there was no number, a small number (under 1 million), or a big number.     Source  
David Diez's Gmail Account, early months of 2012. All personally identifiable information has been removed.    See Also  
email50     Examples    e <- email #______ Variables For Logistic Regression ______# # Variables are modified to match # OpenIntro Statistics, Second Edition # As Is (7): spam, to_multiple, winner, format, # re_subj, exclaim_subj # Omitted (6): from, sent_email, time, image, # viagra, urgent_subj, number # Become Indicators (5): cc, attach, dollar, # inherit, password e$cc <- ifelse(email$cc > 0, 1, 0) e$attach <- ifelse(email$attach > 0, 1, 0) e$dollar <- ifelse(email$dollar > 0, 1, 0) e$inherit <- ifelse(email$inherit > 0, 1, 0) e$password <- ifelse(email$password > 0, 1, 0) # Transform (3): num_char, line_breaks, exclaim_mess #e$num_char <- cut(email$num_char, c(0,1,5,10,20,1000)) #e$line_breaks <- cut(email$line_breaks, c(0,10,100,500,10000)) #e$exclaim_mess <- cut(email$exclaim_mess, c(-1,0,1,5,10000)) g <- glm(spam ~ to_multiple + winner + format + re_subj + exclaim_subj + cc + attach + dollar + inherit + password, # + #num_char + line_breaks + exclaim_mess, data=e, family=binomial) summary(g) #______ Variable Selection Via AIC ______# g. <- step(g) plot(predict(g., type=""response""), e$spam) #______ Splitting num_char by html ______# x <- log(email$num_char) bw <- 0.004 R <- range(x) + c(-1, 1) wt <- sum(email$format == 1)/nrow(email) htmlAll <- density(x, bw=0.4, from=R[1], to=R[2]) htmlNo <- density(x[email$format != 1], bw=0.4, from=R[1], to=R[2]) htmlYes <- density(x[email$format == 1], bw=0.4, from=R[1], to=R[2]) htmlNo$y <- htmlNo$y #* (1-wt) htmlYes$y <- htmlYes$y #* wt + htmlNo$y plot(htmlAll, xlim=c(-4, 6), ylim=c(0, 0.4)) lines(htmlNo, col=4) lines(htmlYes, lwd=2, col=2)"
"openintro-email_test","openintro","email_test","Data frame representing information about a collection of emails",1252,21,9,0,2,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/email_test.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/email_test.html","email R Documentation   Data frame representing information about a collection of emails   Description  
These data represent incoming emails for the first three months of 2012 for an email account (see Source).    Usage    email    Format  
A email ( email_sent ) data frame has 3921 (1252) observations on the following 21 variables.    spam
Indicator for whether the email was spam.   to_multiple
Indicator for whether the email was addressed to more than one recipient.   from
Whether the message was listed as from anyone (this is usually set by default for regular outgoing email).   cc
Number of people cc'ed.   sent_email
Indicator for whether the sender had been sent an email in the last 30 days.   time
Time at which email was sent.   image
The number of images attached.   attach
The number of attached files.   dollar
The number of times a dollar sign or the word “dollar” appeared in the email.   winner
Indicates whether “winner” appeared in the email.   inherit
The number of times “inherit” (or an extension, such as “inheritance”) appeared in the email.   viagra
The number of times “viagra” appeared in the email.   password
The number of times “password” appeared in the email.   num_char
The number of characters in the email, in thousands.   line_breaks
The number of line breaks in the email (does not count text wrapping).   format
Indicates whether the email was written using HTML (e.g. may have included bolding or active links).   re_subj
Whether the subject started with “Re:”, “RE:”, “re:”, or “rE:”   exclaim_subj
Whether there was an exclamation point in the subject.   urgent_subj
Whether the word “urgent” was in the email subject.   exclaim_mess
The number of exclamation points in the email message.   number
Factor variable saying whether there was no number, a small number (under 1 million), or a big number.     Source  
David Diez's Gmail Account, early months of 2012. All personally identifiable information has been removed.    See Also  
email50     Examples    e <- email #______ Variables For Logistic Regression ______# # Variables are modified to match # OpenIntro Statistics, Second Edition # As Is (7): spam, to_multiple, winner, format, # re_subj, exclaim_subj # Omitted (6): from, sent_email, time, image, # viagra, urgent_subj, number # Become Indicators (5): cc, attach, dollar, # inherit, password e$cc <- ifelse(email$cc > 0, 1, 0) e$attach <- ifelse(email$attach > 0, 1, 0) e$dollar <- ifelse(email$dollar > 0, 1, 0) e$inherit <- ifelse(email$inherit > 0, 1, 0) e$password <- ifelse(email$password > 0, 1, 0) # Transform (3): num_char, line_breaks, exclaim_mess #e$num_char <- cut(email$num_char, c(0,1,5,10,20,1000)) #e$line_breaks <- cut(email$line_breaks, c(0,10,100,500,10000)) #e$exclaim_mess <- cut(email$exclaim_mess, c(-1,0,1,5,10000)) g <- glm(spam ~ to_multiple + winner + format + re_subj + exclaim_subj + cc + attach + dollar + inherit + password, # + #num_char + line_breaks + exclaim_mess, data=e, family=binomial) summary(g) #______ Variable Selection Via AIC ______# g. <- step(g) plot(predict(g., type=""response""), e$spam) #______ Splitting num_char by html ______# x <- log(email$num_char) bw <- 0.004 R <- range(x) + c(-1, 1) wt <- sum(email$format == 1)/nrow(email) htmlAll <- density(x, bw=0.4, from=R[1], to=R[2]) htmlNo <- density(x[email$format != 1], bw=0.4, from=R[1], to=R[2]) htmlYes <- density(x[email$format == 1], bw=0.4, from=R[1], to=R[2]) htmlNo$y <- htmlNo$y #* (1-wt) htmlYes$y <- htmlYes$y #* wt + htmlNo$y plot(htmlAll, xlim=c(-4, 6), ylim=c(0, 0.4)) lines(htmlNo, col=4) lines(htmlYes, lwd=2, col=2)"
"openintro-email50","openintro","email50","Sample of 50 emails",50,21,7,0,9,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/email50.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/email50.html","email50 R Documentation   Sample of 50 emails   Description  
This is a subsample of the email data set.    Usage    email50    Format  
A data frame with 50 observations on the following 21 variables.    spam
Indicator for whether the email was spam.   to_multiple
Indicator for whether the email was addressed to more than one recipient.   from
Whether the message was listed as from anyone (this is usually set by default for regular outgoing email).   cc
Number of people cc'ed.   sent_email
Indicator for whether the sender had been sent an email in the last 30 days.   time
Time at which email was sent.   image
The number of images attached.   attach
The number of attached files.   dollar
The number of times a dollar sign or the word “dollar” appeared in the email.   winner
Indicates whether “winner” appeared in the email.   inherit
The number of times “inherit” (or an extension, such as “inheritance”) appeared in the email.   viagra
The number of times “viagra” appeared in the email.   password
The number of times “password” appeared in the email.   num_char
The number of characters in the email, in thousands.   line_breaks
The number of line breaks in the email (does not count text wrapping).   format
Indicates whether the email was written using HTML (e.g. may have included bolding or active links).   re_subj
Whether the subject started with “Re:”, “RE:”, “re:”, or “rE:”   exclaim_subj
Whether there was an exclamation point in the subject.   urgent_subj
Whether the word “urgent” was in the email subject.   exclaim_mess
The number of exclamation points in the email message.   number
Factor variable saying whether there was no number, a small number (under 1 million), or a big number.     Source  
David Diez's Gmail Account, early months of 2012. All personally identifiable information has been removed.    See Also  
email     Examples    index <- c( 101, 105, 116, 162, 194, 211, 263, 308, 361, 374, 375, 465, 509, 513, 571, 691, 785, 842, 966, 968, 1051, 1201, 1251, 1433, 1519, 1727, 1760, 1777, 1899, 1920, 1943, 2013, 2052, 2252, 2515, 2629, 2634, 2710, 2823, 2835, 2944, 3098, 3227, 3360, 3452, 3496, 3530, 3665, 3786, 3877) order <- c(3, 33, 12, 1, 21, 15, 43, 49, 8, 6, 34, 25, 24, 35, 41, 9, 22, 50, 4, 48, 7, 14, 46, 10, 38, 32, 26, 18, 23, 45, 30, 16, 17, 20, 40, 47, 31, 37, 27, 11, 5, 44, 29, 19, 13, 36, 39, 42, 28, 2) d <- email[index, ][order, ] identical(d, email50)"
"openintro-env_regulation","openintro","env_regulation","American Adults on Regulation and Renewable Energy",705,1,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/env_regulation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/env_regulation.html","env_regulation R Documentation   American Adults on Regulation and Renewable Energy   Description  
Pew Research conducted a poll to find whether American adults support regulation or believe the private market will move the American economy towards renewable energy.    Usage    env_regulation    Format  
A data frame with 705 observations on the following variable.    statement
There were three possible outcomes for each person:  ""Regulations necessary"" , ""Private marketplace will ensure"" , and ""Don't know"" .     Details  
The exact statements being selected were: (1) Government regulations are necessary to encourage businesses and consumers to rely more on renewable energy sources. (2) The private marketplace will ensure that businesses and consumers rely more on renewable energy sources, even without government regulations.   
The actual sample size was 1012. However, the original data were not from a simple random sample; after accounting for the design, the equivalent sample size was about 705, which was what was used for the data set here to keep things simpler for intro stat analyses.    Source  
https://www.pewresearch.org/science/2017/05/16/public-divides-over-environmental-regulation-and-energy-policy/     Examples    table(env_regulation)"
"openintro-epa2012","openintro","epa2012","Vehicle info from the EPA for 2012",1129,28,4,0,19,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/epa2012.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/epa2012.html","epa2012 R Documentation   Vehicle info from the EPA for 2012   Description  
Details from the EPA.    Usage    epa2012    Format  
A data frame with 1129 observations on the following 28 variables.    model_yr
a numeric vector   mfr_name
Manufacturer name.   division
Vehicle division.   carline
Vehicle line.   mfr_code
Manufacturer code.   model_type_index
Model type index.   engine_displacement
Engine displacement.   no_cylinders
Number of cylinders.   transmission_speed
Transmission speed.   city_mpg
City mileage.   hwy_mpg
Highway mileage.   comb_mpg
Combined mileage.   guzzler
Whether the car is considered a ""guzzler"" or not, a factor with levels N and Y.   air_aspir_method
Air aspiration method.   air_aspir_method_desc
Air aspiration method description.   transmission
Transmission type.   transmission_desc
Transmission type description.   no_gears
Number of gears.   trans_lockup
Whether transmission locks up, a factor with levels N and Y .   trans_creeper_gear
A factor with level N only.   drive_sys
Drive system, a factor with levels.   drive_desc
Drive system description.   fuel_usage
Fuel usage, a factor with levels.   fuel_usage_desc
Fuel usage description.   class
Class of car.   car_truck
Car or truck, a factor with levels car , 1 , 2 .   release_date
Date of vehicle release.   fuel_cell
Whether the car has a fuel cell or not, a factor with levels N , Y .     Source  
Fueleconomy.gov, Shared MPG Estimates: Toyota Prius 2012.    See Also  
epa2021    Examples    library(ggplot2) library(dplyr) # Variable descriptions distinct(epa2012, air_aspir_method_desc, air_aspir_method) distinct(epa2012, transmission_desc, transmission) distinct(epa2012, drive_desc, drive_sys) distinct(epa2012, fuel_usage_desc, fuel_usage) # Guzzlers and their mileages ggplot(epa2012, aes(x = city_mpg, y = hwy_mpg, color = guzzler)) + geom_point() + facet_wrap(~guzzler, ncol = 1)"
"openintro-epa2021","openintro","epa2021","Vehicle info from the EPA for 2021",1108,28,3,0,19,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/epa2021.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/epa2021.html","epa2021 R Documentation   Vehicle info from the EPA for 2021   Description  
Details from the EPA.    Usage    epa2021    Format  
A data frame with 1108 observations on the following 28 variables.    model_yr
a numeric vector   mfr_name
Manufacturer name.   division
Vehicle division.   carline
Vehicle line.   mfr_code
Manufacturer code.   model_type_index
Model type index.   engine_displacement
Engine displacement.   no_cylinders
Number of cylinders.   transmission_speed
Transmission speed.   city_mpg
City mileage.   hwy_mpg
Highway mileage.   comb_mpg
Combined mileage.   guzzler
Whether the car is considered a ""guzzler"" or not, a factor with levels N and Y.   air_aspir_method
Air aspiration method.   air_aspir_method_desc
Air aspiration method description.   transmission
Transmission type.   transmission_desc
Transmission type description.   no_gears
Number of gears.   trans_lockup
Whether transmission locks up, a factor with levels N and Y .   trans_creeper_gear
A factor with level N only.   drive_sys
Drive system, a factor with levels.   drive_desc
Drive system description.   fuel_usage
Fuel usage, a factor with levels.   fuel_usage_desc
Fuel usage description.   class
Class of car.   car_truck
Car or truck, a factor with levels car , 1 , ?? , 1 .   release_date
Date of vehicle release.   fuel_cell
Whether the car has a fuel cell or not, a factor with levels N , NA .     Source  
Fuel Economy Data from fueleconomy.gov . Retrieved 6 May, 2021.    See Also  
epa2012    Examples    library(ggplot2) library(dplyr) # Variable descriptions distinct(epa2021, air_aspir_method_desc, air_aspir_method) distinct(epa2021, transmission_desc, transmission) distinct(epa2021, drive_desc, drive_sys) distinct(epa2021, fuel_usage_desc, fuel_usage) # Guzzlers and their mileages ggplot(epa2021, aes(x = city_mpg, y = hwy_mpg, color = guzzler)) + geom_point() + facet_wrap(~guzzler, ncol = 1) # Compare to 2012 epa2021 %>% bind_rows(epa2012) %>% group_by(model_yr) %>% summarise( mean_city = mean(city_mpg), mean_hwy = mean(hwy_mpg) )"
"openintro-esi","openintro","esi","Environmental Sustainability Index 2005",146,29,0,0,2,0,27,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/esi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/esi.html","esi R Documentation   Environmental Sustainability Index 2005   Description  
This data set comes from the 2005 Environmental Sustainability Index: Benchmarking National Environmental Stewardship. Countries are given an overall sustainability score as well as scores in each of several different environmental areas.    Usage    esi    Format  
A data frame with 146 observations on the following 29 variables.    code
ISO3 country code.   country
Country.   esi
Environmental Sustainability Index.   system
ESI core component: systems   stress
ESI core component: stresses   vulner
ESI core component: vulnerability   cap
ESI core component: capacity   global
ESI core component: global stewardship   sys_air
Air quality.   sys_bio
Biodiversity.   sys_lan
Land.   sys_wql
Water quality.   sys_wqn
Water quantity.   str_air
Reducing air pollution.   str_eco
Reducing ecosystem stress.   str_pop
Reducing population pressure.   str_was
Reducing waste and consumption pressures.   str_wat
Reducing water stress.   str_nrm
Natural resource management.   vul_hea
Environmental health.   vul_sus
Basic human sustenance.   vul_dis
Exposure to natural disasters.   cap_gov
Environmental governance.   cap_eff
Eco-efficiency.   cap_pri
Private sector responsiveness.   cap_st
Science and technology.   glo_col
Participation in international collaboration efforts.   glo_ghg
Greenhouse gas emissions.   glo_tbp
Reducing transboundary environmental pressures.     Details  
ESI and Component scores are presented as standard normal percentiles. Indicator scores are in the form of z-scores. See Appendix A of the report for information on the methodology and Appendix C for more detail on original data sources.   
For more information on how each of the indices were calculated, see the documentation linked below.    Source  
ESI Component Indicators. 2005 Environmental Sustainability Index: Benchmarking National Environmental Stewardship , Yale Center for Environmental Law and Policy, Yale University & Center for International Earth Science Information Network (CIESIN), Columbia University   
In collaboration with: World Economic Forum, Geneva, Switzerland Joint Research Centre of the European Commission, Ispra, Italy.   
Available at https://www.earth.columbia.edu/news/2005/images/ESI2005_policysummary.pdf .    References  
Esty, Daniel C., Marc Levy, Tanja Srebotnjak, and Alexander de Sherbinin (2005). 2005 Environmental Sustainability Index: Benchmarking National Environmental Stewardship. New Haven: Yale Center for Environmental Law and Policy    Examples    library(ggplot2) ggplot(esi, aes(x = cap_st, y = glo_col)) + geom_point(color = ifelse(esi$code == ""USA"", ""red"", ""black"")) + geom_text(aes(label = ifelse(code == ""USA"", as.character(code),"""")), hjust = 1.2, color = ""red"") + labs(x = ""Science and technology"", y = ""Participation in international collaboration efforts"") ggplot(esi, aes(x = vulner, y = cap)) + geom_point(color = ifelse(esi$code == ""USA"", ""red"", ""black"")) + geom_text(aes(label = ifelse(code == ""USA"", as.character(code),"""")), hjust = 1.2, color = ""red"") + labs(x = ""Vulnerability"", y = ""Capacity"")"
"openintro-ethanol","openintro","ethanol","Ethanol Treatment for Tumors Experiment",24,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ethanol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ethanol.html","ethanol R Documentation   Ethanol Treatment for Tumors Experiment   Description  
Experiment where 3 different treatments of ethanol were tested on the treatment of oral cancer tumors in hamsters.    Usage    ethanol    Format  
A data frame with 24 observations, each representing one hamster, on the following 2 variables.   treatment
Treatment the hamster received.   regress
a factor with levels no   yes     Details  
The ethyl_cellulose and pure_ethanol treatments consisted of about a quarter of the volume of the tumors, while the  pure_ethanol_16x treatment was 16x that, so about 4 times the size of the tumors.    Source  
Morhard R, et al. 2017. Development of enhanced ethanol ablation as an alternative to surgery in treatment of superficial solid tumors. Scientific Reports 7:8750.    Examples    table(ethanol) fisher.test(table(ethanol))"
"openintro-evals","openintro","evals","Professor evaluations and beauty",463,23,8,0,9,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/evals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/evals.html","evals R Documentation   Professor evaluations and beauty   Description  
The data are gathered from end of semester student evaluations for 463 courses taught by a sample of 94 professors from the University of Texas at Austin. In addition, six students rate the professors' physical appearance. The result is a data frame where each row contains a different course and each column has information on the course and the professor who taught that course.    Usage    evals    Format  
A data frame with 463 observations on the following 23 variables.    course_id
Variable identifying the course (out of 463 courses).   prof_id
Variable identifying the professor who taught the course (out of 94 professors).   score
Average professor evaluation score: (1) very unsatisfactory - (5) excellent.   rank
Rank of professor: teaching, tenure track, tenured.   ethnicity
Ethnicity of professor: not minority, minority.   gender
Gender of professor: female, male.   language
Language of school where professor received education: English or non-English.   age
Age of professor.   cls_perc_eval
Percent of students in class who completed evaluation.   cls_did_eval
Number of students in class who completed evaluation.   cls_students
Total number of students in class.   cls_level
Class level: lower, upper.   cls_profs
Number of professors teaching sections in course in sample: single, multiple.   cls_credits
Number of credits of class: one credit (lab, PE, etc.), multi credit.   bty_f1lower
Beauty rating of professor from lower level female: (1) lowest - (10) highest.   bty_f1upper
Beauty rating of professor from upper level female: (1) lowest - (10) highest.   bty_f2upper
Beauty rating of professor from second level female: (1) lowest - (10) highest.   bty_m1lower
Beauty rating of professor from lower level male: (1) lowest - (10) highest.   bty_m1upper
Beauty rating of professor from upper level male: (1) lowest - (10) highest.   bty_m2upper
Beauty rating of professor from second upper level male: (1) lowest - (10) highest.   bty_avg
Average beauty rating of professor.   pic_outfit
Outfit of professor in picture: not formal, formal.   pic_color
Color of professor's picture: color, black & white.     Source  
Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, 2005. doi: 10.1016/j.econedurev.2004.07.013 .    Examples    evals"
"openintro-exam_grades","openintro","exam_grades","Exam and course grades for statistics students",233,6,1,2,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/exam_grades.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/exam_grades.html","exam_grades R Documentation   Exam and course grades for statistics students   Description  
Grades on three exams and overall course grade for 233 students during several years for a statistics course at a university.    Usage    exam_grades    Format  
A data frame with 233 observations, each representing a student.    semester
Semester when grades were recorded.   sex
Sex of the student as recorded on the university registration system: Man or Woman.   exam1
Exam 1 grade.   exam2
Exam 2 grade.   exam3
Exam 3 grade.   course_grade
Overall course grade.     Examples    library(ggplot2) library(dplyr) # Course grade vs. each exam ggplot(exam_grades, aes(x = exam1, y = course_grade)) + geom_point() ggplot(exam_grades, aes(x = exam2, y = course_grade)) + geom_point() ggplot(exam_grades, aes(x = exam2, y = course_grade)) + geom_point() # Semester averages exam_grades %>% group_by(semester) %>% summarise(across(exam1:course_grade, mean, na.rm = TRUE))"
"openintro-exams","openintro","exams","Exam scores",19,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/exams.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/exams.html","exams R Documentation   Exam scores   Description  
Exam scores from a class of 19 students.    Usage    exams    Format  
A data frame with 19 observations on the following variable.    scores
a numeric vector     Examples    hist(exams$scores)"
"openintro-exclusive_relationship","openintro","exclusive_relationship","Number of Exclusive Relationships",218,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/exclusive_relationship.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/exclusive_relationship.html","exclusive_relationship R Documentation   Number of Exclusive Relationships   Description  
A survey conducted on a reasonably random sample of 203 undergraduates asked, among many other questions, about the number of exclusive relationships these students have been in.    Usage    exclusive_relationship    Format  
A data frame with 218 observations on the following variable.    num
Number of exclusive relationships.     Examples    summary(exclusive_relationship$num) table(exclusive_relationship$num) hist(exclusive_relationship$num)"
"openintro-fact_opinion","openintro","fact_opinion","Can Americans categorize facts and opinions?",5035,3,1,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fact_opinion.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/fact_opinion.html","fact_opinion R Documentation   Can Americans categorize facts and opinions?   Description  
Pew Research Center conducted a survey in 2018, asking a sample of U.S. adults to categorize five factual and five opinion statements. This dataset provides data from this survey, with information on the age group of the participant as well as the number of factual and opinion statements they classified correctly (out of 5).    Usage    fact_opinion    Format  
A data frame with 5,035 rows and 3 variables.    age_group
Age group of survey participant.   fact_correct
Number of factual statements classified correctly (out of 5).   opinion_correct
Number of opinion statements classified correctly (out of 5).     Source  
Younger Americans are better than older Americans at telling factual news statements from opinions , Pew Research Center, October 23, 2018.    Examples    library(ggplot2) library(dplyr) library(tidyr) library(forcats) # Distribution of fact_correct by age group ggplot(fact_opinion, aes(x = age_group, y = fact_correct)) + geom_boxplot() + labs( x = ""Age group"", y = ""Number correct (factual)"", title = ""Number of factual statements classified correctly by age group"" ) # Distribution of opinion_correct by age group ggplot(fact_opinion, aes(x = age_group, y = opinion_correct)) + geom_boxplot() + labs( x = ""Age group"", y = ""Number correct (opinion)"", title = ""Number of opinion statements classified correctly by age group"" ) # Replicating the figure from Pew report (see source for link) fact_opinion %>% mutate( facts = case_when( fact_correct <= 2 ~ ""Two or fewer"", fact_correct %in% c(3,4) ~ ""Three or four"", fact_correct == 5 ~ ""All five"" ), facts = fct_relevel(facts, ""Two or fewer"", ""Three or four"", ""All five""), opinions = case_when( opinion_correct <= 2 ~ ""Two or fewer"", opinion_correct %in% c(3,4) ~ ""Three or four"", opinion_correct == 5 ~ ""All five"" ), opinions = fct_relevel(opinions, ""Two or fewer"", ""Three or four"", ""All five"") ) %>% select(-fact_correct, -opinion_correct) %>% pivot_longer(cols = -age_group, names_to = ""question_type"", values_to = ""n_correct"") %>% ggplot(aes(y = fct_rev(age_group), fill = n_correct)) + geom_bar(position = ""fill"") + facet_wrap(~question_type, ncol = 1) + scale_fill_viridis_d(guide = guide_legend(reverse = TRUE)) + labs( x = ""Proportion"", y = ""Age group"", fill = ""Number of\ncorrect\nclassifications"" )"
"openintro-family_college","openintro","family_college","Simulated sample of parent / teen college attendance",792,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/family_college.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/family_college.html","family_college R Documentation   Simulated sample of parent / teen college attendance   Description  
A simulated data set based on real population summaries.    Usage    family_college    Format  
A data frame with 792 observations on the following 2 variables.    teen
Whether the teen goes to college or not .   parents
Whether the parent holds a college degree or not .     Source  
Simulation based off of summary information provided at  https://eric.ed.gov/?id=ED460660 .    Examples    library(dplyr) family_college %>% count(teen, parents)"
"openintro-fastfood","openintro","fastfood","Nutrition in fast food",515,17,0,3,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fastfood.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/fastfood.html","fastfood R Documentation   Nutrition in fast food   Description  
Nutrition amounts in 515 fast food items.    Usage    fastfood    Format  
A data frame with 515 observations on the following 17 variables.    restaurant
Name of restaurant   item
Name of item   calories
Number of calories   cal_fat
Calories from fat   total_fat
Total fat   sat_fat
Saturated fat   trans_fat
Trans fat   cholesterol
Cholesterol   sodium
Sodium   total_carb
Total carbs   fiber
Fiber   sugar
Suger   protein
Protein   vit_a
Vitamin A   vit_c
Vitamin C   calcium
Calcium   salad
Salad or not"
"openintro-fcid","openintro","fcid","Summary of male heights from USDA Food Commodity Intake Database",100,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fcid.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/fcid.html","fcid R Documentation   Summary of male heights from USDA Food Commodity Intake Database   Description  
Sample of heights based on the weighted sample in the survey.    Usage    fcid    Format  
A data frame with 100 observations on the following 2 variables.    height
a numeric vector   num_of_adults
a numeric vector     Examples    fcid"
"openintro-fheights","openintro","fheights","Female college student heights, in inches",24,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fheights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/fheights.html","fheights R Documentation   Female college student heights, in inches   Description  
24 sample observations.    Usage    fheights    Format  
A data frame with 24 observations on the following variable.    heights
height, in inches     Examples    hist(fheights$heights)"
"openintro-fish_oil_18","openintro","fish_oil_18","Findings on n-3 Fatty Acid Supplement Health Benefits",2,48,46,0,0,0,48,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/fish_oil_18.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/fish_oil_18.html","fish_oil_18 R Documentation   Findings on n-3 Fatty Acid Supplement Health Benefits   Description  
The results summarize each of the health outcomes for an experiment where 12,933 subjects received a 1g fish oil supplement daily and 12,938 received a placebo daily. The experiment's duration was 5-years.    Usage    fish_oil_18    Format  
The format is a list of 24 matrices. Each matrix is a 2x2 table, and below are the named items in the list, which also represent the outcomes.    major_cardio_event
Major cardiovascular event. (Primary end point.)   cardio_event_expanded
Cardiovascular event in expanded composite endpoint.   myocardioal_infarction
Total myocardial infarction. (Heart attack.)   stroke
Total stroke.   cardio_death
Death from cardiovascular causes.   PCI
Percutaneous coronary intervention.   CABG
Coronary artery bypass graft.   total_coronary_heart_disease
Total coronary heart disease.   ischemic_stroke
Ischemic stroke.   hemorrhagic_stroke
Hemorrhagic stroke.   chd_death
Death from coronary heart disease.   myocardial_infarction_death
Death from myocardial infraction.   stroke_death
Death from stroke.   invasive_cancer
Invasive cancer of any type. (Primary end point.)   breast_cancer
Breast cancer.   prostate_cancer
Prostate cancer.   colorectal_cancer
Colorectal cancer.   cancer_death
Death from cancer.   death
Death from any cause.   major_cardio_event_after_2y
Major cardiovascular event, excluding the first 2 years of follow-up.   myocardial_infarction_after_2y
Total myocardial infarction, excluding the first 2 years of follow-up.   invasive_cancer_after_2y
Invasive cancer of any type, excluding the first 2 years of follow-up.   cancer_death_after_2y
Death from cancer, excluding the first 2 years of follow-up.   death_after_2y
Death from any cause, excluding the first 2 years of follow-up.     Source  
Manson JE, et al. 2018. Marine n-3 Fatty Acids and Prevention of Cardiovascular Disease and Cancer. NEJMoa1811403. doi: 10.1056/NEJMoa1811403 .    Examples    names(fish_oil_18) (tab <- fish_oil_18[[""major_cardio_event""]]) chisq.test(tab) fisher.test(tab) (tab <- fish_oil_18[[""myocardioal_infarction""]]) chisq.test(tab) fisher.test(tab)"
"openintro-flow_rates","openintro","flow_rates","River flow data",31,3,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/flow_rates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/flow_rates.html","flow_rates R Documentation   River flow data   Description  
Flow rates (mesured in cubic feet per second) of Clarks Creek, Leach Creek, Silver Creek, and Wildwood Creek Spring collected by volunteers of the Pierce Conservation District in the State of Washington in the US.    Usage    flow_rates    Format  
A data frame with 31 rows and 3 variables.    site
Location where measurments were taken.   date
Date measurements were taken.   flow
Flow rate of the river in cubic feet per second.     Source  
Pierce County Water Data Viewer .    Examples    library(ggplot2) # River flow rates by site ggplot(flow_rates, aes(x = site, y = flow)) + geom_boxplot() + labs( title = ""River flow rates by site"", x = ""Site"", y = expression(paste(""Flow (ft""^3*""/s)"")) ) # River flow rates over time ggplot(flow_rates, aes(x = date, y = flow, color = site, shape = site)) + geom_point(size = 2) + labs( title = ""River flow rates over time"", x = ""Date"", y = expression(paste(""Flow (ft""^3*""/s)"")), color = ""Site"", shape = ""Site"" )"
"openintro-friday","openintro","friday","Friday the 13th",61,6,0,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/friday.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/friday.html","friday R Documentation   Friday the 13th   Description  
This data set addresses issues of how superstitions regarding Friday the 13th affect human behavior, and whether Friday the 13th is an unlucky day. Scanlon, et al. collected data on traffic and shopping patterns and accident frequency for Fridays the 6th and 13th between October of 1989 and November of 1992.    Usage    friday    Format  
A data frame with 61 observations and 6 variables.    type
Type of observation, traffic , shopping , or accident .   date
Year and month of observation.   sixth
Counts on the 6th of the month.   thirteenth
Counts on the 13th of the month.   diff
Difference between the sixth and the thirteenth.   location
Location where data is collected.     Details  
There are three types of observations: traffic, shopping, and accident. For traffic, the researchers obtained information from the British Department of Transport regarding the traffic flows between junctions 7 to 8 and junctions 9 to 10 of the M25 motorway. For shopping, they collected the numbers of shoppers in nine different supermarkets in southeast England. For accidents, they collected numbers of emergency admissions to hospitals due to transport accidents.    Source  
Scanlon, T.J., Luben, R.N., Scanlon, F.L., Singleton, N. (1993), ""Is Friday the 13th Bad For Your Health?,"" BMJ, 307, 1584-1586.  https://dasl.datadescription.com/datafile/friday-the-13th-traffic and  https://dasl.datadescription.com/datafile/friday-the-13th-accidents .    Examples    library(dplyr) library(ggplot2) friday %>% filter(type == ""traffic"") %>% ggplot(aes(x = sixth)) + geom_histogram(binwidth = 2000) + xlim(110000, 140000) friday %>% filter(type == ""traffic"") %>% ggplot(aes(x = thirteenth)) + geom_histogram(binwidth = 2000) + xlim(110000, 140000)"
"openintro-full_body_scan","openintro","full_body_scan","Poll about use of full-body airport scanners",1137,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/full_body_scan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/full_body_scan.html","full_body_scan R Documentation   Poll about use of full-body airport scanners   Description  
Poll about use of full-body airport scanners, where about 4-in-5 people supported the use of the scanners.    Usage    full_body_scan    Format  
A data frame with 1137 observations on the following 2 variables.    answer
a factor with levels do not know / no answer should should not   party.affiliation
a factor with levels Democrat Independent Republican     Source  
S. Condon. Poll: 4 in 5 Support Full-Body Airport Scanners. In: CBS News (2010).    Examples    full_body_scan"
"openintro-gear_company","openintro","gear_company","Fake data for a gear company example",2000,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gear_company.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gear_company.html","gear_company R Documentation   Fake data for a gear company example   Description  
Made-up data for whether a sample of two gear companies' parts pass inspection.    Usage    gear_company    Format  
A data frame with 2000 observations on the following 2 variables.    company
a factor with levels current   prospective   outcome
a factor with levels not   pass     Examples    gear_company"
"openintro-gender_discrimination","openintro","gender_discrimination","Bank manager recommendations based on gender",48,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gender_discrimination.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gender_discrimination.html","gender_discrimination R Documentation   Bank manager recommendations based on gender   Description  
Study from the 1970s about whether gender influences hiring recommendations.    Usage    gender_discrimination    Format  
A data frame with 48 observations on the following 2 variables.    gender
a factor with levels female and male   decision
a factor with levels not promoted and promoted     Source  
Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel decisions. Journal of Applied Psychology 59(1):9-14.    Examples    library(ggplot2) table(gender_discrimination) ggplot(gender_discrimination, aes(y = gender, fill = decision)) + geom_bar(position = ""fill"")"
"openintro-get_it_dunn_run","openintro","get_it_dunn_run","Get it Dunn Run, Race Times",978,10,3,7,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/get_it_dunn_run.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/get_it_dunn_run.html","get_it_dunn_run R Documentation   Get it Dunn Run, Race Times   Description  
Get it Dunn is a small regional run that got extra attention when a runner, Nichole Porath, made the Guiness Book of World Records for the fastest time pushing a double stroller in a half marathon. This dataset contains results from the 2017 and 2018 races.    Usage    get_it_dunn_run    Format  
A data frame with 978 observations on the following 10 variables.    date
Date of the run.   race
Run distance.   bib_num
Bib number of the runner.   first_name
First name of the runner.   last_initial
Initial of the runner's last name.   sex
Sex of the runner.   age
Age of the runner.   city
City of residence.   state
State of residence.   run_time_minutes
Run time, in minutes.     Source  
Data were collected from GSE Timing:  2018 data ,  2017 race data .    Examples    d <- subset(get_it_dunn_run, race == ""5k"" & date == ""2018-05-12"" & !is.na(age) & state %in% c(""MN"", ""WI"")) head(d) m <- lm(run_time_minutes ~ sex + age + state, d) summary(m) plot(m$fitted, m$residuals) boxplot(m$residuals ~ d$sex) plot(m$residuals ~ d$age) hist(m$residuals)"
"openintro-gifted","openintro","gifted","Analytical skills of young gifted children",36,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gifted.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gifted.html","gifted R Documentation   Analytical skills of young gifted children   Description  
An investigator is interested in understanding the relationship, if any, between the analytical skills of young gifted children and the following variables: father's IQ, mother's IQ, age in month when the child first said ""mummy"" or ""daddy"", age in month when the child first counted to 10 successfully, average number of hours per week the child's mother or father reads to the child, average number of hours per week the child watched an educational program on TV during the past three months, average number of hours per week the child watched cartoons on TV during the past three months. The analytical skills are evaluated using a standard testing procedure, and the score on this test is used as the response variable.    Usage    gifted    Format  
A data frame with 36 observations and 8 variables.    score
Score in test of analytical skills.   fatheriq
Father's IQ.   motheriq
Mother's IQ.   speak
Age in months when the child first said ""mummy"" or ""daddy"".   count
Age in months when the child first counted to 10 successfully.   read
Average number of hours per week the child's mother or father reads to the child.   edutv
Average number of hours per week the child watched an educational program on TV during the past three months.   cartoons
Average number of hours per week the child watched cartoons on TV during the past three months.     Details  
Data were collected from schools in a large city on a set of thirty-six children who were identified as gifted children soon after they reached the age of four.    Source  
Graybill, F.A. & Iyer, H.K., (1994) Regression Analysis: Concepts and Applications, Duxbury, p. 511-6.    Examples    gifted"
"openintro-global_warming_pew","openintro","global_warming_pew","Pew survey on global warming",2253,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/global_warming_pew.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/global_warming_pew.html","global_warming_pew R Documentation   Pew survey on global warming   Description  
A 2010 Pew Research poll asked 1,306 Americans, ""From what you've read and heard, is there solid evidence that the average temperature on earth has been getting warmer over the past few decades, or not?""    Usage    global_warming_pew    Format  
A data frame with 2253 observations on the following 2 variables.    party_or_ideology
a factor with levels  Conservative Republican Liberal Democrat Mod/Cons Democrat Mod/Lib Republican   response
Response.     Source  
Pew Research Center, Majority of Republicans No Longer See Evidence of Global Warming, data collected on October 27, 2010.    Examples    global_warming_pew"
"openintro-goog","openintro","goog","Google stock data",98,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/goog.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/goog.html","goog R Documentation   Google stock data   Description  
Google stock data from 2006 to early 2014, where data from the first day each month was collected.    Usage    goog    Format  
A data frame with 98 observations on the following 7 variables.    date
a factor with levels 2006-01-03 , 2006-02-01 , and so on   open
a numeric vector   high
a numeric vector   low
a numeric vector   close
a numeric vector   volume
a numeric vector   adj_close
a numeric vector     Source  
Yahoo! Finance.    Examples    goog"
"openintro-gov_poll","openintro","gov_poll","Pew Research poll on government approval ratings",4223,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gov_poll.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gov_poll.html","gov_poll R Documentation   Pew Research poll on government approval ratings   Description  
The poll's focus is on Obama and then Democrats and Republicans in Congress.    Usage    gov_poll    Format  
A data frame with 4223 observations on the following 2 variables.    poll
a factor with levels approve   disapprove   eval
a factor with levels Democrats   Obama Republicans     Source  
See the Pew Research website: www.people-press.org/2012/03/14/romney-leads-gop-contest-trails-in- matchup-with-obama. The counts in Table 6.19 are approximate.    Examples    gov_poll"
"openintro-gpa","openintro","gpa","Survey of Duke students on GPA, studying, and more",55,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gpa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gpa.html","gpa R Documentation   Survey of Duke students on GPA, studying, and more   Description  
A survey of 55 Duke University students asked about their GPA, number of hours they study at night, number of nights they go out, and their gender.    Usage    gpa    Format  
A data frame with 55 observations on the following 5 variables.    gpa
a numeric vector   studyweek
a numeric vector   sleepnight
a numeric vector   out
a numeric vector   gender
a factor with levels female male     Examples    gpa"
"openintro-gpa_iq","openintro","gpa_iq","Sample of students and their GPA and IQ",78,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gpa_iq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gpa_iq.html","gpa_iq R Documentation   Sample of students and their GPA and IQ   Description  
Data on 78 students including GPA, IQ, and gender.    Usage    gpa_iq    Format  
A data frame with 78 observations representing students on the following 5 variables.   obs
a numeric vector   gpa
Grade point average (GPA).   iq
IQ.   gender
Gender.   concept
a numeric vector     Examples    gpa_iq"
"openintro-gpa_study_hours","openintro","gpa_study_hours","gpa_study_hours",193,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gpa_study_hours.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gpa_study_hours.html","gpa_study_hours R Documentation   gpa_study_hours   Description  
A data frame with 193 rows and 2 columns. The columns represent the variables gpa and study_hours for a sample of 193 undergraduate students who took an introductory statistics course in 2012 at a private US university.    Usage    gpa_study_hours    Format  
A data frame with 193 observations on the following 2 variables.    gpa
Grade point average (GPA) of student.   study_hours
Number of hours students study per week.     Details  
GPA ranges from 0 to 4 points, however one student reported a GPA > 4. This is a data error but this observation has been left in the dataset as it is used to illustrate issues with real survey data. Both variables are self reported, hence may not be accurate.    Source  
Collected at a private US university as part of an anonymous survey in an introductory statistics course.    Examples    library(ggplot2) ggplot(gpa_study_hours, aes(x = study_hours, y = gpa)) + geom_point(alpha = 0.5) + labs(x = ""Study hours/week"", y = ""GPA"")"
"openintro-gradestv","openintro","gradestv","Simulated data for analyzing the relationship between watching TV and grades",25,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gradestv.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gradestv.html","gradestv R Documentation   Simulated data for analyzing the relationship between watching TV and grades   Description  
This is a simulated data set to be used to estimate the relationship between number of hours per week students watch TV and the grade they got in a statistics class.    Usage    gradestv    Format  
A data frame with 25 observations on the following 2 variables.    tv
Number of hours per week students watch TV.   grades
Grades students got in a statistics class (out of 100).     Details  
There are a few potential outliers in this data set. When analyzing the data one should consider how (if at all) these outliers may affect the estimates of correlation coefficient and regression parameters.    Source  
Simulated data    Examples    library(ggplot2) ggplot(gradestv, aes(x = tv, y = grades)) + geom_point() + geom_smooth(method = ""lm"")"
"openintro-gsearch","openintro","gsearch","Simulated Google search experiment",10000,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gsearch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gsearch.html","gsearch R Documentation   Simulated Google search experiment   Description  
The data were simulated to look like sample results from a Google search experiment.    Usage    gsearch    Format  
A data frame with 10000 observations on the following 2 variables.    type
a factor with levels new search no new search   outcome
a factor with levels current test 1 test 2     Examples    library(ggplot2) table(gsearch$type, gsearch$outcome) ggplot(gsearch, aes(x = type, fill = outcome)) + geom_bar(position = ""fill"") + labs(y = ""proportion"")"
"openintro-gss2010","openintro","gss2010","2010 General Social Survey",2044,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/gss2010.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/gss2010.html","gss2010 R Documentation   2010 General Social Survey   Description  
Data from the 2010 General Social Survey.    Usage    gss2010    Format  
A data frame with 2044 observations on the following 5 variables.    hrsrelax
After an average work day, about how many hours do you have to relax or pursue activities that you enjoy   mntlhlth
For how many days during the past 30 days was your mental health, which includes stress, depression, and problems with emotions, not good?   hrs1
Hours worked each week.   degree
Educational attainment or degree.   grass
Do you think the use of marijuana should be made legal, or not?     Source  
US 2010 General Social Survey.    Examples    gss2010"
"openintro-health_coverage","openintro","health_coverage","Health Coverage and Health Status",20000,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/health_coverage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/health_coverage.html","health_coverage R Documentation   Health Coverage and Health Status   Description  
Survey responses for 20,000 responses to the Behavioral Risk Factor Surveillance System.    Usage    health_coverage    Format  
A data frame with 20000 observations on the following 2 variables.    coverage
Whether the person had health coverage or not.   health_status
The person's health status.     Source  
Office of Surveillance, Epidemiology, and Laboratory Services Behavioral Risk Factor Surveillance System, BRFSS 2010 Survey Data.    Examples    table(health_coverage)"
"openintro-healthcare_law_survey","openintro","healthcare_law_survey","Pew Research Center poll on health care, including question variants",1503,2,1,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/healthcare_law_survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/healthcare_law_survey.html","healthcare_law_survey R Documentation   Pew Research Center poll on health care, including question variants   Description  
For example, Pew Research Center conducted a survey with the following question: ""As you may know, by 2014 nearly all Americans will be required to have health insurance. People who do not buy insurance will pay a penalty while people who cannot afford it will receive financial help from the government. Do you approve or disapprove of this policy?"" For each randomly sampled respondent, the statements in brackets were randomized: either they were kept in the order given above, or the two statements were reversed.    Usage    healthcare_law_survey    Format  
A data frame with 1503 observations on the following 2 variables.    order
a factor with levels cannot_afford_second   penalty_second   response
a factor with levels approve   disapprove other     Source  
www.people-press.org/2012/03/26/public-remains-split-on-health-care-bill-opposed-to-mandate/. Sample sizes for each polling group are approximate.    Examples    healthcare_law_survey"
"openintro-heart_transplant","openintro","heart_transplant","Heart Transplant Data",103,8,3,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/heart_transplant.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/heart_transplant.html","heart_transplant R Documentation   Heart Transplant Data   Description  
The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated officially a heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Then the actual heart transplant occurs between a few weeks to several months depending on the availability of a donor. Very few candidates during this waiting period show improvement and get  deselected as a heart transplant candidate, but for the purposes of this experiment those patients were kept in the data as continuing candidates.    Usage    heart_transplant    Format  
A data frame with 103 observations on the following 8 variables.    id
ID number of the patient.   acceptyear
Year of acceptance as a heart transplant candidate.   age
Age of the patient at the beginning of the study.   survived
Survival status with levels alive and dead .   survtime
Number of days patients were alive after the date they were determined to be a candidate for a heart transplant until the termination date of the study   prior
Whether or not the patient had prior surgery with levels  yes and no .   transplant
Transplant status with levels control (did not receive a transplant) and treatment (received a transplant).   wait
Waiting Time for Transplant     Source  
http://www.stat.ucla.edu/~jsanchez/data/stanford.txt     References  
Turnbull B, Brown B, and Hu M (1974). ""Survivorship of heart transplant data."" Journal of the American Statistical Association, vol. 69, pp. 74-80.    Examples    library(ggplot2) ggplot(heart_transplant, aes(x = transplant, y = survtime)) + geom_boxplot() + labs(x = ""Transplant"", y = ""Survival time (days)"") ggplot(heart_transplant, aes(x = transplant, fill = survived)) + geom_bar(position = ""fill"") + labs(x = ""Transplant"", y = ""Proportion"", fill = ""Outcome"")"
"openintro-helium","openintro","helium","Helium football",39,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/helium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/helium.html","helium R Documentation   Helium football   Description  
At the 1976 Pro Bowl, Ray Guy, a punter for the Oakland Raiders, punted a ball that hung mid-air long enough for officials to question whether the pigskin was filled with helium. The ball was found to be filled with air, but since then many have tossed around the idea that a helium-filled football would outdistance an air-filled one. Students at Ohio State University conducted an experiment to test this myth. They used two identical footballs, one air filled with air and one filled with helium. Each football was kicked 39 times and the two footballs were alternated with each kick.    Usage    helium    Format  
A data frame with 39 observations on the following 3 variables.    trial
Trial number.   air
Distance in years for air-filled football.   helium
Distance in years for helium-filled football.     Details  
Lafferty, M. B. (1993), ""OSU scientists get a kick out of sports controversy, ""The Columbus Dispatch (November, 21, 1993), B7.    Source  
Previously part of the Data and Story Library, https://dasl.datadescription.com . Removed as of 2020.    Examples    boxPlot(helium$air, xlab = ""air"") boxPlot(helium$helium, xlab = ""helium"")"
"openintro-helmet","openintro","helmet","Socioeconomic status and reduced-fee school lunches",12,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/helmet.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/helmet.html","helmet R Documentation   Socioeconomic status and reduced-fee school lunches   Description  
Examining the relationship between socioeconomic status measured as the percentage of children in a neighborhood receiving reduced-fee lunches at school (lunch) and the percentage of bike riders in the neighborhood wearing helmets (helmet).    Usage    helmet    Format  
A data frame with 12 observations representing neighborhoods on the following 2 variables.    lunch
Percent of students receiving reduced-fee school lunches.   helmet
Percent of bike riders wearing helmets.     Examples    library(ggplot2) ggplot(helmet, aes(x = lunch, y = helmet)) + geom_point()"
"openintro-hfi","openintro","hfi","Human Freedom Index",1458,123,0,3,0,0,120,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/hfi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/hfi.html","hfi R Documentation   Human Freedom Index   Description  
The Human Freedom Index is a report that attempts to summarize the idea of ""freedom"" through a bunch of different variables for many countries around the globe. It serves as a rough objective measure for the relationships between the different types of freedom - whether it's political, religious, economical or personal freedom - and other social and economic circumstances. The Human Freedom Index is an annually co-published report by the Cato Institute, the Fraser Institute, and the Liberales Institut at the Friedrich Naumann Foundation for Freedom.    Usage    hfi    Format  
A data frame with 1458 observations on the following 123 variables.    year
Year   ISO_code
ISO code of country   countries
Name of country   region
Region where country is located   pf_rol_procedural
Procedural justice   pf_rol_civil
Civil justice   pf_rol_criminal
Criminal justice   pf_rol
Rule of law   pf_ss_homicide
Homicide   pf_ss_disappearances_disap
Disappearances   pf_ss_disappearances_violent
Violent conflicts   pf_ss_disappearances_organized
Violent conflicts   pf_ss_disappearances_fatalities
Terrorism fatalities   pf_ss_disappearances_injuries
Terrorism injuries   pf_ss_disappearances
Disappearances, conflict, and terrorism   pf_ss_women_fgm
Female genital mutilation   pf_ss_women_missing
Missing women   pf_ss_women_inheritance_widows
Inheritance rights for widows   pf_ss_women_inheritance_daughters
Inheritance rights for daughters   pf_ss_women_inheritance
Inheritance   pf_ss_women
Women's security   pf_ss
Security and safety   pf_movement_domestic
Freedom of domestic movement   pf_movement_foreign
Freedom of foreign movement   pf_movement_women
Women's movement   pf_movement
Freedom of movement   pf_religion_estop_establish
Freedom to establish religious organizations   pf_religion_estop_operate
Freedom to operate religious organizations   pf_religion_estop
Freedom to establish and operate religious organizations   pf_religion_harassment
Harassment and physical hostilities   pf_religion_restrictions
Legal and regulatory restrictions   pf_religion
Religious freedom   pf_association_association
Freedom of association   pf_association_assembly
Freedom of assembly   pf_association_political_establish
Freedom to establish political parties   pf_association_political_operate
Freedom to operate political parties   pf_association_political
Freedom to establish and operate political parties   pf_association_prof_establish
Freedom to establish professional organizations   pf_association_prof_operate
Freedom to operate professional organizations   pf_association_prof
Freedom to establish and operate professional organizations   pf_association_sport_establish
Freedom to establish educational, sporting, and cultural organizations   pf_association_sport_operate
Freedom to operate educational, sporting, and cultural organizations   pf_association_sport
Freedom to establish and operate educational, sporting, and cultural organizations   pf_association
Freedom to associate and assemble with peaceful individuals or organizations   pf_expression_killed
Press killed   pf_expression_jailed
Press jailed   pf_expression_influence
Laws and regulations that influence media content   pf_expression_control
Political pressures and controls on media content   pf_expression_cable
Access to cable/satellite   pf_expression_newspapers
Access to foreign newspapers   pf_expression_internet
State control over internet access   pf_expression
Freedom of expression   pf_identity_legal
Legal gender   pf_identity_parental_marriage
Parental rights in marriage   pf_identity_parental_divorce
Parental rights after divorce   pf_identity_parental
Parental rights   pf_identity_sex_male
Male-to-male relationships   pf_identity_sex_female
Female-to-female relationships   pf_identity_sex
Same-sex relationships   pf_identity_divorce
Divor   pf_identity
Identity and relationships   pf_score
Personal Freedom (score)   pf_rank
Personal Freedom (rank)   ef_government_consumption
Government consumption   ef_government_transfers
Transfers and subsidies   ef_government_enterprises
Government enterprises and investments   ef_government_tax_income
Top marginal income tax rate - Top marginal income tax rates   ef_government_tax_payroll
Top marginal income tax rate - Top marginal income and payroll tax rate   ef_government_tax
Top marginal tax rate   ef_government
Size of government   ef_legal_judicial
Judicial independence   ef_legal_courts
Impartial courts   ef_legal_protection
Protection of property rights   ef_legal_military
Military interference in rule of law and politics   ef_legal_integrity
Integrity of the legal system   ef_legal_enforcement
Legal enforcement of contracts   ef_legal_restrictions
Regulatory restrictions on the sale of real property   ef_legal_police
Reliability of police   ef_legal_crime
Business costs of crime   ef_legal_gender
Gender adjustment   ef_legal
Legal system and property rights   ef_money_growth
Money growth   ef_money_sd
Standard deviation of inflation   ef_money_inflation
Inflation - most recent year   ef_money_currency
Freedom to own foreign currency bank account   ef_money
Sound money   ef_trade_tariffs_revenue
Tariffs - Revenue from trade taxes (percentage of trade sector)   ef_trade_tariffs_mean
Tariffs - Mean tariff rate   ef_trade_tariffs_sd
Tariffs - Standard deviation of tariffs rates   ef_trade_tariffs
Tariffs   ef_trade_regulatory_nontariff
Regulatory trade barriers - Nontariff trade barriers   ef_trade_regulatory_compliance
Regulatory trade barriers - Compliance costs of importing and exporting   ef_trade_regulatory
Regulatory trade barriers   ef_trade_black
Black-market exchange rates   ef_trade_movement_foreign
Controls of the movement of capital and people - Foreign ownership/investment restrictions   ef_trade_movement_capital
Controls of the movement of capital and people - Capital controls   ef_trade_movement_visit
Controls of the movement of capital and people - Freedom of foreigners to visit   ef_trade_movement
Controls of the movement of capital and people   ef_trade
Freedom to trade internationally   ef_regulation_credit_ownership
Credit market regulations - Ownership of banks   ef_regulation_credit_private
Credit market regulations - Private sector credit   ef_regulation_credit_interest
Credit market regulations - Interest rate controls/negative real interest rates   ef_regulation_credit
Credit market regulation   ef_regulation_labor_minwage
Labor market regulations - Hiring regulations and minimum wage   ef_regulation_labor_firing
Labor market regulations - Hiring and firing regulations   ef_regulation_labor_bargain
Labor market regulations - Centralized collective bargaining   ef_regulation_labor_hours
Labor market regulations - Hours regulations   ef_regulation_labor_dismissal
Labor market regulations - Dismissal regulations   ef_regulation_labor_conscription
Labor market regulations - Conscription   ef_regulation_labor
Labor market regulation   ef_regulation_business_adm
Business regulations - Administrative requirements   ef_regulation_business_bureaucracy
Business regulations - Bureaucracy costs   ef_regulation_business_start
Business regulations - Starting a business   ef_regulation_business_bribes
Business regulations - Extra payments/bribes/favoritism   ef_regulation_business_licensing
Business regulations - Licensing restrictions   ef_regulation_business_compliance
Business regulations - Cost of tax compliance   ef_regulation_business
Business regulation   ef_regulation
Economic freedom regulation score   ef_score
Economic freedom score   ef_rank
Economic freedom rank   hf_score
Human freedom score   hf_rank
Human freedom rank   hf_quartile
Human freedom quartile     Details  
This dataset contains information from Human Freedom Index reports from 2008-2016.    Source  
Ian Vasquez and Tanja Porcnik, The Human Freedom Index 2018: A Global Measurement of Personal, Civil, and Economic Freedom (Washington: Cato Institute, Fraser Institute, and the Friedrich Naumann Foundation for Freedom, 2018).  https://www.cato.org/sites/cato.org/files/human-freedom-index-files/human-freedom-index-2016.pdf .  https://www.kaggle.com/gsutters/the-human-freedom-index ."
"openintro-house","openintro","house","United States House of Representatives historical make-up",116,12,0,2,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/house.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/house.html","house R Documentation   United States House of Representatives historical make-up   Description  
The make-up of the United States House of Representatives every two years since 1789. The last Congress included is the 112th Congress, which completed its term in 2013.    Usage    house    Format  
A data frame with 112 observations on the following 12 variables.    congress
The number of that year's Congress   year_start
Starting year   year_end
Ending year   seats
Total number of seats   p1
Name of the first political party   np1
Number of seats held by the first political party   p2
Name of the second political party   np2
Number of seats held by the second political party   other
Other   vac
Vacancy   del
Delegate   res
Resident commissioner     Source  
Party Divisions of the House of Representatives, 1789 to Present.  https://history.house.gov/Institution/Party-Divisions/Party-Divisions .    Examples    library(dplyr) library(ggplot2) library(forcats) # Examine two-party relationship since 1855 house_since_1855 <- house %>% filter(year_start >= 1855) %>% mutate( p1_perc = 100 * np1 / seats, p2_perc = 100 * np2 / seats, era = case_when( between(year_start, 1861, 1865) ~ ""Civil War"", between(year_start, 1914, 1918) ~ ""World War I"", between(year_start, 1929, 1939) ~ ""Great Depression"", between(year_start, 1940, 1945) ~ ""World War II"", between(year_start, 1960, 1965) ~ ""Vietnam War Start"", between(year_start, 1965, 1975) ~ ""Vietnam War Escalated"", TRUE ~ NA_character_ ), era = fct_relevel(era, ""Civil War"", ""World War I"", ""Great Depression"", ""World War II"", ""Vietnam War Start"", ""Vietnam War Escalated"") ) ggplot(house_since_1855, aes(x = year_start)) + geom_rect(aes(xmin = year_start, xmax = lead(year_start), ymin = -Inf, ymax = Inf, fill = era)) + geom_line(aes(y = p1_perc, color = ""Democrats"")) + # Democrats geom_line(aes(y = p2_perc, color = ""Republicans"")) + # Republicans scale_fill_brewer(palette = ""Pastel1"", na.translate = FALSE) + scale_color_manual( name = ""Party"", values = c(""Democrats"" = ""blue"", ""Republicans"" = ""red""), labels = c(""Democrats"", ""Republicans"") ) + theme_minimal() + ylim(0, 100) + labs(x = ""Year"", y = ""Percentage of seats"", fill = ""Era"")"
"openintro-housing","openintro","housing","Simulated data set on student housing",75,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/housing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/housing.html","housing R Documentation   Simulated data set on student housing   Description  
Each observation represents a simulated rent price for a student.    Usage    housing    Format  
A data frame with 75 observations on the following variable.    cost
a numeric vector     Examples    housing"
"openintro-hsb2","openintro","hsb2","High School and Beyond survey",200,11,2,2,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/hsb2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/hsb2.html","hsb2 R Documentation   High School and Beyond survey   Description  
Two hundred observations were randomly sampled from the High School and Beyond survey, a survey conducted on high school seniors by the National Center of Education Statistics.    Usage    hsb2    Format  
A data frame with 200 observations and 11 variables.   id
Student ID.   gender
Student's gender, with levels  female and male .   race
Student's race, with levels  african american , asian , hispanic , and white .   ses
Socio economic status of student's family, with levels  low , middle , and high .   schtyp
Type of school, with levels public and private .   prog
Type of program, with levels general , academic , and vocational .   read
Standardized reading score.   write
Standardized writing score.   math
Standardized math score.   science
Standardized science score.   socst
Standardized social studies score.     Source  
UCLA Institute for Digital Research & Education - Statistical Consulting.    Examples    library(ggplot2) ggplot(hsb2, aes(x = read - write, y = ses)) + geom_boxplot() + labs( x = ""Difference between reading and writing scores"", y = ""Socio-economic status"" )"
"openintro-husbands_wives","openintro","husbands_wives","Great Britain: husband and wife pairs",199,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/husbands_wives.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/husbands_wives.html","husbands_wives R Documentation   Great Britain: husband and wife pairs   Description  
The Great Britain Office of Population Census and Surveys once collected data on a random sample of 170 married couples in Britain, recording the age (in years) and heights of the husbands and wives.    Usage    husbands_wives    Format  
A data frame with 199 observations on the following 8 variables.    age_husband
Age of husband.   age_wife
Age of wife.   ht_husband
Height of husband (mm).   ht_wife
Height of wife (mm).   age_husb_at_marriage
Age of husband at the time they married.   age_wife_at_marriage
Age of wife at the time they married.   years_married
Number of years married.     Source  
Hand DJ. 1994. A handbook of small data sets. Chapman & Hall/CRC.    Examples    library(ggplot2) ggplot(husbands_wives, aes(x = ht_husband, y = ht_wife)) + geom_point()"
"openintro-immigration","openintro","immigration","Poll on illegal workers in the US",910,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/immigration.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/immigration.html","immigration R Documentation   Poll on illegal workers in the US   Description  
910 randomly sampled registered voters in Tampa, FL were asked if they thought workers who have illegally entered the US should be (i) allowed to keep their jobs and apply for US citizenship, (ii) allowed to keep their jobs as temporary guest workers but not allowed to apply for US citizenship, or (iii) lose their jobs and have to leave the country as well as their political ideology.    Usage    immigration    Format  
A data frame with 910 observations on the following 2 variables.    response
a factor with levels Apply for citizenship   Guest worker Leave the country Not sure   political
a factor with levels conservative liberal   moderate     Source  
SurveyUSA, News Poll #18927, data collected Jan 27-29, 2012.    Examples    immigration"
"openintro-IMSCOL","openintro","IMSCOL","Introduction to Modern Statistics (IMS) Colors",8,13,0,13,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/IMSCOL.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/IMSCOL.html","IMSCOL R Documentation   Introduction to Modern Statistics (IMS) Colors   Description  
These are the core colors used for the Introduction to Modern Statistics textbook. The blue, green, pink, yellow, and red colors are also gray-scaled, meaning no changes are required when printing black and white copies.    Usage    IMSCOL    Format  
A 8-by-13 matrix of 7 colors with four fading scales: blue, green, pink, yellow, red, black, gray, and light gray.    Examples    plot(1:7, 7:1, col=IMSCOL, pch=19, cex=6, xlab="""", ylab="""", xlim=c(0.5,7.5), ylim=c(-2.5,8), axes=FALSE) text(1:7, 7:1+0.7, paste(""IMSCOL["", 1:7, ""]"", sep=""""), cex=0.9) points(1:7, 7:1-0.7, col=IMSCOL[,2], pch=19, cex=6) points(1:7, 7:1-1.4, col=IMSCOL[,3], pch=19, cex=6) points(1:7, 7:1-2.1, col=IMSCOL[,4], pch=19, cex=6)"
"openintro-infmortrate","openintro","infmortrate","Infant Mortality Rates, 2012",222,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/infmortrate.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/infmortrate.html","infmortrate R Documentation   Infant Mortality Rates, 2012   Description  
This entry gives the number of deaths of infants under one year old in 2012 per 1,000 live births in the same year. This rate is often used as an indicator of the level of health in a country.    Usage    infmortrate    Format  
A data frame with 222 observations on the following 2 variables.    country
Name of country.   inf_mort_rate
Infant mortality rate per 1,000 live births.     Details  
The data is given in decreasing order of infant mortality rates. There are a few potential outliers.    Source  
CIA World Factbook,  https://www.cia.gov/the-world-factbook/field/infant-mortality-rate/country-comparison .    Examples    library(ggplot2) ggplot(infmortrate, aes(x = inf_mort_rate)) + geom_histogram(binwidth = 10) ggplot(infmortrate, aes(x = inf_mort_rate)) + geom_density()"
"openintro-ipod","openintro","ipod","Length of songs on an iPod",3000,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ipod.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ipod.html","ipod R Documentation   Length of songs on an iPod   Description  
A simulated data set on lengths of songs on an iPod.    Usage    ipod    Format  
A data frame with 3000 observations on the following variable.    song_length
Length of song (in minutes).     Source  
Simulated data.    Examples    library(ggplot2) ggplot(ipod, aes(x = song_length)) + geom_histogram(binwidth = 0.5)"
"openintro-jury","openintro","jury","Simulated juror data set",275,1,0,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/jury.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/jury.html","jury R Documentation   Simulated juror data set   Description  
Simulated data set of registered voters proportions and representation on juries.    Usage    jury    Format  
A data frame with 275 observations on the following variable.    race
a factor with levels black hispanic   other white     Examples    jury"
"openintro-kobe_basket","openintro","kobe_basket","Kobe Bryant basketball performance",133,6,1,1,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/kobe_basket.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/kobe_basket.html","kobe_basket R Documentation   Kobe Bryant basketball performance   Description  
Data from the five games the Los Angeles Lakers played against the Orlando Magic in the 2009 NBA finals.    Usage    kobe_basket    Format  
A data frame with 133 rows and 6 variables:    vs
A categorical vector, ORL if the Los Angeles Lakers played against Orlando   game
A numerical vector, game in the 2009 NBA finals   quarter
A categorical vector, quarter in the game, OT stands for overtime   time
A character vector, time at which Kobe took a shot   description
A character vector, description of the shot   shot
A categorical vector, H if the shot was a hit, M if the shot was a miss     Details  
Each row represents a shot Kobe Bryant took during the five games of the 2009 NBA finals. Kobe Bryant's performance earned him the title of Most Valuable Player and many spectators commented on how he appeared to show a hot hand."
"openintro-law_resume","openintro","law_resume","Gender, Socioeconomic Class, and Interview Invites",316,3,3,3,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/law_resume.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/law_resume.html","law_resume R Documentation   Gender, Socioeconomic Class, and Interview Invites   Description  
Resumes were sent out to 316 top law firms in the United States, and there were two randomized characteristics of each resume. First, the gender associated with the resume was randomized by assigning a first name of either James or Julia. Second, the socioeconomic class of the candidate was randomly assigned and represented through five minor changes associated with personal interests and other other minor details (e.g. an extracurricular activity of sailing team vs track and field). The outcome variable was whether the candidate was received an interview.    Usage    law_resume    Format  
A data frame with 316 observations on the following 3 variables. Each row represents a resume sent a top law firm for this experiment.    class
The resume represented irrelevant details suggesting either ""low"" or ""high"" socioeconomic class.   gender
The resume implied the candidate was either ""male"" or ""female"" .   outcome
If the candidate received an invitation for an  ""interview"" or ""not"" .     Source  
For a casual overview, see  https://hbr.org/2016/12/research-how-subtle-class-cues-can-backfire-on-your-resume .   
For the academic paper, see Tilcsik A, Rivera LA. 2016. Class Advantage, Commitment Penalty. The Gendered Effect of Social Class Signals in an Elite Labor Market. American Sociological Review 81:6 p1097-1131. doi: 10.1177/0003122416668154 .    Examples    tapply(law_resume$outcome == ""interview"", law_resume[, c(""class"", ""gender"")], mean) m <- glm(I(outcome == ""interview"") ~ gender * class, data = law_resume, family = binomial) summary(m) predict(m, type = ""response"")"
"openintro-leg_mari","openintro","leg_mari","Legalization of Marijuana Support in 2010 California Survey",119,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/leg_mari.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/leg_mari.html","leg_mari R Documentation   Legalization of Marijuana Support in 2010 California Survey   Description  
In a 2010 Survey USA poll, 70% of the 119 respondents between the ages of 18 and 34 said they would vote in the 2010 general election for Prop 19, which would change California law to legalize marijuana and allow it to be regulated and taxed.    Usage    leg_mari    Format  
A data frame with 119 observations on the following variable.    response
One of two values: oppose or  support .     Source  
Survey USA, Election Poll #16804, data collected July 8-11, 2010.    Examples    table(leg_mari)"
"openintro-lizard_habitat","openintro","lizard_habitat","Field data on lizards observed in their natural habitat",332,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/lizard_habitat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/lizard_habitat.html","lizard_habitat R Documentation   Field data on lizards observed in their natural habitat   Description  
Data on here lizard was observed and the level of sunlight. The data are collected on Sceloporus occidentalis (western fence lizards) by Stephen C. Adolph in 1983 (in desert and mountain sites) and by Dee Asbury in 2002-3 (in valley site).    Usage    lizard_habitat    Format  
A data frame with 332 observations on the following 2 variables.    site
Site of lizard observation: desert , mountain , or valley .   sunlight
Sunlight level at time of observation:  sun (lizard was observed perching in full sunlight),  partial (lizard was observed perching with part of its body in the sun, part in the shade),  shade (lizard was observed perching in the shade).     Source  
Adolph, S. C. 1990. Influence of behavioral thermoregulation on microhabitat use by two Sceloporus lizards. Ecology 71: 315-327. Asbury, D.A., and S. C. Adolph. 2007. Behavioral plasticity in an ecological generalist: microhabitat use by western fence lizards. Evolutionary Ecology Research 9:801-815.    Examples    library(ggplot2) # Frequencies table(lizard_habitat) # Stacked bar plots ggplot(lizard_habitat, aes(y = site, fill = sunlight)) + geom_bar(position = ""fill"") + labs(x = ""Proportion"")"
"openintro-lizard_run","openintro","lizard_run","Lizard speeds",48,3,2,2,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/lizard_run.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/lizard_run.html","lizard_run R Documentation   Lizard speeds   Description  
Data on top speeds measured on a laboratory race track for two species of lizards: Western fence lizard (Sceloporus occidentalis) and Sagebrush lizard (Sceloporus graciosus).    Usage    lizard_run    Format  
A data frame with 48 observations on the following 3 variables.    top_speed
Top speed of lizard, meters per second.   common_name
Common name: Western fence lizard and Sagebrush lizard .   scientific_name
Scientific name (Genus and species): Sceloporus occidentalis and Sceloporus graciosus .     Source  
Adolph, S. C. 1987. Physiological and behavioral ecology of the lizards Sceloporus occidentalis and Sceloporus graciosus. Dissertation. University of Washington, Seattle, Washington, USA.    Examples    library(ggplot2) library(dplyr) # Top speed by species ggplot(lizard_run, aes(x = top_speed, color = common_name, fill = common_name)) + geom_density(alpha = 0.5) # Top speed summary statistics by species lizard_run %>% group_by(common_name) %>% summarise( n = n(), mean = mean(top_speed), sd = sd(top_speed) )"
"openintro-loan50","openintro","loan50","Loan data from Lending Club",50,18,4,0,6,1,11,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/loan50.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/loan50.html","loans_full_schema R Documentation   Loan data from Lending Club   Description  
This data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is a essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications!    Usage    loans_full_schema    Format  
A data frame with 10,000 observations on the following 55 variables.    emp_title
Job title.   emp_length
Number of years in the job, rounded down. If longer than 10 years, then this is represented by the value  10 .   state
Two-letter state code.   home_ownership
The ownership status of the applicant's residence.   annual_income
Annual income.   verified_income
Type of verification of the applicant's income.   debt_to_income
Debt-to-income ratio.   annual_income_joint
If this is a joint application, then the annual income of the two parties applying.   verification_income_joint
Type of verification of the joint income.   debt_to_income_joint
Debt-to-income ratio for the two parties.   delinq_2y
Delinquencies on lines of credit in the last 2 years.   months_since_last_delinq
Months since the last delinquency.   earliest_credit_line
Year of the applicant's earliest line of credit   inquiries_last_12m
Inquiries into the applicant's credit during the last 12 months.   total_credit_lines
Total number of credit lines in this applicant's credit history.   open_credit_lines
Number of currently open lines of credit.   total_credit_limit
Total available credit, e.g. if only credit cards, then the total of all the credit limits. This excludes a mortgage.   total_credit_utilized
Total credit balance, excluding a mortgage.   num_collections_last_12m
Number of collections in the last 12 months. This excludes medical collections.   num_historical_failed_to_pay
The number of derogatory public records, which roughly means the number of times the applicant failed to pay.   months_since_90d_late
Months since the last time the applicant was 90 days late on a payment.   current_accounts_delinq
Number of accounts where the applicant is currently delinquent.   total_collection_amount_ever
The total amount that the applicant has had against them in collections.   current_installment_accounts
Number of installment accounts, which are (roughly) accounts with a fixed payment amount and period. A typical example might be a 36-month car loan.   accounts_opened_24m
Number of new lines of credit opened in the last 24 months.   months_since_last_credit_inquiry
Number of months since the last credit inquiry on this applicant.   num_satisfactory_accounts
Number of satisfactory accounts.   num_accounts_120d_past_due
Number of current accounts that are 120 days past due.   num_accounts_30d_past_due
Number of current accounts that are 30 days past due.   num_active_debit_accounts
Number of currently active bank cards.   total_debit_limit
Total of all bank card limits.   num_total_cc_accounts
Total number of credit card accounts in the applicant's history.   num_open_cc_accounts
Total number of currently open credit card accounts.   num_cc_carrying_balance
Number of credit cards that are carrying a balance.   num_mort_accounts
Number of mortgage accounts.   account_never_delinq_percent
Percent of all lines of credit where the applicant was never delinquent.   tax_liens
a numeric vector   public_record_bankrupt
Number of bankruptcies listed in the public record for this applicant.   loan_purpose
The category for the purpose of the loan.   application_type
The type of application: either  individual or joint .   loan_amount
The amount of the loan the applicant received.   term
The number of months of the loan the applicant received.   interest_rate
Interest rate of the loan the applicant received.   installment
Monthly payment for the loan the applicant received.   grade
Grade associated with the loan.   sub_grade
Detailed grade associated with the loan.   issue_month
Month the loan was issued.   loan_status
Status of the loan.   initial_listing_status
Initial listing status of the loan. (I think this has to do with whether the lender provided the entire loan or if the loan is across multiple lenders.)   disbursement_method
Dispersement method of the loan.   balance
Current balance on the loan.   paid_total
Total that has been paid on the loan by the applicant.   paid_principal
The difference between the original loan amount and the current balance on the loan.   paid_interest
The amount of interest paid so far by the applicant.   paid_late_fees
Late fees paid by the applicant.     Source  
This data comes from Lending Club ( https://www.lendingclub.com/info/statistics.action ), which provides a very large, open set of data on the people who received loans through their platform.    Examples    loans_full_schema"
"openintro-loans_full_schema","openintro","loans_full_schema","Loan data from Lending Club",10000,55,6,1,12,0,42,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/loans_full_schema.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/loans_full_schema.html","loans_full_schema R Documentation   Loan data from Lending Club   Description  
This data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is a essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications!    Usage    loans_full_schema    Format  
A data frame with 10,000 observations on the following 55 variables.    emp_title
Job title.   emp_length
Number of years in the job, rounded down. If longer than 10 years, then this is represented by the value  10 .   state
Two-letter state code.   home_ownership
The ownership status of the applicant's residence.   annual_income
Annual income.   verified_income
Type of verification of the applicant's income.   debt_to_income
Debt-to-income ratio.   annual_income_joint
If this is a joint application, then the annual income of the two parties applying.   verification_income_joint
Type of verification of the joint income.   debt_to_income_joint
Debt-to-income ratio for the two parties.   delinq_2y
Delinquencies on lines of credit in the last 2 years.   months_since_last_delinq
Months since the last delinquency.   earliest_credit_line
Year of the applicant's earliest line of credit   inquiries_last_12m
Inquiries into the applicant's credit during the last 12 months.   total_credit_lines
Total number of credit lines in this applicant's credit history.   open_credit_lines
Number of currently open lines of credit.   total_credit_limit
Total available credit, e.g. if only credit cards, then the total of all the credit limits. This excludes a mortgage.   total_credit_utilized
Total credit balance, excluding a mortgage.   num_collections_last_12m
Number of collections in the last 12 months. This excludes medical collections.   num_historical_failed_to_pay
The number of derogatory public records, which roughly means the number of times the applicant failed to pay.   months_since_90d_late
Months since the last time the applicant was 90 days late on a payment.   current_accounts_delinq
Number of accounts where the applicant is currently delinquent.   total_collection_amount_ever
The total amount that the applicant has had against them in collections.   current_installment_accounts
Number of installment accounts, which are (roughly) accounts with a fixed payment amount and period. A typical example might be a 36-month car loan.   accounts_opened_24m
Number of new lines of credit opened in the last 24 months.   months_since_last_credit_inquiry
Number of months since the last credit inquiry on this applicant.   num_satisfactory_accounts
Number of satisfactory accounts.   num_accounts_120d_past_due
Number of current accounts that are 120 days past due.   num_accounts_30d_past_due
Number of current accounts that are 30 days past due.   num_active_debit_accounts
Number of currently active bank cards.   total_debit_limit
Total of all bank card limits.   num_total_cc_accounts
Total number of credit card accounts in the applicant's history.   num_open_cc_accounts
Total number of currently open credit card accounts.   num_cc_carrying_balance
Number of credit cards that are carrying a balance.   num_mort_accounts
Number of mortgage accounts.   account_never_delinq_percent
Percent of all lines of credit where the applicant was never delinquent.   tax_liens
a numeric vector   public_record_bankrupt
Number of bankruptcies listed in the public record for this applicant.   loan_purpose
The category for the purpose of the loan.   application_type
The type of application: either  individual or joint .   loan_amount
The amount of the loan the applicant received.   term
The number of months of the loan the applicant received.   interest_rate
Interest rate of the loan the applicant received.   installment
Monthly payment for the loan the applicant received.   grade
Grade associated with the loan.   sub_grade
Detailed grade associated with the loan.   issue_month
Month the loan was issued.   loan_status
Status of the loan.   initial_listing_status
Initial listing status of the loan. (I think this has to do with whether the lender provided the entire loan or if the loan is across multiple lenders.)   disbursement_method
Dispersement method of the loan.   balance
Current balance on the loan.   paid_total
Total that has been paid on the loan by the applicant.   paid_principal
The difference between the original loan amount and the current balance on the loan.   paid_interest
The amount of interest paid so far by the applicant.   paid_late_fees
Late fees paid by the applicant.     Source  
This data comes from Lending Club ( https://www.lendingclub.com/info/statistics.action ), which provides a very large, open set of data on the people who received loans through their platform.    Examples    loans_full_schema"
"openintro-london_boroughs","openintro","london_boroughs","London Borough Boundaries",45341,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/london_boroughs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/london_boroughs.html","london_boroughs R Documentation   London Borough Boundaries   Description  
This dataset contains the coordinates of the boundaries of all 32 boroughs of the Greater London area.    Usage    london_boroughs    Format  
A data frame with 45341 observations on the following 3 variables.    borough
Name of the borough.   x
The ""easting"" component of the coordinate, see details.   y
The ""northing"" component of the coordinate, see details.     Details  
Map data was made available through the Ordnance Survey Open Data initiative. The data use the  National Grid coordinate system, based upon eastings ( x ) and northings ( y ) instead of longitude and latitude.   
The name variable covers all 32 boroughs in Greater London:  Barking & Dagenham , Barnet , Bexley , Brent ,  Bromley , Camden , Croydon , Ealing ,  Enfield , Greenwich , Hackney , Hammersmith & Fulham , Haringey , Harrow , Havering , Hillingdon ,  Hounslow , Islington , Kensington & Chelsea ,  Kingston , Lambeth , Lewisham , Merton ,  Newham , Redbridge , Richmond , Southwark ,  Sutton , Tower Hamlets , Waltham Forest ,  Wandsworth , Westminster     Source  
https://data.london.gov.uk/dataset/ordnance-survey-code-point    
Contains Ordinance Survey data released under the  Open Government License, OGL v2 .    See Also  
london_murders    Examples    library(dplyr) library(ggplot2) # Calculate number of murders by borough london_murders_counts <- london_murders %>% group_by(borough) %>% add_tally() london_murders_counts ## Not run: # Add number of murders to geographic boundary data london_boroughs_murders <- inner_join(london_boroughs, london_murders_counts, by = ""borough"") # Map murders ggplot(london_boroughs_murders) + geom_polygon(aes(x = x, y = y, group = borough, fill = n), colour = ""white"") + scale_fill_distiller(direction = 1) + labs(x = ""Easting"", y = ""Northing"", fill = ""Number of murders"") ## End(Not run)"
"openintro-london_murders","openintro","london_murders","London Murders, 2006-2011",838,5,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/london_murders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/london_murders.html","london_murders R Documentation   London Murders, 2006-2011   Description  
This dataset contains the victim name, age, and location of every murder recorded in the Greater London area by the Metropolitan Police from January 1, 2006 to September 7, 2011.    Usage    london_murders    Format  
A data frame with 838 observations on the following 5 variables.    forename
First name(s) of the victim.   age
Age of the victim.   date
Date of the murder (YYYY-MM-DD).   year
Year of the murder.   borough
The London borough in which the murder took place. See the Details section for a list of all the boroughs.     Details  
To visualize this data set using a map, see the  london_boroughs dataset, which contains the latitude and longitude of polygons that define the boundaries of the 32 boroughs of Greater London.   
The borough variable covers all 32 boroughs in Greater London:  Barking & Dagenham , Barnet , Bexley , Brent ,  Bromley , Camden , Croydon , Ealing ,  Enfield , Greenwich , Hackney , Hammersmith & Fulham , Haringey , Harrow , Havering , Hillingdon ,  Hounslow , Islington , Kensington & Chelsea ,  Kingston , Lambeth , Lewisham , Merton ,  Newham , Redbridge , Richmond , Southwark ,  Sutton , Tower Hamlets , Waltham Forest ,  Wandsworth , Westminster     Source  
https://www.theguardian.com/news/datablog/2011/oct/05/murder-london-list#data     References  
Inspired by The Guardian Datablog .    Examples    library(dplyr) library(ggplot2) library(lubridate) london_murders %>% mutate( day_count = as.numeric(date - ymd(""2006-01-01"")), date_cut = cut(day_count, seq(0, 2160, 90)) ) %>% group_by(date_cut) %>% add_tally() %>% ggplot(aes(x = date_cut, y = n)) + geom_col() + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + labs(x = ""Date from 01/2006 - 09/2011"", y = ""Number of deaths per 90 days"")"
"openintro-mail_me","openintro","mail_me","Influence of a Good Mood on Helpfulness",42,4,4,0,4,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mail_me.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mail_me.html","mail_me R Documentation   Influence of a Good Mood on Helpfulness   Description  
This study investigated whether finding a coin influenced a person's likelihood of mailing a sealed but addressed letter that appeared to have been accidentally left in a conspicuous place. Several variables were collected during the experiment, including two randomized variables of whether there was a coin to be found and whether the letter already had a stamp on it.    Usage    mail_me    Format  
A data frame with 42 observations on the following 4 variables.    stamped
a factor with levels no yes   found_coin
a factor with levels coin no_coin   gender
a factor with levels female male   mailed_letter
a factor with levels no yes     Details  
The precise context was in a phone booth (this study is from the 1970s!), where a person who entered a phone booth would find a dime in the phone tray, which would be sufficient to pay for their phone call. There was also a letter next to the phone, which sometimes had a stamp on it.    Source  
Levin PF, Isen AM. 1975. Studies on the Effect of Feeling Good on Helping. Sociometry 31(1), p141-147.    Examples    table(mail_me) (x <- table(mail_me[, c(""mailed_letter"", ""found_coin"")])) chisq.test(x) (x <- table(mail_me[, c(""mailed_letter"", ""stamped"")])) chisq.test(x) m <- glm(mailed_letter ~ stamped + found_coin + gender, data = mail_me, family = binomial) summary(m)"
"openintro-major_survey","openintro","major_survey","Survey of Duke students and the area of their major",218,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/major_survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/major_survey.html","major_survey R Documentation   Survey of Duke students and the area of their major   Description  
Survey of 218 students, collecting information on their GPAs and their academic major.    Usage    major_survey    Format  
A data frame with 218 observations on the following 2 variables.    gpa
Grade point average (GPA).   major
Area of academic major.     Examples    library(ggplot2) ggplot(major_survey, aes(x = major, y = gpa)) + geom_boxplot()"
"openintro-malaria","openintro","malaria","Malaria Vaccine Trial",20,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/malaria.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/malaria.html","malaria R Documentation   Malaria Vaccine Trial   Description  
Volunteer patients were randomized into one of two experiment groups where they would receive an experimental vaccine or a placebo. They were subsequently exposed to a drug-sensitive strain of malaria and observed to see whether they came down with an infection.    Usage    malaria    Format  
A data frame with 20 observations on the following 2 variables.    treatment
Whether a person was given the experimental vaccine or a placebo .   outcome
Whether the person got an infection or no infection .     Details  
In this study, volunteer patients were randomized into one of two experiment groups: 14 patients received an experimental vaccine or 6 patients received a placebo vaccine. Nineteen weeks later, all 20 patients were exposed to a drug-sensitive malaria virus strain; the motivation of using a drug-sensitive strain of virus here is for ethical considerations, allowing any infections to be treated effectively.    Source  
Lyke et al. 2017. PfSPZ vaccine induces strain-transcending T cells and durable protection against heterologous controlled human malaria infection. PNAS 114(10):2711-2716. doi: 10.1073/pnas.1615324114 .    Examples    library(dplyr) # Calculate conditional probabilities of infection after vaccine/placebo malaria %>% count(treatment, outcome) %>% group_by(treatment) %>% mutate(prop = n / sum(n)) # Fisher's exact text fisher.test(table(malaria))"
"openintro-male_heights","openintro","male_heights","Sample of 100 male heights",100,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/male_heights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/male_heights.html","male_heights R Documentation   Sample of 100 male heights   Description  
Random sample based on Food Commodity Intake Database distribution    Usage    male_heights    Format  
A data frame with 100 observations on the following variable.    heights
a numeric vector     References  
What We Eat In America - Food Commodity Intake Database. Available at https://fcid.foodrisk.org/ .    Examples    male_heights"
"openintro-male_heights_fcid","openintro","male_heights_fcid","Random sample of adult male heights",100,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/male_heights_fcid.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/male_heights_fcid.html","male_heights_fcid R Documentation   Random sample of adult male heights   Description  
This sample is based on data from the USDA Food Commodity Intake Database.    Usage    male_heights_fcid    Format  
A data frame with 100 observations on the following variable.    height_inch
Height, in inches.     Source  
Simulated based on data from USDA.    Examples    data(male_heights_fcid) histPlot(male_heights_fcid$height_inch)"
"openintro-mammals","openintro","mammals","Sleep in Mammals",62,11,0,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mammals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mammals.html","mammals R Documentation   Sleep in Mammals   Description  
This data set includes data for 39 species of mammals distributed over 13 orders. The data were used for analyzing the relationship between constitutional and ecological factors and sleeping in mammals. Two qualitatively different sleep variables (dreaming and non dreaming) were recorded. Constitutional variables such as life span, body weight, brain weight and gestation time were evaluated. Ecological variables such as severity of predation, safety of sleeping place and overall danger were inferred from field observations in the literature.    Usage    mammals    Format  
A data frame with 62 observations on the following 11 variables.    species
Species of mammals   body_wt
Total body weight of the mammal (in kg)   brain_wt
Brain weight of the mammal (in kg)   non_dreaming
Number of hours of non dreaming sleep   dreaming
Number of hours of dreaming sleep   total_sleep
Total number of hours of sleep   life_span
Life span (in years)   gestation
Gestation time (in days)   predation
An index of how likely the mammal is to be preyed upon. 1 = least likely to be preyed upon. 5 = most likely to be preyed upon.   exposure
An index of the how exposed the mammal is during sleep. 1 = least exposed (e.g., sleeps in a well-protected den). 5 = most exposed.   danger
An index of how much danger the mammal faces from other animals. This index is based upon Predation and Exposure. 1 = least danger from other animals. 5 = most danger from other animals.     Source  
http://www.statsci.org/data/general/sleep.txt     References  
T. Allison and D. Cicchetti, ""Sleep in mammals: ecological and constitutional correlates,"" Arch. Hydrobiol, vol. 75, p. 442, 1975.    Examples    library(ggplot2) ggplot(mammals, aes(x = log(body_wt), y = log(brain_wt))) + geom_point() + geom_smooth(method = ""lm"") + labs(x = ""Log of body weight"", x = ""Log of brain weight"")"
"openintro-mammogram","openintro","mammogram","Experiment with Mammogram Randomized",89835,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mammogram.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mammogram.html","mammogram R Documentation   Experiment with Mammogram Randomized   Description  
An experiment where 89,835 women were randomized to either get a mammogram or a non-mammogram breast screening. The response measured was whether they had died from breast cancer within 25 years.    Usage    mammogram    Format  
A data frame with 89835 observations on the following 2 variables.    treatment
a factor with levels control   mammogram   breast_cancer_death
a factor with levels no   yes     Source  
Miller AB. 2014. Twenty five year follow-up for breast cancer incidence and mortality of the Canadian National Breast Screening Study: randomised screening trial. BMJ 2014;348:g366.    Examples    table(mammogram) chisq.test(table(mammogram))"
"openintro-marathon","openintro","marathon","New York City Marathon Times (outdated)",59,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/marathon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/marathon.html","marathon R Documentation   New York City Marathon Times (outdated)   Description  
Marathon times of male and female winners of the New York City Marathon 1970-1999. See nyc_marathon for a more updated dataset.    Usage    marathon    Format  
A data frame with 60 observations on the following 3 variables.    year
Year   gender
Gender   time
Running time (in hours)     Source  
https://www.webcitation.org/5kx7ilFLp     Examples    library(ggplot2) ggplot(marathon, aes(x = time)) + geom_histogram(binwidth = 0.15) ggplot(marathon, aes(y = time, x = gender)) + geom_boxplot()"
"openintro-mariokart","openintro","mariokart","Wii Mario Kart auctions from Ebay",143,12,2,0,4,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mariokart.html","mariokart R Documentation   Wii Mario Kart auctions from Ebay   Description  
Auction data from Ebay for the game Mario Kart for the Nintendo Wii. This data was collected in early October 2009.    Usage    mariokart    Format  
A data frame with 143 observations on the following 12 variables. All prices are in US dollars.    id
Auction ID assigned by Ebay.   duration
Auction length, in days.   n_bids
Number of bids.   cond
Game condition, either new or used .   start_pr
Start price of the auction.   ship_pr
Shipping price.   total_pr
Total price, which equals the auction price plus the shipping price.   ship_sp
Shipping speed or method.   seller_rate
The seller's rating on Ebay. This is the number of positive ratings minus the number of negative ratings for the seller.   stock_photo
Whether the auction feature photo was a stock photo or not. If the picture was used in many auctions, then it was called a stock photo.   wheels
Number of Wii wheels included in the auction. These are steering wheel attachments to make it seem as though you are actually driving in the game. When used with the controller, turning the wheel actually causes the character on screen to turn.   title
The title of the auctions.     Details  
There are several interesting features in the data. First off, note that there are two outliers in the data. These serve as a nice example of what one should do when encountering an outlier: examine the data point and remove it only if there is a good reason. In these two cases, we can see from the auction titles that they included other items in their auctions besides the game, which justifies removing them from the data set.   
This data set includes all auctions for a full week in October 2009. Auctions were included in the data set if they satisfied a number of conditions. (1) They were included in a search for ""wii mario kart"" on ebay.com, (2) items were in the Video Games > Games > Nintendo Wii section of Ebay, (3) the listing was an auction and not exclusively a ""Buy it Now"" listing (sellers sometimes offer an optional higher price for a buyer to end bidding and win the auction immediately, which is an optional Buy it Now auction), (4) the item listed was the actual game, (5) the item was being sold from the US, (6) the item had at least one bidder, (7) there were no other items included in the auction with the exception of racing wheels, either generic or brand-name being acceptable, and (8) the auction did not end with a Buy It Now option.    Source  
Ebay.    Examples    library(ggplot2) library(broom) library(dplyr) # Identify outliers ggplot(mariokart, aes(x = total_pr, y = cond)) + geom_boxplot() # Replot without the outliers mariokart %>% filter(total_pr < 80) %>% ggplot(aes(x = total_pr, y = cond)) + geom_boxplot() # Fit a multiple regression models mariokart_no <- mariokart %>% filter(total_pr < 80) m1 <- lm(total_pr ~ cond + stock_photo + duration + wheels, data = mariokart_no) tidy(m1) m2 <- lm(total_pr ~ cond + stock_photo + wheels, data = mariokart_no) tidy(m2) m3 <- lm(total_pr ~ cond + wheels, data = mariokart_no) tidy(m3) # Fit diagnostics aug_m3 <- augment(m3) ggplot(aug_m3, aes(x = .fitted, y = .resid)) + geom_point() + geom_hline(yintercept = 0, linetype = ""dashed"") + labs(x = ""Fitted values"", y = ""Residuals"") ggplot(aug_m3, aes(x = .fitted, y = abs(.resid))) + geom_point() + geom_hline(yintercept = 0, linetype = ""dashed"") + labs(x = ""Fitted values"", y = ""Absolute value of residuals"") ggplot(aug_m3, aes(x = 1:nrow(aug_m3), y = .resid)) + geom_point() + geom_hline(yintercept = 0, linetype = ""dashed"") + labs(x = ""Order of data collection"", y = ""Residuals"") ggplot(aug_m3, aes(x = cond, y = .resid)) + geom_boxplot() + labs(x = ""Condition"", y = ""Residuals"") ggplot(aug_m3, aes(x = wheels, y = .resid)) + geom_point() + labs(x = ""Number of wheels"", y = ""Residuals"", title = ""Notice curvature"")"
"openintro-mcu_films","openintro","mcu_films","Marvel Cinematic Universe films",23,7,0,2,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mcu_films.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mcu_films.html","mcu_films R Documentation   Marvel Cinematic Universe films   Description  
A list of Marvel Cinematic Universe films through the Infinity saga. The Infinity saga is a 23 movie storyline spanning from Ironman in 2008 to Endgame in 2019.    Usage    mcu_films    Format  
A data frame with 23 rows and 7 variables.    movie
Title of the movie.   length_hrs
Length of the movie: hours portion.   length_min
Length of the movie: minutes portion.   release_date
Date the movie was released in the US.   opening_weekend_us
Box office totals for opening weekend in the US.   gross_us
All box office totals in US.   gross_world
All box office totals world wide.     Details  
Box office figures are not adjusted to a specific year. They are from the year the film was released.    Source  
Internet Movie Database .    Examples    library(ggplot2) library(scales) ggplot(mcu_films, aes(x = opening_weekend_us, y = gross_us))+ geom_point() + labs( title = ""MCU Box Office Totals: Opening weekend vs. all-time"", x = ""Opening weekend totals (USD in millions)"", y = ""All-time totals (USD)"" ) + scale_x_continuous(labels = label_dollar(scale = 1/1000000)) + scale_y_continuous(labels = label_dollar(scale = 1/1000000))"
"openintro-midterms_house","openintro","midterms_house","President's party performance and unemployment rate",31,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/midterms_house.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/midterms_house.html","midterms_house R Documentation   President's party performance and unemployment rate   Description  
Covers midterm elections.    Usage    midterms_house    Format  
A data frame with 29 observations on the following 5 variables.    year
Year.   potus
The president in office.   party
President's party: Democrat or Republican.   unemp
Unemployment rate.   house_change
Change in House seats for the President's party.     Details  
An older version of this data is at unemploy_pres .    Source  
Wikipedia.    Examples    library(ggplot2) ggplot(midterms_house, aes(x = unemp, y = house_change)) + geom_point()"
"openintro-migraine","openintro","migraine","Migraines and acupuncture",89,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/migraine.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/migraine.html","migraine R Documentation   Migraines and acupuncture   Description  
Experiment involving acupuncture and sham acupuncture (as placebo) in the treatment of migraines.    Usage    migraine    Format  
A data frame with 89 observations on the following 2 variables.    group
a factor with levels control treatment   pain_free
a factor with levels no yes     Source  
G. Allais et al. Ear acupuncture in the treatment of migraine attacks: a randomized trial on the efficacy of appropriate versus inappropriate acupoints. In: Neurological Sci. 32.1 (2011), pp. 173-175.    Examples    migraine"
"openintro-military","openintro","military","US Military Demographics",1414593,6,2,0,4,1,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/military.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/military.html","military R Documentation   US Military Demographics   Description  
This dataset contains demographic information on every member of the US armed forces including gender, race, and rank.    Usage    military    Format  
A data frame with 1,414,593 observations on the following 6 variables.    grade
The status of the service member as enlisted officer or warrant officer .   branch
The branch of the armed forces: air force , army , marine corps , navy .   gender
Whether the service member is female or male .   race
The race identified by the service member: ami/aln (american indian/alaskan native), asian , black , multi (multi-ethnic), p/i (pacific islander), unk (unknown), or white .   hisp
Whether a service member identifies with being hispanic ( TRUE ) or not ( FALSE ).   rank
The numeric rank of the service member (higher number indicates higher rank).     Details  
The branches covered by this data set include the Army, Navy, Air Force, and Marine Corps. Demographic information on the Coast Guard is contained in the original data set but has not been included here.    Source  
Data provided by the Department of Defense and made available at  https://catalog.data.gov/dataset/personnel-trends-by-gender-race , retrieved 2012-02-20.    Examples    ## Not run: library(dplyr) library(ggplot2) library(forcats) # Proportion of females in military branches military %>% ggplot(aes(x = branch, fill = gender)) + geom_bar(position = ""fill"") + labs( x = ""Branch"", y = ""Proportion"", fill = ""Gender"", title = ""Proportion of females in military branches"" ) # Proportion of army officer females across ranks military %>% filter( grade == ""officer"", branch == ""army"" ) %>% ggplot(aes(x = factor(rank), fill = fct_rev(gender))) + geom_bar(position = ""fill"") + labs( x = ""Rank"", y = ""Proportion"", fill = ""Gender"", title = ""Proportion of army officer females across ranks"" ) ## End(Not run)"
"openintro-mlb","openintro","mlb","Salary data for Major League Baseball (2010)",828,4,0,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mlb.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mlb.html","mlb R Documentation   Salary data for Major League Baseball (2010)   Description  
Salary data for Major League Baseball players in the year 2010.    Usage    mlb    Format  
A data frame with 828 observations on the following 4 variables.    player
Player name   team
Team   position
Field position   salary
Salary (in $1000s)     Source  
https://databases.usatoday.com/mlb-salaries/ , retrieved 2011-02-23.    Examples    # _____ Basic Histogram _____ # hist(mlb$salary / 1000, breaks = 15, main = """", xlab = ""Salary (millions of dollars)"", ylab = """", axes = FALSE, col = ""#22558844"") axis(1, seq(0, 40, 10)) axis(2, c(0, 500)) axis(2, seq(100, 400, 100), rep("""", 4), tcl = -0.2) # _____ Histogram on Log Scale _____ # hist(log(mlb$salary / 1000), breaks=15, main = """", xlab = ""log(Salary)"", ylab = """", axes = FALSE, col = ""#22558844"") axis(1) #, seq(0, 40, 10)) axis(2, seq(0, 300, 100)) # _____ Box plot of log(salary) against position _____ # boxPlot(log(mlb$salary / 1000), mlb$position, horiz = TRUE, ylab = """")"
"openintro-mlb_players_18","openintro","mlb_players_18","Batter Statistics for 2018 Major League Baseball (MLB) Season",1270,19,0,3,0,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mlb_players_18.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mlb_players_18.html","mlb_players_18 R Documentation   Batter Statistics for 2018 Major League Baseball (MLB) Season   Description  
Batter statistics for 2018 Major League Baseball season.    Usage    mlb_players_18    Format  
A data frame with 1270 observations on the following 19 variables.    name
Player name   team
Team abbreviation   position
Position abbreviation: 1B = first base,  2B = second base, 3B = third base, C = catcher,  CF = center field (outfield), DH = designated hitter,  LF = left field (outfield), P = pitcher,  RF = right field (outfield), SS = shortstop.   games
Number of games played.   AB
At bats.   R
Runs.   H
Hits.   doubles
Doubles.   triples
Triples.   HR
Home runs.   RBI
Runs batted in.   walks
Walks.   strike_outs
Strike outs.   stolen_bases
Stolen bases.   caught_stealing_base
Number of times caught stealing a base.   AVG
Batting average.   OBP
On-base percentage.   SLG
Slugging percentage.   OPS
On-base percentage plus slugging percentage.     Source  
https://www.mlb.com/stats     See Also  
mlbbat10 , mlb     Examples    d <- subset(mlb_players_18, !position %in% c(""P"", ""DH"") & AB >= 100) dim(d) # _____ Per Position, No Further Grouping _____ # plot(d$OBP ~ as.factor(d$position)) model <- lm(OBP ~ as.factor(position), d) summary(model) anova(model) # _____ Simplified Analysis, Fewer Positions _____ # pos <- list(c(""LF"", ""CF"", ""RF""), c(""1B"", ""2B"", ""3B"", ""SS""), ""C"") POS <- c(""OF"", ""IF"", ""C"") table(d$position) # _____ On-Base Percentage Across Positions _____ # out <- c() gp <- c() for(i in 1:length(pos)){ these <- which(d$position %in% pos[[i]]) out <- c(out, d$OBP[these]) gp <- c(gp, rep(POS[i], length(these))) } plot(out ~ as.factor(gp)) summary(lm(out ~ as.factor(gp))) anova(lm(out ~ as.factor(gp)))"
"openintro-mlbbat10","openintro","mlbbat10","Major League Baseball Player Hitting Statistics for 2010",1199,19,0,0,3,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mlbbat10.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mlbbat10.html","mlbbat10 R Documentation   Major League Baseball Player Hitting Statistics for 2010   Description  
Major League Baseball Player Hitting Statistics for 2010.    Usage    mlbbat10    Format  
A data frame with 1199 observations on the following 19 variables.    name
Player name   team
Team abbreviation   position
Player position   game
Number of games   at_bat
Number of at bats   run
Number of runs   hit
Number of hits   double
Number of doubles   triple
Number of triples   home_run
Number of home runs   rbi
Number of runs batted in   total_base
Total bases, computed as 3 HR + 2 3B + 1*2B + H   walk
Number of walks   strike_out
Number of strikeouts   stolen_base
Number of stolen bases   caught_stealing
Number of times caught stealing   obp
On base percentage   slg
Slugging percentage (total_base / at_bat)   bat_avg
Batting average     Source  
https://www.mlb.com , retrieved 2011-04-22.    Examples    library(ggplot2) library(dplyr) library(scales) mlbbat10_200 <- mlbbat10 %>% filter(mlbbat10$at_bat > 200) # On-base percentage across positions ggplot(mlbbat10_200, aes(x = position, y = obp, fill = position)) + geom_boxplot(show.legend = FALSE) + scale_y_continuous(labels = label_number(suffix = ""%"", accuracy = 0.01)) + labs( title = ""On-base percentage across positions"", y = ""On-base percentage across positions"", x = ""Position"" ) # Batting average across positions ggplot(mlbbat10_200, aes(x = bat_avg, fill = position)) + geom_density(alpha = 0.5) + labs( title = ""Batting average across positions"", fill = NULL, y = ""Batting average"", x = ""Position"" ) # Mean number of home runs across positions mlbbat10_200 %>% group_by(position) %>% summarise(mean_home_run = mean(home_run)) %>% ggplot(aes(x = position, y = mean_home_run, fill = position)) + geom_col(show.legend = FALSE) + labs( title = ""Mean number of home runs across positions"", y = ""Home runs"", x = ""Position"" ) # Runs batted in across positions ggplot(mlbbat10_200, aes(x = run, y = obp, fill = position)) + geom_boxplot(show.legend = FALSE) + labs( title = ""Runs batted in across positions"", y = ""Runs"", x = ""Position"" )"
"openintro-mtl","openintro","mtl","Medial temporal lobe (MTL) and other data for 26 participants",35,23,4,4,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mtl.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/mtl.html","mtl R Documentation   Medial temporal lobe (MTL) and other data for 26 participants   Description  
The data are from a convenience sample of 25 women and 10 men who were middle-aged or older. The purpose of the study was to understand the relationship between sedentary behavior and thickness of the medial temporal lobe (MTL) in the brain.    Usage    mtl    Format  
A data frame with 35 observations on the following 23 variables.    subject
ID for the individual.   sex
Gender, which takes values F (female) or M (male).   ethnic
Ethnicity, simplified to Caucasian and Other .   educ
Years of educational.   e4grp
APOE-4 status, taking a value of E4 or Non-E4 .   age
Age, in years.   mmse
Score from the Mini-Mental State Examination, which is a global cognition evaluation.   ham_a
Score on the Hamilton Rating Scale for anxiety.   ham_d
Score on the Hamilton Rating Scale for depression.   dig_sym
We (the authors of this R package) are unsure as to the meaning of this variable.   delay_vp
We (the authors of this R package) are unsure as to the meaning of this variable.   bfr_selective_reminding_delayed
We (the authors of this R package) are unsure as to the meaning of this variable.   sitting
Self-reported time sitting per day, averaged to the nearest hour.   met_minwk
Metabolic equivalent units score (activity level). A score of  0 means ""no activity"" while 3000 is considered ""high activity"".   ipa_qgrp
Classification of METminwk into Low or High .   aca1
Thickness of the CA1 subregion of the MTL.   aca23dg
Thickness of the CA23DG subregion of the MTL.   ae_cort
Thickness of a subregion of the MTL.   a_fusi_cort
Thickness of the fusiform gyrus subregion of the MTL.   a_ph_cort
Thickness of the perirhinal cortex subregion of the MTL.   a_pe_cort
Thickness of the entorhinal cortex subregion of the MTL.   asubic
Thickness of the subiculum subregion of the MTL.   total
Total MTL thickness.     Source  
Siddarth P, Burggren AC, Eyre HA, Small GW, Merrill DA. 2018. Sedentary behavior associated with reduced medial temporal lobe thickness in middle-aged and older adults. PLoS ONE 13(4): e0195549. doi: 10.1371/journal.pone.0195549 .   
Thank you to Professor Silas Bergen of Winona State University for pointing us to this data set!    References  
A New York Times article references this study.  https://www.nytimes.com/2018/04/19/opinion/standing-up-at-your-desk-could-make-you-smarter.html     Examples    library(ggplot2) ggplot(mtl, aes(x = ipa_qgrp, y = met_minwk)) + geom_boxplot()"
"openintro-murders","openintro","murders","Data for 20 metropolitan areas",20,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/murders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/murders.html","murders R Documentation   Data for 20 metropolitan areas   Description  
Population, percent in poverty, percent unemployment, and murder rate.    Usage    murders    Format  
A data frame with 20 metropolitan areas on the following 4 variables.    population
Population.   perc_pov
Percent in poverty.   perc_unemp
Percent unemployed.   annual_murders_per_mil
Number of murders per year per million people.     Source  
We do not have provenance for these data hence recommend not using them for analysis.    Examples    library(ggplot2) ggplot(murders, aes(x = perc_pov, y = annual_murders_per_mil)) + geom_point() + labs( x = ""Percent in poverty"", y = ""Number of murders per year per million people"" )"
"openintro-nba_heights","openintro","nba_heights","NBA Player heights from 2008-9",435,4,0,2,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/nba_heights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/nba_heights.html","nba_heights R Documentation   NBA Player heights from 2008-9   Description  
Heights of all NBA players from the 2008-9 season.    Usage    nba_heights    Format  
A data frame with 435 observations (players) on the following 4 variables.    last_name
Last name.   first_name
First name.   h_meters
Height, in meters.   h_in
Height, in inches.     Source  
Collected from NBA .    Examples    qqnorm(nba_heights$h_meters)"
"openintro-nba_players_19","openintro","nba_players_19","NBA Players for the 2018-2019 season",494,7,0,6,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/nba_players_19.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/nba_players_19.html","nba_players_19 R Documentation   NBA Players for the 2018-2019 season   Description  
Summary information from the NBA players for the 2018-2019 season.    Usage    nba_players_19    Format  
A data frame with 494 observations on the following 7 variables.    first_name
First name.   last_name
Last name.   team
Team name   team_abbr
3-letter team abbreviation.   position
Player position.   number
Jersey number.   height
Height, in inches.     Source  
https://www.nba.com/players     Examples    hist(nba_players_19$height, 20) table(nba_players_19$team)"
"openintro-ncbirths","openintro","ncbirths","North Carolina births, 1000 cases",1000,13,7,0,7,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ncbirths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ncbirths.html","ncbirths R Documentation   North Carolina births, 1000 cases   Description  
In 2004, the state of North Carolina released to the public a large data set containing information on births recorded in this state. This data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from this data set.    Usage    ncbirths    Format  
A data frame with 1000 observations on the following 13 variables.    fage
Father's age in years.   mage
Mother's age in years.   mature
Maturity status of mother.   weeks
Length of pregnancy in weeks.   premie
Whether the birth was classified as premature (premie) or full-term.   visits
Number of hospital visits during pregnancy.   gained
Weight gained by mother during pregnancy in pounds.   weight
Weight of the baby at birth in pounds.   lowbirthweight
Whether baby was classified as low birthweight ( low ) or not ( not low ).   gender
Gender of the baby, female or male .   habit
Status of the mother as a nonsmoker or a smoker .   marital
Whether mother is married or not married at birth.   whitemom
Whether mom is white or not white .     See Also  
We do not have ideal provenance for these data. For a better documented and more recent dataset on a similar topic with similar variables, see births14.    Examples    library(ggplot2) ggplot(ncbirths, aes(x = habit, y = weight)) + geom_boxplot() + labs(x = ""Smoking status of mother"", y = ""Birth weight of baby (in lbs)"") ggplot(ncbirths, aes(x = whitemom, y = visits)) + geom_boxplot() + labs(x = ""Mother's race"", y = ""Number of doctor visits during pregnancy"") ggplot(ncbirths, aes(x = mature, y = gained)) + geom_boxplot() + labs(x = ""Mother's age category"", y = ""Weight gained during pregnancy"")"
"openintro-nuclear_survey","openintro","nuclear_survey","Nuclear Arms Reduction Survey",1028,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/nuclear_survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/nuclear_survey.html","nuclear_survey R Documentation   Nuclear Arms Reduction Survey   Description  
A simple random sample of 1,028 US adults in March 2013 found that 56\ support nuclear arms reduction.    Usage    nuclear_survey    Format  
A data frame with 1028 observations on the following variable.    arms_reduction
Responses of favor or  against .     Source  
Gallup report: In U.S., 56 percent Favor U.S.-Russian Nuclear Arms Reductions. Available at https://news.gallup.com/poll/161198/favor-russian-nuclear-arms-reductions.aspx .    Examples    table(nuclear_survey)"
"openintro-nyc_marathon","openintro","nyc_marathon","New York City Marathon Times",102,7,1,4,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/nyc_marathon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/nyc_marathon.html","nyc_marathon R Documentation   New York City Marathon Times   Description  
Marathon times of runners in the Men and Women divisions of the New York City Marathon, 1970 - 2020.    Usage    nyc_marathon    Format  
A data frame with 102 observations on the following 7 variables.    year
Year of marathom.   name
Name of winner.   country
Country of winner.   time
Running time (HH:MM:SS).   time_hrs
Running time (in hours).   division
Division: Men or Women .   note
Note about the race or the winning time.     Source  
Wikipedia, List of winners of the New York City Marathon . Retrieved 28 April, 2021.    Examples    library(ggplot2) ggplot(nyc_marathon, aes(x = year, y = time_hrs, color = division, shape = division)) + geom_point()"
"openintro-nycflights","openintro","nycflights","Flights data",32735,16,0,4,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/nycflights.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/nycflights.html","nycflights R Documentation   Flights data   Description  
On-time data for a random sample of flights that departed NYC (i.e. JFK, LGA or EWR) in 2013.    Usage    nycflights    Format  
A tbl_df with 32,735 rows and 16 variables:    year,month,day
Date of departure.   dep_time,arr_time
Departure and arrival times, local tz.   dep_delay,arr_delay
Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.   hour,minute
Time of departure broken in to hour and minutes.   carrier
Two letter carrier abbreviation. See airlines in the  nycflights13 package for more information or google the airline code.   tailnum
Plane tail number.   flight
Flight number.   origin,dest
Origin and destination. See airports in the  nycflights13 package for more information or google airport the code.   air_time
Amount of time spent in the air.   distance
Distance flown.     Source  
Hadley Wickham (2014). nycflights13 : Data about flights departing NYC in 2013. R package version 0.1.    Examples    library(dplyr) # Longest departure delays nycflights %>% select(flight, origin, dest, dep_delay, arr_delay) %>% arrange(desc(dep_delay)) # Longest arrival delays nycflights %>% select(flight, origin, dest, dep_delay, arr_delay) %>% arrange(desc(arr_delay))"
"openintro-offshore_drilling","openintro","offshore_drilling","California poll on drilling off the California coast",828,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/offshore_drilling.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/offshore_drilling.html","offshore_drilling R Documentation   California poll on drilling off the California coast   Description  
A 2010 survey asking a randomly sample of registered voters in California for their position on drilling for oil and natural gas off the Coast of California.    Usage    offshore_drilling    Format  
A data frame with 827 observations on the following 2 variables.    position
a factor with levels do not know   oppose support   college_grad
a factor with levels no yes     Source  
Survey USA, Election Poll #16804, data collected July 8-11, 2010.    Examples    offshore_drilling"
"openintro-openintro_colors","openintro","openintro_colors","OpenIntro colors",8,1,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/openintro_colors.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/openintro_colors.html","openintro_colors R Documentation   OpenIntro colors   Description  
A character string of full colors from IMSCOL[,1]     Usage    openintro_colors    Format  
A named character string with 9 elements: ""blue"", ""green"", ""pink"", ""yellow"", ""red"", ""black"", ""gray"", ""lgray    Examples    openintro_colors openintro_colors[""blue""]"
"openintro-opportunity_cost","openintro","opportunity_cost","Opportunity cost of purchases",150,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/opportunity_cost.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/opportunity_cost.html","opportunity_cost R Documentation   Opportunity cost of purchases   Description  
In a study on opportunity cost, 150 students were given the following statement: ""Imagine that you have been saving some extra money on the side to make some purchases, and on your most recent visit to the video store you come across a special sale on a new video. This video is one with your favorite actor or actress, and your favorite type of movie (such as a comedy, drama, thriller, etc.). This particular video that you are considering is one you have been thinking about buying for a long time. It is available for a special sale price of $14.99. What would you do in this situation? Please circle one of the options below."" Half of the students were given the following two options: (A) Buy this entertaining video. (B) Not buy this entertaining video. The other half were given the following two options (note the modified option B): (A) Buy this entertaining video. (B) Not buy this entertaining video. Keep the $14.99 for other purchases. The results of this study are in this dataset.    Usage    opportunity_cost    Format  
A data frame with 150 observations on the following 2 variables.    group
a factor with levels control and treatment   decision
a factor with levels buy video and not buy video     Source  
Frederick S, Novemsky N, Wang J, Dhar R, Nowlis S. 2009. Opportunity Cost Neglect. Journal of Consumer Research 36: 553-561.    Examples    library(ggplot2) table(opportunity_cost) ggplot(opportunity_cost, aes(y = group, fill = decision)) + geom_bar(position = ""fill"")"
"openintro-orings","openintro","orings","1986 Challenger disaster and O-rings",23,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/orings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/orings.html","orings R Documentation   1986 Challenger disaster and O-rings   Description  
On January 28, 1986, a routine launch was anticipated for the Challenger space shuttle. Seventy-three seconds into the flight, disaster happened: the shuttle broke apart, killing all seven crew members on board. An investigation into the cause of the disaster focused on a critical seal called an O-ring, and it is believed that damage to these O-rings during a shuttle launch may be related to the ambient temperature during the launch. The table below summarizes observational data on O-rings for 23 shuttle missions, where the mission order is based on the temperature at the time of the launch.    Usage    orings    Format  
A data frame with 23 observations on the following 4 variables.    mission
Shuttle mission number.   temperature
Temperature, in Fahrenheit.   damaged
Number of damaged O-rings (out of 6).   undamaged
Number of undamaged O-rings (out of 6).     Source  
https://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring     Examples    library(dplyr) library(forcats) library(tidyr) library(broom) # This is a wide data frame. You can convert it to a long # data frame to predict probability of O-ring damage based # on temperature using logistic regression. orings_long <- orings %>% pivot_longer(cols = c(damaged, undamaged), names_to = ""outcome"", values_to = ""n"") %>% uncount(n) %>% mutate(outcome = fct_relevel(outcome, ""undamaged"", ""damaged"")) orings_mod <- glm(outcome ~ temperature, data = orings_long, family = ""binomial"") tidy(orings_mod)"
"openintro-oscars","openintro","oscars","Oscar winners, 1929 to 2018",184,11,1,4,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/oscars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/oscars.html","oscars R Documentation   Oscar winners, 1929 to 2018   Description  
Best actor and actress Oscar winners from 1929 to 2018    Usage    oscars    Format  
A data frame with 182 observations on the following 10 variables.    oscar_no
Oscar ceremony number.   oscar_yr
Year the Oscar ceremony was held.   award
Best actress or Best actor .   name
Name of winning actor or actress.   movie
Name of movie actor or actress got the Oscar for.   age
Age at which the actor or actress won the Oscar.   birth_pl
US State where the actor or actress was born, country if foreign.   birth_date
Birth date of actor or actress.   birth_mo
Birth month of actor or actress.   birth_d
Birth day of actor or actress.   birth_y
Birth year of actor or actress.     Details  
Although there have been only 84 Oscar ceremonies until 2012, there are 85 male winners and 85 female winners because ties happened on two occasions (1933 for the best actor and 1969 for the best actress).    Source  
Journal of Statistical Education,  http://jse.amstat.org/datasets/oscars.dat.txt , updated through 2019 using information from Oscars.org and Wikipedia.org.    Examples    library(ggplot2) library(dplyr) ggplot(oscars, aes(x = award, y = age)) + geom_boxplot() ggplot(oscars, aes(x = factor(birth_mo))) + geom_bar() oscars %>% count(birth_pl, sort = TRUE)"
"openintro-outliers","openintro","outliers","Simulated data sets for different types of outliers",50,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/outliers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/outliers.html","outliers R Documentation   Simulated data sets for different types of outliers   Description  
Data sets for showing different types of outliers    Usage    outliers    Format  
A data frame with 50 observations on the following 5 variables.    x
a numeric vector   y
a numeric vector   x_inf
a numeric vector   y_lev
a numeric vector   y_out
a numeric vector     Examples    outliers"
"openintro-penelope","openintro","penelope","Guesses at the weight of Penelope (a cow)",17184,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/penelope.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/penelope.html","penelope R Documentation   Guesses at the weight of Penelope (a cow)   Description  
The data was collected by the Planet Money podcast to test a theory about crowd-sourcing. Penelope's actual weight was 1,355 pounds.    Usage    penelope    Format  
A data frame with 17,184 observations on the following variable.    weight
Guesses of Penelope's weight, in pounds.     Source  
https://www.npr.org/sections/money/2015/08/07/429720443/17-205-people-guessed-the-weight-of-a-cow-heres-how-they-did     Examples    library(ggplot2) ggplot(penelope, aes(x = weight)) + geom_histogram(binwidth = 250) summary(penelope$weight)"
"openintro-penetrating_oil","openintro","penetrating_oil","What's the best way to loosen a rusty bolt?",30,2,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/penetrating_oil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/penetrating_oil.html","penetrating_oil R Documentation   What's the best way to loosen a rusty bolt?   Description  
The channel Project Farm on YouTube investigated penetrating oils and other options for loosening rusty bolts. Eight options were evaluated, including a control group, to determine which was most effective.    Usage    penetrating_oil    Format  
A data frame with 30 observations on the following 2 variables.    treatment
The different treatments tried:  none (control), Heat (via blow torch), Acetone/ATF ,  AeroKroil , Liquid Wrench , PB Blaster , Royal Purple , and WD-40 .   torque
Torque required to loosen the rusty bolt, which was measured in foot-pounds.     Source  
https://www.youtube.com/watch?v=xUEob2oAKVs     Examples    m <- lm(torque ~ treatment, data = penetrating_oil) anova(m) # There are 28 pairwise comparisons to be made. xbar <- tapply(penetrating_oil$torque, penetrating_oil$treatment, mean) n <- tapply(penetrating_oil$torque, penetrating_oil$treatment, length) s <- summary(m)$sigma df <- summary(m)$df[1] diff <- c() se <- c() k <- 0 N <- length(n) K <- N * (N - 1) / 2 for (i in 1:(N - 1)) { for (j in (i + 1):N) { k <- k + 1 diff[k] <- xbar[i] - xbar[j] se[k] <- s * sqrt(1 / n[i] + 1 / n[j]) if (2 * K * pt(-abs(diff[k] / se[k]), df) < 0.05) { cat(""0.05 - "", names(n)[c(i, j)], ""\n"") } else if (2 * K * pt(-abs(diff[k] / se[k]), df) < 0.1) { cat(""0.1 - "", names(n)[c(i, j)], ""\n"") } else if (2 * K * pt(-abs(diff[k] / se[k]), df) < 0.2) { cat(""0.2 - "", names(n)[c(i, j)], ""\n"") } else if (2 * K * pt(-abs(diff[k] / se[k]), df) < 0.3) { cat(""0.3 - "", names(n)[c(i, j)], ""\n"") } } } # Smallest p-value using Bonferroni min(2 * K * pt(-abs(diff / se), df)) # Better pairwise comparison method. anova(m1 <- aov(torque ~ treatment, data = penetrating_oil)) TukeyHSD(m1)"
"openintro-penny_ages","openintro","penny_ages","Penny Ages",648,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/penny_ages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/penny_ages.html","penny_ages R Documentation   Penny Ages   Description  
Sample of pennies and their ages. Taken in 2004.    Usage    penny_ages    Format  
A data frame with 648 observations on the following 2 variables.    year
Penny's year.   age
Age as of 2004.     Examples    hist(penny_ages$year)"
"openintro-pew_energy_2018","openintro","pew_energy_2018","Pew Survey on Energy Sources in 2018",2541,6,6,6,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/pew_energy_2018.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/pew_energy_2018.html","pew_energy_2018 R Documentation   Pew Survey on Energy Sources in 2018   Description  
US-based survey on support for expanding six different sources of energy, including solar, wind, offshore drilling, hydrolic fracturing (""fracking""), coal, and nuclear.    Usage    pew_energy_2018    Format  
The format is: List of 6 $ solar_panel_farms : List of responses on solar farms. $ wind_turbine_farms : List of responses on wind turbine farms. $ offshore_drilling : List of responses on offshore drilling. $ hydrolic_fracturing : List of responses on hydrolic fracturing. $ coal_mining : List of responses on coal mining. $ nuclear_power_plants: List of responses on nuclear.    Details  
We did not have access to individual responses in original data set, so we took the published percentages and backed out the breakdown    Source  
https://www.pewresearch.org/science/2018/05/14/majorities-see-government-efforts-to-protect-the-environment-as-insufficient/     Examples    data(pew_energy_2018) lapply(pew_energy_2018, head) lapply(pew_energy_2018, length) lapply(pew_energy_2018, table) Prop <- function(x) { table(x) / length(x) } lapply(pew_energy_2018, Prop)"
"openintro-photo_classify","openintro","photo_classify","Photo classifications: fashion or not",1822,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/photo_classify.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/photo_classify.html","photo_classify R Documentation   Photo classifications: fashion or not   Description  
This is a simulated data set for photo classifications based on a machine learning algorithm versus what the true classification is for those photos. While the data are not real, they resemble performance that would be reasonable to expect in a well-built classifier.    Usage    photo_classify    Format  
A data frame with 1822 observations on the following 2 variables.    mach_learn
The prediction by the machine learning system as to whether the photo is about fashion or not.   truth
The actual classification of the photo by a team of humans.     Details  
The hypothetical ML algorithm has a precision of 90\ photos it claims are fashion, about 90\ The recall of the ML algorithm is about 64\ about fashion, it correctly predicts that they are about fashion about 64\ of the time.    Source  
The data are simulated / hypothetical.    Examples    data(photo_classify) table(photo_classify)"
"openintro-piracy","openintro","piracy","Piracy and PIPA/SOPA",534,8,1,1,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/piracy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/piracy.html","piracy R Documentation   Piracy and PIPA/SOPA   Description  
This data set contains observations on all 100 US Senators and 434 of the 325 US Congressional Representatives related to their support of anti-piracy legislation that was introduced at the end of 2011.    Usage    piracy    Format  
A data frame with 534 observations on the following 8 variables.    name
Name of legislator.   party
Party affiliation as democrat ( D ), Republican ( R ), or Independent ( I ).   state
Two letter state abbreviation.   money_pro
Amount of money in dollars contributed to the legislator's campaign in 2010 by groups generally thought to be supportive of PIPA/SOPA: movie and TV studios, record labels.   money_con
Amount of money in dollars contributed to the legislator's campaign in 2010 by groups generally thought to be opposed to PIPA/SOPA: computer and internet companies.   years
Number of years of service in Congress.   stance
Degree of support for PIPA/SOPA with levels Leaning No , No , Undecided , Unknown , Yes   chamber
Whether the legislator is a member of either the house or senate .     Details  
The Stop Online Piracy Act (SOPA) and the Protect Intellectual Property Act (PIPA) were two bills introduced in the US House of Representatives and the US Senate, respectively, to curtail copyright infringement. The bill was controversial because there were concerns the bill limited free speech rights. ProPublica, the independent and non-profit news organization, compiled this data set to compare the stance of legislators towards the bills with the amount of campaign funds that they received from groups considered to be supportive of or in opposition to the legislation.   
For more background on the legislation and the formulation of  money_pro and money_con , read the documentation on ProPublica, linked below.    Source  
https://projects.propublica.org/sopa  The list may be slightly out of date since many politician's perspectives on the legislation were in flux at the time of data collection.    Examples    library(dplyr) library(ggplot2) pipa <- filter(piracy, chamber == ""senate"") pipa %>% group_by(stance) %>% summarise(money_pro_mean = mean(money_pro, na.rm = TRUE)) %>% ggplot(aes(x = stance, y = money_pro_mean)) + geom_col() + labs(x = ""Stance"", y = ""Average contribution, in $"", title = ""Average contribution to the legislator's campaign in 2010"", subtitle = ""by groups supportive of PIPA/SOPA (movie and TV studios, record labels)"") ggplot(pipa, aes(x = stance, y = money_pro)) + geom_boxplot() + labs(x = ""Stance"", y = ""Contribution, in $"", title = ""Contribution by groups supportive of PIPA/SOPA"", subtitle = ""Movie and TV studios, record labels"") ggplot(pipa, aes(x = stance, y = money_con)) + geom_boxplot() + labs(x = ""Stance"", y = ""Contribution, in $"", title = ""Contribution by groups opposed to PIPA/SOPA"", subtitle = ""Computer and internet companies"") pipa %>% filter( money_pro > 0, money_con > 0 ) %>% mutate(for_pipa = ifelse(stance == ""yes"", ""yes"", ""no"")) %>% ggplot(aes(x = money_pro, y = money_con, color = for_pipa)) + geom_point() + scale_color_manual(values = c(""gray"", ""red"")) + scale_y_log10() + scale_x_log10() + labs(x = ""Contribution by pro-PIPA groups"", y = ""Contribution by anti-PIPA groups"", color = ""For PIPA"")"
"openintro-playing_cards","openintro","playing_cards","Table of Playing Cards in 52-Card Deck",52,3,1,1,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/playing_cards.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/playing_cards.html","playing_cards R Documentation   Table of Playing Cards in 52-Card Deck   Description  
A table describing each of the 52 cards in a deck.    Usage    playing_cards    Format  
A data frame with 52 observations on the following 2 variables.    number
The number or card type.   suit
Card suit, which takes one of four values: Club , Diamond , Heart , or Spade .   face_card
Whether the card counts as a face card.     Source  
This extremely complex data set was generated from scratch.    Examples    playing_cards <- data.frame( number = rep(c(2:10, ""J"", ""Q"", ""K"", ""A""), 4), suit = rep(c(""Spade"", ""Diamond"", ""Club"", ""Heart""), rep(13, 4))) playing_cards$face_card <- ifelse(playing_cards$number %in% c(2:10, ""A""), ""no"", ""yes"")"
"openintro-pm25_2011_durham","openintro","pm25_2011_durham","Air quality for Durham, NC",449,20,3,0,8,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/pm25_2011_durham.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/pm25_2011_durham.html","pm25_2011_durham R Documentation   Air quality for Durham, NC   Description  
Daily air quality is measured by the air quality index (AQI) reported by the Environmental Protection Agency.    Usage    pm25_2011_durham    Format  
A data frame with 449 observations on the following 20 variables.    date
Date   aqs_site_id
a factor with levels 37-063-0015   poc
a numeric vector   daily_mean_pm2_5_concentration
a numeric vector   units
a factor with levels ug/m3 LC   daily_aqi_value
a numeric vector   daily_obs_count
a numeric vector   percent_complete
a numeric vector   aqs_parameter_code
a numeric vector   aqs_parameter_desc
a factor with levels Acceptable PM2.5 AQI & Speciation Mass PM2.5 - Local Conditions   csa_code
a numeric vector   csa_name
a factor with levels Raleigh-Durham-Cary, NC   cbsa_code
a numeric vector   cbsa_name
a factor with levels Durham, NC   state_code
a numeric vector   state
a factor with levels North Carolina   county_code
a numeric vector   county
a factor with levels Durham   site_latitude
a numeric vector   site_longitude
a numeric vector     Source  
US Environmental Protection Agency, AirData, 2011.  http://www3.epa.gov/airdata/ad_data_daily.html     Examples    pm25_2011_durham"
"openintro-poker","openintro","poker","Poker winnings during 50 sessions",50,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/poker.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/poker.html","poker R Documentation   Poker winnings during 50 sessions   Description  
Poker winnings (and losses) for 50 days by a professional poker player.    Usage    poker    Format  
A data frame with 49 observations on the following variable.    winnings
Poker winnings and losses, in US dollars.     Source  
Anonymity has been requested by the player.    Examples    library(ggplot2) ggplot(poker, aes(x = winnings)) + geom_histogram(binwidth = 250)"
"openintro-possum","openintro","possum","Possums in Australia and New Guinea",104,8,2,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/possum.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/possum.html","possum R Documentation   Possums in Australia and New Guinea   Description  
Data representing possums in Australia and New Guinea. This is a copy of the data set by the same name in the DAAG package, however, the data set included here includes fewer variables.    Usage    possum    Format  
A data frame with 104 observations on the following 8 variables.    site
The site number where the possum was trapped.   pop
Population, either Vic (Victoria) or other  (New South Wales or Queensland).   sex
Gender, either m (male) or f (female).   age
Age.   head_l
Head length, in mm.   skull_w
Skull width, in mm.   total_l
Total length, in cm.   tail_l
Tail length, in cm.     Source  
Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458.    Examples    library(ggplot2) # Skull width vs. head length ggplot(possum, aes(x = head_l, y = skull_w)) + geom_point() # Total length vs. sex ggplot(possum, aes(x = total_l, fill = sex)) + geom_density(alpha = 0.5)"
"openintro-ppp_201503","openintro","ppp_201503","US Poll on who it is better to raise taxes on",691,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ppp_201503.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ppp_201503.html","ppp_201503 R Documentation   US Poll on who it is better to raise taxes on   Description  
A poll of 691 people, with party affiliation collected, asked whether they think it's better to raise taxes on the rich or raise taxes on the poor.    Usage    ppp_201503    Format  
A data frame with 691 observations on the following 2 variables.    party
Political party affiliation.   taxes
Support for who to raise taxes on.     Source  
Public Policy Polling, Americans on College Degrees, Classic Literature, the Seasons, and More, data collected Feb 20-22, 2015.    Examples    library(ggplot2) ggplot(ppp_201503, aes(x = party, fill = taxes)) + geom_bar(position = ""fill"") + labs(x = ""Party"", x = ""Proportion"", fill = ""Taxes"")"
"openintro-present","openintro","present","Birth counts",63,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/present.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/present.html","present R Documentation   Birth counts   Description  
An updated version of the historical Arbuthnot dataset. Numbers of boys and girls born in the United States between 1940 and 2002.    Usage    present    Format  
A data frame with 63 observations on the following 3 variables.    year
Year.   boys
Number of boys born.   girls
Number of girls born.     Source  
Mathews, T. J., and Brady E. Hamilton. ""Trend analysis of the sex ratio at birth in the United States."" National vital statistics reports 53.20 (2005): 1-17.    Examples    library(ggplot2) ggplot(present, mapping = aes(x = year, y = boys / girls)) + geom_line()"
"openintro-president","openintro","president","United States Presidental History",67,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/president.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/president.html","president R Documentation   United States Presidental History   Description  
Summary of the changes in the president and vice president for the United States of America.    Usage    president    Format  
A data frame with 67 observations on the following 5 variables.    potus
President of the United States   party
Political party of the president   start
Start year   end
End year   vpotus
Vice President of the United States     Source  
Presidents of the United States (table) – infoplease.com (visited: Nov 2nd, 2010)   
http://www.infoplease.com/ce6/history/A0840075.html     Examples    president"
"openintro-prison","openintro","prison","Prison isolation experiment",14,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/prison.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/prison.html","prison R Documentation   Prison isolation experiment   Description  
Subjects from Central Prison in Raleigh, NC, volunteered for an experiment involving an ""isolation"" experience. The goal of the experiment was to find a treatment that reduces subjects' psychopathic deviant T scores. This score measures a person's need for control or their rebellion against control, and it is part of a commonly used mental health test called the Minnesota Multiphasic Personality Inventory (MMPI) test.    Usage    prison    Format  
A data frame with 14 observations on the following 6 variables.    pre_trt1
Pre-treatment 1.   post_trt1
Post-treatment 1.   pre_trt2
Pre-treatment 2.   post_trt2
Post-treatment 2.   pre_trt3
Pre-treatment 3.   post_trt3
Post-treatment 3.     Source  
https://stat.duke.edu/datasets/prison-isolation     Examples    prison"
"openintro-prius_mpg","openintro","prius_mpg","User reported fuel efficiency for 2017 Toyota Prius Prime",19,5,0,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/prius_mpg.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/prius_mpg.html","prius_mpg R Documentation   User reported fuel efficiency for 2017 Toyota Prius Prime   Description  
Fueleconomy.gov, the official US government source for fuel economy information, allows users to share gas mileage information on their vehicles. These data come from 19 users sharing gas mileage on their 2017 Toyota Prius Prime. Note that these data are user estimates and since the sources data cannot be verified, the accuracy of these estimates are not guaranteed.    Usage    prius_mpg    Format  
A data frame with 19 observations on the following 10 variables.    average_mpg
Average mileage as estimated by the user.   state
US State the user lives in.   stop_and_go
Proportion of stop and go driving.   highway
Proportion of highway driving.   last_updated
Date estimate was last updated.     Source  
Fueleconomy.gov,  https://www.fueleconomy.gov/mpg/MPG.do?action=mpgData&vehicleID=38531&browser=true&details=on , retrieved 2019-04-14.    Examples    library(ggplot2) library(dplyr) ggplot(prius_mpg, aes(x = average_mpg)) + geom_histogram(binwidth = 25)"
"openintro-race_justice","openintro","race_justice","Yahoo! News Race and Justice poll results",1059,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/race_justice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/race_justice.html","race_justice R Documentation   Yahoo! News Race and Justice poll results   Description  
Results from a Yahoo! News poll conducted by YouGov on May 29-39, 2020. In total 1060 U.S. adults were asked a series of questions regarding race and justice in the wake of the killing of George Floyd by a police officer. Results in this data set are percentages for the question, ""Do you think Blacks and Whites receive equal treatment from the police?"" For this particular question there were 1059 respondents.    Usage    race_justice    Format  
A data frame with 1,059 rows and 2 variables.    race_eth
Race/ethnicity of respondent, with levels White , Black , Hispanic , and Other .   response
Response to the question ""Do you think Black and White people receive equal treatment from the police?"", with levels Yes , No , and Not sure .     Source  
Yahoo! News Race and Justice - May 31, 2020 .    Examples    library(ggplot2) library(dplyr) # Conditional probabilities of response for each race/ethnicity race_justice %>% count(race_eth, response) %>% group_by(race_eth) %>% mutate(prop = n / sum(n)) # Stacked bar plot of counts ggplot(race_justice, aes(x = race_eth, fill = response)) + geom_bar() + labs( x = ""Race / ethnicity"", y = ""Count"", title = ""Do you think Black and White people receive equal treatment from the police?"", fill = ""Response"" ) # Stacked bar plot of proportions ggplot(race_justice, aes(x = race_eth, fill = response)) + geom_bar(position = ""fill"") + labs( x = ""Race / ethnicity"", y = ""Proportion"", title = ""Do you think Black and White people receive equal treatment from the police?"", fill = ""Response"" )"
"openintro-res_demo_1","openintro","res_demo_1","Simulated data for regression",100,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/res_demo_1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/res_demo_1.html","res_demo_1 R Documentation   Simulated data for regression   Description  
Simulated data for regression    Usage    res_demo_1    Format  
A data frame with 100 observations on the following 3 variables.    x
a numeric vector   y_lin
a numeric vector   y_fan_back
a numeric vector     Examples    res_demo_1"
"openintro-res_demo_2","openintro","res_demo_2","Simulated data for regression",300,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/res_demo_2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/res_demo_2.html","res_demo_2 R Documentation   Simulated data for regression   Description  
Simulated data for regression    Usage    res_demo_2    Format  
A data frame with 300 observations on the following 3 variables.    x
a numeric vector   y_fan
a numeric vector   y_log
a numeric vector     Examples    res_demo_2"
"openintro-resume","openintro","resume","Which resume attributes drive job callbacks?",4870,30,21,10,0,0,20,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/resume.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/resume.html","resume R Documentation   Which resume attributes drive job callbacks?   Description  
This experiment data comes from a study that sought to understand the influence of race and gender on job application callback rates. The study monitored job postings in Boston and Chicago for several months during 2001 and 2002 and used this to build up a set of test cases. Over this time period, the researchers randomly generating resumes to go out to a job posting, such as years of experience and education details, to create a realistic-looking resume. They then randomly assigned a name to the resume that would communicate the applicant's gender and race. The first names chosen for the study were selected so that the names would predominantly be recognized as belonging to black or white individuals. For example, Lakisha was a name that their survey indicated would be interpreted as a black woman, while Greg was a name that would generally be interpreted to be associated with a white male.    Usage    resume    Format  
A data frame with 4870 observations, representing 4870 resumes, over 30 different variables that describe the job details, the outcome ( received_callback ), and attributes of the resume.   job_ad_id
Unique ID associated with the advertisement.   job_city
City where the job was located.   job_industry
Industry of the job.   job_type
Type of role.   job_fed_contractor  
Indicator for if the employer is a federal contractor.   job_equal_opp_employer
Indicator for if the employer is an Equal Opportunity Employer.   job_ownership
The type of company, e.g. a nonprofit or a private company.   job_req_any
Indicator for if any job requirements are listed. If so, the other job_req_* fields give more detail.   job_req_communication
Indicator for if communication skills are required.   job_req_education
Indicator for if some level of education is required.   job_req_min_experience  
Amount of experience required.   job_req_computer
Indicator for if computer skills are required.   job_req_organization  
Indicator for if organization skills are required.   job_req_school
Level of education required.   received_callback
Indicator for if there was a callback from the job posting for the person listed on this resume.   firstname
The first name used on the resume.   race
Inferred race associated with the first name on the resume.   gender
Inferred gender associated with the first name on the resume.   years_college
Years of college education listed on the resume.   college_degree
Indicator for if the resume listed a college degree.   honors  
Indicator for if the resume listed that the candidate has been awarded some honors.   worked_during_school
Indicator for if the resume listed working while in school.   years_experience
Years of experience listed on the resume.   computer_skills  
Indicator for if computer skills were listed on the resume. These skills were adapted for listings, though the skills were assigned independently of other details on the resume.   special_skills
Indicator for if any special skills were listed on the resume.   volunteer
Indicator for if volunteering was listed on the resume.   military
Indicator for if military experience was listed on the resume.   employment_holes
Indicator for if there were holes in the person's employment history.   has_email_address
Indicator for if the resume lists an email address.   resume_quality
Each resume was generally classified as either lower or higher quality.     Details  
Because this is an experiment, where the race and gender attributes are being randomly assigned to the resumes, we can conclude that any statistically significant difference in callback rates is causally linked to these attributes.   
Do you think it's reasonable to make a causal conclusion? You may have some health skepticism. However, do take care to appreciate that this was an experiment: the first name (and so the inferred race and gender) were randomly assigned to the resumes, and the quality and attributes of a resume were assigned independent of the race and gender. This means that any effects we observe are in fact causal, and the effects related to race are both statistically significant and very large: white applicants had about a 50\   
Do you still have doubts lingering in the back of your mind about the validity of this study? Maybe a counterargument about why the standard conclusions from this study may not apply? The article summarizing the results was exceptionally well-written, and it addresses many potential concerns about the study's approach. So if you're feeling skeptical about the conclusions, please find the link below and explore!    Source  
Bertrand M, Mullainathan S. 2004. ""Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination"". The American Economic Review 94:4 (991-1013). doi: 10.3386/w9873 .    See Also  
resume     Examples    head(resume, 5) # Some checks to confirm balance between race and # other attributes of a resume. There should be # some minor differences due to randomness, but # each variable should be (and is) generally # well-balanced. table(resume$race, resume$years_college) table(resume$race, resume$college_degree) table(resume$race, resume$honors) table(resume$race, resume$worked_during_school) table(resume$race, resume$years_experience) table(resume$race, resume$computer_skills) table(resume$race, resume$special_skills) table(resume$race, resume$volunteer) table(resume$race, resume$military) table(resume$race, resume$employment_holes) table(resume$race, resume$has_email_address) table(resume$race, resume$resume_quality) # Regarding the callback outcome for race, # we observe a very large difference. tapply( resume$received_callback, resume[c(""race"", ""gender"")], mean) # Natural question: is this statisticaly significant? # A proper analysis would take into account the # paired nature of the data. For each ad, let's # compute the following statistic: # <callback rate for white candidates> # - <callback rate for black candidates> # First contruct the callbacks for white and # black candidates by ad ID: table(resume$race) cb_white <- with( subset(resume, race == ""white""), tapply(received_callback, job_ad_id, mean)) cb_black <- with( subset(resume, race == ""black""), tapply(received_callback, job_ad_id, mean)) # Next, compute the differences, where the # names(cb_white) part ensures we matched up the # job ad IDs. diff <- cb_white - cb_black[names(cb_white)] # Finally, we can apply a t-test on the differences: t.test(diff) # There is very strong evidence of an effect. # Here's a similar check with gender. There are # more female-inferred candidates used on the resumes. table(resume$gender) cb_male <- with( subset(resume, gender == ""m""), tapply(received_callback, job_ad_id, mean)) cb_female <- with( subset(resume, gender == ""f""), tapply(received_callback, job_ad_id, mean)) diff <- cb_female - cb_male[names(cb_female)] # The `na.rm = TRUE` part ensures we limit to jobs # where both a male and female resume were sent. t.test(diff, na.rm = TRUE) # There is no statistically significant difference. # Was that the best analysis? Absolutely not! # However, the analysis was unbiased. To get more # precision on the estimates, we could build a # multivariate model that includes many characteristics # of the resumes sent, e.g. years of experience. # Since those other characteristics were assigned # independently of the race characteristics, this # means the race finding will almost certainy will # hold. However, it is possible that we'll find # more interesting results with the gender investigation."
"openintro-rosling_responses","openintro","rosling_responses","Sample Responses to Two Public Health Questions",278,3,2,2,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/rosling_responses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/rosling_responses.html","rosling_responses R Documentation   Sample Responses to Two Public Health Questions   Description  
Public health has improved and evolved, but has the public's knowledge changed with it? This data set explores sample responses for two survey questions posed by Hans Rosling during lectures to a wide array of well-educated audiences.    Usage    rosling_responses    Format  
A data frame with 278 rows and 3 variables:    question
ID for the question being posed.   response
Noting whether the response was correct  or incorrect .   prob_random_correct
The probability the person would have guessed the answer correctly if they were guessing completely randomly.     Source  
The samples we describe are plausible based on the exact rates observed in larger samples. For more info on the actual rates observed, visit https://www.gapminder.org .   
Another relevant reference is a book by Hans Rosling, Anna Rosling Ronnlund, and Ola Rosling called  Factfulness .    Examples    frac_correct <- tapply( rosling_responses$response == ""correct"", rosling_responses$question, mean ) frac_correct n <- table(rosling_responses$question) n expected <- tapply( rosling_responses$prob_random_correct, rosling_responses$question, mean ) # Construct confidence intervals. se <- sqrt(frac_correct * (1 - frac_correct) / n) # Lower bounds. frac_correct - 1.96 * se # Upper bounds. frac_correct + 1.96 * se # Construct Z-scores and p-values. z <- (frac_correct - expected) / se pt(z, df = n - 1)"
"openintro-russian_influence_on_us_election_2016","openintro","russian_influence_on_us_election_2016","Russians' Opinions on US Election Influence in 2016",506,1,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/russian_influence_on_us_election_2016.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/russian_influence_on_us_election_2016.html","russian_influence_on_us_election_2016 R Documentation   Russians' Opinions on US Election Influence in 2016   Description  
Survey of Russian citizens on whether they believed their government tried to influence the 2016 US election. The survey was taken in Spring 2018 by Pew Research.    Usage    russian_influence_on_us_election_2016    Format  
A data frame with 506 observations on the following variable.    influence_2016
Response of the Russian survey participant to the question of whether their government tried to influence the 2016 election in the United States.     Details  
The actual sample size was 1000. However, the original data were not from a simple random sample; after accounting for the design, the equivalent sample size was 506, which was what was used for the data set here to keep things simpler for intro stat analyses.    Source  
https://www.pewresearch.org/global/2018/08/21/russians-say-their-government-did-not-try-to-influence-u-s-presidential-election/     Examples    table(russian_influence_on_us_election_2016)"
"openintro-salinity","openintro","salinity","Salinity in Bimini Lagoon, Bahamas",30,2,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/salinity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/salinity.html","salinity R Documentation   Salinity in Bimini Lagoon, Bahamas   Description  
Data collected at three different water masses in the Bimini Lagoon, Bahamas.    Usage    salinity    Format  
A data frame with 30 rows and 2 variables.    site_number
Location where measurments were taken.   salinity_ppt
Salinity value in parts per thousand.     Source  
Till, R. (1974) Statistical Methods for the Earth Scientist: An Introduction. London: Macmillon, 104.    Examples    library(ggplot2) library(broom) ggplot(salinity, aes(x = salinity_ppt)) + geom_dotplot() + facet_wrap(~site_number, ncol = 1) tidy(aov(salinity_ppt ~ site_number, data = salinity))"
"openintro-sat_improve","openintro","sat_improve","Simulated data for SAT score improvement",30,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sat_improve.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sat_improve.html","sat_improve R Documentation   Simulated data for SAT score improvement   Description  
Fake data for score improvements from students who took a course from an SAT score improvement company.    Usage    sat_improve    Format  
A data frame with 30 observations on the following variable.    sat_improve
a numeric vector     Examples    sat_improve"
"openintro-satgpa","openintro","satgpa","SAT and GPA data",1000,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/satgpa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/satgpa.html","satgpa R Documentation   SAT and GPA data   Description  
SAT and GPA data for 1000 students at an unnamed college.    Usage    satgpa    Format  
A data frame with 1000 observations on the following 6 variables.    sex
Gender of the student.   sat_v
Verbal SAT percentile.   sat_m
Math SAT percentile.   sat_sum
Total of verbal and math SAT percentiles.   hs_gpa
High school grade point average.   fy_gpa
First year (college) grade point average.     Source  
Educational Testing Service originally collected the data.    References  
https://chance.dartmouth.edu/course/Syllabi/Princeton96/ETSValidation.html     Examples    library(ggplot2) library(broom) # Verbal scores ggplot(satgpa, aes(x = sat_v, fy_gpa)) + geom_point() + geom_smooth(method = ""lm"") + labs( x = ""Verbal SAT percentile"", y = ""First year (college) grade point average"" ) mod <- lm(fy_gpa ~ sat_v, data = satgpa) tidy(mod) # Math scores ggplot(satgpa, aes(x = sat_m, fy_gpa)) + geom_point() + geom_smooth(method = ""lm"") + labs( x = ""Math SAT percentile"", y = ""First year (college) grade point average"" ) mod <- lm(fy_gpa ~ sat_m, data = satgpa) tidy(mod)"
"openintro-scotus_healthcare","openintro","scotus_healthcare","Public Opinion with SCOTUS ruling on American Healthcare Act",1012,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/scotus_healthcare.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/scotus_healthcare.html","scotus_healthcare R Documentation   Public Opinion with SCOTUS ruling on American Healthcare Act   Description  
On June 28, 2012 the U.S. Supreme Court upheld the much debated 2010 healthcare law, declaring it constitutional. A Gallup poll released the day after this decision indicates that 46% of 1,012 Americans agree with this decision.    Usage    scotus_healthcare    Format  
A data frame with 1012 observations on the following variable.    response
Response values reported are agree and other .     Source  
Gallup, Americans Issue Split Decision on Healthcare Ruling, retrieved 2012-06-28.    Examples    table(scotus_healthcare)"
"openintro-seattlepets","openintro","seattlepets","Names of pets in Seattle",52519,7,0,6,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/seattlepets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/seattlepets.html","seattlepets R Documentation   Names of pets in Seattle   Description  
Names of registered pets in Seattle, WA, between 2003 and 2018, provided by the city's Open Data Portal.    Usage    seattlepets    Format  
A data frame with 52,519 rows and 7 variables:    license_issue_date
Date the animal was registered with Seattle   license_number
Unique license number   animal_name
Animal's name   species
Animal's species (dog, cat, goat, etc.)   primary_breed
Primary breed of the animal   secondary_breed
Secondary breed if mixed   zip_code
Zip code animal is registered in     Source  
These data come from Seattle's Open Data Portal, https://data.seattle.gov/Community/Seattle-Pet-Licenses/jguv-t9rb"
"openintro-sex_discrimination","openintro","sex_discrimination","Bank manager recommendations based on sex",48,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sex_discrimination.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sex_discrimination.html","sex_discrimination R Documentation   Bank manager recommendations based on sex   Description  
Study from the 1970s about whether sex influences hiring recommendations.    Usage    sex_discrimination    Format  
A data frame with 48 observations on the following 2 variables.    sex
a factor with levels female and male   decision
a factor with levels not promoted and promoted     Source  
Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel decisions. Journal of Applied Psychology 59(1):9-14.    Examples    library(ggplot2) table(sex_discrimination) ggplot(sex_discrimination, aes(y = sex, fill = decision)) + geom_bar(position = ""fill"")"
"openintro-simulated_normal","openintro","simulated_normal","Simulated data sets, drawn from a normal distribution.",400,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/simulated_normal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/simulated_normal.html","simulated_normal R Documentation   Simulated data sets, drawn from a normal distribution.   Description  
Data were simulated using rnorm .    Usage    simulated_normal    Format  
The format is: List of 3 $ n40 : 40 observations from a standard normal distribution. $ n100: 100 observations from a standard normal distribution. $ n400: 400 observations from a standard normal distribution.    Examples    data(simulated_normal) lapply(simulated_normal, qqnorm)"
"openintro-simulated_scatter","openintro","simulated_scatter","Simulated data for sample scatterplots",2033,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/simulated_scatter.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/simulated_scatter.html","simulated_scatter R Documentation   Simulated data for sample scatterplots   Description  
Fake data.    Usage    simulated_scatter    Format  
A data frame with 500 observations on the following 3 variables.    group
Group, representing data for a specific plot.   x
x-value.   y
y-value.     Examples    library(ggplot2) ggplot(simulated_scatter, aes(x = x, y = y)) + geom_point() + facet_wrap(~group)"
"openintro-sinusitis","openintro","sinusitis","Sinusitis and antibiotic experiment",166,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sinusitis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sinusitis.html","sinusitis R Documentation   Sinusitis and antibiotic experiment   Description  
Researchers studying the effect of antibiotic treatment for acute sinusitis to one of two groups: treatment or control.    Usage    sinusitis    Format  
A data frame with 166 observations on the following 2 variables.    group
a factor with levels control and treatment   self_reported_improvement
a factor with levels no and yes     Source  
J.M. Garbutt et al. Amoxicillin for Acute Rhinosinusitis: A Randomized Controlled Trial. In: JAMA: The Journal of the American Medical Association 307.7 (2012), pp. 685-692.    Examples    sinusitis"
"openintro-sleep_deprivation","openintro","sleep_deprivation","Survey on sleep deprivation and transportation workers",1087,2,0,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sleep_deprivation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sleep_deprivation.html","sleep_deprivation R Documentation   Survey on sleep deprivation and transportation workers   Description  
The National Sleep Foundation conducted a survey on the sleep habits of randomly sampled transportation workers and a control sample of non-transportation workers.    Usage    sleep_deprivation    Format  
A data frame with 1087 observations on the following 2 variables.    sleep
a factor with levels <6 , 6-8 , and >8   profession
a factor with levels bus / taxi / limo drivers ,  control , pilots , train operators , truck drivers     Source  
National Sleep Foundation, 2012 Sleep in America Poll: Transportation Workers' Sleep, 2012.  https://www.sleepfoundation.org/professionals/sleep-americar-polls/2012-sleep-america-poll-transportation-workers-sleep     Examples    sleep_deprivation"
"openintro-smallpox","openintro","smallpox","Smallpox vaccine results",6224,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/smallpox.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/smallpox.html","smallpox R Documentation   Smallpox vaccine results   Description  
A sample of 6,224 individuals from the year 1721 who were exposed to smallpox in Boston. Some of them had received a vaccine (inoculated) while others had not. Doctors at the time believed that inoculation, which involves exposing a person to the disease in a controlled form, could reduce the likelihood of death.    Usage    smallpox    Format  
A data frame with 6224 observations on the following 2 variables.    result
Whether the person died or lived .   inoculated
Whether the person received inoculated.     Source  
Fenner F. 1988. Smallpox and Its Eradication (History of International Public Health, No. 6). Geneva: World Health Organization. ISBN 92-4-156110-6.    Examples    data(smallpox) table(smallpox)"
"openintro-smoking","openintro","smoking","UK Smoking Data",1691,12,2,0,9,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/smoking.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/smoking.html","smoking R Documentation   UK Smoking Data   Description  
Survey data on smoking habits from the UK. The data set can be used for analyzing the demographic characteristics of smokers and types of tobacco consumed.    Usage    smoking    Format  
A data frame with 1691 observations on the following 12 variables.    gender
Gender with levels Female and Male .   age
Age.   marital_status
Marital status with levels Divorced ,  Married , Separated , Single and Widowed .   highest_qualification
Highest education level with levels  A Levels , Degree , GCSE/CSE , GCSE/O Level ,  Higher/Sub Degree , No Qualification , ONC/BTEC and  Other/Sub Degree   nationality
Nationality with levels British , English ,  Irish , Scottish , Welsh , Other , Refused  and Unknown .   ethnicity
Ethnicity with levels Asian , Black ,  Chinese , Mixed , White and Refused   Unknown .   gross_income
Gross income with levels Under 2,600 ,  2,600 to 5,200 , 5,200 to 10,400 , 10,400 to 15,600 ,  15,600 to 20,800 , 20,800 to 28,600 , 28,600 to 36,400 ,  Above 36,400 , Refused and Unknown .   region
Region with levels London , Midlands & East Anglia ,  Scotland , South East , South West , The North  and Wales   smoke
Smoking status with levels No and Yes   amt_weekends
Number of cigarettes smoked per day on weekends.   amt_weekdays
Number of cigarettes smoked per day on weekdays.   type
Type of cigarettes smoked with levels Packets ,  Hand-Rolled , Both/Mainly Packets and Both/Mainly Hand-Rolled     Source  
National STEM Centre, Large Datasets from stats4schools,  https://www.stem.org.uk/resources/elibrary/resource/28452/large-datasets-stats4schools .    Examples    library(ggplot2) ggplot(smoking, aes(x = amt_weekends)) + geom_histogram(binwidth = 5) ggplot(smoking, aes(x = amt_weekdays)) + geom_histogram(binwidth = 5) ggplot(smoking, aes(x = gender, fill = smoke)) + geom_bar(position = ""fill"") ggplot(smoking, aes(x = marital_status, fill = smoke)) + geom_bar(position = ""fill"")"
"openintro-snowfall","openintro","snowfall","Snowfall at Paradise, Mt. Rainier National Park",100,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/snowfall.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/snowfall.html","snowfall R Documentation   Snowfall at Paradise, Mt. Rainier National Park   Description  
Annual snowfall data for Paradise, Mt. Rainier National Park. To include a full winter season, snowfall is recorded from July 1 to June 30. Data from 1943-1946 not available due to road closure during World War II. Records also unavailable from 1948-1954.    Usage    snowfall    Format  
A data frame with 100 rows and 3 variables.    year_start
The year snowfall measurement began on July 1.   year_end
The year snowfall measurement ended on June 30.   total_snow
Snowfall measured in inches.     Source  
National Parks Services .    Examples    library(ggplot2) ggplot(snowfall, aes(x = total_snow))+ geom_histogram(binwidth = 50)+ labs( title = ""Annual Snowfall"", subtitle = ""Paradise, Mt. Rainier National Park"", x = ""Snowfall (in.)"", y = ""Number of Years"", caption = ""Source: National Parks Services"" ) ggplot(snowfall, aes(x = year_start, y = total_snow, group = 1))+ geom_line()+ labs( title = ""Annual Snowfall"", subtitle = ""Paradise, Mt. Rainier National Park"", y = ""Snowfall (in.)"", x = ""Year"", caption = ""Source: National Parks Services"" )"
"openintro-socialexp","openintro","socialexp","Social experiment",45,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/socialexp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/socialexp.html","socialexp R Documentation   Social experiment   Description  
A ""social experiment"" conducted by a TV program questioned what people do when they see a very obviously bruised woman getting picked on by her boyfriend. On two different occasions at the same restaurant, the same couple was depicted. In one scenario the woman was dressed ""provocatively"" and in the other scenario the woman was dressed ""conservatively"". The table below shows how many restaurant diners were present under each scenario, and whether or not they intervened.    Usage    socialexp    Format  
A data frame with 45 observations on the following 2 variables.    intervene
Whether other diners intervened or not.   scenario
How the woman was dressed.     Examples    table(socialexp)"
"openintro-solar","openintro","solar","Energy Output From Two Solar Arrays in San Francisco",284,3,1,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/solar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/solar.html","solar R Documentation   Energy Output From Two Solar Arrays in San Francisco   Description  
The data provide the energy output for several months from two roof-top solar arrays in San Francisco. This city is known for having highly variable weather, so while these two arrays are only about 1 mile apart from each other, the Inner Sunset location tends to have more fog.    Usage    solar    Format  
A data frame with 284 observations on the following 3 variables. Each row represents a single day for one of the arrays.    location
Location for the array.   date
Date.   kwh
Number of kWh     Details  
The Haight-Ashbury array is a 10.4 kWh array, while the Inner Sunset array is a 2.8 kWh array. The kWh units represents kilowatt-hours, which is the unit of energy that typically is used for electricity bills. The cost per kWh in San Francisco was about $0.25 in 2016.    Source  
These data were provided by Larry Rosenfeld, a resident in San Francisco.    Examples    solar.is <- subset(solar, location == ""Inner_Sunset"") solar.ha <- subset(solar, location == ""Haight_Ashbury"") plot(solar.is$date, solar.is$kwh, type = ""l"", ylim = c(0, max(solar$kwh))) lines(solar.ha$date, solar.ha$kwh, col = 4) d <- merge(solar.ha, solar.is, by = ""date"") plot(d$date, d$kwh.x / d$kwh.y, type = ""l"")"
"openintro-sp500","openintro","sp500","Financial information for 50 S&P 500 companies",50,12,0,0,1,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sp500.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sp500.html","sp500 R Documentation   Financial information for 50 S&P 500 companies   Description  
Fifty companies were randomly sampled from the 500 companies in the S&P 500, and their financial information was collected on March 8, 2012.    Usage    sp500    Format  
A data frame with 50 observations on the following 12 variables.    market_cap
Total value of all company shares, in millions of dollars.   stock
The name of the stock (e.g. AAPL for Apple).   ent_value
Enterprise value, which is an alternative to market cap that also accounts for things like cash and debt, in millions of dollars.   trail_pe
The market cap divided by the earnings (profits) over the last year.   forward_pe
The market cap divided by the forecasted earnings (profits) over the next year.   ev_over_rev
Enterprise value divided by the company's revenue.   profit_margin
Percent of earnings that are profits.   revenue
Revenue, in millions of dollars.   growth
Quartly revenue growth (year over year), in millions of dollars.   earn_before
Earnings before interest, taxes, depreciation, and amortization, in millions of dollars.   cash
Total cash, in millions of dollars.   debt
Total debt, in millions of dollars.     Source  
Yahoo! Finance, retrieved 2012-03-08.    Examples    library(ggplot2) ggplot(sp500, aes(x = ent_value, y = earn_before)) + geom_point() + labs(x = ""Enterprise value"", y = ""Earnings"") ggplot(sp500, aes(x = ev_over_rev, y = forward_pe)) + geom_point() + labs(x = ""Enterprise value / revenue, logged"", y = ""Market cap / forecasted earnings, logged"") ggplot(sp500, aes(x = ent_value, y = earn_before)) + geom_point() + scale_x_log10() + scale_y_log10() + labs(x = ""Enterprise value"", y = ""Earnings"") ggplot(sp500, aes(x = ev_over_rev, y = forward_pe)) + geom_point() + scale_x_log10() + scale_y_log10() + labs(x = ""Enterprise value / revenue, logged"", y = ""Market cap / forecasted earnings, logged"")"
"openintro-sp500_1950_2018","openintro","sp500_1950_2018","Daily observations for the S&P 500",17346,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sp500_1950_2018.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sp500_1950_2018.html","sp500_1950_2018 R Documentation   Daily observations for the S\&P 500   Description  
Data runs from 1950 to near the end of 2018.    Usage    sp500_1950_2018    Format  
A data frame with 17346 observations on the following 7 variables.    Date
Date of the form ""YYYY-MM-DD"" .   Open
Opening price.   High
Highest price of the day.   Low
Lowest price of the day.   Close
Closing price of the day.   Adj.Close
Adjusted price at close after accounting for dividends paid out.   Volume
Trading volume.     Source  
Yahoo! Finance    Examples    data(sp500_1950_2018) sp500.ten.years <- subset(sp500_1950_2018, ""2009-01-01"" <= as.Date(Date) & as.Date(Date) <= ""2018-12-31"") d <- diff(sp500.ten.years$Adj.Close) mean(d > 0)"
"openintro-sp500_seq","openintro","sp500_seq","S&P 500 stock data",2948,1,0,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sp500_seq.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sp500_seq.html","sp500_seq R Documentation   S&P 500 stock data   Description  
Daily stock returns from the S&P500 for 1990-2011 can be used to assess whether stock activity each day is independent of the stock's behavior on previous days. We label each day as Up or Down (D) depending on whether the market was up or down that day. For example, consider the following changes in price, their new labels of up and down, and then the number of days that must be observed before each Up day.    Usage    sp500_seq    Format  
A data frame with 2948 observations on the following variable.    race
a factor with levels 1 , 2 , 3 , 4 ,  5 , 6 , and 7+     Source  
Google Finance .    Examples    sp500_seq"
"openintro-speed_gender_height","openintro","speed_gender_height","Speed, gender, and height of 1325 students",1325,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/speed_gender_height.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/speed_gender_height.html","speed_gender_height R Documentation   Speed, gender, and height of 1325 students   Description  
1,325 UCLA students were asked to fill out a survey where they were asked about their height, fastest speed they have ever driven, and gender.    Usage    speed_gender_height    Format  
A data frame with 1325 observations on the following 3 variables.    speed
a numeric vector   gender
a factor with levels female and male   height
a numeric vector     Examples    speed_gender_height"
"openintro-ssd_speed","openintro","ssd_speed","SSD read and write speeds",54,7,1,3,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ssd_speed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ssd_speed.html","ssd_speed R Documentation   SSD read and write speeds   Description  
User submitted data on 1TB solid state drives (SSD).    Usage    ssd_speed    Format  
A data frame with 54 rows and 7 variables.    brand
Brand name of the drive.   model
Model name of the drive.   samples
Number of user submitted benchmarks.   form_factor
Physical form of the drive with levels 2.5 , m.2 , and mSATA .   nvme
If a drive uses the nvme protocol this value is 1, 0 if it does not.   read
Average read speed from user benchmarks in MB/s.   write
Average write speed from user benchmarks in MB/s.     Source  
UserBenchmark , retrieved September 1, 2020.    Examples    library(ggplot2) library(dplyr) ssd_speed %>% count(form_factor) ssd_speed %>% filter(form_factor != ""mSATA"") %>% ggplot(aes(x = read, y = write, color = form_factor))+ geom_point()+ labs( title = ""Average read vs. write speed of SSDs"", x = ""Read speed (MB/s)"", y = ""Write speed (MB/s)"" ) + facet_wrap(~form_factor, ncol = 1, scales = ""free"") + guides(color = FALSE)"
"openintro-starbucks","openintro","starbucks","Starbucks nutrition",77,7,0,1,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/starbucks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/starbucks.html","starbucks R Documentation   Starbucks nutrition   Description  
Nutrition facts for several Starbucks food items    Usage    starbucks    Format  
A data frame with 77 observations on the following 7 variables.    item
Food item.   calories
Calories.   fat
a numeric vector   carb
a numeric vector   fiber
a numeric vector   protein
a numeric vector   type
a factor with levels bakery , bistro box , hot breakfast , parfait , petite , salad , and sandwich     Source  
https://www.starbucks.com/menu , retrieved 2011-03-10.    Examples    starbucks"
"openintro-stats_scores","openintro","stats_scores","Final exam scores for twenty students",20,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/stats_scores.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/stats_scores.html","stats_scores R Documentation   Final exam scores for twenty students   Description  
Scores range from 57 to 94.    Usage    stats_scores    Format  
A data frame with 20 observations on the following variable.    scores
a numeric vector     Examples    stats_scores"
"openintro-stem_cell","openintro","stem_cell","Embryonic stem cells to treat heart attack (in sheep)",18,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/stem_cell.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/stem_cell.html","stem_cell R Documentation   Embryonic stem cells to treat heart attack (in sheep)   Description  
Does treatment using embryonic stem cells (ESCs) help improve heart function following a heart attack? Each sheep in the study was randomly assigned to the ESC or control group, and the change in their hearts' pumping capacity was measured in the study. A positive value corresponds to increased pumping capacity, which generally suggests a stronger recovery.    Usage    stem_cell    Format  
A data frame with 18 observations on the following 3 variables.    trmt
a factor with levels ctrl esc   before
a numeric vector   after
a numeric vector     Source  
https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(05)67380-1/fulltext     Examples    stem_cell"
"openintro-stent30","openintro","stent30","Stents for the treatment of stroke",451,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/stent30.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/stent30.html","stent30 R Documentation   Stents for the treatment of stroke   Description  
An experiment that studies effectiveness of stents in treating patients at risk of stroke with some unexpected results. stent30 represents the results 30 days after stroke and stent365 represents the results 365 days after stroke.    Usage    stent30    Format  
A data frame with 451 observations on the following 2 variables.    group
a factor with levels control and treatment   outcome
a factor with levels no event and stroke     Source  
Chimowitz MI, Lynn MJ, Derdeyn CP, et al. 2011. Stenting versus Aggressive Med- ical Therapy for Intracranial Arterial Stenosis. New England Journal of Medicine 365:993- 1003. doi: 10.1056/NEJMoa1105335 . NY Times article reporting on the study: https://www.nytimes.com/2011/09/08/health/research/08stent.html .    Examples    # 30-day results table(stent30) # 365-day results table(stent365)"
"openintro-stent365","openintro","stent365","Stents for the treatment of stroke",451,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/stent365.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/stent365.html","stent30 R Documentation   Stents for the treatment of stroke   Description  
An experiment that studies effectiveness of stents in treating patients at risk of stroke with some unexpected results. stent30 represents the results 30 days after stroke and stent365 represents the results 365 days after stroke.    Usage    stent30    Format  
A data frame with 451 observations on the following 2 variables.    group
a factor with levels control and treatment   outcome
a factor with levels no event and stroke     Source  
Chimowitz MI, Lynn MJ, Derdeyn CP, et al. 2011. Stenting versus Aggressive Med- ical Therapy for Intracranial Arterial Stenosis. New England Journal of Medicine 365:993- 1003. doi: 10.1056/NEJMoa1105335 . NY Times article reporting on the study: https://www.nytimes.com/2011/09/08/health/research/08stent.html .    Examples    # 30-day results table(stent30) # 365-day results table(stent365)"
"openintro-stocks_18","openintro","stocks_18","Monthly Returns for a few stocks",36,4,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/stocks_18.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/stocks_18.html","stocks_18 R Documentation   Monthly Returns for a few stocks   Description  
Monthly return data for a few stocks, which covers stock prices from November 2015 through October 2018.    Usage    stocks_18    Format  
A data frame with 36 observations on the following 3 variables.    date
First day of the month corresponding to the returns.   goog
Google stock price change.   cat
Caterpillar stock price change.   xom
Exxon Mobil stock price change.     Source  
Yahoo! Finance, direct download.    Examples    d <- stocks_18 dim(d) apply(d[, 2:3], 2, mean) apply(d[, 2:3], 2, sd)"
"openintro-student_housing","openintro","student_housing","Community college housing (simulated data, 2015)",175,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/student_housing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/student_housing.html","student_housing R Documentation   Community college housing (simulated data, 2015)   Description  
These are simulated data and intended to represent housing prices of students at a college.    Usage    student_housing    Format  
A data frame with 175 observations on the following variable.    price
Monthly housing price, simulated.     Examples    set.seed(5) generate_student_housing<- data.frame( price = round(rnorm(175, 515, 65) + exp(rnorm(175, 4.2, 1)))) hist(student_housing$price, 20) t.test(student_housing$price) mean(student_housing$price) sd(student_housing$price) identical(student_housing, generate_student_housing)"
"openintro-student_sleep","openintro","student_sleep","Sleep for 110 students (simulated)",110,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/student_sleep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/student_sleep.html","student_sleep R Documentation   Sleep for 110 students (simulated)   Description  
A simulated data set for how much 110 college students each slept in a single night.    Usage    student_sleep    Format  
A data frame with 110 observations on the following variable.    hours
Number of hours slept by this student (simulated).     Source  
Simulated data.    Examples    set.seed(2) x <- exp(c(rnorm(100, log(7.5), 0.15), rnorm(10, log(10), 0.196))) x <- round(x - mean(x) + 7.42, 2) identical(x, student_sleep$hours)"
"openintro-sulphinpyrazone","openintro","sulphinpyrazone","Treating heart attacks",1475,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/sulphinpyrazone.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/sulphinpyrazone.html","sulphinpyrazone R Documentation   Treating heart attacks   Description  
Experiment data for studying the efficacy of treating patients who have had a heart attack with Sulphinpyrazone.    Usage    sulphinpyrazone    Format  
A data frame with 1475 observations on the following 2 variables.    group
a factor with levels control treatment   outcome
a factor with levels died lived     Source  
Anturane Reinfarction Trial Research Group. 1980. Sulfinpyrazone in the prevention of sudden death after myocardial infarction. New England Journal of Medicine 302(5):250-256.    Examples    sulphinpyrazone"
"openintro-supreme_court","openintro","supreme_court","Supreme Court approval rating",976,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/supreme_court.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/supreme_court.html","supreme_court R Documentation   Supreme Court approval rating   Description  
Summary of a random survey of 976 people.    Usage    supreme_court    Format  
A data frame with 976 observations on the following variable.    answer
a factor with levels approve and not     Source  
https://www.nytimes.com/2012/06/08/us/politics/44-percent-of-americans-approve-of-supreme-court-in-new-poll.html     Examples    supreme_court"
"openintro-teacher","openintro","teacher","Teacher Salaries in St. Louis, Michigan",71,8,2,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/teacher.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/teacher.html","teacher R Documentation   Teacher Salaries in St. Louis, Michigan   Description  
This data set contains teacher salaries from 2009-2010 for 71 teachers employed by the St. Louis Public School in Michigan, as well as several covariates.    Usage    teacher    Format  
A data frame with 71 observations on the following 8 variables.    id
Identification code for each teacher, assigned randomly.   degree
Highest educational degree attained: BA (bachelor's degree) or MA (master's degree).   fte
Full-time enrollment status: full-time 1 or part-time 0.5 .   years
Number of years employed by the school district.   base
Base annual salary, in dollars.   fica
Amount paid into Social Security and Medicare per year through the Federal Insurance Contribution Act (FICA), in dollars.   retirement
Amount paid into the retirement fund of the teacher per year, in dollars.   total
Total annual salary of the teacher, resulting from the sum of base salary + fica + retirement, in dollars.     Source  
Originally posted on https://dev.socrata.com/data , removed in 2020.    Examples    library(ggplot2) # Salary and education level ggplot(teacher, aes(x = degree, y = base)) + geom_boxplot() + labs(x = ""Highest educational degree attained"", y = ""Base annual salary, in $"", color = ""Degree"", title = ""Salary and education level"") # Salary and years of employment ggplot(teacher, aes(x = years, y = base, color = degree)) + geom_point() + labs(x = ""Number of years employed by the school district"", y = ""Base annual salary, in $"", color = ""Degree"", title = ""Salary and years of employment"")"
"openintro-textbooks","openintro","textbooks","Textbook data for UCLA Bookstore and Amazon",73,7,1,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/textbooks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/textbooks.html","textbooks R Documentation   Textbook data for UCLA Bookstore and Amazon   Description  
A random sample was taken of nearly 10\ textbook for each course was identified, and its new price at the UCLA Bookstore and on Amazon.com were recorded.    Usage    textbooks    Format  
A data frame with 73 observations on the following 7 variables.    dept_abbr
Course department (abbreviated).   course
Course number.   isbn
Book ISBN.   ucla_new
New price at the UCLA Bookstore.   amaz_new
New price on Amazon.com.   more
Whether additional books were required for the course ( Y means ""yes, additional books were required"").   diff
The UCLA Bookstore price minus the Amazon.com price for each book.     Details  
The sample represents only courses where textbooks were listed online through UCLA Bookstore's website. The most expensive textbook was selected based on the UCLA Bookstore price, which may insert bias into the data; for this reason, it may be beneficial to analyze only the data where more  is ""N"" .    Source  
Collected by David Diez.    Examples    library(ggplot2) ggplot(textbooks, aes(x = diff)) + geom_histogram(binwidth = 5) t.test(textbooks$diff)"
"openintro-thanksgiving_spend","openintro","thanksgiving_spend","Thanksgiving spending, simulated based on Gallup poll.",436,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/thanksgiving_spend.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/thanksgiving_spend.html","thanksgiving_spend R Documentation   Thanksgiving spending, simulated based on Gallup poll.   Description  
This entry gives simulated spending data for Americans during Thanksgiving in 2009 based on findings of a Gallup poll.    Usage    thanksgiving_spend    Format  
A data frame with 436 observations on the following 1 variable.    spending
Amount of spending, in US dollars.     Examples    library(ggplot2) ggplot(thanksgiving_spend, aes(x = spending)) + geom_histogram(binwidth = 20)"
"openintro-tips","openintro","tips","Tip data",95,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/tips.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/tips.html","tips R Documentation   Tip data   Description  
A simulated data set of tips over a few weeks on a couple days per week. Each tip is associated with a single group, which may include several bills and tables (i.e. groups paid in one lump sum in simulations).    Usage    tips    Format  
A data frame with 95 observations on the following 5 variables.    week
Week number.   day
Day, either Friday or Tuesday .   n_peop
Number of people associated with the group.   bill
Total bill for the group.   tip
Total tip from the group.     Details  
This data set was built using simulations of tables, then bills, then tips based on the bills. Large groups were assumed to only pay the gratuity, which is evident in the data. Tips were set to be plausible round values; they were often (but not always) rounded to dollars, quarters, etc.    Source  
Simulated data set.    Examples    library(ggplot2) ggplot(tips, aes(x = day, y = tip)) + geom_boxplot() ggplot(tips, aes(x = tip, fill = factor(week))) + geom_density(alpha = 0.5) + labs(x = ""Tip"", y = ""Density"", fill = ""Week"") ggplot(tips, aes(x = tip)) + geom_dotplot() ggplot(tips, aes(x = tip, fill = factor(day))) + geom_density(alpha = 0.5) + labs(x = ""Tip"", y = ""Density"", fill = ""Day"")"
"openintro-toohey","openintro","toohey","Simulated polling data set",500,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/toohey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/toohey.html","toohey R Documentation   Simulated polling data set   Description  
Simulated data for a fake political candidate.    Usage    toohey    Format  
A data frame with 500 observations on the following variable.    vote_for
a factor with levels no yes     Examples    toohey"
"openintro-tourism","openintro","tourism","Turkey tourism",47,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/tourism.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/tourism.html","tourism R Documentation   Turkey tourism   Description  
Summary of tourism in Turkey.    Usage    tourism    Format  
A data frame with 47 observations on the following 3 variables.    year
a numeric vector   visitor_count_tho
a numeric vector   tourist_spending
a numeric vector     Source  
Association of Turkish Travel Agencies, Foreign Visitors Figure & Tourist Spendings By Years.  http://www.tursab.org.tr/en/statistics/foreign-visitors-figure-tourist-spendings-by-years_1083.html     Examples    tourism"
"openintro-toy_anova","openintro","toy_anova","Simulated data set for ANOVA",140,2,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/toy_anova.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/toy_anova.html","toy_anova R Documentation   Simulated data set for ANOVA   Description  
Simulated data set for getting a better understanding of intuition that ANOVA is based off of.    Usage    toy_anova    Format  
A data frame with 70 observations on the following 3 variables.    group
a factor with levels I II III   outcome
a numeric vector     Examples    toy_anova"
"openintro-transplant","openintro","transplant","Transplant consultant success rate (fake data)",62,1,1,0,1,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/transplant.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/transplant.html","transplant R Documentation   Transplant consultant success rate (fake data)   Description  
Summarizing whether there was or was not a complication for 62 patients who used a particular medical consultant.    Usage    transplant    Format  
A data frame with 62 observations on the following variable.    outcome
a factor with levels complications okay     Examples    transplant"
"openintro-ucla_f18","openintro","ucla_f18","UCLA courses in Fall 2018",3950,14,7,5,0,7,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ucla_f18.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ucla_f18.html","ucla_f18 R Documentation   UCLA courses in Fall 2018   Description  
List of all courses at UCLA during Fall 2018.    Usage    ucla_f18    Format  
A data frame with 3950 observations on the following 14 variables.    year
Year the course was offered   term
Term the course was offered   subject
Subject   subject_abbr
Subject abbreviation, if any   course
Course name   course_num
Course number, complete   course_numeric
Course number, numeric only   seminar
Boolean for if this is a seminar course   ind_study
Boolean for if this is some form of independent study   apprenticeship
Boolean for if this is an apprenticeship   internship
Boolean for if this is an internship   honors_contracts
Boolean for if this is an honors contracts course   laboratory
Boolean for if this is a lab   special_topic
Boolean for if this is any of the special types of courses listed     Source  
https://sa.ucla.edu/ro/public/soc , retrieved 2018-11-22.    Examples    nrow(ucla_f18) table(ucla_f18$special_topic) subset(ucla_f18, is.na(course_numeric)) table(subset(ucla_f18, !special_topic)$course_numeric < 100) elig_courses <- subset(ucla_f18, !special_topic & course_numeric < 100) set.seed(1) ucla_textbooks_f18 <- elig_courses[sample(nrow(elig_courses), 100), ] tmp <- order(ucla_textbooks_f18$subject, ucla_textbooks_f18$course_numeric) ucla_textbooks_f18 <- ucla_textbooks_f18[tmp, ] rownames(ucla_textbooks_f18) <- NULL head(ucla_textbooks_f18)"
"openintro-ucla_textbooks_f18","openintro","ucla_textbooks_f18","Sample of UCLA course textbooks for Fall 2018",201,20,2,1,6,7,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ucla_textbooks_f18.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ucla_textbooks_f18.html","ucla_textbooks_f18 R Documentation   Sample of UCLA course textbooks for Fall 2018   Description  
A sample of courses were collected from UCLA from Fall 2018, and the corresponding textbook prices were collected from the UCLA bookstore and also from Amazon.    Usage    ucla_textbooks_f18    Format  
A data frame with 201 observations on the following 20 variables.    year
Year the course was offered   term
Term the course was offered   subject
Subject   subject_abbr
Subject abbreviation, if any   course
Course name   course_num
Course number, complete   course_numeric
Course number, numeric only   seminar
Boolean for if this is a seminar course.   ind_study
Boolean for if this is some form of independent study   apprenticeship
Boolean for if this is an apprenticeship   internship
Boolean for if this is an internship   honors_contracts
Boolean for if this is an honors contracts course   laboratory
Boolean for if this is a lab   special_topic
Boolean for if this is any of the special types of courses listed   textbook_isbn
Textbook ISBN   bookstore_new
New price at the UCLA bookstore   bookstore_used
Used price at the UCLA bookstore   amazon_new
New price sold by Amazon   amazon_used
Used price sold by Amazon   notes
Any relevant notes     Details  
A past data set was collected from UCLA courses in Spring 2010, and Amazon at that time was found to be almost uniformly lower than those of the UCLA bookstore's. Now in 2018, the UCLA bookstore is about even with Amazon on the vast majority of titles, and there is no statistical difference in the sample data.   
The most expensive book required for the course was generally used.   
The reason why we advocate for using raw amount differences instead of percent differences is that a 20\ to a 20\ price difference on low-priced books would balance numerically (but not in a practical sense) a moderate but important price difference on more expensive books. So while this tends to result in a bit less sensitivity in detecting  some effect, we believe the absolute difference compares prices in a more meaningful way.   
Used prices contain the shipping cost but do not contain tax. The used prices are a more nuanced comparison, since these are all 3rd party sellers. Amazon is often more a marketplace than a retail site at this point, and many people buy from 3rd party sellers on Amazon now without realizing it. The relationship Amazon has with 3rd party sellers is also challenging. Given the frequently changing dynamics in this space, we don't think any analysis here will be very reliable for long term insights since products from these sellers changes frequently in quantity and price. For this reason, we focus only on new books sold directly by Amazon in our comparison. In a future round of data collection, it may be interesting to explore whether the dynamics have changed in the used market.    Source  
https://sa.ucla.edu/ro/public/soc    
https://ucla.verbacompare.com    
https://www.amazon.com     See Also  
textbooks , ucla_f18     Examples    library(ggplot2) library(dplyr) ggplot(ucla_textbooks_f18, aes(x = bookstore_new, y = amazon_new)) + geom_point() + geom_abline(slope = 1, intercept = 0, color = ""orange"") + labs(x = ""UCLA Bookstore price"", y = ""Amazon price"", title = ""Amazon vs. UCLA Bookstore prices of new textbooks"", subtitle = ""Orange line represents y = x"") # The following outliers were double checked for accuracy ucla_textbooks_f18_with_diff <- ucla_textbooks_f18 %>% mutate(diff = bookstore_new - amazon_new) ucla_textbooks_f18_with_diff %>% filter(diff > 20 | diff < -20) # Distribution of price differences ggplot(ucla_textbooks_f18_with_diff, aes(x = diff)) + geom_histogram(binwidth = 5) # t-test of price differences t.test(ucla_textbooks_f18_with_diff$diff)"
"openintro-ukdemo","openintro","ukdemo","United Kingdom Demographic Data",12,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/ukdemo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/ukdemo.html","ukdemo R Documentation   United Kingdom Demographic Data   Description  
This data set comes from the Guardian's Data Blog and includes five financial demographic variables.    Usage    ukdemo    Format  
A data frame with 12 observations on the following 6 variables.    region
Region in the United Kingdom   debt
Average regional debt, not including mortgages, in pounds   unemployment
Percent unemployment   house
Average house price, in pounds   pay
Average hourly pay, in pounds   rpi
Retail price index, which is standardized to 100 for the entire UK, and lower index scores correspond to lower prices     Source  
The data was described in the Guardian Data Blog:  https://www.theguardian.com/news/datablog/interactive/2011/oct/27/debt-money-expert-facts , retrieved 2011-11-01.    References  
Guardian Data Blog    Examples    library(ggplot2) ggplot(ukdemo, aes(x = pay, y = rpi)) + geom_point() + labs(x = ""Average hourly pay"", y = ""Retail price index"")"
"openintro-unempl","openintro","unempl","Annual unemployment since 1890",121,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/unempl.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/unempl.html","unempl R Documentation   Annual unemployment since 1890   Description  
A compilation of two data sets that provides an estimate of unemployment from 1890 to 2010.    Usage    unempl    Format  
A data frame with 121 observations on the following 3 variables.    year
Year   unemp
Unemployment rate, in percent   us_data
1 if from the Bureau of Labor Statistics, 0  otherwise     Source  
The data are from Wikipedia at the following URL accessed on November 1st, 2010:   
https://en.wikipedia.org/wiki/File:US_Unemployment_1890-2009.gif    
Below is a direct quote from Wikipedia describing the sources of the data:   
Own work by Peace01234 Complete raw data are on Peace01234. 1930-2009 data are from Bureau of Labor Statistics (BLS), Employment status of the civilian noninstitutional population, 1940 to date retrieved on March 6, 2009 and February 12, 2010 from the BLS' FTP server. Data prior to 1948 are for persons age 14 and over. Data beginning in 1948 are for persons age 16 and over. See also ""Historical Comparability"" under the Household Data section of the Explanatory Notes at https://www.bls.gov/cps/eetech_methods.pdf . 1890-1930 data are from Christina Romer (1986). ""Spurious Volatility in Historical Unemployment Data"", The Journal of Political Economy, 94(1): 1-37. 1930-1940 data are from Robert M. Coen (1973). ""Labor Force and Unemployment in the 1920's and 1930's: A Re-Examination Based on Postwar Experience"", The Review of Economics and Statistics, 55(1): 46-55. Unemployment data was only surveyed once each decade until 1940 when yearly surveys were begun. The yearly data estimates before 1940 are based on the decade surveys combined with other relevant surveys that were collected during those years. The methods are described in detail by Coen and Romer.    Examples    #=====> Time Series Plot of Data <=====# COL <- c(""#DDEEBB"", ""#EEDDBB"", ""#BBDDEE"", ""#FFD5DD"", ""#FFC5CC"") plot(unempl$year, unempl$unemp, type=""n"") rect(0, -50, 3000, 100, col=""#E2E2E2"") rect(1914.5, -1000, 1918.9, 1000, col=COL[1], border=""#E2E2E2"") rect(1929, -1000, 1939, 1000, col=COL[2], border=""#E2E2E2"") rect(1939.7, -1000, 1945.6, 1000, col=COL[3], border=""#E2E2E2"") rect(1955.8, -1000, 1965.3, 1000, col=COL[4], border=""#E2E2E2"") rect(1965.3, -1000, 1975.4, 1000, col=COL[5], border=""#E2E2E2"") abline(h=seq(0,50,5), col=""#F8F8F8"", lwd=2) abline(v=seq(1900, 2000, 20), col=""#FFFFFF"", lwd=1.3) lines(unempl$year, unempl$unemp) points(unempl$year, unempl$unemp, pch=20) legend(""topright"", fill=COL, c(""World War I"", ""Great Depression"", ""World War II"", ""Vietnam War Start"", ""Vietnam War Escalated""), bg=""#FFFFFF"", border=""#FFFFFF"")"
"openintro-unemploy_pres","openintro","unemploy_pres","President's party performance and unemployment rate",29,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/unemploy_pres.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/unemploy_pres.html","unemploy_pres R Documentation   President's party performance and unemployment rate   Description  
Covers midterm elections.    Usage    unemploy_pres    Format  
A data frame with 29 observations on the following 5 variables.    year
Year.   potus
The president in office.   party
President's party.   unemp
Unemployment rate.   change
Change in House seats for the president's party.     Source  
Wikipedia.    Examples    unemploy_pres"
"openintro-winery_cars","openintro","winery_cars","Time Between Gondola Cars at Sterling Winery",52,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/winery_cars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/winery_cars.html","winery_cars R Documentation   Time Between Gondola Cars at Sterling Winery   Description  
These times represent times between gondolas at Sterling Winery. The main take-away: there are 7 cars, as evidenced by the somewhat regular increases in splits between every 7 cars. The reason the times are slightly non-constant is that the gondolas come off the tracks, so times will change a little between each period.    Usage    winery_cars    Format  
A data frame with 52 observations on the following 2 variables.    obs_number
The observation number, e.g. observation 3 was immediately preceded by observation 2.   time_until_next
Time until this gondola car arrived since the last car had left.     Details  
Important context: there was a sufficient line that people were leaving the winery.   
So why is this data valuable? It indicates that the winery should add one more car since it has a lot of time wasted every 7th car. By adding another car, fewer visitors are likely to be turned away, resulting in increased revenue.    Source  
In-person data collection by David Diez (OpenIntro) on 2013-07-04.    Examples    winery_cars$car_number <- rep(1:7, 10)[1:nrow(winery_cars)] col <- COL[ifelse(winery_cars$car_number == 3, 4, 1)] plot(winery_cars[, c(""obs_number"", ""time_until_next"")], col = col, pch = 19) plot(winery_cars$car_number, winery_cars$time_until_next, col = fadeColor(col, ""88""), pch = 19)"
"openintro-xom","openintro","xom","Exxon Mobile stock data",98,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/xom.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/xom.html","xom R Documentation   Exxon Mobile stock data   Description  
Monthly data covering 2006 through early 2014.    Usage    xom    Format  
A data frame with 98 observations on the following 7 variables.    date
Date.   open
a numeric vector   high
a numeric vector   low
a numeric vector   close
a numeric vector   volume
a numeric vector   adj_close
a numeric vector     Source  
Yahoo! Finance.    Examples    xom"
"openintro-yawn","openintro","yawn","Contagiousness of yawning",50,2,2,0,2,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/yawn.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/yawn.html","yawn R Documentation   Contagiousness of yawning   Description  
An experiment conducted by the MythBusters, a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn't a person yawning near them (control).    Usage    yawn    Format  
A data frame with 50 observations on the following 2 variables.    result
a factor with levels not yawn yawn   group
a factor with levels ctrl trmt     Source  
MythBusters, Season 3, Episode 28.    Examples    yawn"
"openintro-yrbss","openintro","yrbss","Youth Risk Behavior Surveillance System (YRBSS)",13583,13,2,8,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/yrbss.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/yrbss.html","yrbss R Documentation   Youth Risk Behavior Surveillance System (YRBSS)   Description  
Select variables from YRBSS.    Usage    yrbss    Format  
A data frame with 13583 observations on the following 13 variables.    age
Age, in years.   gender
Gender.   grade
School grade.   hispanic
Hispanic or not.   race
Race / ethnicity.   height
Height, in meters (3.28 feet per meter).   weight
Weight, in kilograms (2.2 pounds per kilogram).   helmet_12m
How often did you wear a helmet when biking in the last 12 months?   text_while_driving_30d
How many days did you text while driving in the last 30 days?   physically_active_7d
How many days were you physically active for 60+ minutes in the last 7 days?   hours_tv_per_school_day
How many hours of TV do you typically watch on a school night?   strength_training_7d
How many days did you do strength training (e.g. lift weights) in the last 7 days?   school_night_hours_sleep
How many hours of sleep do you typically get on a school night?     Source  
CDC's Youth Risk Behavior Surveillance System (YRBSS)     Examples    table(yrbss$physically_active_7d)"
"openintro-yrbss_samp","openintro","yrbss_samp","Sample of Youth Risk Behavior Surveillance System (YRBSS)",100,13,2,8,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/yrbss_samp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/openintro/yrbss_samp.html","yrbss_samp R Documentation   Sample of Youth Risk Behavior Surveillance System (YRBSS)   Description  
A sample of the yrbss data set.    Usage    yrbss_samp    Format  
A data frame with 100 observations on the following 13 variables.    age
Age, in years.   gender
Gender.   grade
School grade.   hispanic
Hispanic or not.   race
Race / ethnicity.   height
Height, in meters (3.28 feet per meter).   weight
Weight, in kilograms (2.2 pounds per kilogram).   helmet_12m
How often did you wear a helmet when biking in the last 12 months?   text_while_driving_30d
How many days did you text while driving in the last 30 days?   physically_active_7d
How many days were you physically active for 60+ minutes in the last 7 days?   hours_tv_per_school_day
How many hours of TV do you typically watch on a school night?   strength_training_7d
How many days did you do strength training (e.g. lift weights) in the last 7 days?   school_night_hours_sleep
How many hours of sleep do you typically get on a school night?     Source  
CDC's Youth Risk Behavior Surveillance System (YRBSS)     Examples    table(yrbss_samp$physically_active_7d)"
"palmerpenguins-penguins","palmerpenguins","penguins","Size measurements for adult foraging penguins near Palmer Station, Antarctica",344,8,1,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv","https://vincentarelbundock.github.io/Rdatasets/doc/palmerpenguins/penguins.html","penguins R Documentation   Size measurements for adult foraging penguins near Palmer Station, Antarctica   Description  
Includes measurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex. This is a subset of penguins_raw .    Usage    penguins    Format  
A tibble with 344 rows and 8 variables:    species
a factor denoting penguin species (Adélie, Chinstrap and Gentoo)   island
a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)   bill_length_mm
a number denoting bill length (millimeters)   bill_depth_mm
a number denoting bill depth (millimeters)   flipper_length_mm
an integer denoting flipper length (millimeters)   body_mass_g
an integer denoting body mass (grams)   sex
a factor denoting penguin sex (female, male)   year
an integer denoting the study year (2007, 2008, or 2009)     Source  
Adélie penguins: Palmer Station Antarctica LTER and K. Gorman. 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Adélie penguins (Pygoscelis adeliae) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 5. Environmental Data Initiative https://doi.org/10.6073/pasta/98b16d7d563f265cb52372c8ca99e60f    
Gentoo penguins: Palmer Station Antarctica LTER and K. Gorman. 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Gentoo penguin (Pygoscelis papua) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 5. Environmental Data Initiative https://doi.org/10.6073/pasta/7fca67fb28d56ee2ffa3d9370ebda689    
Chinstrap penguins: Palmer Station Antarctica LTER and K. Gorman. 2020. Structural size measurements and isotopic signatures of foraging among adult male and female Chinstrap penguin (Pygoscelis antarcticus) nesting along the Palmer Archipelago near Palmer Station, 2007-2009 ver 6. Environmental Data Initiative https://doi.org/10.6073/pasta/c14dfcfada8ea13a17536e73eb6fbe9e    
Originally published in: Gorman KB, Williams TD, Fraser WR (2014) Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis). PLoS ONE 9(3): e90081. doi:10.1371/journal.pone.0090081"
"plm-Cigar","plm","Cigar","Cigarette Consumption",1380,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Cigar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Cigar.html","Cigar R Documentation   Cigarette Consumption   Description  
a panel of 46 observations from 1963 to 1992    Format  
A data frame containing :    state
state abbreviation   year
the year   price
price per pack of cigarettes   pop
population   pop16
population above the age of 16   cpi
consumer price index (1983=100)   ndi
per capita disposable income   sales
cigarette sales in packs per capita   pimin
minimum price in adjoining states per pack of cigarettes     Details  
total number of observations : 1380   
observation : regional   
country : United States    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Baltagi B, Levin D (1992). “Cigarette taxation: Raising revenues and reducing consumption.”  Structural Change and Economic Dynamics , 3 (2), 321–335.  https://EconPapers.repec.org/RePEc:eee:streco:v:3:y:1992:i:2:p:321-335 .   
Baltagi BH, Griffin JM, Xiong W (2000). “To Pool or Not to Pool: Homogeneous Versus Heterogeneous Estimators Applied to Cigarette Demand.”  The Review of Economics and Statistics , 82 (1), 117–126. doi: 10.1162/003465300558551 , https://doi.org/10.1162/003465300558551 ."
"plm-Crime","plm","Crime","Crime in North Carolina",630,44,1,0,2,0,42,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Crime.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Crime.html","Crime R Documentation   Crime in North Carolina   Description  
a panel of 90 observational units (counties) from 1981 to 1987    Format  
A data frame containing :    county
county identifier   year
year from 1981 to 1987   crmrte
crimes committed per person   prbarr
'probability' of arrest   prbconv
'probability' of conviction   prbpris
'probability' of prison sentence   avgsen
average sentence, days   polpc
police per capita   density
people per square mile   taxpc
tax revenue per capita   region
factor. One of 'other', 'west' or 'central'.   smsa
factor. (Also called ""urban"".) Does the individual reside in a SMSA (standard metropolitan statistical area)?   pctmin
percentage minority in 1980   wcon
weekly wage in construction   wtuc
weekly wage in transportation, utilities, communications   wtrd
weekly wage in wholesale and retail trade   wfir
weekly wage in finance, insurance and real estate   wser
weekly wage in service industry   wmfg
weekly wage in manufacturing   wfed
weekly wage in federal government   wsta
weekly wage in state government   wloc
weekly wage in local government   mix
offence mix: face-to-face/other   pctymle
percentage of young males (between ages 15 to 24)   lcrmrte
log of crimes committed per person   lprbarr
log of 'probability' of arrest   lprbconv
log of 'probability' of conviction   lprbpris
log of 'probability' of prison sentence   lavgsen
log of average sentence, days   lpolpc
log of police per capita   ldensity
log of people per square mile   ltaxpc
log of tax revenue per capita   lpctmin
log of percentage minority in 1980   lwcon
log of weekly wage in construction   lwtuc
log of weekly wage in transportation, utilities, communications   lwtrd
log of weekly wage in wholesale and retail trade   lwfir
log of weekly wage in finance, insurance and real estate   lwser
log of weekly wage in service industry   lwmfg
log of weekly wage in manufacturing   lwfed
log of weekly wage in federal government   lwsta
log of weekly wage in state government   lwloc
log of weekly wage in local government   lmix
log of offence mix: face-to-face/other   lpctymle
log of percentage of young males (between ages 15 to 24)     Details  
total number of observations : 630   
observation : regional   
country : United States   
The variables l* (lcrmrte, lprbarr, ...) contain the pre-computed logarithms of the base variables as found in the original data set. Note that these values slightly differ from what R's log() function yields for the base variables. In order to reproduce examples from the literature, the pre-computed logs need to be used, otherwise the results differ slightly.    Source  
Journal of Applied Econometrics Data Archive (complements Baltagi (2006)):   
http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/    
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452    
See also Journal of Applied Econometrics data archive entry for Baltagi (2006) at  http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/ .    References  
Cornwell C, Trumbull WN (1994). “Estimating the economic model of crime with panel data.”  Review of Economics and Statistics , 76 , 360–366.   
Baltagi BH (2006). “Estmating an economic model of crime using panel data from North Carolina.”  Journal of Applied Econometrics , 21 (4).   
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd."
"plm-EmplUK","plm","EmplUK","Employment and Wages in the United Kingdom",1031,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/EmplUK.html","EmplUK R Documentation   Employment and Wages in the United Kingdom   Description  
An unbalanced panel of 140 observations from 1976 to 1984    Format  
A data frame containing :    firm
firm index   year
year   sector
the sector of activity   emp
employment   wage
wages   capital
capital   output
output     Details  
total number of observations : 1031   
observation : firms   
country : United Kingdom    Source  
Arellano M, Bond S (1991). “Some Tests of Specification for Panel Data : Monte Carlo Evidence and an Application to Employment Equations.”  Review of Economic Studies , 58 , 277–297."
"plm-Gasoline","plm","Gasoline","Gasoline Consumption",342,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Gasoline.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Gasoline.html","Gasoline R Documentation   Gasoline Consumption   Description  
A panel of 18 observations from 1960 to 1978    Format  
A data frame containing :    country
a factor with 18 levels   year
the year   lgaspcar
logarithm of motor gasoline consumption per car   lincomep
logarithm of real per-capita income   lrpmg
logarithm of real motor gasoline price   lcarpcap
logarithm of the stock of cars per capita     Details  
total number of observations : 342   
observation : country   
country : OECD    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Baltagi BH, Griffin JM (1983). “Gasoline demand in the OECD: An application of pooling and testing procedures.”  European Economic Review , 22 (2), 117–137. ISSN 0014-2921, https://www.sciencedirect.com/science/article/pii/0014292183900776 ."
"plm-Grunfeld","plm","Grunfeld","Grunfeld's Investment Data",200,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Grunfeld.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Grunfeld.html","Grunfeld R Documentation   Grunfeld's Investment Data   Description  
A balanced panel of 10 observational units (firms) from 1935 to 1954    Format  
A data frame containing :    firm
observation   year
date   inv
gross Investment   value
value of the firm   capital
stock of plant and equipment     Details  
total number of observations : 200   
observation : production units   
country : United States    Note  
The Grunfeld data as provided in package plm is the same data as used in Baltagi (2001), see Examples below.   
NB:
Various versions of the Grunfeld data circulate online. Also, various text books (and also varying among editions) and papers use different subsets of the original Grunfeld data, some of which contain errors in a few data points compared to the original data used by Grunfeld (1958) in his PhD thesis. See Kleiber/Zeileis (2010) and its accompanying website for a comparison of various Grunfeld data sets in use.    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
https://www.wiley.com/legacy/wileychi/baltagi/supp/Grunfeld.fil    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Grunfeld Y (1958).  The determinants of corporate investment . Ph.D. thesis, Department of Economics, University of Chicago.   
Kleiber C, Zeileis A (2010). “The Grunfeld Data at 50.”  German Economic Review , 11 , 404–417. doi: 10.1111/j.1468-0475.2010.00513.x , https://doi.org/10.1111/j.1468-0475.2010.00513.x .   
website accompanying the paper with various variants of the Grunfeld data:  https://www.zeileis.org/grunfeld/ .    See Also  
For the complete Grunfeld data (11 firms), see AER::Grunfeld, in the AER package.    Examples    ## Not run: # Compare plm's Grunfeld data to Baltagi's (2001) Grunfeld data: data(""Grunfeld"", package=""plm"") Grunfeld_baltagi2001 <- read.csv(""http://www.wiley.com/legacy/wileychi/ baltagi/supp/Grunfeld.fil"", sep="""", header = FALSE) library(compare) compare::compare(Grunfeld, Grunfeld_baltagi2001, allowAll = T) # same data set ## End(Not run)"
"plm-Hedonic","plm","Hedonic","Hedonic Prices of Census Tracts in the Boston Area",506,15,1,0,1,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Hedonic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Hedonic.html","Hedonic R Documentation   Hedonic Prices of Census Tracts in the Boston Area   Description  
A cross-section    Format  
A dataframe containing:    mv
median value of owner–occupied homes   crim
crime rate   zn
proportion of 25,000 square feet residential lots   indus
proportion of no–retail business acres   chas
is the tract bounds the Charles River?   nox
annual average nitrogen oxide concentration in parts per hundred million   rm
average number of rooms   age
proportion of owner units built prior to 1940   dis
weighted distances to five employment centers in the Boston area   rad
index of accessibility to radial highways   tax
full value property tax rate ($/$10,000)   ptratio
pupil/teacher ratio   blacks
proportion of blacks in the population   lstat
proportion of population that is lower status   townid
town identifier     Details  
number of observations : 506   
observation : regional   
country : United States    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Besley DA, Kuh E, Welsch RE (1980).  Regression diagnostics: identifying influential data and sources of collinearity . John Wiley and Sons ltd. Wiley series in probability and statistics.   
Harrison D, Rubinfeld DL (1978). “Hedonic housing prices and the demand for clean air.”  Journal of Environmental Economics and Management , 5 , 81–102."
"plm-LaborSupply","plm","LaborSupply","Wages and Hours Worked",5320,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/LaborSupply.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/LaborSupply.html","LaborSupply R Documentation   Wages and Hours Worked   Description  
A panel of 532 observations from 1979 to 1988    Format  
A data frame containing :    lnhr
log of annual hours worked   lnwg
log of hourly wage   kids
number of children   age
age   disab
bad health   id
id   year
year     Details  
number of observations : 5320    Source  
Online complements to Ziliak (1997).   
Journal of Business Economics and Statistics web site:  https://amstat.tandfonline.com/loi/ubes20/ .    References  
Colin Cameron A, K. Trivedi P (2005).  Microeconometrics: Methods and Applications . Cambridge University Press. ISBN 0521848059, doi: 10.1017/CBO9780511811241 , https://doi.org/10.1017/CBO9780511811241 .   
Ziliak JP (1997). “Efficient Estimation with Panel Data When Instruments Are Predetermined: An Empirical Comparison of Moment-Condition Estimators.”  Journal of Business & Economic Statistics , 15 (4), 419–431. ISSN 07350015."
"plm-Males","plm","Males","Wages and Education of Young Males",4360,12,3,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Males.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Males.html","Males R Documentation   Wages and Education of Young Males   Description  
A panel of 545 observations from 1980 to 1987    Format  
A data frame containing :    nr
identifier   year
year   school
years of schooling   exper
years of experience (computed as age-6-school )   union
wage set by collective bargaining?   ethn
a factor with levels black, hisp, other   married
married?   health
health problem?   wage
log of hourly wage   industry
a factor with 12 levels   occupation
a factor with 9 levels   residence
a factor with levels rural_area, north_east, northern_central, south     Details  
total number of observations : 4360   
observation : individuals   
country : United States    Source  
Journal of Applied Econometrics data archive  http://qed.econ.queensu.ca/jae/1998-v13.2/vella-verbeek/ .    References  
Vella F, Verbeek M (1998). “Whose wages do unions raise? A dynamic model of unionism and wage rate determination for young men.”  Journal of Applied Econometrics , 13 , 163–183.   
Verbeek M (2004).  A Guide to Modern Econometrics . Wiley."
"plm-Parity","plm","Parity","Purchasing Power Parity and other parity relationships",1768,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Parity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Parity.html","Parity R Documentation   Purchasing Power Parity and other parity relationships   Description  
A panel of 104 quarterly observations from 1973Q1 to 1998Q4    Format  
A data frame containing :    country
country codes: a factor with 17 levels   time
the quarter index, 1973Q1-1998Q4   ls
log spot exchange rate vs. USD   lp
log price level   is
short term interest rate   il
long term interest rate   ld
log price differential vs. USA   uis
U.S. short term interest rate   uil
U.S. long term interest rate     Details  
total number of observations : 1768   
observation : country   
country : OECD    Source  
Coakley J, Fuertes A, Smith R (2006). “Unobserved heterogeneity in panel time series models.”  Computational Statistics \& Data Analysis , 50 (9), 2361–2380.    References  
Coakley J, Fuertes A, Smith R (2006). “Unobserved heterogeneity in panel time series models.”  Computational Statistics \& Data Analysis , 50 (9), 2361–2380.   
Driscoll JC, Kraay AC (1998). “Consistent covariance matrix estimation with spatially dependent panel data.”  Review of economics and statistics , 80 (4), 549–560."
"plm-Produc","plm","Produc","US States Production",816,11,0,0,2,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Produc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Produc.html","Produc R Documentation   US States Production   Description  
A panel of 48 observations from 1970 to 1986    Format  
A data frame containing :    state
the state   year
the year   region
the region   pcap
public capital stock   hwy
highway and streets   water
water and sewer facilities   util
other public buildings and structures   pc
private capital stock   gsp
gross state product   emp
labor input measured by the employment in non–agricultural payrolls   unemp
state unemployment rate     Details  
total number of observations : 816   
observation : regional   
country : United States    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Baltagi BH, Pinnoi N (1995). “Public capital stock and state productivity growth: further evidence from an error components model.”  Empirical Economics , 20 , 351–359.   
Munnell A (1990). “Why Has Productivity Growth Declined? Productivity and Public Investment.”  New England Economic Review , 3–22."
"plm-RiceFarms","plm","RiceFarms","Production of Rice in Indonesia",1026,20,0,0,4,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/RiceFarms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/RiceFarms.html","RiceFarms R Documentation   Production of Rice in Indonesia   Description  
a panel of 171 observations    Format  
A dataframe containing :    id
the farm identifier   size
the total area cultivated with rice, measured in hectares   status
land status, on of 'owner' (non sharecroppers, owner operators or leaseholders or both), 'share'  (sharecroppers), 'mixed' (mixed of the two previous status)   varieties
one of 'trad' (traditional varieties),  'high' (high yielding varieties) and 'mixed' (mixed varieties)   bimas
bIMAS is an intensification program; one of  'no' (non-bimas farmer), 'yes' (bimas farmer) or  'mixed' (part but not all of farmer's land was registered to be in the bimas program)   seed
seed in kilogram   urea
urea in kilogram   phosphate
phosphate in kilogram   pesticide
pesticide cost in Rupiah   pseed
price of seed in Rupiah per kg   purea
price of urea in Rupiah per kg   pphosph
price of phosphate in Rupiah per kg   hiredlabor
hired labor in hours   famlabor
family labor in hours   totlabor
total labor (excluding harvest labor)   wage
labor wage in Rupiah per hour   goutput
gross output of rice in kg   noutput
net output, gross output minus harvesting cost (paid in terms of rice)   price
price of rough rice in Rupiah per kg   region
one of 'wargabinangun' , 'langan' ,  'gunungwangi' , 'malausma' , 'sukaambit' ,  'ciwangi'     Details  
number of observations : 1026   
observation : farms   
country : Indonesia    Source  
Feng Q, Horrace WC (2012). “Alternative technical efficiency measures: Skew, bias and scale.”  Journal of Applied Econometrics , 27 (2), 253–268. doi: 10.1002/jae.1190 , https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1190 ."
"plm-Snmesp","plm","Snmesp","Employment and Wages in Spain",5904,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Snmesp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Snmesp.html","Snmesp R Documentation   Employment and Wages in Spain   Description  
A panel of 738 observations from 1983 to 1990    Format  
A data frame containing:    firm
firm index   year
year   n
log of employment   w
log of wages   y
log of real output   i
log of intermediate inputs   k
log of real capital stock   f
real cash flow     Details  
total number of observations : 5904   
observation : firms   
country : Spain    Source  
Journal of Business Economics and Statistics data archive:   
https://amstat.tandfonline.com/loi/ubes20/ .    References  
Alonso-Borrego C, Arellano M (1999). “Symmetrically Normalized Instrumental-Variable Estimation Using Panel Data.”  Journal of Business and Economic Statistics , 17 (1), 36–49."
"plm-SumHes","plm","SumHes","The Penn World Table, v. 5",3250,7,2,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/SumHes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/SumHes.html","SumHes R Documentation   The Penn World Table, v. 5   Description  
A panel of 125 observations from 1960 to 1985    Format  
A data frame containing :    year
the year   country
the country name (factor)   opec
OPEC member?   com
communist regime?   pop
country's population (in thousands)   gdp
real GDP per capita (in 1985 US dollars)   sr
saving rate (in percent)     Details  
total number of observations : 3250   
observation : country   
country : World    Source  
Online supplements to Hayashi (2000).   
http://fhayashi.fc2web.com/datasets.htm     References  
Hayashi F (2000).  Econometrics . Princeton University Press.   
Summers R, Heston A (1991). “The Penn World Table (Mark 5): An Expanded Set of International Comparisons, 1950–1988.”  The Quarterly Journal of Economics , 106 , 327–68. doi: 10.2307/2937941 , https://doi.org/10.2307/2937941 ."
"plm-Wages","plm","Wages","Panel Data of Individual Wages",4165,12,8,0,7,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/plm/Wages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plm/Wages.html","Wages R Documentation   Panel Data of Individual Wages   Description  
A panel of 595 individuals from 1976 to 1982, taken from the Panel Study of Income Dynamics (PSID).

The data are organized as a stacked time series/balanced panel, see Examples on how to convert to a  pdata.frame .    Format  
A data frame containing:    exp
years of full-time work experience.   wks
weeks worked.   bluecol
blue collar?   ind
works in a manufacturing industry?   south
resides in the south?   smsa
resides in a standard metropolitan statistical area?   married
married?   sex
a factor with levels ""male"" and ""female""   union
individual's wage set by a union contract?   ed
years of education.   black
is the individual black?   lwage
logarithm of wage.     Details  
total number of observations : 4165   
observation : individuals   
country : United States    Source  
Online complements to Baltagi (2001):   
https://www.wiley.com/legacy/wileychi/baltagi/    
Online complements to Baltagi (2013):   
https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=4338&itemId=1118672321&resourceId=13452     References  
Baltagi BH (2001).  Econometric Analysis of Panel Data , 3rd edition. John Wiley and Sons ltd.   
Baltagi BH (2013).  Econometric Analysis of Panel Data , 5th edition. John Wiley and Sons ltd.   
Cornwell C, Rupert P (1988). “Efficient Estimation With Panel Data: an Empirical Comparison of Instrumental Variables Estimators.”  Journal of Applied Econometrics , 3 , 149–155.    Examples    # data set 'Wages' is organized as a stacked time series/balanced panel data(""Wages"", package = ""plm"") Wag <- pdata.frame(Wages, index=595)"
"plyr-baseball","plyr","baseball","Yearly batting records for all major league baseball players",21699,22,0,3,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/plyr/baseball.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plyr/baseball.html","baseball R Documentation   Yearly batting records for all major league baseball players   Description  
This data frame contains batting statistics for a subset of players collected from http://www.baseball-databank.org/ . There are a total of 21,699 records, covering 1,228 players from 1871 to 2007. Only players with more 15 seasons of play are included.    Usage    baseball    Format  
A 21699 x 22 data frame   Variables  
Variables:   

id, unique player id   
year, year of data   
stint   
team, team played for   
lg, league   
g, number of games   
ab, number of times at bat   
r, number of runs   
h, hits, times reached base because of a batted, fair ball without error by the defense   
X2b, hits on which the batter reached second base safely   
X3b, hits on which the batter reached third base safely   
hr, number of home runs   
rbi, runs batted in   
sb, stolen bases   
cs, caught stealing   
bb, base on balls (walk)   
so, strike outs   
ibb, intentional base on balls   
hbp, hits by pitch   
sh, sacrifice hits   
sf, sacrifice flies   
gidp, ground into double play      References  
http://www.baseball-databank.org/     Examples    baberuth <- subset(baseball, id == ""ruthba01"") baberuth$cyear <- baberuth$year - min(baberuth$year) + 1 calculate_cyear <- function(df) { mutate(df, cyear = year - min(year), cpercent = cyear / (max(year) - min(year)) ) } baseball <- ddply(baseball, .(id), calculate_cyear) baseball <- subset(baseball, ab >= 25) model <- function(df) { lm(rbi / ab ~ cyear, data=df) } model(baberuth) models <- dlply(baseball, .(id), model)"
"plyr-ozone","plyr","ozone","Monthly ozone measurements over Central America.",24,1728,0,0,0,0,1728,"https://vincentarelbundock.github.io/Rdatasets/csv/plyr/ozone.csv","https://vincentarelbundock.github.io/Rdatasets/doc/plyr/ozone.html","ozone R Documentation   Monthly ozone measurements over Central America.   Description  
This data set is a subset of the data from the 2006 ASA Data expo challenge, http://stat-computing.org/dataexpo/2006/ . The data are monthly ozone averages on a very coarse 24 by 24 grid covering Central America, from Jan 1995 to Dec 2000. The data is stored in a 3d area with the first two dimensions representing latitude and longitude, and the third representing time.    Usage    ozone    Format  
A 24 x 24 x 72 numeric array   References  
http://stat-computing.org/dataexpo/2006/     Examples    value <- ozone[1, 1, ] time <- 1:72 month.abbr <- c(""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"", ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec"") month <- factor(rep(month.abbr, length = 72), levels = month.abbr) year <- rep(1:6, each = 12) deseasf <- function(value) lm(value ~ month - 1) models <- alply(ozone, 1:2, deseasf) coefs <- laply(models, coef) dimnames(coefs)[[3]] <- month.abbr names(dimnames(coefs))[3] <- ""month"" deseas <- laply(models, resid) dimnames(deseas)[[3]] <- 1:72 names(dimnames(deseas))[3] <- ""time"" dim(coefs) dim(deseas)"
"pscl-absentee","pscl","absentee","Absentee and Machine Ballots in Pennsylvania State Senate Races",22,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/absentee.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/absentee.html","absentee R Documentation   Absentee and Machine Ballots in Pennsylvania State Senate Races   Description  
Absentee ballot outcomes contrasted with machine ballots, cast in Pennsylvania State Senate elections, selected districts, 1982-1993.   Usage   data(absentee)   Format  
A data frame with 22 observations on the following 8 variables.    year
a numeric vector, year of election, 19xx   district
a numeric vector, Pennsylvania State Senate district   absdem
a numeric vector, absentee ballots cast for the Democratic candidate   absrep
a numeric vector, absentee ballots cast for the Republican candidate   machdem
a numeric vector, votes cast on voting machines for the Democratic candidate   machrep
a numeric vector, votes cast on voting machines for the Republican candidate   dabs
a numeric vector, Democratic margin among absentee ballots   dmach
a numeric vector, Democratic margin among ballots case on voting machines     Details  
In November 1993, the state of Pennsylvania conducted elections for its state legislature. The result in the Senate election in the 2nd district (based in Philadelphia) was challenged in court, and ultimately overturned. The Democratic candidate won 19,127 of the votes cast by voting machine, while the Republican won 19,691 votes cast by voting machine, giving the Republican a lead of 564 votes. However, the Democrat won 1,396 absentee ballots, while the Republican won just 371 absentee ballots, more than offsetting the Republican lead based on the votes recorded by machines on election day. The Republican candidate sued, claiming that many of the absentee ballots were fraudulent. The judge in the case solicited expert analysis from Orley Ashenfelter, an economist at Princeton University. Ashenfelter examined the relationship between absentee vote margins and machine vote margins in 21 previous Pennsylvania Senate elections in seven districts in the Philadelphia area over the preceding decade.   Source  
Ashenfelter, Orley. 1994. Report on Expected Absentee Ballots. Typescript. Department of Economics, Princeton University.    References  
Ashenfelter, Orley, Phillip Levine and David Zimmerman. 2003.  Statistics and Econometrics: Methods and Applications . New York: John Wiley and Sons.   
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey. Examples 2.13, 2.14, 2.15.    Examples    data(absentee) summary(absentee) denom <- absentee$absdem + absentee$absrep y <- (absentee$absdem - absentee$absrep)/denom * 100 denom <- absentee$machdem + absentee$machrep x <- (absentee$machdem - absentee$machrep)/denom *100 ols <- lm(y ~ x, subset=c(rep(TRUE,21),FALSE) ## drop data point 22 ) ## predictions for disputed absentee point yhat22 <- predict(ols, newdata=list(x=x[22]), se.fit=TRUE, interval=""prediction"") tstat <- (y[22]-yhat22$fit[,""fit""])/yhat22$se.fit cat(""tstat on actual outcome for obs 22:"",tstat,""\n"") cat(paste(""Pr(t>"",round(tstat,2),"") i.e., one-sided:\n"",sep="""")) cat(1-pt(tstat,df=yhat22$df),""\n"") ## make a picture xseq <- seq(min(x)-.1*diff(range(x)), max(x)+.1*diff(range(x)), length=100) yhat <- predict(ols,interval=""prediction"", newdata=list(x=xseq)) plot(y~x, type=""n"", axes=FALSE, ylim=range(yhat,y), xlim=range(xseq),xaxs=""i"", xlab=""Democratic Margin, Machine Ballots (Percentage Points)"", ylab=""Democratic Margin, Absentee Ballots (Percentage Points)"") polygon(x=c(xseq,rev(xseq)), ## overlay 95% prediction CI y=c(yhat[,""lwr""],rev(yhat[,""upr""])), border=FALSE, col=gray(.85)) abline(ols,lwd=2) ## overlay ols points(x[-22],y[-22],pch=1) ## data points(x[22],y[22],pch=16) ## disputed data point text(x[22],y[22], ""Disputed\nElection"", cex=.75, adj=1.25) axis(1) axis(2)"
"pscl-admit","pscl","admit","Applications to a Political Science PhD Program",106,6,3,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/admit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/admit.html","admit R Documentation   Applications to a Political Science PhD Program   Description  
Ordinal ratings (faculty evaluations) of applicants to a Political Science PhD Program.   Usage   data(admit)   Format  
A data frame with 106 observations on the following 6 variables.    score
an ordered factor with levels 1 < 2 < 3 < 4 < 5   gre.quant
applicant's score on the quantitative section of the GRE; the maximum score is 800   gre.verbal
applicant's score on the verbal section of the GRE; the maximum score is 800   ap
1 if the applicant indicated an interest in American politics; 0 otherwise   pt
1 if the applicant indicated an interest in Political Theory; 0 otherwise   female
1 for female applicants; 0 otherwise     References  
Jackman, Simon. 2004. ""What Do We Learn From Graduate Admissions Committees?: A Multiple-Rater, Latent Variable Model, with Incomplete Discrete and Continuous Indicators."" Political Analysis . 12(4):400-424.   Examples    data(admit) summary(admit) ## ordered probit model op1 <- MASS::polr(score ~ gre.quant + gre.verbal + ap + pt + female, Hess=TRUE, data=admit, method=""probit"") summary(op1) hitmiss(op1) logLik(op1) pR2(op1)"
"pscl-AustralianElectionPolling","pscl","AustralianElectionPolling","Political opinion polls in Australia, 2004-07",239,14,0,2,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/AustralianElectionPolling.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/AustralianElectionPolling.html","AustralianElectionPolling R Documentation    Political opinion polls in Australia, 2004-07    Description  
The results of 239 published opinion polls measuring vote intentions (1st preference vote intention in a House of Representatives election) between the 2004 and 2007 Australian Federal elections, from 4 survey houses.    Usage   data(AustralianElectionPolling)   Format  
A data frame with 239 observations on the following 14 variables.    ALP
a numeric vector, percentage of respondents reported as intending to vote for the Australian Labor Party   Lib
a numeric vector, percentage of respondents reported as intending to vote for the Liberal Party   Nat
a numeric vector, percentage of respondents reported as intending to vote for the National Party   Green
a numeric vector, percentage of respondents reported as intending to vote for the Greens   FamilyFirst
a numeric vector, percentage of respondents reported as intending to vote for the Family First party   Dems
a numeric vector, percentage of respondents reported as intending to vote for the Australian Democrats   OneNation
a numeric vector, percentage of respondents reported as intending to vote for One Nation   DK
a numeric vector, percentage of respondents reported as expressing no preference or a “don't know” response   sampleSize
a numeric vector, reported sample size of the poll   org
a factor with levels Galaxy , Morgan, F2F , Newspoll , Nielsen and Morgan, Phone , indicating the survey house and/or mode of the poll   startDate
a Date, reported start of the field period   endDate
a Date, reported end of the field period   source
a character vector, source of the poll report   remark
a character vector, remarks noted by author and/or research assistant coders     Details  
Morgan uses two modes: phone and face-to-face.  
The 2004 Australian election was on October 9; the ALP won 37.6% of the 1st preferences cast in elections for the House of Representatives. The ALP won the 2007 election (November 24) with 43.4% of 1st preferences.  
The ALP changed leaders twice in the 2004-07 inter-election period spanned by these data: (1) Mark Latham resigned the ALP leadership on January 18 2005 and was replaced by Kim Beazley; (2) Beazley lost the ALP leadership to Kevin Rudd on December 4, 2006.  
The then Prime Minister, John Howard, announced the November 2007 election on October 14, 2007.   Source  
See the source variable. Andrea Abel assisted with the data collection.    References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey. Example 9.3.    Examples    data(AustralianElectionPolling) if(require(lattice)) { lattice::xyplot(ALP ~ startDate | org, data=AustralianElectionPolling, layout=c(1,5), type=""b"", xlab=""Start Date"", ylab=""ALP"") } ## test for house effects y <- AustralianElectionPolling$ALP/100 v <- y*(1-y)/AustralianElectionPolling$sampleSize w <- 1/v m1 <- mgcv::gam(y ~ s(as.numeric(startDate)), weight=w, data=AustralianElectionPolling) m2 <- update(m1, ~ . + org) anova(m1,m2)"
"pscl-AustralianElections","pscl","AustralianElections","elections to Australian House of Representatives, 1949-2016",27,19,0,0,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/AustralianElections.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/AustralianElections.html","AustralianElections R Documentation   elections to Australian House of Representatives, 1949-2016   Description  
Aggregate data on the 24 elections to Australia's House of Representatives, 1949 to 2016.   Usage   data(AustralianElections)   Format  
A data frame with the following variables:    date
date of election, stored using the  Date class   Seats
numeric, number of seats in the House of Representatives   Uncontested
numeric, number of uncontested seats   ALPSeats
numeric, number of seats won by the Australian Labor Party   LPSeats
numeric, number of seats won by the Liberal Party   NPSeats
numeric, number of seats won by the National Party (previously known as the Country Party)   OtherSeats
numeric, number of seats won by other parties and/or independent candidates   ALP
numeric, percentage of first preference votes cast for Australian Labor Party candidates   ALP2PP
numeric, percentage of the two-party preferred vote won by Australian Labor Party candidates   LP
numeric, percent of first preference votes cast for Liberal Party candidates   NP
numeric, percent of first preference votes cast for National Party (Country Party) candidates   DLP
numeric, percent of first preference votes cast for Democratic Labor Party candidates   Dem
numeric, percent of first preference votes cast for Australian Democrat candidates   Green
numeric, percent of first preference votes cast for Green Party candidates   Hanson
numeric, percent of first preference votes cast for candidates from Pauline Hanson's One Nation party   Com
numeric, percent of first preference votes cast for Communist Party candidates   AP
numeric, percent of first preference votes cast for Australia Party candidates   Informal
numeric, percent of ballots cast that are spoiled, blank, or otherwise uncountable (usually because of errors in enumerating preferences)   Turnout
numeric, percent of enrolled voters recorded as having turned out to vote (Australia has compulsory voting)     Note  
The Liberal National Party of Queensland formed in 2008 after a merger of the Liberal Party and the National Party. In all elections following 2008, they have been categorised under LP .   Source  
Australian Electoral Commission. http://www.aec.gov.au .    References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey. Example 3.5.    Examples    data(AustralianElections) attach(AustralianElections) alpSeatShare <- ALPSeats/Seats alpVoteShare <- ALP2PP/100 ## log-odds transforms x <- log(alpVoteShare/(1-alpVoteShare)) y <- log(alpSeatShare/(1-alpSeatShare)) ols <- lm(y~x) ## Tufte-style seats-votes regression xseq <- seq(-4.5,4.5,length=500) yhat <- coef(ols)[1] + coef(ols)[2]*xseq yhat <- exp(yhat)/(1+exp(yhat)) xseq <- exp(xseq)/(1+exp(xseq)) ## seats vote curve plot(x=alpVoteShare, y=alpSeatShare, xlab=""ALP Vote Share"", ylab=""ALP Seat Share"") lines(xseq,yhat,lwd=2) abline(h=.5,lty=2) abline(v=.5,lty=2)"
"pscl-bioChemists","pscl","bioChemists","article production by graduate students in biochemistry Ph.D. programs",915,6,2,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/bioChemists.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/bioChemists.html","bioChemists R Documentation   article production by graduate students in biochemistry Ph.D. programs   Description  
A sample of 915 biochemistry graduate students.    Usage   data(bioChemists)   Format   art
count of articles produced during last 3 years of Ph.D.   fem
factor indicating gender of student, with levels Men and Women   mar
factor indicating marital status of student, with levels Single and Married   kid5
number of children aged 5 or younger   phd
prestige of Ph.D. department   ment
count of articles produced by Ph.D. mentor during last 3 years     References  
Long, J. Scott. 1990. The origins of sex differences in science. Social Forces . 68(3):1297-1316.   
Long, J. Scott. 1997. Regression Models for Categorical and Limited Dependent Variables . Thousand Oaks, California: Sage."
"pscl-ca2006","pscl","ca2006","California Congressional Districts in 2006",53,13,3,2,0,2,9,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/ca2006.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/ca2006.html","ca2006 R Documentation   California Congressional Districts in 2006   Description  
Election returns and identifying information, California's 53 congressional districts in the 2006 Congressional elections.    Usage   data(ca2006)   Format  
A data frame with 53 observations on the following 11 variables.    district
numeric, number of Congressional district   D
numeric, number of votes for the Democratic candidate   R
numeric, votes for the Republican candidate   Other
numeric, votes for other candidates   IncParty
character, party of the incumbent (or retiring member),  D or R   IncName
character, last name of the incumbent, character  NA if no incumbent running   open
logical, TRUE if no incumbent running   contested
logical, TRUE if both major parties ran candidates   Bush2004
numeric, votes for George W. Bush (R) in the district in the 2004 presidential election   Kerry2004
numeric, votes for John Kerry (D) in 2004   Other2004
numeric votes for other candidates in 2004   Bush2000
numeric, votes for George W. Bush in 2000   Gore2000
numeric, votes for Al Gore (D) in 2000     Source  
2006 data from the California Secretary of State's web site,  http://www.sos.ca.gov/elections/prior-elections/statewide-election-results/general-election-november-7-2006/statement-vote/ . 2004 and 2000 presidential vote in congressional districts from the 2006 Almanac of American Politics .   
Thanks to Arthur Aguirre for the updated links, above.    References  
Michael Baraon and Richard E. Cohen. 2006. The Almanac of American Politics, 2006. National Journal Group: Washington, D.C.    Examples    data(ca2006) ## 2006 CA congressional vote against 2004 pvote y <- ca2006$D/(ca2006$D+ca2006$R) x <- ca2006$Kerry2004/(ca2006$Kerry2004+ca2006$Bush2004) pch <- rep(19,length(y)) pch[ca2006$open] <- 1 col <- rep(""black"",length(y)) col[11] <- ""red"" ## Pembo (R) loses to McNerney (D) plot(y~x,pch=pch, col=col, xlim=range(x,y,na.rm=TRUE), ylim=range(x,y,na.rm=TRUE), xlab=""Kerry Two-Party Vote, 2004"", ylab=""Democratic Two-Party Vote Share, 2006"") abline(0,1) abline(h=.5,lty=2) abline(v=.5,lty=2) legend(x=""topleft"", bty=""n"", col=c(""red"",""black"",""black""), pch=c(19,19,1), legend=c(""Seat Changing Hands"", ""Seat Retained by Incumbent Party"", ""Open Seat (no incumbent running)"") )"
"pscl-EfronMorris","pscl","EfronMorris","Batting Averages for 18 major league baseball players, 1970",18,7,1,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/EfronMorris.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/EfronMorris.html","EfronMorris R Documentation   Batting Averages for 18 major league baseball players, 1970   Description  
Batting averages for 18 major league baseball players, first 45 at bats of the 1970 season.   Usage   data(EfronMorris)   Format   name
character, name of player   team
character, team of player, abbreviated   league
character, National League or American League   r
numeric, hits in 1st 45 at bats   y
numeric, r /45, batting average over 1st 45 at bats   n
numeric, number of at bats, remainder of 1970 season   p
numeric, batting average over remainder of 1970 season     Source  
Efron, Bradley and Carl Morris. 1975. Data Analysis Using Stein's Estimator and Its Generalizations. Journal of the American Statistical Association . 70:311-319.    Examples    data(EfronMorris) attach(EfronMorris) plot(p~y, xlim=range(p,y), ylim=range(p,y), xlab=""Batting Average, 1st 45 at bats"", ylab=""Batting Average, Remainder of Season"") abline(0,1)"
"pscl-iraqVote","pscl","iraqVote","U.S. Senate vote on the use of force against Iraq, 2002.",100,6,2,1,2,1,2,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/iraqVote.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/iraqVote.html","iraqVote R Documentation    U.S. Senate vote on the use of force against Iraq, 2002.    Description  
On October 11, 2002, the United States Senate voted 77-23 to authorize the use of military force against Iraq. This data set lists the “Ayes” and “Nays” for each Senator and some covariates.    Usage   data(iraqVote)   Format  
A data frame with 100 observations on the following 6 variables.    y
a numeric vector, the recorded vote (1 if Aye, 0 if Nay)   state.abb
two letter abbreviation for each state   name
senator name, party and state, e.g., AKAKA (D HI)   rep
logical, TRUE for Republican senators   state.name
name of state   gorevote
numeric, the vote share recorded by Al Gore in the corresponding state in the 2000 Presidential election     Details  
The only Republican to vote against the resolution was Lincoln Chafee (Rhode Island); Democrats split 29-22 in favor of the resolution.    Source  
Keith Poole, 107th Senate Roll Call Data. https://voteview.com/static/data/out/votes/S107_votes.ord The Iraq vote is vote number 617.   
David Leip's Atlas of U.S. Presidential Elections. http://uselectionatlas.org    References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Chichester. Example 8.3.    Examples    data(iraqVote) ## probit model glm1 <- glm(y ~ gorevote + rep, data=iraqVote, family=binomial(link=probit))"
"pscl-partycodes","pscl","partycodes","political parties appearing in the U.S. Congress",85,2,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/partycodes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/partycodes.html","partycodes R Documentation   political parties appearing in the U.S. Congress   Description  
Numeric codes and names of 85 political parties appearing in Poole and Rosenthal's collection of U.S. Congressional roll calls.    Usage   data(partycodes)   Format  

code integer, numeric code for legislator appearing in Poole and Rosenthal rollcall data files   
party character, name of party      Details  
The function readKH converts the integer codes into strings, via a table lookup in this data frame.   Source  
Keith Poole's website: http://legacy.voteview.com/PARTY3.HTM   See Also  
readKH"
"pscl-politicalInformation","pscl","politicalInformation","Interviewer ratings of respondent levels of political information",1807,8,4,0,6,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/politicalInformation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/politicalInformation.html","politicalInformation R Documentation   Interviewer ratings of respondent levels of political information   Description  
Interviewers administering the 2000 American National Election Studies assigned an ordinal rating to each respondent's ""general level of information"" about politics and public affairs.    Usage   data(politicalInformation)   Format  
A data frame with 1807 observations on the following 8 variables.    y
interviewer rating, a factor with levels Very Low Fairly Low Average Fairly High Very High   collegeDegree
a factor with levels No Yes   female
a factor with levels No Yes   age
a numeric vector, respondent age in years   homeOwn
a factor with levels No Yes   govt
a factor with levels No Yes   length
a numeric vector, length of ANES pre-election interview in minutes   id
a factor, unique identifier for each interviewer     Details  
Seven respondents have missing data on the ordinal interviewer rating. The covariates age and length also have some missing data.    Source  
The National Election Studies (www.electionstudies.org). THE 2000 NATIONAL ELECTION STUDY [dataset]. Ann Arbor, MI: University of Michigan, Center for Political Studies [producer and distributor].   References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey.    Examples    data(politicalInformation) table(politicalInformation$y,exclude=NULL) op <- MASS::polr(y ~ collegeDegree + female + log(age) + homeOwn + govt + log(length), data=politicalInformation, Hess=TRUE, method=""probit"")"
"pscl-presidentialElections","pscl","presidentialElections","elections for U.S. President, 1932-2016, by state",1097,4,1,1,0,1,2,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/presidentialElections.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/presidentialElections.html","presidentialElections R Documentation   elections for U.S. President, 1932-2016, by state   Description  
Democratic share of the presidential vote, 1932-2016, in each state and the District of Columbia.   Usage   data(presidentialElections)   Format  

state character, name of state   
demVotenumeric, percent of the vote for president won by the Democratic candidate   
yearnumeric, integer   
southlogical, TRUE if state is one of the 11 states of the former Confederacy      Note  
1,047 observations, unbalanced panel data in long format. Hawaii and Alaska contribute data from 1960 onwards the District of Columbia contributes data from 1964 onward; Alabama has missing data for 1948 and 1964.   Source  
David Leip's Atlas of U.S. Presidential Elections https://uselectionatlas.org     Examples    data(presidentialElections) if(require(lattice)) { lattice::xyplot(demVote ~ year | state, panel=lattice::panel.lines, ylab=""Democratic Vote for President (percent)"", xlab=""Year"", data=presidentialElections, scales=list(y=list(cex=.6),x=list(cex=.35)), strip=strip.custom(par.strip.text=list(cex=.6))) } ## Obama vs Kerry, except DC y08 <- presidentialElections$year==2008 y04 <- presidentialElections$year==2004 tmpData <- merge(y=presidentialElections[y08,], x=presidentialElections[y04,], by=""state"") tmpData <- tmpData[tmpData$state!=""DC"",] xlim <- range(tmpData$demVote.x,tmpData$demVote.y) col <- rep(""black"",dim(tmpData)[1]) col[tmpData$south.x] <- ""red"" plot(demVote.y ~ demVote.x, xlab=""Kerry Vote Share, 2004 (percent)"", ylab=""Obama Vote Share, 2008 (percent)"", xlim=xlim, ylim=xlim, type=""n"", las=1, data=tmpData) abline(0,1,lwd=2,col=gray(.65)) ols <- lm(demVote.y ~ demVote.x, data=tmpData) abline(ols,lwd=2) text(tmpData$demVote.x, tmpData$demVote.y, tmpData$state, col=col, cex=.65) legend(x=""topleft"", bty=""n"", lwd=c(2,2), col=c(gray(.65),""black""), legend=c(""No Change from 2004"",""Regression"")) legend(x=""bottomright"", bty=""n"", text.col=c(""red"",""black""), legend=c(""South"",""Non-South""))"
"pscl-prussian","pscl","prussian","Prussian army horse kick data",280,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/prussian.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/prussian.html","prussian R Documentation   Prussian army horse kick data   Description  
Deaths by year, by corp, from horse kicks.    Usage   data(prussian)   Format  
A data frame with 280 observations on the following 3 variables.    y
a numeric vector, count of deaths   year
a numeric vector, 18XX, year of observation   corp
a factor , corp of Prussian Army generating observation     Source  
von Bortkiewicz, L. 1898. Das Gesetz der Kleinen Zahlen. Leipzig: Teubner.   Examples    data(prussian) corpP <- glm(y ~ corp, family=poisson,data=prussian) summary(corpP)"
"pscl-RockTheVote","pscl","RockTheVote","Voter turnout experiment, using Rock The Vote ads",85,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/RockTheVote.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/RockTheVote.html","RockTheVote R Documentation   Voter turnout experiment, using Rock The Vote ads   Description  
Voter turnout data spanning 85 cable TV systems, randomly allocated to a voter mobilization experiment targeting 18-19 year olds with ""Rock the Vote"" television advertisements   Usage   data(RockTheVote)   Format  
A data frame with 85 observations on the following 6 variables.    strata
numeric, experimental strata   treated
numeric, 1 if a treated cable system, 0 otherwise   r
numeric, number of 18 and 19 year olds turning out   n
numeric, number of 19 and 19 year olds registered   p
numeric, proportion of 18 and 19 year olds turning out   treatedIndex
numeric, a counter indexing the 42 treated units     Details  
Green and Vavreck (2008) implemented a cluster-randomized experimental design in assessing the effects of a voter mobilization treatment in the 2004 U.S. Presidential election. The clusters in this design are geographic areas served by a single cable television system. So as to facilitate analysis, the researchers restricted their attention to small cable systems whose reach is limited to a single zip code. Further, since the experiment was fielded during the last week of the presidential election, the researchers restricted their search to cable systems that were not in the 16 hotly-contested “battleground” states (as designated by the Los Angeles Times ).   
Eighty-five cable systems were available for randomization and were assigned to treatment after stratification on previous turnout levels in presidential elections (as determined from analysis of the corresponding states' voter registration files). Each cable system was matched with one or sometimes two other cable systems in the same state, yielding 40 strata. Then within each strata, cable systems were randomly assigned to treatment and control conditions. Strata 3, 8 and 25 have two control cable systems and 1 treated system each, while strata 6 and 20 have two treated cable systems and one control system. The remaining 35 strata have 1 treated cable system and 1 control system. In this way there are 38 + 4 = 42 treated systems, spanning 40 experiment strata.   
The treatment involved researchers purchasing prime-time advertising spots on four channels in the respective cable system in which the researchers aired voter mobilization ads. The ads were produced by  Rock the Vote , targeted at younger voters, and aired four times per night, per channel, over the last eight days of the election campaign. After the election, public records were consulted to assemble data on turnout levels in the treated and control cable systems. In the analysis reported in Green and Vavreck (2008), the researchers focused on turnout among registered voters aged 18 and 19 years old.    References  
Green, Donald P. and Lynn Vavreck. 2008. Analysis of Cluster-Randomized Experiments: A Comparison of Alternative Estimation Approaches. Political Analysis 16:138-152.   
Jackman, Simon, 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey. Example 7.9.    Examples    data(RockTheVote) ## estimate MLEs of treatment effects deltaFunction <- function(data){ model <- glm(cbind(r,n-r)~treated, data=data, family=binomial) c(coef(model)[2], confint(model)[2,]) } tmp <- by(RockTheVote, as.factor(RockTheVote$strata), deltaFunction) tmp <- matrix(unlist(tmp),ncol=3,byrow=TRUE) indx <- order(tmp[,1]) plot(y=1:40, x=tmp[indx,1], pch=16,cex=1.25, xlim=range(tmp), ylab="""", axes=FALSE, xlab=""Estimated Treatment Effect (MLEs, Logit Scale)"") text(y=1:40, x=par()$usr[1], pos=4, as.character((1:40)[indx]), cex=.5) segments(x0=tmp[indx,2], x1=tmp[indx,3], y0=1:40, y1=1:40) axis(1) axis(3) abline(v=0)"
"pscl-state.info","pscl","state.info","information about the American states needed for U.S. Congress",51,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/state.info.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/state.info.html","state.info R Documentation   information about the American states needed for U.S. Congress   Description  
Numeric codes and names of 50 states and the District of Columbia, required to parse Keith Poole and Howard Rosenthal's collections of U.S. Congressional roll calls.    Usage   data(state.info)    Format   icpsr
integer, numeric code for state used by the Inter-university Consortium for Political and Social Research   state
character, name of state or Washington D.C.   year
numeric or NA , year of statehood     Details  
The function readKH converts the integer ICPSR codes into strings, via a table lookup in this data frame. Another table lookup in state.abb provides the 2-letter abbreviation commonly used in identifying American legislators, e.g.,  KENNEDY, E (D-MA) .   Source  
Various ICPSR codebooks. http://www.icpsr.umich.edu   See Also  
state"
"pscl-UKHouseOfCommons","pscl","UKHouseOfCommons","1992 United Kingdom electoral returns",521,12,3,2,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/UKHouseOfCommons.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/UKHouseOfCommons.html","UKHouseOfCommons R Documentation   1992 United Kingdom electoral returns   Description  
Electoral returns, selected constituencies, 1992 general election for the British House of Commons   Usage   data(UKHouseOfCommons)   Format  
A data frame with 521 observations on the following 12 variables.    constituency
a character vector, name of the House of Commons constituency   county
a character vector, county of the House of Commons constituency   y1
a numeric vector, log-odds of Conservative to LibDem vote share   y2
a numeric vector, log-odds of Labor to LibDem vote share   y1lag
a numeric vector, y1 from previous election   y2lag
a numeric vector, y2 from previous election   coninc
a numeric vector, 1 if the incumbent is a Conservative, 0 otherwise   labinc
a numeric vector, 1 if the incumbent is from the Labor Party, 0 otherwise   libinc
a numeric vector, 1 if the incumbent is from the LibDems, 0 otherwise   v1
a numeric vector, Conservative vote share (proportion of 3 party vote)   v2
a numeric vector, Labor vote share (proportion of 3 party vote)   v3
a numeric vector, LibDem vote share (proportion of 3 party vote)     Details  
These data span only 521 of the 621 seats in the House of Commons at the time of 1992 election. Seats missing either a Conservative, Labor, or a LibDem candidate appear to have been dropped.  
The original Katz and King data set does not have case labels. I used matches to an additional data source to recover a set of constituency labels for these data; labels could not recovered for two of the constituencies.    Source  
Jonathan Katz; Gary King. 1999. ""Replication data for: A Statistical Model of Multiparty Electoral Data"", http://hdl.handle.net/1902.1/QIGTWZYTLZ     References  
Katz, Jonathan and Gary King. 1999. “A Statistical Model for Multiparty Electoral Data”. American Political Science Review . 93(1): 15-32.   
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Chichester. Example 6.9.    Examples    data(UKHouseOfCommons) tmp <- UKHouseOfCommons[,c(""v1"",""v2"",""v3"")] summary(apply(tmp,1,sum)) col <- rep(""black"",dim(tmp)[1]) col[UKHouseOfCommons$coninc==1] <- ""blue"" col[UKHouseOfCommons$labinc==1] <- ""red"" col[UKHouseOfCommons$libinc==1] <- ""orange"" library(vcd) vcd::ternaryplot(tmp, dimnames=c(""Cons"",""Lab"",""Lib-Dem""), labels=""outside"", col=col, pch=1, main=""1992 UK House of Commons Election"", cex=.75)"
"pscl-unionDensity","pscl","unionDensity","cross national rates of trade union density",20,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/unionDensity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/unionDensity.html","unionDensity R Documentation   cross national rates of trade union density   Description  
Cross-national data on relative size of the trade unions and predictors, in 20 countries. Two of the predictors are highly collinear, and are the source of a debate between Stephens and Wallerstein (1991), later reviewed by Western and Jackman (1994).    Usage   data(unionDensity)    Format  

union numeric, percentage of the total number of wage and salary earners plus the unemployed who are union members, measured between 1975 and 1980, with most of the data drawn from 1979   
left numeric, an index tapping the extent to which parties of the left have controlled governments since 1919, due to Wilensky (1981).   
size numeric, log of labor force size, defined as the number of wage and salary earners, plus the unemployed   
concen numeric, percentage of employment, shipments, or production accounted for by the four largest enterprises in a particular industry, averaged over industries (with weights proportional to the size of the industry) and the resulting measure is normalized such that the United States scores a 1.0, and is due to Pryor (1973). Some of the scores on this variable are imputed using procedures described in Stephens and Wallerstein (1991, 945).      Source  
Pryor, Frederic. 1973. Property and Industrial Organization in Communist and Capitalist Countries . Bloomington: Indiana University Press.  
Stephens, John and Michael Wallerstein. 1991. Industrial Concentration, Country Size and Trade Union Membership.  American Political Science Review 85:941-953.   
Western, Bruce and Simon Jackman. 1994. Bayesian Inference for Comparative Research. American Political Science Review  88:412-423.  
Wilensky, Harold L. 1981. Leftism, Catholicism, Democratic Corporatism: The Role of Political Parties in Recent Welfare State Development. In The Development of Welfare States in Europe and America , ed. Peter Flora and Arnold J. Heidenheimer. New Brunswick: Transaction Books.   References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey.   Examples    data(unionDensity) summary(unionDensity) pairs(unionDensity, labels=c(""Union\nDensity"", ""Left\nGovernment"", ""log Size of\nLabor Force"", ""Economic\nConcentration""), lower.panel=function(x,y,digits=2){ r <- cor(x,y) par(usr=c(0,1,0,1)) text(.5,.5, format(c(r,0.123456789),digits=digits)[1], cex=1.5) } ) ols <- lm(union ~ left + size + concen, data=unionDensity) summary(ols)"
"pscl-vote92","pscl","vote92","Reports of voting in the 1992 U.S. Presidential election.",909,9,3,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/pscl/vote92.csv","https://vincentarelbundock.github.io/Rdatasets/doc/pscl/vote92.html","vote92 R Documentation    Reports of voting in the 1992 U.S. Presidential election.    Description  
Survey data containing self-reports of vote choice in the 1992 U.S. Presidential election, with numerous covariates, from the 1992 American National Election Studies.    Usage   data(vote92)   Format  
A data frame with 909 observations on the following 10 variables.    vote
a factor with levels Perot Clinton Bush   dem
a numeric vector, 1 if the respondent reports identifying with the Democratic party, 0 otherwise.   rep
a numeric vector, 1 if the respondent reports identifying with the Republican party, 0 otherwise   female
a numeric vector, 1 if the respondent is female, 0 otherwise   persfinance
a numeric vector, -1 if the respondent reports that their personal financial situation has gotten worse over the last 12 months, 0 for no change, 1 if better   natlecon
a numeric vector, -1 if the respondent reports that national economic conditions have gotten worse over the last 12 months, 0 for no change, 1 if better   clintondis
a numeric vector, squared difference between respondent's self-placement on a scale measure of political ideology and the respondent's placement of the Democratic candidate, Bill Clinton   bushdis
a numeric vector, squared ideological distance of the respondent from the Republican candidate, President George H.W. Bush   perotdis
a numeric vector, squared ideological distance of the respondent from the Reform Party candidate, Ross Perot     Details  
These data are unweighted. Refer to the original data source for weights that purport to correct for non-representativeness and non-response.   Source  
Alvarez, R. Michael and Jonathan Nagler. 1995. Economics, issues and the Perot candidacy: Voter choice in the 1992 Presidential election. American Journal of Political Science . 39:714-44.   
Miller, Warren E., Donald R. Kinder, Steven J. Rosenstone and the National Election Studies. 1999. National Election Studies, 1992: Pre-/Post-Election Study . Center for Political Studies, University of Michigan: Ann Arbor, Michigan.   
Inter-University Consortium for Political and Social Research. Study Number 1112. http://dx.doi.org/10.3886/ICPSR01112 .   References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences . Wiley: Hoboken, New Jersey. Examples 8.7 and 8.8.    Examples    data(vote92) summary(vote92)"
"psych-Bechtoldt","psych","Bechtoldt","Seven data sets showing a bifactor solution.",17,17,0,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Bechtoldt.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Bechtoldt.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Bechtoldt.1","psych","Bechtoldt.1","Seven data sets showing a bifactor solution.",17,17,0,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Bechtoldt.1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Bechtoldt.1.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Bechtoldt.2","psych","Bechtoldt.2","Seven data sets showing a bifactor solution.",17,17,0,0,0,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Bechtoldt.2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Bechtoldt.2.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-bfi","psych","bfi","25 Personality items representing 5 factors",2800,28,1,0,0,0,28,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/bfi.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/bfi.html","bfi R Documentation   25 Personality items representing 5 factors   Description  
25 personality self report items taken from the International Personality Item Pool (ipip.ori.org) were included as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. The data from 2800 subjects are included here as a demonstration set for scale construction, factor analysis, and Item Response Theory analysis. Three additional demographic variables (sex, education, and age) are also included. This data set is deprecated and users are encouraged to use bfi .    Usage   data(bfi)    Format  
A data frame with 2800 observations on the following 28 variables. (The q numbers are the SAPA item numbers).    A1
Am indifferent to the feelings of others. (q_146)   A2
Inquire about others' well-being. (q_1162)   A3
Know how to comfort others. (q_1206)   A4
Love children. (q_1364)   A5
Make people feel at ease. (q_1419)   C1
Am exacting in my work. (q_124)   C2
Continue until everything is perfect. (q_530)   C3
Do things according to a plan. (q_619)   C4
Do things in a half-way manner. (q_626)   C5
Waste my time. (q_1949)   E1
Don't talk a lot. (q_712)   E2
Find it difficult to approach others. (q_901)   E3
Know how to captivate people. (q_1205)   E4
Make friends easily. (q_1410)   E5
Take charge. (q_1768)   N1
Get angry easily. (q_952)   N2
Get irritated easily. (q_974)   N3
Have frequent mood swings. (q_1099   N4
Often feel blue. (q_1479)   N5
Panic easily. (q_1505)   O1
Am full of ideas. (q_128)   O2
Avoid difficult reading material.(q_316)   O3
Carry the conversation to a higher level. (q_492)   O4
Spend time reflecting on things. (q_1738)   O5
Will not probe deeply into a subject. (q_1964)   gender
Males = 1, Females =2   education
1 = HS, 2 = finished HS, 3 = some college, 4 = college graduate 5 = graduate degree   age
age in years     Details  
This data set is deprecated and users are encouraged to use bfi .It is kept here backward compatability for one more release.   
The first 25 items are organized by five putative factors: Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Opennness. The scoring key is created using make.keys , the scores are found using score.items .   
These five factors are a useful example of using irt.fa to do Item Response Theory based latent factor analysis of the polychoric correlation matrix. The endorsement plots for each item, as well as the item information functions reveal that the items differ in their quality.   
The item data were collected using a 6 point response scale: 1 Very Inaccurate 2 Moderately Inaccurate 3 Slightly Inaccurate 4 Slightly Accurate 5 Moderately Accurate 6 Very Accurate   
as part of the Synthetic Apeture Personality Assessment (SAPA https://www.sapa-project.org/ ) project. To see an example of the data collection technique, visit https://www.sapa-project.org/ or the International Cognitive Ability Resource at https://icar-project.org/ . The items given were sampled from the International Personality Item Pool of Lewis Goldberg using the sampling technique of SAPA. This is a sample data set taken from the much larger SAPA data bank.    Note  
This data set is deprecated and users are encouraged to use bfi .It is kept here backward compatability for one more release.   
The bfi data set and items should not be confused with the BFI (Big Five Inventory) of Oliver John and colleagues (John, O. P., Donahue, E. M., & Kentle, R. L. (1991). The Big Five Inventory–Versions 4a and 54. Berkeley, CA: University of California,Berkeley, Institute of Personality and Social Research.)    Source  
The items are from the ipip (Goldberg, 1999). The data are from the SAPA project (Revelle, Wilt and Rosenthal, 2010) , collected Spring, 2010 ( https://www.sapa-project.org/ ).    References  
Goldberg, L.R. (1999) A broad-bandwidth, public domain, personality inventory measuring the lower-level facets of several five-factor models. In Mervielde, I. and Deary, I. and De Fruyt, F. and Ostendorf, F. (eds) Personality psychology in Europe. 7. Tilburg University Press. Tilburg, The Netherlands.   
Revelle, W., Wilt, J., and Rosenthal, A. (2010) Individual Differences in Cognition: New Methods for examining the Personality-Cognition Link In Gruszka, A. and Matthews, G. and Szymura, B. (Eds.) Handbook of Individual Differences in Cognition: Attention, Memory and Executive Control, Springer.   
Revelle, W, Condon, D.M., Wilt, J., French, J.A., Brown, A., and Elleman, L.G. (2016) Web and phone based data collection using planned missing designs. In Fielding, N.G., Lee, R.M. and Blank, G. (Eds). SAGE Handbook of Online Research Methods (2nd Ed), Sage Publcations.   See Also  
bi.bars to show the data by age and gender, irt.fa for item factor analysis applying the irt model.   Examples    data(bfi) psych::describe(bfi) # create the bfi.keys (actually already saved in the data file) keys <- list(agree=c(""-A1"",""A2"",""A3"",""A4"",""A5""),conscientious=c(""C1"",""C2"",""C3"",""-C4"",""-C5""), extraversion=c(""-E1"",""-E2"",""E3"",""E4"",""E5""),neuroticism=c(""N1"",""N2"",""N3"",""N4"",""N5""), openness = c(""O1"",""-O2"",""O3"",""O4"",""-O5"")) scores <- psych::scoreItems(keys,bfi,min=1,max=6) #specify the minimum and maximum values scores #show the use of the fa.lookup with a dictionary #psych::keys.lookup(bfi.keys,bfi.dictionary[,1:4]) #deprecated -- use psychTools"
"psych-cattell","psych","cattell","12 cognitive variables from Cattell (1963)",12,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/cattell.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/cattell.html","cattell R Documentation   12 cognitive variables from Cattell (1963)   Description  
Rindskopf and Rose (1988) use this data set to demonstrate confirmatory second order factor models. It is a nice example data set to explore hierarchical structure and alternative factor solutions. It contains measures of fluid and crystallized intelligence.    Usage   data(""cattell"")   Format  
A correlation matrix of the following 12 variables from 277 7th and 8th graders    Verbal
A verbal ability test from Thurstone   Verbal2
A verbal ability test from Thurstone   Space1
A Spatial ability test from Thurstone   Space2
A Spatial ability test from Thurstone   Reason1
A reasoning test from Thurstone   Reason2
A reasoning test from Thurstone   Number1
A Numerical ability test from Thurstone   Number2
A Numerical ability test from Thurstone   IPATSer
A ""culture fair"" series from the IPAT   IPATCLAS
A ""culture fair"" classification test from the IPAT   IPATMatr
A ""culture fair"" matrix reasoning test from the IPAT   IPATTop
A ""culture fair"" topology test from the IPAT     Details  
Cattell (1963) reported on 8 cognitive variables from Thurstone and four from the Institute for Personality Assessment Test (IPAT). Rindskopf and Rose (1988) use this data set as an example of second order factor analysis. It is thus a nice set for examining alternative solutions such as bifactor rotation, omega hierarchical, as well as esem and interbattery factor analysis.    Source  
David Rindskopf and Tedd Rose, (1988) Some Theory and Applications of Confirmatory Second- Order Factor Analysis, Multivariate Behavioral Research, 23, 51-67.   References  
Cattell, R. B. (1963).Theory of fluid and crystallized intelligence: A critical experiment. Journal of Educational Psychology, 54, 1-22.   
David Rindskopf and Tedd Rose, (1988) Some Theory and Applications of Confirmatory Second- Order Factor Analysis, Multivariate Behavioral Research, 23, 51-67.    Examples    data(cattell) corPlot(cattell,numbers=TRUE,upper=FALSE,diag=FALSE, main=""12 cognitive variables from Cattell (1963)"",xlas=2)"
"psych-Damian","psych","Damian","Project Talent data set from Marion Spengler and Rodica Damian",19,19,0,0,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Damian.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Damian.html","Spengler R Documentation   Project Talent data set from Marion Spengler and Rodica Damian    Description  
Project Talent gave 440,000 US high school students a number of personality and ability tests. Of these, the data fror 346,000 were available for followup. Subsequent followups were collected 11 and 50 years later. Marion Spengler and her colleagues Rodica Damian, and Brent Roberts reported on the stability and change across 50 years of personality and ability. Here is the correlation matrix of 25 of their variables (Spengler) as well as a slightly different set of 19 variables (Damian). This is a nice example of mediation and regression from a correlation matrix. (Temporarily copied from psychTools to pass CRAN checks. )    Usage   data(""Damian"")   Format  
A 25 x 25 correlation matrix of demographic, personality, and ability variables, based upon 346,660 participants.    Race/Ethnicity
1 = other, 2 = white/caucasian   Sex
1=Male, 2=Female   Age
Cohort =9th grade, 10th grade, 11th grade, 12th grade   Parental
Parental SES based upon 9 questions of home value, family income, etc.   IQ
Standardized composite of Verbal, Spatial and Mathematical   Sociability etc.
10 scales based upon prior work by Damian and Roberts   Maturity
A higher order factor from the prior 10 scales   Extraversion
The second higher order factor   Interest
Self reported interest in school   Reading
Self report reading skills   Writing
Self report writing skills   Responsible
Self reported responsibility scale   Ed.11
Education level at 11 year followup   Educ.50
Education level at 50 year followup   OccPres.11
Occupational Prestige at 11 year followup   OccPres.50
Occupational Prestige at 50 year followup   Income.11
Income at 11 year followup   Income.50
Income at 50 year followup     Details  
Data from Project Talent was collected in 1960 on a representative sample of American high school students. Subsequent follow up 11 and 50 years later are reported by Spengler et al (2018) and others.    Source  
Marion Spengler, supplementary material to Damian et al. and Spengler et al.    References  
Rodica Ioana Damian and Marion Spengler and Andreea Sutu and Brent W. Roberts, 2019, Sixteen going on sixty-six: A longitudinal study of personality stability and change across 50 years Journal of Personality and Social Psychology. 117, (3) 274-695.   
Marian Spengler and Rodica Ioana Damian and Brent W. Roberts (2018), How you behave in school predicts life success above and beyond family background, broad traits, and cognitive ability Journal of Personality and Social Psychology, 114 (4) 600-636    Examples    data(Damian) Spengler.stat #show the basic descriptives of the original data set psych::lowerMat(Spengler[psych::cs(IQ,Parental,Ed.11,OccPres.50), psych::cs(IQ,Parental,Ed.11,OccPres.50)]) psych::setCor(OccPres.50 ~ IQ + Parental + (Ed.11),data=Spengler) #we reduce the number of subjects for faster replication in this example mod <- psych::mediate(OccPres.50 ~ IQ + Parental + (Ed.11),data=Spengler, n.iter=50,n.obs=1000) #for speed summary(mod)"
"psych-Dwyer","psych","Dwyer","8 cognitive variables used by Dwyer for an example.",8,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Dwyer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Dwyer.html","Dwyer R Documentation   8 cognitive variables used by Dwyer for an example.    Description  
Dwyer (1937) introduced a technique for factor extension and used 8 cognitive variables from Thurstone. This is the example data set used in his paper.    Usage   data(Dwyer)   Format  
The format is: num [1:8, 1:8] 1 0.58 -0.28 0.01 0.36 0.38 0.61 0.15 0.58 1 ... - attr(*, ""dimnames"")=List of 2 ..$ : chr [1:8] ""V1"" ""V2"" ""V3"" ""V4"" ... ..$ : chr [1:8] ""V1"" ""V2"" ""V3"" ""V4"" ...    Source  
Data matrix retyped from the original publication.   References  
Dwyer, Paul S. (1937), The determination of the factor loadings of a given test from the known factor loadings of other tests. Psychometrika, 3, 173-178    Examples    data(Dwyer) Ro <- Dwyer[1:7,1:7] Roe <- Dwyer[1:7,8] fo <- fa(Ro,2,rotate=""none"") fa.extension(Roe,fo)"
"psych-Gleser","psych","Gleser","Example data from Gleser, Cronbach and Rajaratnam (1965) to show basic principles of generalizability theory.",12,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Gleser.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Gleser.html","Gleser R Documentation    Example data from Gleser, Cronbach and Rajaratnam (1965) to show basic principles of generalizability theory.   Description  
Gleser, Cronbach and Rajaratnam (1965) discuss the estimation of variance components and their ratios as part of their introduction to generalizability theory. This is a adaptation of their ""illustrative data for a completely matched G study"" (Table 3). 12 patients are rated on 6 symptoms by two judges. Components of variance are derived from the ANOVA.   Usage   data(Gleser)   Format  
A data frame with 12 observations on the following 12 variables. J item by judge:    J11
a numeric vector   J12
a numeric vector   J21
a numeric vector   J22
a numeric vector   J31
a numeric vector   J32
a numeric vector   J41
a numeric vector   J42
a numeric vector   J51
a numeric vector   J52
a numeric vector   J61
a numeric vector   J62
a numeric vector     Details  
Generalizability theory is the application of a components of variance approach to the analysis of reliability. Given a G study (generalizability) the components are estimated and then may be used in a D study (Decision). Different ratios are formed as appropriate for the particular D study.    Source  
Gleser, G., Cronbach, L., and Rajaratnam, N. (1965). Generalizability of scores influenced by multiple sources of variance. Psychometrika, 30(4):395-418. (Table 3, rearranged to show increasing patient severity and increasing item severity.    References  
Gleser, G., Cronbach, L., and Rajaratnam, N. (1965). Generalizability of scores influenced by multiple sources of variance. Psychometrika, 30(4):395-418.    Examples    #Find the MS for each component: #First, stack the data data(Gleser) stack.g <- stack(Gleser) st.gc.df <- data.frame(stack.g,Persons=rep(letters[1:12],12), Items=rep(letters[1:6],each=24),Judges=rep(letters[1:2],each=12)) #now do the ANOVA anov <- aov(values ~ (Persons*Judges*Items),data=st.gc.df) summary(anov)"
"psych-Gorsuch","psych","Gorsuch","Example data set from Gorsuch (1997) for an example factor extension.",10,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Gorsuch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Gorsuch.html","Gorsuch R Documentation   Example data set from Gorsuch (1997) for an example factor extension.    Description  
Gorsuch (1997) suggests an alternative to the classic Dwyer (1937) factor extension technique. This data set is taken from that article. Useful for comparing link{fa.extension} with and without the correct=TRUE option.   Usage   data(Gorsuch)   Details  
Gorsuc (1997) suggested an alternative model for factor extension. His method is appropriate for the case of repeated variables. This is handled in link{fa.extension} with correct=FALSE    Source  
Richard L. Gorsuch (1997) New Procedure for Extension Analysis in Exploratory Factor Analysis. Educational and Psychological Measurement, 57, 725-740.    References  
Dwyer, Paul S. (1937), The determination of the factor loadings of a given test from the known factor loadings of other tests. Psychometrika, 3, 173-178    Examples    data(Gorsuch) Ro <- Gorsuch[1:6,1:6] Roe <- Gorsuch[1:6,7:10] fo <- fa(Ro,2,rotate=""none"") fa.extension(Roe,fo,correct=FALSE)"
"psych-Harman.5","psych","Harman.5","Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt",12,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Harman.5.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Harman.5.html","Harman R Documentation   Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt   Description  
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables. All five of these are used for tests and demonstrations of various factoring algortithms.    Usage   data(Harman) data(Harman.5) data(Harman.political) data(Harman.8)    Details  

Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.   
Harman.Burt: a 8 x 8 correlation matrix of “emotional"" items. N = 172   
Harman.5: 12 census tracts for 5 socioeconomic data (Harman p 14)   
Harman.political: p 166.   
Harman.8 8 physical measures     
Harman.Holzinger. The nine psychological variables from Harman (1967, p 244) are taken from unpublished class notes of K.J. Holzinger with 696 participants. This is a subset of 12 tests with 4 factors. It is yet another nice example of a bifactor solution. Bentler (2007) uses this data set to discuss reliablity analysis. The data show a clear bifactor structure and are a nice example of the various estimates of reliability included in the omega function. Should not be confused with the Holzinger or Holzinger.9 data sets in bifactor .   
See also the Holzinger-Swineford data set of 301 subjects with 26 variables in holzinger.swineford . These data were provided by Keith Widaman. ""The Holzinger and Swineford (1939) data have been used as a model data set by many investigators. For example, Harman (1976) used the ""24 Psychological Variables"" example prominently in his authoritative text on multiple factor analysis, and the data presented under this rubric consisted of 24 of the variables from the Grant-White school (N = 145). Meredith (1964a, 1964b) used several variables from the Holzinger and Swineford study in his work on factorial invariance under selection. Joreskog (1971) based his work on multiple-group confirmatory factor analysis using the Holzinger and Swineford data, subsetting the data into four groups.   
Rosseel, who developed the ""lavaan"" package for R , included 9 of the manifest variables from Holzinger and Swineford (1939) as a ""resident"" data set when one downloads the lavaan package. Several background variables are included in this ""resident"" data set in addition to 9 of the psychological tests (which are named x1 - x9 in the data set). When analyzing these data, I found the distributions of the variables (means, SDs) did not match the sample statistics from the original article. For example, in the ""resident"" data set in lavaan, scores on all manifest variables ranged between 0 and 10, sample means varied between 3 and 6, and sample SDs varied between 1.0 and 1.5. In the original data set, scores ranges were rather different across tests, with some variables having scores that ranged between 0 and 20, but other manifest variables having scores ranging from 50 to over 300 - with obvious attendant differences in sample means and SDs.""   
Harman.Burt. Eight “emotional"" variables are taken from Harman (1967, p 164) who in turn adapted them from Burt (1939). They are said be from 172 normal children aged nine to twelve. As pointed out by Harman, this correlation matrix is singular and has squared multiple correlations > 1. Because of this problem, it is a nice test case for various factoring algorithms. (For instance, omega will issue warning messages for fm=""minres"" or fm=""pa"" but will fail for fm=""ml"".)   
The Eight Physical Variables problem is taken from Harman (1976) and represents the correlations between eight physical variables for 305 girls. The two correlated clusters represent four measures of ""lankiness"" and then four measures of ""stockiness"". The original data were selected from 17 variables reported in an unpublished dissertation by Mullen (1939).  
Variable 6 (""Bitrochanteric diamter"") is the distance between the outer points of the hips.  
The row names match the original Harman paper, the column names have been abbreviated.   
See also the usaf data set for other physical measurements.   
The fa solution for principal axes (fm=""pa"") matches the reported minres solution, as does the fm=""minres"".  
For those interested in teaching examples using various body measurements, see the body data set in the gclus package.  
The Burt data set probably has a typo in the original correlation matrix. Changing the Sorrow- Tenderness correlation from .87 to .81 makes the correlation positive definite.  
As pointed out by Jan DeLeeuw, the Burt data set is a subset of 8 variables from the original 11 reported by Burt in 1915. That matrix has the same problem. See burt .   
Other example data sets that are useful demonstrations of factor analysis are the seven bifactor examples in Bechtoldt and the 24 ability measures in Harman74.cor    
There are several other Harman examples in the psych package (i.e., Harman.8) as well as in the dataseta and GPArotation packages. The Harman 24 mental tests problem is in the basic datasets package at Harman74.cor.  
Other Harman data sets are 5 socioeconomic variables for 12 census tracts Harman.5 used by John Loehlin as an example for EFA. Another one of the many Harman (1967) data sets is Harman.political. This contains 8 political variables taken over 147 election areas. The principal factor method with SMCs as communalities match those of table 8.18. The data are used by Dziubian and Shirkey as an example of the Kaiser-Meyer-Olkin test of factor adequacy.    Source  
Harman (1967 p 164 and p 244.)   
H. Harman and W.Jones. (1966) Factor analysis by minimizing residuals (minres). Psychometrika, 31(3):351-368.    References  
Harman, Harry Horace (1967), Modern factor analysis. Chicago, University of Chicago Press.   
P.Bentler. Covariance structure models for maximal reliability of unit-weighted composites. In Handbook of latent variable and related models, pages 1–17. North Holland, 2007.   
Burt, C.General and Specific Factors underlying the Primary Emotions. Reports of the British Association for the Advancement of Science, 85th meeting, held in Manchester, September 7-11, 1915. London, John Murray, 1916, p. 694-696 (retrieved from the web at https://www.biodiversitylibrary.org/item/95822#790    See Also  
See also the original burt data set, the Harman.5 and Harman.political data sets.   Examples    data(Harman) cor.plot(Harman.Holzinger) cor.plot(Harman.Burt) smc(Harman.Burt) #note how this produces impossible results f2 <- fa(Harman.8,2, rotate=""none"") #minres matches Harman and Jones"
"psych-Harman.8","psych","Harman.8","Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt",8,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Harman.8.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Harman.8.html","Harman R Documentation   Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt   Description  
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables. All five of these are used for tests and demonstrations of various factoring algortithms.    Usage   data(Harman) data(Harman.5) data(Harman.political) data(Harman.8)    Details  

Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.   
Harman.Burt: a 8 x 8 correlation matrix of “emotional"" items. N = 172   
Harman.5: 12 census tracts for 5 socioeconomic data (Harman p 14)   
Harman.political: p 166.   
Harman.8 8 physical measures     
Harman.Holzinger. The nine psychological variables from Harman (1967, p 244) are taken from unpublished class notes of K.J. Holzinger with 696 participants. This is a subset of 12 tests with 4 factors. It is yet another nice example of a bifactor solution. Bentler (2007) uses this data set to discuss reliablity analysis. The data show a clear bifactor structure and are a nice example of the various estimates of reliability included in the omega function. Should not be confused with the Holzinger or Holzinger.9 data sets in bifactor .   
See also the Holzinger-Swineford data set of 301 subjects with 26 variables in holzinger.swineford . These data were provided by Keith Widaman. ""The Holzinger and Swineford (1939) data have been used as a model data set by many investigators. For example, Harman (1976) used the ""24 Psychological Variables"" example prominently in his authoritative text on multiple factor analysis, and the data presented under this rubric consisted of 24 of the variables from the Grant-White school (N = 145). Meredith (1964a, 1964b) used several variables from the Holzinger and Swineford study in his work on factorial invariance under selection. Joreskog (1971) based his work on multiple-group confirmatory factor analysis using the Holzinger and Swineford data, subsetting the data into four groups.   
Rosseel, who developed the ""lavaan"" package for R , included 9 of the manifest variables from Holzinger and Swineford (1939) as a ""resident"" data set when one downloads the lavaan package. Several background variables are included in this ""resident"" data set in addition to 9 of the psychological tests (which are named x1 - x9 in the data set). When analyzing these data, I found the distributions of the variables (means, SDs) did not match the sample statistics from the original article. For example, in the ""resident"" data set in lavaan, scores on all manifest variables ranged between 0 and 10, sample means varied between 3 and 6, and sample SDs varied between 1.0 and 1.5. In the original data set, scores ranges were rather different across tests, with some variables having scores that ranged between 0 and 20, but other manifest variables having scores ranging from 50 to over 300 - with obvious attendant differences in sample means and SDs.""   
Harman.Burt. Eight “emotional"" variables are taken from Harman (1967, p 164) who in turn adapted them from Burt (1939). They are said be from 172 normal children aged nine to twelve. As pointed out by Harman, this correlation matrix is singular and has squared multiple correlations > 1. Because of this problem, it is a nice test case for various factoring algorithms. (For instance, omega will issue warning messages for fm=""minres"" or fm=""pa"" but will fail for fm=""ml"".)   
The Eight Physical Variables problem is taken from Harman (1976) and represents the correlations between eight physical variables for 305 girls. The two correlated clusters represent four measures of ""lankiness"" and then four measures of ""stockiness"". The original data were selected from 17 variables reported in an unpublished dissertation by Mullen (1939).  
Variable 6 (""Bitrochanteric diamter"") is the distance between the outer points of the hips.  
The row names match the original Harman paper, the column names have been abbreviated.   
See also the usaf data set for other physical measurements.   
The fa solution for principal axes (fm=""pa"") matches the reported minres solution, as does the fm=""minres"".  
For those interested in teaching examples using various body measurements, see the body data set in the gclus package.  
The Burt data set probably has a typo in the original correlation matrix. Changing the Sorrow- Tenderness correlation from .87 to .81 makes the correlation positive definite.  
As pointed out by Jan DeLeeuw, the Burt data set is a subset of 8 variables from the original 11 reported by Burt in 1915. That matrix has the same problem. See burt .   
Other example data sets that are useful demonstrations of factor analysis are the seven bifactor examples in Bechtoldt and the 24 ability measures in Harman74.cor    
There are several other Harman examples in the psych package (i.e., Harman.8) as well as in the dataseta and GPArotation packages. The Harman 24 mental tests problem is in the basic datasets package at Harman74.cor.  
Other Harman data sets are 5 socioeconomic variables for 12 census tracts Harman.5 used by John Loehlin as an example for EFA. Another one of the many Harman (1967) data sets is Harman.political. This contains 8 political variables taken over 147 election areas. The principal factor method with SMCs as communalities match those of table 8.18. The data are used by Dziubian and Shirkey as an example of the Kaiser-Meyer-Olkin test of factor adequacy.    Source  
Harman (1967 p 164 and p 244.)   
H. Harman and W.Jones. (1966) Factor analysis by minimizing residuals (minres). Psychometrika, 31(3):351-368.    References  
Harman, Harry Horace (1967), Modern factor analysis. Chicago, University of Chicago Press.   
P.Bentler. Covariance structure models for maximal reliability of unit-weighted composites. In Handbook of latent variable and related models, pages 1–17. North Holland, 2007.   
Burt, C.General and Specific Factors underlying the Primary Emotions. Reports of the British Association for the Advancement of Science, 85th meeting, held in Manchester, September 7-11, 1915. London, John Murray, 1916, p. 694-696 (retrieved from the web at https://www.biodiversitylibrary.org/item/95822#790    See Also  
See also the original burt data set, the Harman.5 and Harman.political data sets.   Examples    data(Harman) cor.plot(Harman.Holzinger) cor.plot(Harman.Burt) smc(Harman.Burt) #note how this produces impossible results f2 <- fa(Harman.8,2, rotate=""none"") #minres matches Harman and Jones"
"psych-Harman.political","psych","Harman.political","Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt",8,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Harman.political.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Harman.political.html","Harman R Documentation   Five data sets from Harman (1967). 9 cognitive variables from Holzinger and 8 emotional variables from Burt   Description  
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables. All five of these are used for tests and demonstrations of various factoring algortithms.    Usage   data(Harman) data(Harman.5) data(Harman.political) data(Harman.8)    Details  

Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.   
Harman.Burt: a 8 x 8 correlation matrix of “emotional"" items. N = 172   
Harman.5: 12 census tracts for 5 socioeconomic data (Harman p 14)   
Harman.political: p 166.   
Harman.8 8 physical measures     
Harman.Holzinger. The nine psychological variables from Harman (1967, p 244) are taken from unpublished class notes of K.J. Holzinger with 696 participants. This is a subset of 12 tests with 4 factors. It is yet another nice example of a bifactor solution. Bentler (2007) uses this data set to discuss reliablity analysis. The data show a clear bifactor structure and are a nice example of the various estimates of reliability included in the omega function. Should not be confused with the Holzinger or Holzinger.9 data sets in bifactor .   
See also the Holzinger-Swineford data set of 301 subjects with 26 variables in holzinger.swineford . These data were provided by Keith Widaman. ""The Holzinger and Swineford (1939) data have been used as a model data set by many investigators. For example, Harman (1976) used the ""24 Psychological Variables"" example prominently in his authoritative text on multiple factor analysis, and the data presented under this rubric consisted of 24 of the variables from the Grant-White school (N = 145). Meredith (1964a, 1964b) used several variables from the Holzinger and Swineford study in his work on factorial invariance under selection. Joreskog (1971) based his work on multiple-group confirmatory factor analysis using the Holzinger and Swineford data, subsetting the data into four groups.   
Rosseel, who developed the ""lavaan"" package for R , included 9 of the manifest variables from Holzinger and Swineford (1939) as a ""resident"" data set when one downloads the lavaan package. Several background variables are included in this ""resident"" data set in addition to 9 of the psychological tests (which are named x1 - x9 in the data set). When analyzing these data, I found the distributions of the variables (means, SDs) did not match the sample statistics from the original article. For example, in the ""resident"" data set in lavaan, scores on all manifest variables ranged between 0 and 10, sample means varied between 3 and 6, and sample SDs varied between 1.0 and 1.5. In the original data set, scores ranges were rather different across tests, with some variables having scores that ranged between 0 and 20, but other manifest variables having scores ranging from 50 to over 300 - with obvious attendant differences in sample means and SDs.""   
Harman.Burt. Eight “emotional"" variables are taken from Harman (1967, p 164) who in turn adapted them from Burt (1939). They are said be from 172 normal children aged nine to twelve. As pointed out by Harman, this correlation matrix is singular and has squared multiple correlations > 1. Because of this problem, it is a nice test case for various factoring algorithms. (For instance, omega will issue warning messages for fm=""minres"" or fm=""pa"" but will fail for fm=""ml"".)   
The Eight Physical Variables problem is taken from Harman (1976) and represents the correlations between eight physical variables for 305 girls. The two correlated clusters represent four measures of ""lankiness"" and then four measures of ""stockiness"". The original data were selected from 17 variables reported in an unpublished dissertation by Mullen (1939).  
Variable 6 (""Bitrochanteric diamter"") is the distance between the outer points of the hips.  
The row names match the original Harman paper, the column names have been abbreviated.   
See also the usaf data set for other physical measurements.   
The fa solution for principal axes (fm=""pa"") matches the reported minres solution, as does the fm=""minres"".  
For those interested in teaching examples using various body measurements, see the body data set in the gclus package.  
The Burt data set probably has a typo in the original correlation matrix. Changing the Sorrow- Tenderness correlation from .87 to .81 makes the correlation positive definite.  
As pointed out by Jan DeLeeuw, the Burt data set is a subset of 8 variables from the original 11 reported by Burt in 1915. That matrix has the same problem. See burt .   
Other example data sets that are useful demonstrations of factor analysis are the seven bifactor examples in Bechtoldt and the 24 ability measures in Harman74.cor    
There are several other Harman examples in the psych package (i.e., Harman.8) as well as in the dataseta and GPArotation packages. The Harman 24 mental tests problem is in the basic datasets package at Harman74.cor.  
Other Harman data sets are 5 socioeconomic variables for 12 census tracts Harman.5 used by John Loehlin as an example for EFA. Another one of the many Harman (1967) data sets is Harman.political. This contains 8 political variables taken over 147 election areas. The principal factor method with SMCs as communalities match those of table 8.18. The data are used by Dziubian and Shirkey as an example of the Kaiser-Meyer-Olkin test of factor adequacy.    Source  
Harman (1967 p 164 and p 244.)   
H. Harman and W.Jones. (1966) Factor analysis by minimizing residuals (minres). Psychometrika, 31(3):351-368.    References  
Harman, Harry Horace (1967), Modern factor analysis. Chicago, University of Chicago Press.   
P.Bentler. Covariance structure models for maximal reliability of unit-weighted composites. In Handbook of latent variable and related models, pages 1–17. North Holland, 2007.   
Burt, C.General and Specific Factors underlying the Primary Emotions. Reports of the British Association for the Advancement of Science, 85th meeting, held in Manchester, September 7-11, 1915. London, John Murray, 1916, p. 694-696 (retrieved from the web at https://www.biodiversitylibrary.org/item/95822#790    See Also  
See also the original burt data set, the Harman.5 and Harman.political data sets.   Examples    data(Harman) cor.plot(Harman.Holzinger) cor.plot(Harman.Burt) smc(Harman.Burt) #note how this produces impossible results f2 <- fa(Harman.8,2, rotate=""none"") #minres matches Harman and Jones"
"psych-Holzinger","psych","Holzinger","Seven data sets showing a bifactor solution.",14,14,0,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Holzinger.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Holzinger.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Holzinger.9","psych","Holzinger.9","Seven data sets showing a bifactor solution.",9,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Holzinger.9.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Holzinger.9.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Reise","psych","Reise","Seven data sets showing a bifactor solution.",16,16,0,0,0,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Reise.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Reise.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-sat.act","psych","sat.act","3 Measures of ability: SATV, SATQ, ACT",700,6,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/sat.act.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/sat.act.html","sat.act R Documentation   3 Measures of ability: SATV, SATQ, ACT   Description  
Self reported scores on the SAT Verbal, SAT Quantitative and ACT were collected as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project. Age, gender, and education are also reported. The data from 700 subjects are included here as a demonstration set for correlation and analysis.    Usage   data(sat.act)   Format  
A data frame with 700 observations on the following 6 variables.    gender
males = 1, females = 2   education
self reported education 1 = high school ... 5 = graduate work   age
age   ACT
ACT composite scores may range from 1 - 36. National norms have a mean of 20.   SATV
SAT Verbal scores may range from 200 - 800.   SATQ
SAT Quantitative scores may range from 200 - 800     Details  
hese items were collected as part of the SAPA project ( https://www.sapa-project.org/ )to develop online measures of ability (Revelle, Wilt and Rosenthal, 2009). The score means are higher than national norms suggesting both self selection for people taking on line personality and ability tests and a self reporting bias in scores.   
See also the iq.items data set.   Source  
https://personality-project.org/    References  
Revelle, William, Wilt, Joshua, and Rosenthal, Allen (2009) Personality and Cognition: The Personality-Cognition Link. In Gruszka, Alexandra and Matthews, Gerald and Szymura, Blazej (Eds.) Handbook of Individual Differences in Cognition: Attention, Memory and Executive Control, Springer.   Examples    data(sat.act) describe(sat.act) pairs.panels(sat.act)"
"psych-Schmid","psych","Schmid","12 variables created by Schmid and Leiman to show the Schmid-Leiman Transformation",12,12,0,0,0,0,12,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Schmid.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Schmid.html","Schmid R Documentation   12 variables created by Schmid and Leiman to show the Schmid-Leiman Transformation   Description  
John Schmid and John M. Leiman (1957) discuss how to transform a hierarchical factor structure to a bifactor structure. Schmid contains the example 12 x 12 correlation matrix. schmid.leiman is a 12 x 12 correlation matrix with communalities on the diagonal. This can be used to show the effect of correcting for attenuation. Two additional data sets are taken from Chen et al. (2006).    Usage   data(Schmid)   Details  
Two artificial correlation matrices from Schmid and Leiman (1957). One real and one artificial covariance matrices from Chen et al. (2006).  

Schmid: a 12 x 12 artificial correlation matrix created to show the Schmid-Leiman transformation.  
schmid.leiman: A 12 x 12 matrix with communalities on the diagonal. Treating this as a covariance matrix shows the 6 x 6 factor solution   
Chen: An 18 x 18 covariance matrix of health related quality of life items from Chen et al. (2006). Number of observations = 403. The first item is a measure of the quality of life. The remaining 17 items form four subfactors: The items are (a) Cognition subscale: “Have difficulty reasoning and solving problems?"" “React slowly to things that were said or done?""; “Become confused and start several actions at a time?"" “Forget where you put things or appointments?""; “Have difficulty concentrating?"" (b) Vitality subscale: “Feel tired?"" “Have enough energy to do the things you want?"" (R) “Feel worn out?"" ; “Feel full of pep?"" (R). (c) Mental health subscale: “Feel calm and peaceful?""(R) “Feel downhearted and blue?""; “Feel very happy""(R) ; “Feel very nervous?"" ; “Feel so down in the dumps nothing could cheer you up? (d) Disease worry subscale: “Were you afraid because of your health?""; “Were you frustrated about your health?""; “Was your health a worry in your life?"" .   
West: A 16 x 16 artificial covariance matrix from Chen et al. (2006).      Source  
John Schmid Jr. and John. M. Leiman (1957), The development of hierarchical factor solutions.Psychometrika, 22, 83-90.   
F.F. Chen, S.G. West, and K.H. Sousa.(2006) A comparison of bifactor and second-order models of quality of life. Multivariate Behavioral Research, 41(2):189-225, 2006.    References  
Y.-F. Yung, D.Thissen, and L.D. McLeod. (1999) On the relationship between the higher-order factor model and the hierarchical factor model. Psychometrika, 64(2):113-128, 1999.    Examples    data(Schmid) cor.plot(Schmid,TRUE) print(fa(Schmid,6,rotate=""oblimin""),cut=0) #shows an oblique solution round(cov2cor(schmid.leiman),2) cor.plot(cov2cor(West),TRUE)"
"psych-Tal.Or","psych","Tal.Or","Data set testing causal direction in presumed media influence",123,6,2,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Tal.Or.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Tal.Or.html","Tal_Or R Documentation    Data set testing causal direction in presumed media influence   Description  
Nurit Tal-Or, Jonanathan Cohen, Yariv Tasfati, and Albert Gunther (2010) examined the presumed effect of media on other people and change in attitudes. This data set is from Study 2, and examined the effect of presumed influence of the media upon subsequent actions. It is used as an example of mediation by Hayes (2013) and for the mediate function.   Usage   data(""Tal.Or"")   Format  
A data frame with 123 observations on the following 6 variables.    cond
Experimental Condition: 0 low media importance, 1 high media importance   pmi
Presumed media influence (based upon the mean of two items   import
Importance of the issue   reaction
Subjects rated agreement about possible reactions to the story (mean of 4 items).   gender
1 = male, 2 = female   age
a numeric vector     Details  
Tal-Or et al. (2010) examined the presumed effect of the media in two experimental studies. These data are from study 2. '... perceptions regarding the influence of a news story about an expected shortage in sugar were manipulated indirectly, by manipulating the perceived exposure to the news story, and behavioral intentions resulting from the story were consequently measured."" (p 801).   Source  
The data were downloaded from the webpages of Andrew Hayes (https://www.afhayes.com/public/hayes2018data.zip) supporting the first and second edition of his book. The name of the original data set was pmi. (Gender was recoded to reflect the number of X chromosomes).   
The original data are from Nurit Tal-Or, Jonathan Cohen, Yariv Tsfati, and Albert C. Gunther and are used with their kind permission.    References  
Nurit Tal-Or, Jonathan Cohen, Yariv Tsfati and Albert C. Gunther (2010), Testing Causal Direction in the Influence of Presumed Media Influence, Communication Research, 37, 801-824.   
Hayes, Andrew F. (2013) Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. Guilford Press.   Examples    data(Tal.Or) mediate(reaction ~ cond + (pmi), data =Tal.Or,n.iter=50)"
"psych-Thurstone","psych","Thurstone","Seven data sets showing a bifactor solution.",9,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Thurstone.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Thurstone.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Thurstone.33","psych","Thurstone.33","Seven data sets showing a bifactor solution.",9,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Thurstone.33.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Thurstone.33.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Thurstone.9","psych","Thurstone.9","Seven data sets showing a bifactor solution.",9,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Thurstone.9.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Thurstone.9.html","Bechtoldt R Documentation   Seven data sets showing a bifactor solution.   Description  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items. The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.   Usage    data(Thurstone) data(Thurstone.33) data(Thurstone.9) data(Holzinger) data(Holzinger.9) data(Bechtoldt) data(Bechtoldt.1) data(Bechtoldt.2) data(Reise)    Details  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities. This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.   
There are several ways to analyze such data. One is to use the omega function to do a hierarchical factoring using the Schmid-Leiman transformation. This can then be done as an exploratory and then as a confirmatory model using omegaSem . Another way is to do a regular factor analysis and use either a bifactor or biquartimin rotation. These latter two functions implement the Jennrich and Bentler (2011) bifactor and biquartimin transformations. The bifactor rotation suffers from the problem of local minima (Mansolf and Reise, 2016) and thus a mixture of exploratory and confirmatory analysis might be preferred.  
The 14 variables are ordered to reflect 3 spatial tests, 3 mental speed tests, 4 motor speed tests, and 4 verbal tests. The sample size is 355.   
Another data set from Holzinger (Holzinger.9) represents 9 cognitive abilities (Holzinger, 1939) and is used as an example by Karl Joreskog (2003) for factor analysis by the MINRES algorithm and also appears in the LISREL manual as example NPV.KM. This data set represents the scores from the Grant White middle school for 9 tests: ""t01_visperc"" ""t02_cubes"" ""t04_lozenges"" ""t06_paracomp"" ""t07_sentcomp"" ""t09_wordmean"" ""t10_addition"" ""t12_countdot"" and ""t13_sccaps"" and as variables x1 ... x9 (for the Grant-White school) in the lavaan package.   
Another classic data set is the 9 variable Thurstone problem which is discussed in detail by R. P. McDonald (1985, 1999) and and is used as example in the sem package as well as in the PROC CALIS manual for SAS. These nine tests were grouped by Thurstone and Thurstone, 1941 (based on other data) into three factors: Verbal Comprehension, Word Fluency, and Reasoning. The original data came from Thurstone and Thurstone (1941) but were reanalyzed by Bechthold (1961) who broke the data set into two. McDonald, in turn, selected these nine variables from the larger set of 17 found in Bechtoldt.2. The sample size is 213.   
Another set of 9 cognitive variables attributed to Thurstone (1933) is the data set of 4,175 students reported by Professor Brigham of Princeton to the College Entrance Examination Board. This set does not show a clear bifactor solution but is included as a demonstration of the differences between a maximimum likelihood factor analysis solution versus a principal axis factor solution.   
Tucker (1958) uses 9 variables from Thurstone and Thburstone (1941) for his example of interbattery factor analysis.  
More recent applications of the bifactor model are to the measurement of psychological status. The Reise data set is a correlation matrix based upon >35,000 observations to the Consumer Assessment of Health Care Provideers and Systems survey instrument. Reise, Morizot, and Hays (2007) describe a bifactor solution based upon 1,000 cases.  
The five factors from Reise et al. reflect Getting care quickly (1-3), Doctor communicates well (4-7), Courteous and helpful staff (8,9), Getting needed care (10-13), and Health plan customer service (14-16).  
The two Bechtoldt data sets are two samples from Thurstone and Thurstone (1941). They include 17 variables, 9 of which were used by McDonald to form the Thurstone data set. The sample sizes are 212 and 213 respectively. The six proposed factors reflect memory, verbal, words, space, number and reasoning with three markers for all expect the rote memory factor. 9 variables from this set appear in the Thurstone data set.   
Two more data sets with similar structures are found in the Harman data set. This includes the another 9 variables (with 696 subjects) from Holzinger used by Harman link{Harman.Holzinger} as well as 8 affective variables from link{burt} .  
Another data set that is worth examining for tests of bifactor structure is the holzinger.swineford data set which includes the original data from Holzinger and Swineford (1939) supplied by Keith Widaman. This is in psychTools.1.9.11 or later.   

Bechtoldt.1: 17 x 17 correlation matrix of ability tests, N = 212.   
Bechtoldt.2: 17 x 17 correlation matrix of ability tests, N = 213.   
Holzinger: 14 x 14 correlation matrix of ability tests, N = 355   
Holzinger.9: 9 x 9 correlation matrix of ability tests, N = 145   
Reise: 16 x 16 correlation matrix of health satisfaction items. N = 35,000   
Thurstone: 9 x 9 correlation matrix of ability tests, N = 213   
Thurstone.33: Another 9 x 9 correlation matrix of ability tests, N=4175   
Thurstone:9: And yet another 9 x 9 correlation matrix of ability tests, N =710      Note  
Note that these are tests, not items. Thus, it was possible to find the reliabilities of each test.   
For the Holzinger 14 tests these were found from 1- t2 where t = c(.332, .517, .360, .382, .354,.249, .444, .393, .455, .424, .393, .487, .534, .382) (page 53) and thus the reliabilities were 0.890, 0.733, 0.870, 0.854, 0.875, 0.938, 0.803, 0.846, 0.793, 0.820, 0.846, 0.763, 0.715, 0.854.  
For the Holzinger.9 tests, the reliabilities for the Grant-White tests were: .76, .57, .94, .65, .75, .87, .95, .84 and .89 (Keith Widamn, personal communication, 2020),    Source  
Holzinger: Holzinger and Swineford (1937)
 Reise: Steve Reise (personal communication)
 sem help page (for Thurstone)   References  
Bechtoldt, Harold, (1961). An empirical study of the factor analysis stability hypothesis. Psychometrika, 26, 405-432.   
Holzinger, Karl and Swineford, Frances (1937) The Bi-factor method. Psychometrika, 2, 41-54   
Holzinger, K., & Swineford, F. (1939). A study in factor analysis: The stability of a bifactor solution. Supplementary Educational Monograph, no. 48. Chicago: University of Chicago Press.   
McDonald, Roderick P. (1999) Test theory: A unified treatment. L. Erlbaum Associates. Mahwah, N.J.   
Mansolf, Maxwell and Reise, Steven P. (2016) Exploratory Bifactor Analysis: The Schmid-Leiman Orthogonalization and Jennrich-Bentler Analytic Rotations, Multivariate Behavioral Research, 51:5, 698-717, DOI: 10.1080/00273171.2016.1215898   
Reise, Steven and Morizot, Julien and Hays, Ron (2007) The role of the bifactor model in resolving dimensionality issues in health outcomes measures. Quality of Life Research. 16, 19-31.   
Thurstone, Louis Leon (1933) The theory of multiple factors. Edwards Brothers, Inc. Ann Arbor   
Thurstone, Louis Leon and Thurstone, Thelma (Gwinn). (1941) Factorial studies of intelligence. The University of Chicago Press. Chicago, Il.   
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    Examples    if(!require(GPArotation)) {message(""I am sorry, to run omega requires GPArotation"") } else { #holz <- omega(Holzinger,4, title = ""14 ability tests from Holzinger-Swineford"") #bf <- omega(Reise,5,title=""16 health items from Reise"") #omega(Reise,5,labels=colnames(Reise),title=""16 health items from Reise"") thur.om <- omega(Thurstone,title=""9 variables from Thurstone"") #compare with thur.bf <- fa(Thurstone,3,rotate=""biquartimin"") factor.congruence(thur.om,thur.bf) }"
"psych-Tucker","psych","Tucker","9 Cognitive variables discussed by Tucker and Lewis (1973)",9,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/Tucker.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/Tucker.html","Tucker R Documentation    9 Cognitive variables discussed by Tucker and Lewis (1973)    Description  
Tucker and Lewis (1973) introduced a reliability coefficient for ML factor analysis. Their example data set was previously reported by Tucker (1958) and taken from Thurstone and Thurstone (1941). The correlation matrix is a 9 x 9 for 710 subjects and has two correlated factors of ability: Word Fluency and Verbal.    Usage   data(Tucker)   Format  
A data frame with 9 observations on the following 9 variables.    t42
Prefixes   t54
Suffixes   t45
Chicago Reading Test: Vocabulary   t46
Chicago Reading Test: Sentences   t23
First and last letters   t24
First letters   t27
Four letter words   t10
Completion   t51
Same or Opposite     Details  
The correlation matrix from Tucker (1958) was used in Tucker and Lewis (1973) for the Tucker-Lewis Index of factoring reliability.    Source  
Tucker, Ledyard (1958) An inter-battery method of factor analysis, Psychometrika, 23, 111-136.    References  
L.~Tucker and C.~Lewis. (1973) A reliability coefficient for maximum likelihood factor analysis. Psychometrika, 38(1):1–10.   
F.~J. Floyd and K.~F. Widaman. (1995) Factor analysis in the development and refinement of clinical assessment instruments., Psychological Assessment, 7(3):286 – 299.    Examples    data(Tucker) fa(Tucker,2,n.obs=710) omega(Tucker,2)"
"psych-withinBetween","psych","withinBetween","An example of the distinction between within group and between group correlations",16,10,0,0,1,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/psych/withinBetween.csv","https://vincentarelbundock.github.io/Rdatasets/doc/psych/withinBetween.html","withinBetween R Documentation   An example of the distinction between within group and between group correlations   Description  
A demonstration that a correlation may be decomposed to a within group correlation and a between group correlations and these two correlations are independent. Between group correlations are sometimes called ecological correlations, the decomposition into within and between group correlations is a basic concept in multilevel modeling. This data set shows the composite correlations between 9 variables, representing 16 cases with four groups.   Usage   data(withinBetween)   Format  
A data frame with 16 observations on the following 10 variables.    Group
An example grouping factor.   V1
A column of 16 observations   V2
A column of 16 observations   V3
A column of 16 observations   V4
A column of 16 observations   V5
A column of 16 observations   V6
A column of 16 observations   V7
A column of 16 observations   V8
A column of 16 observations   V9
A column of 16 observations     Details  
Correlations between individuals who belong to different natural groups (based upon e.g., ethnicity, age, gender, college major,or country) reflect an unknown mixture of the pooled correlation within each group as well as the correlation of the means of these groups. These two correlations are independent and do not allow inferences from one level (the group) to the other level (the individual). This data set shows this independence. The within group correlations between 9 variables are set to be 1, 0, and -1 while those between groups are also set to be 1, 0, -1. These two sets of correlations are crossed such that V1, V4, and V7 have within group correlations of 1, as do V2, V5 and V8, and V3, V6 and V9. V1 has a within group correlation of 0 with V2, V5, and V8, and a -1 within group correlation with V3, V6 and V9. V1, V2, and V3 share a between group correlation of 1, as do V4, V5 and V6, and V7, V8 and V9. The first group has a 0 between group correlation with the second and a -1 with the third group.  
statsBy can decompose the observed correlation in the between and within correlations. sim.multilevel can produce similar data.    Source  
The data were created for this example   References  
P. D. Bliese. Multilevel modeling in R (2.3) a brief introduction to R, the multilevel package and the nlme package, 2009.   
Pedhazur, E.J. (1997) Multiple regression in behavioral research: explanation and prediction. Harcourt Brace.   
Revelle, W. An introduction to psychometric theory with applications in R (in prep) Springer. Draft chapters available at https://personality-project.org/r/book/     See Also  
statsBy , describeBy , and sim.multilevel    Examples    data(withinBetween) pairs.panels(withinBetween,bg=c(""red"",""blue"",""white"",""black"")[withinBetween[,1]], pch=21,ellipses=FALSE,lm=TRUE) stats <- statsBy(withinBetween,'Group') print(stats,short=FALSE)"
"quantreg-barro","quantreg","barro","Barro Data",161,14,0,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/barro.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/barro.html","barro R Documentation   Barro Data   Description  
Version of the Barro Growth Data used in Koenker and Machado(1999). This is a regression data set consisting of 161 observations on determinants of cross country GDP growth rates. There are 13 covariates with dimnames corresponding to the original Barro and Lee source. See https://www.nber.org/pub/barro.lee/. The first 71 observations are on the period 1965-75, remainder on 1987-85.   Usage   data(barro)   Format  
A data frame containing 161 observations on 14 variables:   
 [,1] ""Annual Change Per Capita GDP""
 [,2] ""Initial Per Capita GDP""
 [,3] ""Male Secondary Education""
 [,4] ""Female Secondary Education""
 [,5] ""Female Higher Education""
 [,6] ""Male Higher Education""
 [,7] ""Life Expectancy""
 [,8] ""Human Capital""
 [,9] ""Education/GDP""
 [,10] ""Investment/GDP""
 [,11] ""Public Consumption/GDP""
 [,12] ""Black Market Premium""
 [,13] ""Political Instability""
 [,14] ""Growth Rate Terms Trade""   References  
Koenker, R. and J.A.F. Machado (1999) Goodness of Fit and Related Inference Processes for Quantile Regression, JASA, 1296-1310."
"quantreg-Bosco","quantreg","Bosco","Boscovich Data",5,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/Bosco.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/Bosco.html","Bosco R Documentation   Boscovich Data   Description  
Boscovich data used to estimate the ellipticity of the earth. There are five measurements of the arc length of one degree of latitude taken at 5 different latitudes. See Koenker (2005) for further details and references.    Usage   data(Bosco)   Format  
A data frame containing 5 observations on 2 variables    x
sine squared of latitude measured in degrees   y
arc length of one degree of latitude measured in toise - 56,700, one toise approximately equals 1.95 meters.     References  
Koenker, R. (2005), ""Quantile Regression"", Cambridge.    Examples    data(Bosco) plot(0:10/10,0:10*100,xlab=""sin^2(latitude)"", ylab=""arc-length of 1 degree of latitude"",type=""n"") points(Bosco) text(Bosco, pos = 3, rownames(Bosco)) z <- rq(y ~ x, tau = -1, data = Bosco) title(""Boscovitch Ellipticity of the Earth Example"") xb <- c(.85,.9,.6,.6) yb <- c(400,600,450,600) for(i in 1:4){ abline(c(z$sol[4:5,i])) interval <- paste(""t=("",format(round(z$sol[1,i],2)),"","", format(round(z$sol[1,i+1],2)),"")"",delim="""") text(xb[i],yb[i],interval) }"
"quantreg-CobarOre","quantreg","CobarOre","Cobar Ore data",38,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/CobarOre.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/CobarOre.html","CobarOre R Documentation   Cobar Ore data   Description  
Cobar Ore data from Green and Silverman (1994). The data consists of measurements on the ""true width"" of an ore-bearing rock layer from a mine in Cobar, Australia.    Usage   data(CobarOre)   Format  
A data frame with 38 observations on the following 3 variables.    x
x-coordinate of location of mine site   y
y-coordinate of location of mine site   z
ore thickness     Source  
Green, P.J. and B.W. Silverman (1994) Nonparametric Regression Generalized Linear Models: A roughness penalty approach, Chapman Hall.    Examples    data(CobarOre) plot(CobarOre)"
"quantreg-engel","quantreg","engel","Engel Data",235,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/engel.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/engel.html","engel R Documentation   Engel Data   Description  
Engel food expenditure data used in Koenker and Bassett(1982). This is a regression data set consisting of 235 observations on income and expenditure on food for Belgian working class households.    Usage   data(engel)   Format  
A data frame containing 235 observations on 2 variables    income
annual household income in Belgian francs   foodexp
annual household food expenditure in Belgian francs     References  
Koenker, R. and Bassett, G (1982) Robust Tests of Heteroscedasticity based on Regression Quantiles;  Econometrica 50 , 43–61.    Examples    ## See also demo(""engel1"") ## -------------- data(engel) plot(engel, log = ""xy"", main = ""'engel' data (log - log scale)"") plot(log10(foodexp) ~ log10(income), data = engel, main = ""'engel' data (log10 - transformed)"") taus <- c(.15, .25, .50, .75, .95, .99) rqs <- as.list(taus) for(i in seq(along = taus)) { rqs[[i]] <- rq(log10(foodexp) ~ log10(income), tau = taus[i], data = engel) lines(log10(engel$income), fitted(rqs[[i]]), col = i+1) } legend(""bottomright"", paste(""tau = "", taus), inset = .04, col = 2:(length(taus)+1), lty=1)"
"quantreg-gasprice","quantreg","gasprice","Time Series of US Gasoline Prices",695,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/gasprice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/gasprice.html","gasprice R Documentation   Time Series of US Gasoline Prices    Description  
Time Series of Weekly US Gasoline Prices: 1990:8 – 2003:26    Usage   data(""gasprice"")   Examples    data(gasprice)"
"quantreg-Mammals","quantreg","Mammals","Garland(1983) Data on Running Speed of Mammals",107,4,2,0,0,2,2,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/Mammals.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/Mammals.html","Mammals R Documentation   Garland(1983) Data on Running Speed of Mammals   Description  
Observations on the maximal running speed of mammal species and their body mass.    Usage   data(Mammals)   Format  
A data frame with 107 observations on the following 4 variables.    weight
Body mass in Kg for ""typical adult sizes""   speed
Maximal running speed (fastest sprint velocity on record)   hoppers
logical variable indicating animals that ambulate by hopping, e.g. kangaroos   specials
logical variable indicating special animals with ""lifestyles in which speed does not figure as an important factor"": Hippopotamus, raccoon (Procyon), badger (Meles), coati (Nasua), skunk (Mephitis), man (Homo), porcupine (Erithizon), oppossum (didelphis), and sloth (Bradypus)      Details  
Used by Chappell (1989) and Koenker, Ng and Portnoy (1994) to illustrate the fitting of piecewise linear curves.    Source  
Garland, T. (1983) The relation between maximal running speed and body mass in terrestrial mammals, J. Zoology , 199, 1557-1570.    References  
Koenker, R., P. Ng and S. Portnoy, (1994) Quantile Smoothing Splines” Biometrika , 81, 673-680.   
Chappell, R. (1989) Fitting Bent Lines to Data, with Applications ot Allometry, J. Theo. Biology , 138, 235-256.    See Also  
rqss   Examples    data(Mammals) attach(Mammals) x <- log(weight) y <- log(speed) plot(x,y, xlab=""Weight in log(Kg)"", ylab=""Speed in log(Km/hour)"",type=""n"") points(x[hoppers],y[hoppers],pch = ""h"", col=""red"") points(x[specials],y[specials],pch = ""s"", col=""blue"") others <- (!hoppers & !specials) points(x[others],y[others], col=""black"",cex = .75) fit <- rqss(y ~ qss(x, lambda = 1),tau = .9) plot(fit)"
"quantreg-uis","quantreg","uis","UIS Drug Treatment study data",575,18,5,0,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/quantreg/uis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/quantreg/uis.html","uis R Documentation   UIS Drug Treatment study data   Description  
There are 628 data points in the original data, 575 of which have no missing values.   
Variable descriptions:   
 Variable Description Codes/Values
 ID Identification Code 1 - 628
 AGE Age at Enrollment Years
 BECK Beck DepressionScore 0.000 - 54.000
 HC Heroin/Cocaine Use During 1 = Heroin & Cocaine
  3 Months Prior to Admission 2 = Heroin Only
  3 = Cocaine Only
   4 = Neither Heroin nor Cocaine
 IV History of IV Drug Use 1 = Never
  2 = Previous
   3 = Recent
 NDT Number of Prior Drug Treatments 0 - 40
 RACE Subject's Race 0 = White
   1 = Non-White
 TREAT Treatment Randomization 0 = Short
  Assignment 1 = Long
 SITE Treatment Site 0 = A
   1 = B
 LEN.T Length of Stay in Treatment Days
  (Admission Date to Exit Date) 
TIME Time to Drug Relapse Days
  (Measured from Admission Date) 
 CENSOR Event for Treating Lost to 1 = Returned to Drugs
  Follow-Up as Returned to Drugs or Lost to Follow-Up
   0 = Otherwise
 Y log of TIME 
ND1 Component of NDT 
ND2 Component of NDT 
 LNDT  
FRAC Compliance fraction LEN.T/90 for short trt
   LEN.T/180 for long trt
 IV3 Recent IV use 1 = Yes
   0 = No   Usage   data(uis)   Format  
A data frame with dimension 575 by 18.   Source  
Table 1.3 of Hosmer,D.W. and Lemeshow, S. (1998)   References  
Hosmer,D.W. and Lemeshow, S. (1998) Applied Survival Analysis: Regression Modeling of Time to Event Data, John Wiley and Sons Inc., New York, NY"
"reshape2-french_fries","reshape2","french_fries","Sensory data from a french fries experiment.",696,9,1,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/reshape2/french_fries.csv","https://vincentarelbundock.github.io/Rdatasets/doc/reshape2/french_fries.html","french_fries R Documentation   Sensory data from a french fries experiment.   Description  
This data was collected from a sensory experiment conducted at Iowa State University in 2004. The investigators were interested in the effect of using three different fryer oils had on the taste of the fries.    Usage    french_fries    Format  
A data frame with 696 rows and 9 variables    Details  
Variables:   

time in weeks from start of study.   
treatment (type of oil),   
subject,   
replicate,   
potato-y flavour,   
buttery flavour,   
grassy flavour,   
rancid flavour,   
painty flavour"
"reshape2-smiths","reshape2","smiths","Demo data describing the Smiths.",2,5,2,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/reshape2/smiths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/reshape2/smiths.html","smiths R Documentation   Demo data describing the Smiths.   Description  
A small demo dataset describing John and Mary Smith. Used in the introductory vignette.    Usage    smiths    Format  
A data frame with 2 rows and 5 variables"
"reshape2-tips","reshape2","tips","Tipping data",244,7,3,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/reshape2/tips.csv","https://vincentarelbundock.github.io/Rdatasets/doc/reshape2/tips.html","tips R Documentation   Tipping data   Description  
One waiter recorded information about each tip he received over a period of a few months working in one restaurant. He collected several variables:    Usage    tips    Format  
A data frame with 244 rows and 7 variables    Details  

tip in dollars,   
bill in dollars,   
sex of the bill payer,   
whether there were smokers in the party,   
day of the week,   
time of day,   
size of the party.     
In all he recorded 244 tips. The data was reported in a collection of case studies for business statistics (Bryant & Smith 1995).    References  
Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics . Homewood, IL: Richard D. Irwin Publishing:"
"robustbase-aircraft","robustbase","aircraft","Aircraft Data",23,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/aircraft.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/aircraft.html","aircraft R Documentation   Aircraft Data   Description  
Aircraft Data, deals with 23 single-engine aircraft built over the years 1947-1979, from Office of Naval Research. The dependent variable is cost (in units of \$100,000) and the explanatory variables are aspect ratio, lift-to-drag ratio, weight of plane (in pounds) and maximal thrust.    Usage   data(aircraft, package=""robustbase"")   Format  
A data frame with 23 observations on the following 5 variables.    X1
Aspect Ratio   X2
Lift-to-Drag Ratio   X3
Weight   X4
Thrust   Y
Cost     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, page 154, table 22.    Examples    data(aircraft) summary( lm.airc <- lm(Y ~ ., data = aircraft)) summary(rlm.airc <- MASS::rlm(Y ~ ., data = aircraft)) aircraft.x <- data.matrix(aircraft[,1:4]) c_air <- covMcd(aircraft.x) c_air"
"robustbase-airmay","robustbase","airmay","Air Quality Data",31,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/airmay.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/airmay.html","airmay R Documentation   Air Quality Data   Description  
Air Quality Data Set for May 1973, from Chambers et al. (1983). The whole data set consists of daily readings of air quality values from May 1, 1973 to September 30, 1973, but here are included only the values for May. This data set is an example of the special treatment of the missing values.    Usage   data(airmay, package=""robustbase"")   Format  
A data frame with 31 observations on the following 4 variables.    X1
Solar Radiation in Longleys in the frequency band 4000-7700 from 0800 to 1200 hours at Central Park   X2
Average windspeed (in miles per hour) between 7000 and 1000 hours at La Guardia Airport   X3
Maximum daily temperature (in degrees Fahrenheit) at La Guardia Airport   Y
Mean ozone concentration (in parts per billion) from 1300 to 1500 hours at Roosevelt Island     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.86, table 6.    Examples    data(airmay) summary(lm.airmay <- lm(Y ~ ., data=airmay)) airmay.x <- data.matrix(airmay[,1:3])"
"robustbase-alcohol","robustbase","alcohol","Alcohol Solubility in Water Data",44,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/alcohol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/alcohol.html","alcohol R Documentation   Alcohol Solubility in Water Data   Description  
The solubility of alcohols in water is important in understanding alcohol transport in living organisms. This dataset from (Romanelli et al., 2001) contains physicochemical characteristics of 44 aliphatic alcohols. The aim of the experiment was the prediction of the solubility on the basis of molecular descriptors.    Usage   data(alcohol, package=""robustbase"")   Format  
A data frame with 44 observations on the following 7 numeric variables.    SAG
solvent accessible surface-bounded molecular volume.   V
volume   logPC
Log(PC); PC = octanol-water partitions coefficient   P
polarizability   RM
molar refractivity   Mass
the mass   logSolubility
ln(Solubility), the response.     Source  
The website accompanying the MMY-book:  https://www.wiley.com/legacy/wileychi/robust_statistics/     References  
Maronna, R.A., Martin, R.D. and Yohai, V.J. (2006)  Robust Statistics, Theory and Methods , Wiley.    Examples    data(alcohol) ## version of data set with trivial names, as s.alcohol <- alcohol names(s.alcohol) <- paste(""Col"", 1:7, sep='')"
"robustbase-ambientNOxCH","robustbase","ambientNOxCH","Daily Means of NOx (mono-nitrogen oxides) in air",366,14,0,0,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/ambientNOxCH.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/ambientNOxCH.html","ambientNOxCH R Documentation   Daily Means of NOx (mono-nitrogen oxides) in air   Description  
This dataset contains daily means (from midnight to midnight) of NOx, i.e., mono-nitrogen oxides, in [ppb] at 13 sites in central Switzerland and Aarau for the year 2004.    Usage   data(ambientNOxCH, package=""robustbase"")   Format  
A data frame with 366 observations on the following 14 variables.    date
date of day, of class ""Date"" .   ad
Site is located north of Altdorf 100 meters east of motorway A2, on an open field at the beginning of a more than 2000m deep valley (690.175, 193.55; 438; inLuft)   ba
Site is located in the centre of the little town of Baden in a residential area. Baden has 34'000 inhabitants and is situated on the swiss plateau (666.075, 257.972; 377; inLuft).   ef
Site is located 6 km south of altdorf and 800 m north of the village of Erstfeld. The motorway A2 passes 5 m west of the measuring site. Over 8 million vehicles have passed Erstfeld in 2004 where 13% of the counts were attributed to trucks (691.43, 187.69; 457; MFM-U).   la
Site is located on a wooded hill in a rural area called Laegern, about 190 m above Baden, which is about 5 km away (669.8, 259; 690; NABEL).   lu
Site is located in the center of town of Lucerne, which has 57'000 inhabitants (666.19, 211.975; 460; inLuft).   re
Site is located 1 km west of Reiden on the Swiss plateau. The motorway A2 passes 5 m west of the measuring site (639.56, 232.11; 462; MFM-U).   ri
Site is located at Rigi Seebodenalp, 649 m above the lake of Lucerne on an alp with half a dozen small houses (677.9, 213.5; 1030; NABEL).   se
Site is located in Sedel next to town of Lucerne 35m above and 250m south of motorway A14 from Zug to Lucerne on a low hill with free 360° panorama (665.5, 213.41; 484; inLuft).   si
Site is located at the border of a small industrial area in Sisseln, 300 m east of a main road (640.725, 266.25; 305; inLuft).   st
Site is located at the south east border of Stans with 7'000 inhabitants (670.85, 201.025; 438; inLuft).   su
Site is located in the center of Suhr (8700 inhabitants), 10 m from the main road (648.49, 246.985; 403; inLuft).   sz
Site is located in Schwyz (14'200 inhabitants) near a shopping center (691.92, 208.03; 470; inLuft).   zg
Site is located in the centre of Zug with 22'000 inhabitants, 24 m from the main road (681.625, 224.625; 420; inLuft).     Details  
The 13 sites are part of one of the three air quality monitoring networks: inLuft (regional authorities of central Switzerland and canton Aargau) 
 NABEL (Swiss federal network) 
 MFM-U (Monitoring flankierende Massnahmen Umwelt), special Swiss federal network along transit motorways A2 and A13 from Germany to Italy through Switzerland 
 The information within the brackets means: Swiss coordinates km east, km north; m above sea level; network   
When the measuring sites are exposed to the same atmospheric condition and when there is no singular emission event at any site,  log(mean(NOx) of a specific day at each site) is a linear function of log(yearly.mean(NOx) at the corresponding site) . The offset and the slope of the straight line reflects the atmospheric conditions at this specific day. During winter time, often an inversion prevents the emissions from being diluted vertically, so that there evolve two separate atmospheric compartements: One below the inversion boundary with polluted air and one above with relatively clean air. In our example below, Rigi Seebodenalp is above the inversion boundary between December 10th and 12th.    Source  
http://www.in-luft.ch/
 http://www.empa.ch/plugin/template/empa/*/6794
 http://www.bafu.admin.ch/umweltbeobachtung/02272/02280    See Also  
another NOx dataset, NOxEmissions .    Examples    data(ambientNOxCH) str (ambientNOxCH) yearly <- log(colMeans(ambientNOxCH[,-1], na.rm=TRUE)) xlim <- range(yearly) lNOx <- log(ambientNOxCH[, -1]) days <- ambientNOxCH[, ""date""] ## Subset of 9 days starting at April 4: idays <- seq(which(ambientNOxCH$date==""2004-12-04""), length=9) ylim <- range(lNOx[idays,],na.rm=TRUE) op <- par(mfrow=c(3,3),mar=rep(1,4), oma = c(0,0,2,0)) for (id in idays) { daily <- unlist(lNOx[id,]) plot(NA, xlim=xlim,ylim=ylim, ann=FALSE, type = ""n"") abline(0:1, col=""light gray"") abline(lmrob(daily~yearly, na.action=na.exclude), col=""red"", lwd=2) text(yearly, daily, names(yearly), col=""blue"") mtext(days[id], side=1, line=-1.2, cex=.75, adj=.98) } mtext(""Daily ~ Yearly log( NOx mean values ) at 13 Swiss locations"", outer=TRUE) par(op) ## do all 366 regressions: Least Squares and Robust: LS <- lapply(1:nrow(ambientNOxCH), function(id) lm(unlist(lNOx[id,]) ~ yearly, na.action = na.exclude)) R <- lapply(1:nrow(ambientNOxCH), function(id) lmrob(unlist(lNOx[id,]) ~ yearly, na.action = na.exclude)) ## currently 4 warnings about non-convergence; ## which ones? days[notOk <- ! sapply(R, `[[`, ""converged"") ] ## ""2004-01-10"" ""2004-05-12"" ""2004-05-16"" ""2004-11-16"" ## first problematic case: daily <- unlist(lNOx[which(notOk)[1],]) plot(daily ~ yearly, main = paste(""lmrob() non-convergent:"",days[notOk[1]])) rr <- lmrob(daily ~ yearly, na.action = na.exclude, control = lmrob.control(trace=3, max.it = 100)) ##-> 53 iter. ## Look at all coefficients: R.cf <- t(sapply(R, coef)) C.cf <- t(sapply(LS, coef)) plot(C.cf, xlim=range(C.cf[,1],R.cf[,1]), ylim=range(C.cf[,2],R.cf[,2])) mD1 <- rowMeans(abs(C.cf - R.cf)) lrg <- mD1 > quantile(mD1, 0.80) arrows(C.cf[lrg,1], C.cf[lrg,2], R.cf[lrg,1], R.cf[lrg,2], length=.1, col=""light gray"") points(R.cf, col=2) ## All robustness weights aW <- t(sapply(R, weights, type=""robustness"")) colnames(aW) <- names(yearly) summary(aW) sort(colSums(aW < 0.05, na.rm = TRUE)) # how often ""clear outlier"": # lu st zg ba se sz su si re la ef ad ri # 0 0 0 1 1 1 2 3 4 10 14 17 48 lattice::levelplot(aW, asp=1/2, main=""Robustness weights"", xlab= ""day"", ylab= ""site"")"
"robustbase-Animals2","robustbase","Animals2","Brain and Body Weights for 65 Species of Land Animals",65,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/Animals2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/Animals2.html","Animals2 R Documentation   Brain and Body Weights for 65 Species of Land Animals   Description  
A data frame with average brain and body weights for 62 species of land mammals and three others.   
Note that this is simply the union of Animals  and mammals .    Usage    Animals2    Format   body
body weight in kg   brain
brain weight in g     Note  
After loading the MASS package, the data set is simply constructed by  Animals2 <- local({D <- rbind(Animals, mammals); unique(D[order(D$body,D$brain),])}) .   
Rousseeuw and Leroy (1987)'s ‘brain’ data is the same as  MASS 's Animals (with Rat and Brachiosaurus interchanged, see the example below).    Source  
Weisberg, S. (1985)  Applied Linear Regression.  2nd edition. Wiley, pp. 144–5.   
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection.  Wiley, p. 57.    References  
Venables, W. N. and Ripley, B. D. (2002)  Modern Applied Statistics with S. Forth Edition. Springer.    Examples    data(Animals2) ## Sensible Plot needs doubly logarithmic scale plot(Animals2, log = ""xy"") ## Regression example plot: plotbb <- function(bbdat) { d.name <- deparse(substitute(bbdat)) plot(log(brain) ~ log(body), data = bbdat, main = d.name) abline( lm(log(brain) ~ log(body), data = bbdat)) abline(MASS::rlm(log(brain) ~ log(body), data = bbdat), col = 2) legend(""bottomright"", leg = c(""lm"", ""rlm""), col=1:2, lwd=1, inset = 1/20) } plotbb(bbdat = Animals2) ## The `same' plot for Rousseeuw's subset: data(Animals, package = ""MASS"") brain <- Animals[c(1:24, 26:25, 27:28),] plotbb(bbdat = brain) lbrain <- log(brain) plot(mahalanobis(lbrain, colMeans(lbrain), var(lbrain)), main = ""Classical Mahalanobis Distances"") mcd <- covMcd(lbrain) plot(mahalanobis(lbrain,mcd$center,mcd$cov), main = ""Robust (MCD) Mahalanobis Distances"")"
"robustbase-biomassTill","robustbase","biomassTill","Biomass Tillage Data",58,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/biomassTill.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/biomassTill.html","biomassTill R Documentation   Biomass Tillage Data   Description  
An agricultural experiment in which different tillage methods were implemented. The effects of tillage on plant (maize) biomass were subsequently determined by modeling biomass accumulation for each tillage treatment using a 3 parameter Weibull function.   
A datset where the total biomass is modeled conditional on a three value factor, and hence vector parameters are used.    Usage   data(""biomassTill"", package=""robustbase"")   Format  
A data frame with 58 observations on the following 3 variables.    Tillage
Tillage treatments, a factor  with levels   CA- :
a no-tillage system with plant residues removed   CA+ :
a no-tillage system with plant residues retained   CT :
a conventionally tilled system with residues incorporated     DVS
the development stage of the maize crop. A DVS of  1 represents maize anthesis (flowering), and a DVS of 2  represents physiological maturity. For the data, numeric vector with 5 different values between 0.5 and 2.   Biomass
accumulated biomass of maize plants from each tillage treatment.   Biom.2
the same as Biomass , but with three values replaced by “gross errors”.     Source  
From Strahinja Stepanovic and John Laborde, Department of Agronomy & Horticulture, University of Nebraska-Lincoln, USA    Examples    data(biomassTill) str(biomassTill) require(lattice) ## With long tailed errors xyplot(Biomass ~ DVS | Tillage, data = biomassTill, type=c(""p"",""smooth"")) ## With additional 2 outliers: xyplot(Biom.2 ~ DVS | Tillage, data = biomassTill, type=c(""p"",""smooth"")) ### Fit nonlinear Regression models: ----------------------------------- ## simple starting values, needed: m00st <- list(Wm = rep(300, 3), a = rep( 1.5, 3), b = rep( 2.2, 3)) robm <- nlrob(Biomass ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])), data = biomassTill, start = m00st, maxit = 200) ## ----------- summary(robm) ## ... 103 IRWLS iterations plot(sort(robm$rweights), log = ""y"", main = ""ordered robustness weights (log scale)"") mtext(getCall(robm)) ## the classical (only works for the mild outliers): cl.m <- nls(Biomass ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])), data = biomassTill, start = m00st) ## now for the extra-outlier data: -- fails with singular gradient !! try( rob2 <- nlrob(Biom.2 ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])), data = biomassTill, start = m00st) ) ## use better starting values: m1st <- setNames(as.list(as.data.frame(matrix( coef(robm), 3))), c(""Wm"", ""a"",""b"")) try(# just breaks a bit later! rob2 <- nlrob(Biom.2 ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])), data = biomassTill, start = m1st, maxit= 200, trace=TRUE) ) ## Comparison {more to come} % once we have ""MM"" working... rbind(start = unlist(m00st), class = coef(cl.m), rob = coef(robm))"
"robustbase-bushfire","robustbase","bushfire","Campbell Bushfire Data",38,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/bushfire.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/bushfire.html","bushfire R Documentation   Campbell Bushfire Data   Description  
This data set was used by Campbell (1984) to locate bushfire scars. The dataset contains satelite measurements on five frequency bands, corresponding to each of 38 pixels.    Usage   data(bushfire, package=""robustbase"")   Format  
A data frame with 38 observations on 5 variables.    Source  
Maronna, R.A. and Yohai, V.J. (1995) The Behavoiur of the Stahel-Donoho Robust Multivariate Estimator.  Journal of the American Statistical Association 90 , 330–341.    Examples    data(bushfire) plot(bushfire) covMcd(bushfire)"
"robustbase-carrots","robustbase","carrots","Insect Damages on Carrots",24,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/carrots.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/carrots.html","carrots R Documentation   Insect Damages on Carrots   Description  
The damage carrots data set from Phelps (1982) was used by McCullagh and Nelder (1989) in order to illustrate diagnostic techniques because of the presence of an outlier. In a soil experiment trial with three blocks, eight levels of insecticide were applied and the carrots were tested for insect damage.    Usage   data(carrots, package=""robustbase"")   Format  
A data frame with 24 observations on the following 4 variables.    success
integer giving the number of carrots with insect damage.   total
integer giving the total number of carrots per experimental unit.   logdose
a numeric vector giving log(dose) values (eight different levels only).   block
factor with levels B1 to B3     Source  
Phelps, K. (1982). Use of the complementary log-log function to describe doseresponse relationships in insecticide evaluation field trials. 
 In R. Gilchrist (Ed.), Lecture Notes in Statistics, No. 14. GLIM.82: Proceedings of the International Conference on Generalized Linear Models ; Springer-Verlag.    References  
McCullagh P. and Nelder, J. A. (1989)  Generalized Linear Models.  London: Chapman and Hall.   
Eva Cantoni and Elvezio Ronchetti (2001); JASA, and
 Eva Cantoni (2004); JSS, see glmrob     Examples    data(carrots) str(carrots) plot(success/total ~ logdose, data = carrots, col = as.integer(block)) coplot(success/total ~ logdose | block, data = carrots) ## Classical glm Cfit0 <- glm(cbind(success, total-success) ~ logdose + block, data=carrots, family=binomial) summary(Cfit0) ## Robust Fit (see help(glmrob)) ...."
"robustbase-cloud","robustbase","cloud","Cloud point of a Liquid",19,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/cloud.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/cloud.html","cloud R Documentation   Cloud point of a Liquid   Description  
This data set contains the measurements concerning the cloud point of a Liquid, from Draper and Smith (1969). The cloud point is a measure of the degree of crystallization in a stock.    Usage   data(cloud, package=""robustbase"")   Format  
A data frame with 19 observations on the following 2 variables.    Percentage
Percentage of I-8   CloudPoint
Cloud point     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.96, table 10.    Examples    data(cloud) summary(lm.cloud <- lm(CloudPoint ~., data=cloud))"
"robustbase-coleman","robustbase","coleman","Coleman Data Set",20,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/coleman.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/coleman.html","coleman R Documentation   Coleman Data Set   Description  
Contains information on 20 Schools from the Mid-Atlantic and New England States, drawn from a population studied by Coleman et al. (1966). Mosteller and Tukey (1977) analyze this sample consisting of measurements on six different variables, one of which will be treated as a responce.    Usage   data(coleman, package=""robustbase"")   Format  
A data frame with 20 observations on the following 6 variables.    salaryP
staff salaries per pupil   fatherWc
percent of white-collar fathers   sstatus
socioeconomic status composite deviation: means for family size, family intactness, father's education, mother's education, and home items   teacherSc
mean teacher's verbal test score   motherLev
mean mother's educational level, one unit is equal to two school years   Y
verbal mean test score (y, all sixth graders)     Author(s)  
Valentin Todorov   Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection Wiley, p.79, table 2.    Examples    data(coleman) pairs(coleman) summary( lm.coleman <- lm(Y ~ . , data = coleman)) summary(lts.coleman <- ltsReg(Y ~ . , data = coleman)) coleman.x <- data.matrix(coleman[, 1:6]) (Cc <- covMcd(coleman.x))"
"robustbase-condroz","robustbase","condroz","Condroz Data",428,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/condroz.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/condroz.html","condroz R Documentation   Condroz Data   Description  
Dataset with pH-value and Calcium content in soil samples, collected in different communities of the Condroz region in Belgium. The data pertain to a subset of 428 samples with a pH-value between 7.0 and 7.5.    Usage   data(condroz, package=""robustbase"")   Format  
A data frame with 428 observations on the following 2 variables.    Ca
Calcium content of the soil sample   pH
pH value of the soil sample     Details  
For more information on the dataset, cf. Goegebeur et al. (2005).    Source  
Hubert and Vandervieren (2006), p. 10. This dataset is also studied in Vandewalle et al. (2004).    References  
See also those for adjbox .   
Goegebeur, Y., Planchon, V., Beirlant, J., Oger, R. (2005). Quality Assesment of Pedochemical Data Using Extreme Value Methodology, Journal of Applied Science, 5, p. 1092-1102.   
Vandewalle, B., Beirlant, J., Hubert, M. (2004). A robust estimator of the tail index based on an exponential regression model, in Hubert, M., Pison G., Struyf, A. and S. Van Aelst, ed., Theory and Applications of Recent Robust Methods, Birkhäuser, Basel, p. 367-376.    Examples    adjbox(condroz$Ca)"
"robustbase-CrohnD","robustbase","CrohnD","Crohn's Disease Adverse Events Data",117,9,2,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/CrohnD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/CrohnD.html","CrohnD R Documentation   Crohn's Disease Adverse Events Data   Description  
Data set issued from a study of the adverse events of a drug on 117 patients affected by Crohn's disease (a chronic inflammatory disease of the intestines).    Usage   data(CrohnD, package=""robustbase"")   Format  
A data frame with 117 observations on the following 9 variables.    ID
the numeric patient IDs   nrAdvE
the number of adverse events   BMI
Body MASS Index, i.e., weight[kg] / (height[m])^2 .   height
in cm   country
a factor with levels 0 and 1   sex
the person's gender, a binary factor with levels  M F   age
in years, a numeric vector   weight
in kilograms, a numeric vector   treat
how CD was treated: a factor with levels  0 , 1 and 2 , meaning placebo, drug 1 and drug 2.     Source  
form the authors of the reference, with permission by the original data collecting agency.    References  
Serigne N. Lô and Elvezio Ronchetti (2006). Robust Second Order Accurate Inference for Generalized Linear Models. Technical report, University of Geneva, Switzerland.    Examples    data(CrohnD) str(CrohnD) with(CrohnD, ftable(table(sex,country, treat)))"
"robustbase-cushny","robustbase","cushny","Cushny and Peebles Prolongation of Sleep Data",10,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/cushny.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/cushny.html","cushny R Documentation   Cushny and Peebles Prolongation of Sleep Data   Description  
The original data set was bivariate and recorded for ten subjects the prolongation of sleep caused by two different drugs. These data were used by Student as the first illustration of the paired t-test which only needs the differences of the two measurements. These differences are the values of cushny .    Usage   data(cushny, package=""robustbase"")   Format  
numeric vector, sorted increasingly:
 0 0.8 1 1.2 1.3 1.3 1.4 1.8 2.4 4.6    Source  
Cushny, A.R. and Peebles, A.R. (1905) The action of optical isomers. II. Hyoscines.  J. Physiol. 32 , 501–510.   
These data were used by Student(1908) as the first illustration of the paired t-test, see also sleep ; then cited by Fisher (1925) and thereforth copied in numerous books as an example of a normally distributed sample, see, e.g., Anderson (1958).    References  
Student (1908) The probable error of a mean.  Biometrika 6 , 1–25.   
Fisher, R.A. (1925)  Statistical Methods for Research Workers ; Oliver & Boyd, Edinburgh.   
Anderson, T.W. (1958)  An Introduction to Multivariate Statistical Analysis ; Wiley, N.Y.   
Hampel, F., Ronchetti, E., Rousseeuw, P. and Stahel, W. (1986)  Robust Statistics: The Approach Based on Influence Functions ; Wiley, N.Y.    Examples    data(cushny) plot(cushny, rep(0, 10), pch = 3, cex = 3, ylab = """", yaxt = ""n"") plot(jitter(cushny), rep(0, 10), pch = 3, cex = 2, main = ""'cushny' data (n= 10)"", ylab = """", yaxt = ""n"") abline(h=0, col=""gray"", lty=3) myPt <- function(m, lwd = 2, ..., e = 1.5*par(""cxy"")[2]) segments(m, +e, m, -e, lwd = lwd, ...) myPt( mean(cushny), col = ""pink3"") myPt(median(cushny), col = ""light blue"") legend(""topright"", c(""mean"", ""median""), lwd = 2, col = c(""pink3"", ""light blue""), inset = .01) ## The 'sleep' data from the standard 'datasets' package: d.sleep <- local({ gr <- with(datasets::sleep, split(extra, group)) gr[[2]] - gr[[1]] }) stopifnot(all.equal(cushny, sort(d.sleep), tolerance=1e-15))"
"robustbase-delivery","robustbase","delivery","Delivery Time Data",25,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/delivery.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/delivery.html","delivery R Documentation   Delivery Time Data   Description  
Delivery Time Data, from Montgomery and Peck (1982). The aim is to explain the time required to service a vending machine (Y) by means of the number of products stocked (X1) and the distance walked by the route driver (X2).    Usage   data(delivery, package=""robustbase"")   Format  
A data frame with 25 observations on the following 3 variables.    n.prod
Number of Products   distance
Distance   delTime
Delivery time     Source  
Montgomery and Peck (1982, p.116)    References  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, page 155, table 23.    Examples    data(delivery) summary(lm.deli <- lm(delTime ~ ., data = delivery)) delivery.x <- as.matrix(delivery[, 1:2]) c_deli <- covMcd(delivery.x) c_deli"
"robustbase-education","robustbase","education","Education Expenditure Data",50,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/education.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/education.html","education R Documentation   Education Expenditure Data   Description  
Education Expenditure Data, from Chatterjee and Price (1977, p.108). This data set, representing the education expenditure variables in the 50 US states, providing an interesting example of heteroscedacity.    Usage   data(education, package=""robustbase"")   Format  
A data frame with 50 observations on the following 6 variables.    State
State   Region
Region (1=Northeastern, 2=North central, 3=Southern, 4=Western)   X1
Number of residents per thousand residing in urban areas in 1970   X2
Per capita personal income in 1973   X3
Number of residents per thousand under 18 years of age in 1974   Y
Per capita expenditure on public education in a state, projected for 1975     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.110, table 16.    Examples    data(education) education.x <- data.matrix(education[, 3:5]) summary(lm.education <- lm(Y ~ Region + X1+X2+X3, data=education)) ## See example(lmrob.M.S) # for how robust regression is used"
"robustbase-epilepsy","robustbase","epilepsy","Epilepsy Attacks Data Set",59,11,1,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/epilepsy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/epilepsy.html","epilepsy R Documentation   Epilepsy Attacks Data Set   Description  
Data from a clinical trial of 59 patients with epilepsy (Breslow, 1996) in order to illustrate diagnostic techniques in Poisson regression.    Usage   data(epilepsy, package=""robustbase"")   Format  
A data frame with 59 observations on the following 11 variables.    ID
Patient identification number   Y1
Number of epilepsy attacks patients have during the first follow-up period   Y2
Number of epilepsy attacks patients have during the second follow-up period   Y3
Number of epilepsy attacks patients have during the third follow-up period   Y4
Number of epilepsy attacks patients have during the forth follow-up period   Base
Number of epileptic attacks recorded during 8 week period prior to randomization   Age
Age of the patients   Trt
a factor with levels placebo   progabide indicating whether the anti-epilepsy drug Progabide has been applied or not   Ysum
Total number of epilepsy attacks patients have during the four follow-up periods   Age10
Age of the patients devided by 10   Base4
Variable Base devided by 4     Details  
Thall and Vail reported data from a clinical trial of 59 patients with epilepsy, 31 of whom were randomized to receive the anti-epilepsy drug Progabide and 28 of whom received a placebo. Baseline data consisted of the patient's age and the number of epileptic seizures recorded during 8 week period prior to randomization. The response consisted of counts of seizures occuring during the four consecutive follow-up periods of two weeks each.    Source  
Thall, P.F. and Vail S.C. (1990) Some covariance models for longitudinal count data with overdispersion.  Biometrics 46 , 657–671.    References  
Diggle, P.J., Liang, K.Y., and Zeger, S.L. (1994)  Analysis of Longitudinal Data ; Clarendon Press.   
Breslow N. E. (1996) Generalized linear models: Checking assumptions and strengthening conclusions.  Statistica Applicata 8 , 23–41.    Examples    data(epilepsy) str(epilepsy) pairs(epilepsy[,c(""Ysum"",""Base4"",""Trt"",""Age10"")]) Efit1 <- glm(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy) summary(Efit1) ## Robust Fit : Efit2 <- glmrob(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy, method = ""Mqle"", tcc=1.2, maxit=100) summary(Efit2)"
"robustbase-exAM","robustbase","exAM","Example Data of Antille and May - for Simple Regression",12,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/exAM.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/exAM.html","exAM R Documentation   Example Data of Antille and May - for Simple Regression   Description  
This is an artificial data set, cleverly construced and used by Antille and May to demonstrate ‘problems’ with LMS and LTS.    Usage   data(exAM, package=""robustbase"")   Format  
A data frame with 12 observations on 2 variables, x and y .    Details  
Because the points are not in general position, both LMS and LTS typically fail ; however, e.g., rlm(*, method=""MM"") “works”.    Source  
Antille, G. and El May, H. (1992) The use of slices in the LMS and the method of density slices: Foundation and comparison.
 In Yadolah Dodge and Joe Whittaker, editors, COMPSTAT: Proc. 10th Symp. Computat. Statist., Neuchatel , 1 , 441–445; Physica-Verlag.    Examples    data(exAM) plot(exAM) summary(ls <- lm(y ~ x, data=exAM)) abline(ls)"
"robustbase-foodstamp","robustbase","foodstamp","Food Stamp Program Participation",150,4,3,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/foodstamp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/foodstamp.html","foodstamp R Documentation   Food Stamp Program Participation   Description  
This data consists of 150 randomly selected persons from a survey with information on over 2000 elderly US citizens, where the response, indicates participation in the U.S. Food Stamp Program.    Usage   data(foodstamp, package=""robustbase"")   Format  
A data frame with 150 observations on the following 4 variables.    participation
participation in U.S. Food Stamp Program; yes = 1, no = 0   tenancy
tenancy, indicating home ownership; yes = 1, no = 0   suppl.income
supplemental income, indicating whether some form of supplemental security income is received; yes = 1, no = 0   income
monthly income (in US dollars)     Source  
Data description and first analysis: Stefanski et al.(1986) who indicate Rizek(1978) as original source of the larger study.   
Electronic version from CRAN package catdata .    References  
Rizek, R. L. (1978) The 1977-78 Nationwide Food Consumption Survey.  Family Econ. Rev. , Fall, 3–7.   
Stefanski, L. A., Carroll, R. J. and Ruppert, D. (1986) Optimally bounded score functions for generalized linear models with applications to logistic regression.  Biometrika 73 , 413–424.   
Künsch, H. R., Stefanski, L. A., Carroll, R. J. (1989) Conditionally unbiased bounded-influence estimation in general regression models, with applications to generalized linear models.  J. American Statistical Association 84 , 460–466.    Examples    data(foodstamp) (T123 <- xtabs(~ participation+ tenancy+ suppl.income, data=foodstamp)) summary(T123) ## ==> the binary var's are clearly not independent foodSt <- within(foodstamp, { logInc <- log(1 + income) rm(income) }) m1 <- glm(participation ~ ., family=binomial, data=foodSt) summary(m1) rm1 <- glmrob(participation ~ ., family=binomial, data=foodSt) summary(rm1) ## Now use robust weights.on.x : rm2 <- glmrob(participation ~ ., family=binomial, data=foodSt, weights.on.x = ""robCov"") summary(rm2)## aha, now the weights are different: which( weights(rm2, type=""robust"") < 0.5)"
"robustbase-hbk","robustbase","hbk","Hawkins, Bradu, Kass's Artificial Data",75,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/hbk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/hbk.html","hbk R Documentation   Hawkins, Bradu, Kass's Artificial Data   Description  
Artificial Data Set generated by Hawkins, Bradu, and Kass (1984). The data set consists of 75 observations in four dimensions (one response and three explanatory variables). It provides a good example of the masking effect. The first 14 observations are outliers, created in two groups: 1–10 and 11–14. Only observations 12, 13 and 14 appear as outliers when using classical methods, but can be easily unmasked using robust distances computed by, e.g., MCD - covMcd().    Usage   data(hbk, package=""robustbase"")   Format  
A data frame with 75 observations on 4 variables, where the last variable is the dependent one.    X1
x[,1]   X2
x[,2]   X3
x[,3]   Y
y     Note  
This data set is also available in package wle as  artificial .    Source  
Hawkins, D.M., Bradu, D., and Kass, G.V. (1984) Location of several outliers in multiple regression data using elemental sets.  Technometrics 26 , 197–208.   
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.94.    Examples    data(hbk) plot(hbk) summary(lm.hbk <- lm(Y ~ ., data = hbk)) hbk.x <- data.matrix(hbk[, 1:3]) (cHBK <- covMcd(hbk.x))"
"robustbase-heart","robustbase","heart","Heart Catherization Data",12,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/heart.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/heart.html","heart R Documentation   Heart Catherization Data   Description  
This data set was analyzed by Weisberg (1980) and Chambers et al. (1983). A catheter is passed into a major vein or artery at the femoral region and moved into the heart. The proper length of the introduced catheter has to be guessed by the physician. The aim of the data set is to describe the relation between the catheter length and the patient's height (X1) and weight (X2).   
This data sets is used to demonstrate the effects caused by collinearity. The correlation between height and weight is so high that either variable almost completely determines the other.    Usage    data(heart)    Format  
A data frame with 12 observations on the following 3 variables.    height
Patient's height in inches   weight
Patient's weights in pounds   clength
Y: Catheter Length (in centimeters)     Note  
There are other heart datasets in other R packages, notably survival , hence considering using  package = ""robustbase"" , see examples.    Source  
Weisberg (1980)   
Chambers et al. (1983)   
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.103, table 13.    Examples    data(heart, package=""robustbase"") heart.x <- data.matrix(heart[, 1:2]) # the X-variables plot(heart.x) covMcd(heart.x) summary( lm.heart <- lm(clength ~ . , data = heart)) summary(lts.heart <- ltsReg(clength ~ . , data = heart))"
"robustbase-kootenay","robustbase","kootenay","Waterflow Measurements of Kootenay River in Libby and Newgate",13,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/kootenay.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/kootenay.html","kootenay R Documentation   Waterflow Measurements of Kootenay River in Libby and Newgate   Description  
The original data set is the waterflow in January of the Kootenay river, measured at two locations, namely, Libby (Montana) and Newgate (British Columbia) for 13 consecutive years, 1931–1943.   
The data set is of mostly interest because it has been used as example in innumerous didactical situations about robust regression. To this end, one number (in observation 4) has been modified from the original data from originally 44.9 to 15.7 (here).    Usage   data(kootenay, package=""robustbase"")   Format  
A data frame with 13 observations on the following 2 variables.    Libby
a numeric vector   Newgate
a numeric vector     Details  
The original (unmodified) version of the data is easily obtainable as kootenay0 from the examples; other modified versions of the data sets are also used in different places, see the examples below.    Source  
Original Data, p.58f of Ezekiel and Fox (1959),  Methods of Correlation and Regression Analysis . Wiley, N.Y.    References  
Hampel, F., Ronchetti, E., Rousseeuw, P. and Stahel, W. (1986)  Robust Statistics: The Approach Based on Influence Functions ; Wiley, N.Y.   
Rousseeuw, P. J. and Leroy, A. M. (1987)  Robust Regression & Outlier Detection , Wiley, N. Y.    Examples    data(kootenay) plot(kootenay, main = ""'kootenay' data"") points(kootenay[4,], col = 2, cex =2, pch = 3) abline(lm (Newgate ~ Libby, data = kootenay), col = ""pink"") abline(lmrob(Newgate ~ Libby, data = kootenay), col = ""blue"") ## The original version of Ezekiel & Fox: kootenay0 <- kootenay kootenay0[4, ""Newgate""] <- 44.9 plot(kootenay0, main = ""'kootenay0': the original data"") abline(lm (Newgate ~ Libby, data = kootenay0), col = ""pink"") abline(lmrob(Newgate ~ Libby, data = kootenay0), col = ""blue"") ## The version with ""milder"" outlier -- Hampel et al., p.310 kootenay2 <- kootenay0 kootenay2[4, ""Libby""] <- 20.0 # instead of 77.6 plot(kootenay2, main = ""The 'kootenay2' data"", xlim = range(kootenay[,""Libby""])) points(kootenay2[4,], col = 2, cex =2, pch = 3) abline(lm (Newgate ~ Libby, data = kootenay2), col = ""pink"") abline(lmrob(Newgate ~ Libby, data = kootenay2), col = ""blue"")"
"robustbase-lactic","robustbase","lactic","Lactic Acid Concentration Measurement Data",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/lactic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/lactic.html","lactic R Documentation   Lactic Acid Concentration Measurement Data   Description  
Data on the Calibration of an Instrument that Measures Lactic Acid Concentration in Blood, from Afifi and Azen (1979) - comparing the true concentration X with the measured value Y.    Usage   data(lactic, package=""robustbase"")   Format  
A data frame with 20 observations on the following 2 variables.    X
True Concentration   Y
Instrument     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.62, table 10.    Examples    data(lactic) summary(lm.lactic <- lm(Y ~., data=lactic))"
"robustbase-los","robustbase","los","Length of Stay Data",201,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/los.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/los.html","los R Documentation   Length of Stay Data   Description  
Length of stay for 201 patients that stayed at the University Hospital of Lausanne during the year 2000.    Usage   data(los, package=""robustbase"")   Format  
Vector of integer values giving the length of stay (days):   
int [1:201] 16 13 17 4 15 24 59 18 33 8 ...    Details  
These data may be used to estimate and predict the total resource consumption of this group of patients.   
Cf. Ruffieux, Paccaud and Marazzi (2000).    Source  
The data were kindly provided by A. Marazzi.   
Cf. Hubert, M. and Vandervieren, E. (2006), p. 13–15.    References  
Ruffieux, C., Paccaud, F. and A. Marazzi (2000) Comparing rules for truncating hospital length of stay;  Casemix Quarterly 2 , n. 1.   
See also those for adjbox .    Examples    summary(los) # quite skewed, with median(.) = 8 plot(table(los)) boxplot(los, horizontal=TRUE, add=TRUE, col = ""red"", axes=FALSE) ##-> ""outliers"" instead of ""just skewed"" hist(log(los)) boxplot(log(los), add=TRUE, col=2, border=2, horizontal = TRUE, at = -1) ## Hubert and Vandervieren (2006), p. 15, Fig. 11. adjbox(los, col = ""gray"", staplecol=""red"", outcol = ""red"", main = ""(Skewness-)Adjusted and original boxplot for 'los' data"") boxplot(los, add = TRUE, staplewex= 0.2, outcex= 0.5, outpch= 4, staplecol = ""blue"", outcol = ""blue"", staplelwd=2) legend(""topright"", c(""adjbox(los)"", ""boxplot(los)""), col=c(""red"",""blue""), lwd = 1:2, bty=""n"")"
"robustbase-milk","robustbase","milk","Daudin's Milk Composition Data",86,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/milk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/milk.html","milk R Documentation   Daudin's Milk Composition Data   Description  
Daudin et al.(1988) give 8 readings on the composition of 86 containers of milk. They speak about 85 observations, but this can be explained with the fact that observations 63 and 64 are identical (as noted by Rocke (1996)).   
The data set was used for analysing the stability of principal component analysis by the bootstrap method. In the same context, but using high breakdown point robust PCA, these data were analysed by Todorov et al. (1994). Atkinson (1994) used these data for ilustration of the forward search algorithm for identifying of multiple outliers.    Usage   data(milk, package=""robustbase"")   Format  
A data frame with 86 observations on the following 8 variables, all but the first measure units in grams / liter .    X1
density   X2
fat content   X3
protein content   X4
casein content   X5
cheese dry substance measured in the factory   X6
cheese dry substance measured in the laboratory   X7
milk dry substance   X8
cheese product     Source  
Daudin, J.J. Duby, C. and Trecourt, P. (1988) Stability of Principal Component Analysis Studied by the Bootstrap Method;  Statistics 19 , 241–258.    References  
Todorov, V., Neyko, N., Neytchev, P. (1994) Stability of High Breakdown Point Robust PCA, in Short Communications, COMPSTAT'94 ; Physica Verlag, Heidelberg.   
Atkinson, A.C. (1994) Fast Very Robust Methods for the Detection of Multiple Outliers.  J. Amer. Statist. Assoc. 89 1329–1339.   
Rocke, D. M. and Woodruff, D. L. (1996) Identification of Outliers in Multivariate Data;  J. Amer. Statist. Assoc. 91 (435), 1047–1061.    Examples    data(milk) (c.milk <- covMcd(milk)) summarizeRobWeights(c.milk $ mcd.wt)# 19..20 outliers umilk <- unique(milk) # dropping obs.64 (== obs.63) summary(cumilk <- covMcd(umilk, nsamp = ""deterministic"")) # 20 outliers"
"robustbase-NOxEmissions","robustbase","NOxEmissions","NOx Air Pollution Data",8088,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/NOxEmissions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/NOxEmissions.html","NOxEmissions R Documentation   NOx Air Pollution Data   Description  
A typical medium sized environmental data set with hourly measurements of NOx pollution content in the ambient air.    Usage   data(NOxEmissions, package=""robustbase"")   Format  
A data frame with 8088 observations on the following 4 variables.    julday
day number, a factor with levels 373  ... 730 , typically with 24 hourly measurements.   LNOx
\log of hourly mean of NOx concentration in ambient air [ppb] next to a highly frequented motorway.   LNOxEm
\log of hourly sum of NOx emission of cars on this motorway in arbitrary units.   sqrtWS
Square root of wind speed [m/s].     Details  
The original data set had more observations, but with missing values. Here, all cases with missing values were omitted ( na.omit(.) ), and then only those were retained that belonged to days with at least 20 (fully) observed hourly measurements.    Source  
René Locher (at ZHAW, Switzerland).    See Also  
another NOx dataset, ambientNOxCH .    Examples    data(NOxEmissions) plot(LNOx ~ LNOxEm, data = NOxEmissions, cex = 0.25, col = ""gray30"") ## Not run: ## these take too much time -- ## p = 340 ==> already Least Squares is not fast (lmNOx <- lm(LNOx ~ . ,data = NOxEmissions)) plot(lmNOx) #-> indication of 1 outlier M.NOx <- MASS::rlm(LNOx ~ . , data = NOxEmissions) ## M-estimation works ## whereas MM-estimation fails: try(MM.NOx <- MASS::rlm(LNOx ~ . , data = NOxEmissions, method = ""MM"")) ## namely because S-estimation fails: try(lts.NOx <- ltsReg(LNOx ~ . , data = NOxEmissions)) try(lmR.NOx <- lmrob (LNOx ~ . , data = NOxEmissions)) ## End(Not run)"
"robustbase-pension","robustbase","pension","Pension Funds Data",18,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/pension.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/pension.html","pension R Documentation   Pension Funds Data   Description  
The total 1981 premium income of pension funds of Dutch firms, for 18 Professional Branches, from de Wit (1982).    Usage   data(pension, package=""robustbase"")   Format  
A data frame with 18 observations on the following 2 variables.    Income
Premium Income (in millions of guilders)   Reserves
Premium Reserves (in millions of guilders)     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.76, table 13.    Examples    data(pension) plot(pension) summary(lm.p <- lm(Reserves ~., data=pension)) summary(lmR.p <- lmrob(Reserves ~., data=pension)) summary(lts.p <- ltsReg(Reserves ~., data=pension)) abline( lm.p) abline(lmR.p, col=2) abline(lts.p, col=2, lty=2) ## MM: ""the"" solution is much simpler: plot(pension, log = ""xy"") lm.lp <- lm(log(Reserves) ~ log(Income), data=pension) lmR.lp <- lmrob(log(Reserves) ~ log(Income), data=pension) plot(log(Reserves) ~ log(Income), data=pension) ## no difference between LS and robust: abline( lm.lp) abline(lmR.lp, col=2)"
"robustbase-phosphor","robustbase","phosphor","Phosphorus Content Data",18,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/phosphor.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/phosphor.html","phosphor R Documentation   Phosphorus Content Data   Description  
This dataset investigates the effect from inorganic and organic Phosphorus in the soil upon the phosphorus content of the corn grown in this soil, from Prescott (1975).    Usage   data(phosphor, package=""robustbase"")   Format  
A data frame with 18 observations on the following 3 variables.    inorg
Inorganic soil Phosphorus   organic
Organic soil Phosphorus   plant
Plant Phosphorus content     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection. Wiley, p.156, table 24.    Examples    data(phosphor) plot(phosphor) summary(lm.phosphor <- lm(plant ~ ., data = phosphor)) summary(lts.phosphor <- ltsReg(plant ~ ., data = phosphor)) phosphor.x <- data.matrix(phosphor[, 1:2]) cPh <- covMcd(phosphor.x) plot(cPh, ""dd"")"
"robustbase-pilot","robustbase","pilot","Pilot-Plant Data",20,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/pilot.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/pilot.html","pilot R Documentation   Pilot-Plant Data   Description  
Pilot-Plant data from Daniel and Wood (1971). The response variable corresponds to the acid content determined by titration and the explanatory variable is the organic acid content determined by extraction and weighing. This data set was analyzed also by Yale and Forsythe (1976).    Usage   data(pilot, package=""robustbase"")   Format  
A data frame with 20 observations on the following 2 variables.    X
Organic acid content - extraction   Y
Acid content - titration     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, page 21, table 1.    Examples    data(pilot) summary(lm.pilot <- lm(Y ~.,data=pilot))"
"robustbase-possumDiv","robustbase","possumDiv","Possum Diversity Data",151,9,1,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/possumDiv.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/possumDiv.html","possumDiv R Documentation   Possum Diversity Data   Description  
Possum diversity data: As issued from a study of the diversity of possum (arboreal marsupials) in the Montane ash forest (Australia), this dataset was collected in view of the management of hardwood forest to take conservation and recreation values, as well as wood production, into account.   
The study is fully described in the two references. The number of different species of arboreal marsupials (possum) was observed on 151 different 3ha sites with uniform vegetation. For each site the nine variable measures (see below) were recorded. The problem is to model the relationship between diversity and these other variables.    Usage   data(possumDiv, package=""robustbase"")   Format  
Two different representations of the same data are available:   
possumDiv is a data frame of 151 observations of 9 variables, where the last two are factors, eucalyptus with 3 levels and aspect with 4 levels.   
possum.mat is a numeric (integer) matrix of 151 rows (observations) and 14 columns (variables) where the last seven ones are 0-1 dummy variables, three ( E.* ) are coding for the kind of  eucalyptus and the last four are 0-1 coding for the  aspect factor.   
The variables have the following meaning:    Diversity
main variable of interest is the number of different species of arboreal marsupial (possum) observed, with values in 0:5.   Shrubs
the number of shrubs.   Stumps
the number of cut stumps from past logging operations.   Stags
the number of stags (hollow-bearing trees).   Bark
bark index (integer) vector reflecting the quantity of decorticating bark.   Habitat
an integer score indicating the suitability of nesting and foraging habitat for Leadbeater's possum.   BAcacia
a numeric vector giving the basal area of acacia species.    

    eucalyptus
a 3-level factor  specifying the species of eucalypt with the greatest stand basal area. This has the same information as the following three variables   E.regnans
0-1 indicator for Eucalyptus regnans   E.delegatensis
0-1 indicator for Eucalyptus deleg.   E.nitens
0-1 indicator for Eucalyptus nitens    

    aspect
a 4-level factor specifying the aspect of the site. It is the same information as the following four variables.   NW-NE
0-1 indicator   NW-SE
0-1 indicator   SE-SW
0-1 indicator   SW-NW
0-1 indicator     Source  
Eva Cantoni (2004) Analysis of Robust Quasi-deviances for Generalized Linear Models.  Journal of Statistical Software 10 , 04,  https://www.jstatsoft.org/article/view/v010i04     References  
Lindenmayer, D. B., Cunningham, R. B., Tanton, M. T., Nix, H. A. and Smith, A. P. (1991) The conservation of arboreal marsupials in the montane ash forests of the central highlands of victoria, south-east australia: III. The habitat requirements of leadbeater's possum gymnobelideus leadbeateri and models of the diversity and abundance of arboreal marsupials.  Biological Conservation 56 , 295–315.   
Lindenmayer, D. B., Cunningham, R. B., Tanton, M. T., Smith, A. P. and Nix, H. A. (1990) The conservation of arboreal marsupials in the montane ash forests of the victoria, south-east australia, I. Factors influencing the occupancy of trees with hollows, Biological Conservation 54 , 111–131.   
See also the references in glmrob .    Examples    data(possumDiv) head(possum.mat) str(possumDiv) ## summarize all variables as multilevel factors: summary(as.data.frame(lapply(possumDiv, function(v) if(is.integer(v)) factor(v) else v))) ## Following Cantoni & Ronchetti (2001), JASA, p.1026 f.:% cf. ../tests/poisson-ex.R pdFit <- glmrob(Diversity ~ . , data = possumDiv, family=poisson, tcc = 1.6, weights.on.x = ""hat"", acc = 1e-15) summary(pdFit) summary(pdF2 <- update(pdFit, ~ . -Shrubs)) summary(pdF3 <- update(pdF2, ~ . -eucalyptus)) summary(pdF4 <- update(pdF3, ~ . -Stumps)) summary(pdF5 <- update(pdF4, ~ . -BAcacia)) summary(pdF6 <- update(pdF5, ~ . -aspect))# too much .. anova(pdFit, pdF3, pdF4, pdF5, pdF6, test = ""QD"") # indeed, ## indeed, the last simplification is too much possumD.2 <- within(possumDiv, levels(aspect)[1:3] <- rep(""other"", 3)) ## and use this binary 'aspect' instead of the 4-level one: summary(pdF5.1 <- update(pdF5, data = possumD.2)) if(FALSE) # not ok, as formually not nested. anova(pdF5, pdF5.1) summarizeRobWeights(weights(pdF5.1, type=""rob""), eps = 0.73) ##-> ""outliers"" (1, 59, 110) wrob <- setNames(weights(pdF5.1, type=""rob""), rownames(possumDiv)) head(sort(wrob))"
"robustbase-pulpfiber","robustbase","pulpfiber","Pulp Fiber and Paper Data",62,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/pulpfiber.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/pulpfiber.html","pulpfiber R Documentation   Pulp Fiber and Paper Data   Description  
Measurements of aspects pulp fibers and the paper produced from them. Four properties of each are measured in sixty-two samples.    Usage   data(pulpfiber, package=""robustbase"")   Format  
A data frame with 62 observations on the following 8 variables.    X1
numeric vector of arithmetic fiber length   X2
numeric vector of long fiber fraction   X3
numeric vector of fine fiber fraction   X4
numeric vector of zero span tensile     Y1
numeric vector of breaking length   Y2
numeric vector of elastic modulus   Y3
numeric vector of stress at failure   Y4
numeric vector of burst strength     Details  
Cited from the reference article:  The dataset contains measurements of properties of pulp fibers and the paper made from them. The aim is to investigate relations between pulp fiber properties and the resulting paper properties. The dataset contains n = 62 measurements of the following four pulp fiber characteristics: arithmetic fiber length, long fiber fraction, fine fiber fraction, and zero span tensile. The four paper properties that have been measured are breaking length, elastic modulus, stress at failure, and burst strength.    
The goal is to predict the q = 4 paper properties from the  p = 4 fiber characteristics.    Author(s)  
port to R and this help page: Martin Maechler    Source  
Rousseeuw, P. J., Van Aelst, S., Van Driessen, K., and Agulló, J. (2004) Robust multivariate regression;  Technometrics 46 , 293–305.   
Till 2016 available from http://users.ugent.be/~svaelst/data/pulpfiber.txt     References  
Lee, J. (1992)  Relationships Between Properties of Pulp-Fibre and Paper , unpublished doctoral thesis, U. Toronto, Faculty of Forestry.    Examples    data(pulpfiber) str(pulpfiber) pairs(pulpfiber, gap=.1) ## 2 blocks of 4 .. c1 <- cov(pulpfiber) cR <- covMcd(pulpfiber) ## how different are they: The robust estimate has more clear high correlations: symnum(cov2cor(c1)) symnum(cov2cor(cR$cov))"
"robustbase-radarImage","robustbase","radarImage","Satellite Radar Image Data from near Munich",1573,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/radarImage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/radarImage.html","radarImage R Documentation   Satellite Radar Image Data from near Munich   Description  
The data were supplied by A. Frery. They are a part of a synthetic aperture satellite radar image corresponding to a suburb of Munich. Provided are coordinates and values corresponding to three frequency bands for each of 1573 pixels.    Usage   data(radarImage, package=""robustbase"")   Format  
A data frame with 1573 observations on the following 5 variables.    X.coord
a numeric vector   Y.coord
a numeric vector   Band.1
a numeric vector   Band.2
a numeric vector   Band.3
a numeric vector     Source  
The website accompanying the MMY-book:  https://www.wiley.com/legacy/wileychi/robust_statistics/     Examples    data(radarImage) plot(Y.coord ~ X.coord, data = radarImage) ## The 8 ""clear"" outliers (see also below) ii8 <- c(1548:1549, 1553:1554, 1565:1566, 1570:1571) outF <- 1+(seq_len(nrow(radarImage)) %in% ii8) pairs(radarImage[, 3:5], main = ""radarImage (n = 1573)"", col = outF, pch=outF) ## Finding outliers ----------------------------------------- set.seed(1) system.time(cc.ri <- covMcd(radarImage))# ~ 0.1 sec ## check for covMcd() consistency: iiO <- as.integer( c(262, 450:451, 480:481, 509, 535, 542, 597, 643, 669, 697, 803:804, 832:834, 862:864, 892, 989, 1123, 1145, 1223:1224, 1232:1233, 1249:1250, 1267, 1303, 1347, 1357, 1375, 1411, 1419:1420, 1443, 1453, 1504, 1510:1512, 1518:1521, 1525:1526, 1543:1544, 1546:1555, 1557:1558, 1561:1562, 1564:1566, 1569:1571, 1573)) length(iiO) # 73 -- other seeds sometimes give 72, rarely 71 ""outliers"" isO <- cc.ri$mcd.wt == 0 stopifnot(identical(iiO, which(isO)), identical(ii8, which(cc.ri$mah > 100)), length(intersect(cc.ri$best, iiO)) == 0) cc <- c(adjustcolor(""black"", 0.4), adjustcolor(""tomato"", 0.8)) pairs(radarImage, main = ""radarImage (n = 1573) + Outliers"", gap=0, col = cc[1+isO], pch = c(1,8)[1+isO], cex = 0.8)"
"robustbase-salinity","robustbase","salinity","Salinity Data",28,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/salinity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/salinity.html","salinity R Documentation   Salinity Data   Description  
This is a data set consisting of measurements of water salinity (i.e., its salt concentration) and river discharge taken in North Carolina's Pamlico Sound, recording some bi-weekly averages in March, April, and May from 1972 to 1977. This dataset was listed by Ruppert and Carroll (1980). In Carrol and Ruppert (1985) the physical background of the data is described. They indicated that observations 5 and 16 correspond to periods of very heavy discharge and showed that the discrepant observation 5 was masked by observations 3 and 16, i.e., only after deletion of these observations it was possible to identify the influential observation 5.   
This data set is a prime example of the masking effect .    Usage   data(salinity, package=""robustbase"")   Format  
A data frame with 28 observations on the following 4 variables (in parentheses are the names used in the 1980 reference).    X1 :
Lagged Salinity (‘SALLAG’)   X2 :
Trend (‘TREND’)   X3 :
Discharge (‘H2OFLOW’)   Y :
Salinity (‘SALINITY’)     Note  
The boot package contains another version of this salinity data set, also attributed to Ruppert and Carroll (1980), but with two clear transcription errors, see the examples.    Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.82, table 5.   
Ruppert, D. and Carroll, R.J. (1980) Trimmed least squares estimation in the linear model.  JASA 75 , 828–838; table 3, p.835.   
Carroll, R.J. and Ruppert, D. (1985) Transformations in regression: A robust analysis.  Technometrics 27 , 1–12    Examples    data(salinity) summary(lm.sali <- lm(Y ~ . , data = salinity)) summary(rlm.sali <- MASS::rlm(Y ~ . , data = salinity)) summary(lts.sali <- ltsReg(Y ~ . , data = salinity)) salinity.x <- data.matrix(salinity[, 1:3]) c_sal <- covMcd(salinity.x) plot(c_sal, ""tolEllipsePlot"") ## Connection with boot package's version : if(requireNamespace(""boot"")) { ## 'always' print( head(boot.sal <- boot::salinity ) ) print( head(robb.sal <- salinity [, c(4, 1:3)]) ) # difference: has one digit more ## Otherwise the same ? dimnames(robb.sal) <- dimnames(boot.sal) ## apart from the 4th column, they are ""identical"": stopifnot( all.equal(boot.sal[, -4], robb.sal[, -4], tol = 1e-15) ) ## But the discharge ('X3', 'dis' or 'H2OFLOW') __differs__ in two places: plot(cbind(robustbase = robb.sal[,4], boot = boot.sal[,4])) abline(0,1, lwd=3, col=adjustcolor(""red"", 1/4)) D.sal <- robb.sal[,4] - boot.sal[,4] stem(robb.sal[,4] - boot.sal[,4]) which(abs(D.sal) > 0.01) ## 2 8 ## *two* typos (=> difference ~= 1) in the version of 'boot': obs. 2 & 8 !!! cbind(robb = robb.sal[,4], boot = boot.sal[,4], D.sal) }# boot"
"robustbase-SiegelsEx","robustbase","SiegelsEx","Siegel's Exact Fit Example Data",9,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/SiegelsEx.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/SiegelsEx.html","SiegelsEx R Documentation   Siegel's Exact Fit Example Data   Description  
A small counterexample data set devised by Andrew Siegel. Six (out of nine) data points lie on the line y = 0 such that some robust regression estimators exhibit the “ exact fit ” property.    Usage   data(SiegelsEx, package=""robustbase"")   Format  
A data frame with 9 observations on the following 2 variables.    x
a numeric vector   y
a numeric vector     Source  
Emerson and Hoaglin (1983, p.139)    References  
Peter J. Rousseeuw and Annick M. Leroy (1987)  Robust Regression and Outlier Detection Wiley, p.60–61    Examples    data(SiegelsEx) plot(SiegelsEx, main = ""Siegel's example for 'exact fit'"") abline( lm(y ~ x, data = SiegelsEx)) abline(MASS::lqs(y ~ x, data = SiegelsEx, method = ""lms""), col = 2) legend(""topright"", leg = c(""lm"", ""LMS""), col=1:2, lwd=1, inset = 1/20)"
"robustbase-starsCYG","robustbase","starsCYG","Hertzsprung-Russell Diagram Data of Star Cluster CYG OB1",47,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/starsCYG.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/starsCYG.html","starsCYG R Documentation   Hertzsprung-Russell Diagram Data of Star Cluster CYG OB1   Description  
Data for the Hertzsprung-Russell Diagram of the Star Cluster CYG OB1, which contains 47 stars in the direction of Cygnus, from C.Doom. The first variable is the logarithm of the effective temperature at the surface of the star (Te) and the second one is the logarithm of its light intencity ( L/L_0 ).   
In the Hertzsprung-Russell diagram, which is the scatterplot of these data points, where the log temperature is plotted from left to right, two groups of points are seen:
 the majority which tend to follow a steep band and four stars in the upper corner. In the astronomy the 43 stars are said to lie on the main sequence and the four remaining stars are called “giants” (the points 11, 20, 30, 34).    Usage   data(starsCYG, package=""robustbase"")   Format  
A data frame with 47 observations on the following 2 variables    log.Te
Logarithm of the effective temperature at the surface of the star (Te).   log.light
Logarithm of its light intencity ( L/L_0 )     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, p.27, table 3.    Examples    data(starsCYG) plot(starsCYG) cst <- covMcd(starsCYG) lm.stars <- lm(log.light ~ log.Te, data = starsCYG) summary(lm.stars) plot(lm.stars) lts.stars <- ltsReg(log.light ~ log.Te, data = starsCYG) plot(lts.stars)"
"robustbase-steamUse","robustbase","steamUse","Steam Usage Data (Excerpt)",25,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/steamUse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/steamUse.html","steamUse R Documentation   Steam Usage Data (Excerpt)   Description  
The monthly use of steam ( Steam ) in a factory may be modeled and described as function of the operating days per month ( Operating.Days ) and mean outside temperature per month ( Temperature ).    Usage   data(""steamUse"", package=""robustbase"")   Format  
A data frame with 25 observations on the following 9 variables.    Steam :
regression response Y , the poinds of steam used monthly.   fattyAcid :
pounds of Real Fatty Acid in storage per month.   glycerine :
pounds of crude glycerine made.   wind :
average wind velocity in miles per hour (a numeric vector).   days :
an integer vector with number of days of that month, i.e., in 28..31 .   op.days :
the number of operating days for the given month (integer).   freeze.d :
the number of days below 32 degrees Fahrenheit ( = 0 °C (C=Celsius) =  freezing temperature of water).   temperature :
a numeric vector of average outside temperature in Fahrenheit (F).   startups :
the number of startups (of production in that month).     Details  
Nor further information is given in Draper and Smith, about the place and exacts years of the measurements, though some educated guesses should be possible, see the examples.    Source  
Data from Draper and Smith, 1st ed, 1966; appendix A.   
A version of this has been used in teaching at SfS ETH Zurich, since at least 1996,  https://stat.ethz.ch/Teaching/Datasets/NDK/dsteam.dat    
The package aprean3 contains all data sets from the 3rd edition of Draper and Smith (1998), and this data set with variable names x1 .. x10 ( x9 being wind^2 , hence extraneous).    References  
Draper and Smith (1981) Applied Regression Analysis (2nd ed., p. 615 ff)    Examples    ## Not run: if(require(""aprean3"")) { # show how 'steamUse' is related to 'dsa01a' stm <- dsa01a names(stm) <- c(""Steam"", ""fattyAcid"", ""glycerine"", ""wind"", ""days"", ""op.days"", ""freeze.d"", ""temperature"", ""wind.2"", ""startups"") ## prove that wind.2 is wind^2, ""traditionally"" rounded to 1 digit: stopifnot(all.equal(floor(0.5 + 10*stm[,""wind""]^2)/10, stm[,""wind.2""], tol = 1e-14)) ## hence drop it steamUse <- stm[, names(stm) != ""wind.2""] } ## End(Not run) data(steamUse) str(steamUse) ## Looking at this, cbind(M=rep_len(month.abb, 25), steamUse[,5:8, drop=FALSE]) ## one will conjecture that these were 25 months, Jan--Jan in a row, ## starting in a leap year (perhaps 1960 ?). plot(steamUse) summary(fm1 <- lmrob(Steam ~ temperature + op.days, data=steamUse)) ## diagnoses 2 outliers: month of July, maybe company-wide summer vacations ## KS2014 alone seems not robust enough: summary(fm.14 <- lmrob(Steam ~ temperature + op.days, data=steamUse, setting=""KS2014"")) pairs(Steam ~ temperature+op.days, steamUse)"
"robustbase-telef","robustbase","telef","Number of International Calls from Belgium",24,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/telef.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/telef.html","telef R Documentation   Number of International Calls from Belgium   Description  
Number of international calls from Belgium, taken from the Belgian Statistical Survey, published by the Ministry of Economy.    Usage   data(telef, package=""robustbase"")   Format  
A data frame with 24 observations on the following 2 variables.    Calls
Number of Calls (in tens of millions)   Year
Year (1950 - 1973)     Source  
P. J. Rousseeuw and A. M. Leroy (1987)  Robust Regression and Outlier Detection ; Wiley, page 26, table 2.    Examples    data(telef) summary(lm.telef <- lm(Year~., data=telef))"
"robustbase-toxicity","robustbase","toxicity","Toxicity of Carboxylic Acids Data",38,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/toxicity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/toxicity.html","toxicity R Documentation   Toxicity of Carboxylic Acids Data   Description  
The aim of the experiment was to predict the toxicity of carboxylic acids on the basis of several molecular descriptors.    Usage   data(toxicity, package=""robustbase"")   Format  
A data frame with 38 observations on the following 10 variables which are attributes for carboxylic acids:    toxicity
aquatic toxicity, defined as  log(IGC50^(-1)) ; typically the “response”.   logKow
log Kow , the partition coefficient   pKa
pKa: the dissociation constant   ELUMO
E nergy of the l owest  u noccupied m olecular o rbital   Ecarb
Electrotopological state of the carb oxylic group   Emet
Electrotopological state of the met hyl group   RM
Molar refractivity   IR
Refraction index   Ts
Surface tension   P
Polarizability     Source  
The website accompanying the MMY-book:  https://www.wiley.com/legacy/wileychi/robust_statistics/     References  
Maguna, F.P., Núñez, M.B., Okulik, N.B. and Castro, E.A. (2003) Improved QSAR analysis of the toxicity of aliphatic carboxylic acids;  Russian Journal of General Chemistry 73 , 1792–1798.    Examples    data(toxicity) summary(toxicity) plot(toxicity) plot(toxicity ~ pKa, data = toxicity) ## robustly scale the data (to scale 1) using Qn (scQ.tox <- sapply(toxicity, Qn)) scTox <- scale(toxicity, center = FALSE, scale = scQ.tox) csT <- covOGK(scTox, n.iter = 2, sigmamu = s_Qn, weight.fn = hard.rejection) as.dist(round(cov2cor(csT$cov), 2))"
"robustbase-vaso","robustbase","vaso","Vaso Constriction Skin Data Set",39,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/vaso.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/vaso.html","vaso R Documentation   Vaso Constriction Skin Data Set   Description  
Finney's data on vaso constriction in the skin of the digits.    Usage   data(vaso, package=""robustbase"")   Format  
A data frame with 39 observations on the following 3 variables.    Volume
Inhaled volume of air   Rate
Rate of inhalation   Y
vector of 0 or 1 values.     Details  
The data taken from Finney (1947) were obtained in a carefully controlled study in human physiology where a reflex “vaso constriction” may occur in the skin of the digits after taking a single deep breath. The response y is the occurence (y = 1) or non-occurence (y = 0) of vaso constriction in the skin of the digits of a subject after he or she inhaled a certain volume of air at a certain rate. The responses of three subjects are available. The first contributed 9 responses, the second contributed 8 responses, and the third contributed 22 responses.   
Although the data represent repeated measurements, an analysis that assumes independent observations may be applied, as claimed by Pregibon (1981).    Source  
Finney, D.J. (1947) The estimation from individual records of the relationship between dose and quantal response.  Biometrika 34 , 320–334    References  
Atkinson, A.C. and Riani, M. (2000)  Robust Diagnostic Regression Analysis , First Edition. New York: Springer, Table A.23.   
Fahrmeir, L. and Tutz, G. (2001)  Multivariate Statistical Modelling Based on Generalized Linear Models , Springer, Table 4.2.   
Kuensch, H.R., Stefanski, A. and Carrol, R.J. (1989) Conditionally unbiased bounded influence estimation in general regression models, with applications to generalized linear models,  JASA 84 , 460–466.   
Pregibon, D. (1981) Logistic regression diagnostics,  Annals of Statistics 9 , 705–724.    Examples    data(vaso) str(vaso) pairs(vaso) glmV <- glm(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso) summary(glmV) ## --> example(glmrob) showing classical & robust GLM"
"robustbase-wagnerGrowth","robustbase","wagnerGrowth","Wagner's Hannover Employment Growth Data",63,7,0,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/wagnerGrowth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/wagnerGrowth.html","wagnerGrowth R Documentation    Wagner's Hannover Employment Growth Data    Description  
Wagner (1994) investigates the rate of employment growth ( y ) as function of percentage of people engaged in p roducation  a ctivities ( PA ) and h igher s ervices ( HS ) and of the g rowth of these percentages ( GPA ,  GHS ) during three time periods in 21 geographical regions of the greater Hannover area.    Usage   data(wagnerGrowth, package=""robustbase"")   Format  
A data frame with 21 * 3 = 63 observations (one per Region x Period ) on the following 7 variables.    Region
a factor with 21 levels, denoting the corresponding region in Hannover (conceptually a “block factor”).   PA
numeric: percent of people involved in production activities.   GPA
g rowth of PA .   HS
a numeric vector   GHS
a numeric vector   y
a numeric vector   Period
a factor with levels 1:3 , denoting the time period, 1 = 1979-1982, 2 = 1983-1988, 3 = 1989-1992.     Source  
Hubert, M. and Rousseeuw, P. J. (1997). Robust regression with both continuous and binary regressors,  Journal of Statistical Planning and Inference 57 , 153–163.    References  
Wagner J. (1994). Regionale Beschäftigungsdynamik und höherwertige Produktionsdienste: Ergebnisse für den Grossraum Hannover (1979-1992).  Raumforschung und Raumordnung 52 , 146–150.    Examples    data(wagnerGrowth) ## maybe str(wagnerGrowth) require(lattice) (xyplot(y ~ Period | Region, data = wagnerGrowth, main = ""wagnerGrowth: 21 regions @ Hannover"")) (dotplot(y ~ reorder(Region,y,median), data = wagnerGrowth, main = ""wagnerGrowth"", xlab = ""Region [ordered by median(y | Region) ]""))"
"robustbase-wood","robustbase","wood","Modified Data on Wood Specific Gravity",20,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/robustbase/wood.csv","https://vincentarelbundock.github.io/Rdatasets/doc/robustbase/wood.html","wood R Documentation   Modified Data on Wood Specific Gravity   Description  
The original data are from Draper and Smith (1966) and were used to determine the influence of anatomical factors on wood specific gravity, with five explanatory variables and an intercept. These data were contaminated by replacing a few observations with outliers.    Usage   data(wood, package=""robustbase"")   Format  
A data frame with 20 observations on the following 6 variables.    x1, x2, x3, x4, x5
explanatory “anatomical” wood variables.   y
wood specific gravity, the target variable.     Source  
Draper and Smith (1966, p.227)   
Peter J. Rousseeuw and Annick M. Leroy (1987)  Robust Regression and Outlier Detection Wiley, p.243, table 8.    Examples    data(wood) plot(wood) summary( lm.wood <- lm(y ~ ., data = wood)) summary(rlm.wood <- MASS::rlm(y ~ ., data = wood)) summary(lts.wood <- ltsReg(y ~ ., data = wood)) wood.x <- as.matrix(wood)[,1:5] c_wood <- covMcd(wood.x) c_wood"
"rpart-car.test.frame","rpart","car.test.frame","Automobile Data from 'Consumer Reports' 1990",60,8,0,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/car.test.frame.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/car.test.frame.html","car.test.frame R Documentation   Automobile Data from 'Consumer Reports' 1990   Description  
The car.test.frame data frame has 60 rows and 8 columns, giving data on makes of cars taken from the April, 1990 issue of  Consumer Reports . This is part of a larger dataset, some columns of which are given in cu.summary .    Usage    car.test.frame    Format  
This data frame contains the following columns:    Price  
a numeric vector giving the list price in US dollars of a standard model    Country  
of origin, a factor with levels  France , Germany , Japan ,  Japan/USA , Korea ,  Mexico ,  Sweden and  USA    Reliability  
a numeric vector coded 1 to 5 .    Mileage  
fuel consumption miles per US gallon, as tested.   Type  
a factor with levels  Compact  Large  Medium  Small  Sporty  Van    Weight  
kerb weight in pounds.    Disp.  
the engine capacity (displacement) in litres.    HP  
the net horsepower of the vehicle.      Source  
Consumer Reports , April, 1990, pp. 235–288 quoted in   
John M. Chambers and Trevor J. Hastie eds. (1992)  Statistical Models in S , Wadsworth and Brooks/Cole, Pacific Grove, CA, pp. 46–47.    See Also  
car90 ,  cu.summary     Examples    z.auto <- rpart(Mileage ~ Weight, car.test.frame) summary(z.auto)"
"rpart-car90","rpart","car90","Automobile Data from 'Consumer Reports' 1990",111,34,0,0,9,0,25,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/car90.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/car90.html","car90 R Documentation   Automobile Data from 'Consumer Reports' 1990   Description  
Data on 111 cars, taken from pages 235–255, 281–285 and 287–288 of the April 1990 Consumer Reports Magazine.    Usage   data(car90)   Format  
The data frame contains the following columns    Country
a factor giving the country in which the car was manufactured   Disp
engine displacement in cubic inches   Disp2
engine displacement in liters   Eng.Rev
engine revolutions per mile, or engine speed at 60 mph   Front.Hd
distance between the car's head-liner and the head of a 5 ft. 9 in. front seat passenger, in inches, as measured by CU   Frt.Leg.Room
maximum front leg room, in inches, as measured by CU   Frt.Shld
front shoulder room, in inches, as measured by CU   Gear.Ratio
the overall gear ratio, high gear, for manual transmission   Gear2
the overall gear ratio, high gear, for automatic transmission   HP
net horsepower   HP.revs
the red line—the maximum safe engine speed in rpm   Height
height of car, in inches, as supplied by manufacturer   Length
overall length, in inches, as supplied by manufacturer   Luggage
luggage space   Mileage
a numeric vector of gas mileage in miles/gallon as tested by CU; contains NAs.   Model2
alternate name, if the car was sold under two labels   Price
list price with standard equipment, in dollars   Rear.Hd
distance between the car's head-liner and the head of a 5 ft 9 in. rear seat passenger, in inches, as measured by CU   Rear.Seating
rear fore-and-aft seating room, in inches, as measured by CU   RearShld
rear shoulder room, in inches, as measured by CU   Reliability
an ordered factor with levels Much worse <  worse < average < better < Much better : contains NA s.   Rim
factor giving the rim size   Sratio.m
Number of turns of the steering wheel required for a turn of 30 foot radius, manual steering   Sratio.p
Number of turns of the steering wheel required for a turn of 30 foot radius, power steering   Steering
steering type offered: manual, power, or both   Tank
fuel refill capacity in gallons   Tires
factor giving tire size   Trans1
manual transmission, a factor with levels ,  man.4 , man.5 and man.6   Trans2
automatic transmission, a factor with levels ,  auto.3 , auto.4 , and auto.CVT . No car is missing both the manual and automatic transmission variables, but several had both as options   Turning
the radius of the turning circle in feet   Type
a factor giving the general type of car. The levels are: Small , Sporty , Compact , Medium , Large , Van   Weight
an order statistic giving the relative weights of the cars; 1 is the lightest and 111 is the heaviest   Wheel.base
length of wheelbase, in inches, as supplied by manufacturer   Width
width of car, in inches, as supplied by manufacturer     Source  
This is derived (with permission) from the data set car.all in S-PLUS, but with some further clean up of variable names and definitions.    See Also  
car.test.frame ,  cu.summary for extracts from other versions of the dataset.    Examples    data(car90) plot(car90$Price/1000, car90$Weight, xlab = ""Price (thousands)"", ylab = ""Weight (lbs)"") mlowess <- function(x, y, ...) { keep <- !(is.na(x) | is.na(y)) lowess(x[keep], y[keep], ...) } with(car90, lines(mlowess(Price/1000, Weight, f = 0.5)))"
"rpart-cu.summary","rpart","cu.summary","Automobile Data from 'Consumer Reports' 1990",117,5,0,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/cu.summary.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/cu.summary.html","cu.summary R Documentation   Automobile Data from 'Consumer Reports' 1990   Description  
The cu.summary data frame has 117 rows and 5 columns, giving data on makes of cars taken from the April, 1990 issue of  Consumer Reports .    Usage    cu.summary    Format  
This data frame contains the following columns:    Price  
a numeric vector giving the list price in US dollars of a standard model    Country  
of origin, a factor with levels  Brazil ,  England ,  France ,  Germany ,  Japan ,  Japan/USA ,  Korea ,  Mexico ,  Sweden and  USA     Reliability  
an ordered factor with levels  Much worse < worse < average < better < Much better     Mileage  
fuel consumption miles per US gallon, as tested.    Type  
a factor with levels  Compact   Large   Medium   Small   Sporty   Van       Source  
Consumer Reports , April, 1990, pp. 235–288 quoted in   
John M. Chambers and Trevor J. Hastie eds. (1992)  Statistical Models in S , Wadsworth and Brooks/Cole, Pacific Grove, CA, pp. 46–47.    See Also  
car.test.frame ,  car90     Examples    fit <- rpart(Price ~ Mileage + Type + Country, cu.summary) par(xpd = TRUE) plot(fit, compress = TRUE) text(fit, use.n = TRUE)"
"rpart-kyphosis","rpart","kyphosis","Data on Children who have had Corrective Spinal Surgery",81,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/kyphosis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/kyphosis.html","kyphosis R Documentation   Data on Children who have had Corrective Spinal Surgery   Description  
The kyphosis data frame has 81 rows and 4 columns. representing data on children who have had corrective spinal surgery    Usage    kyphosis    Format  
This data frame contains the following columns:    Kyphosis  
a factor with levels  absent  present  indicating if a kyphosis (a type of deformation) was present after the operation.    Age  
in months    Number  
the number of vertebrae involved   Start  
the number of the first (topmost) vertebra operated on.      Source  
John M. Chambers and Trevor J. Hastie eds. (1992)  Statistical Models in S , Wadsworth and Brooks/Cole, Pacific Grove, CA.    Examples    fit <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis) fit2 <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, parms = list(prior = c(0.65, 0.35), split = ""information"")) fit3 <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis, control = rpart.control(cp = 0.05)) par(mfrow = c(1,2), xpd = TRUE) plot(fit) text(fit, use.n = TRUE) plot(fit2) text(fit2, use.n = TRUE)"
"rpart-solder","rpart","solder","Soldering of Components on Printed-Circuit Boards",900,6,1,0,5,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/solder.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/solder.html","solder.balance R Documentation   Soldering of Components on Printed-Circuit Boards   Description  
The solder.balance data frame has 720 rows and 6 columns, representing a balanced subset of a designed experiment varying 5 factors on the soldering of components on printed-circuit boards.   
The solder data frame is the full version of the data with 900 rows. It is located in both the rpart and the survival packages.    Usage    solder    Format  
This data frame contains the following columns:    Opening  
a factor with levels  L , M and S  indicating the amount of clearance around the mounting pad.    Solder  
a factor with levels  Thick and Thin  giving the thickness of the solder used.    Mask  
a factor with levels  A1.5 , A3 , B3 and B6  indicating the type and thickness of mask used.    PadType  
a factor with levels D4 , D6 , D7 , L4 ,  L6 , L7 , L8 , L9 , W4 and W9  giving the size and geometry of the mounting pad.    Panel  
1:3 indicating the panel on a board being tested.    skips  
a numeric vector giving the number of visible solder skips.      Source  
John M. Chambers and Trevor J. Hastie eds. (1992)  Statistical Models in S , Wadsworth and Brooks/Cole, Pacific Grove, CA.    Examples    fit <- rpart(skips ~ Opening + Solder + Mask + PadType + Panel, data = solder.balance, method = ""anova"") summary(residuals(fit)) plot(predict(fit), residuals(fit))"
"rpart-stagec","rpart","stagec","Stage C Prostate Cancer",146,8,2,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/rpart/stagec.csv","https://vincentarelbundock.github.io/Rdatasets/doc/rpart/stagec.html","stagec R Documentation   Stage C Prostate Cancer   Description  
A set of 146 patients with stage C prostate cancer, from a study exploring the prognostic value of flow cytometry.   Usage   data(stagec)   Format  
A data frame with 146 observations on the following 8 variables.    pgtime
Time to progression or last follow-up (years)   pgstat
1 = progression observed, 0 = censored   age
age in years   eet
early endocrine therapy, 1 = no, 2 = yes   g2
percent of cells in G2 phase, as found by flow cytometry   grade
grade of the tumor, Farrow system   gleason
grade of the tumor, Gleason system   ploidy
the ploidy status of the tumor, from flow cytometry. Values are diploid , tetraploid , and aneuploid     Details  
A tumor is called diploid (normal complement of dividing cells) if the fraction of cells in G2 phase was determined to be 13% or less. Aneuploid cells have a measurable fraction with a chromosome count that is neither 24 nor 48, for these the G2 percent is difficult or impossible to measure.    Examples    require(survival) rpart(Surv(pgtime, pgstat) ~ ., stagec)"
"sandwich-InstInnovation","sandwich","InstInnovation","Innovation and Institutional Ownership",6208,25,4,0,7,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/sandwich/InstInnovation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sandwich/InstInnovation.html","InstInnovation R Documentation   Innovation and Institutional Ownership   Description  
Firm-level panel data on innovation and institutional ownership from 1991 to 1999 over 803 firms. The observations refer to different firms over different years.    Usage   data(""InstInnovation"")   Format  
A data frame containing 6208 observations on 25 variables.    company
factor. Company names.   sales
numeric. Sales (in millions of dollars).   acompetition
numeric. Constant inverse Lerner index.   competition
numeric. Varying inverse Lerner index.   capital
numeric. Net stock of property, plant, and equipment.   cites
integer. Future cite-weighted patents.   precites
numeric. Presample average of cite-weighted patents.   dprecites
factor. Indicates zero precites.   patents
integer. Granted patents.   drandd
factor. Indicates a zero R&D stock.   randd
numeric. R&D stock (in millions of dollars).   employment
numeric. Employment (in 1000s).   sp500
factor. Membership of firms in the S&P500 index.   tobinq
numeric. Tobin's q.   value
numeric. Stock market value.   institutions
numeric. Proportion of stock owned by institutions.   industry
factor. Four-digit industry code.   year
factor. Estimation period.   top1
numeric. Share of the largest institution.   quasiindexed
numeric. Share of ""quasi-indexed"" institutional owners.   nonquasiindexed
numeric. Share of ""non-quasi-indexed"" institutional owners.   transient
numeric. Share of ""transient"" institutional owners.   dedicated
numeric. Share of ""dedicated"" institutional owners.   competition4
numeric. Varying inverse Lerner index in the firm's four-digit industry.   subsample
factor. Subsample for the replication of columns 1–5 from Table 4 in Aghion et al. (2013).     Details  
Aghion et al. (2013) combine several firm level panel datasets (e.g., USPTO, SEC and Compustat) to examine the role of institutional investors in the governance of innovation. Their baseline to model innovation is the Poisson model, but they also consider negative binomial models. Berger et al. (2017) argue that nonlinearities in the innovation process emerge in case that the first innovation is especially hard to obtain in comparison to succeeding innovations. Then, hurdle models offer a useful way that allows for a distinction between these two processes. Berger et al. (2017) show that an extended analysis with negative binomial hurdle models differs materially from the outcomes of the single-equation Poisson approach of Aghion et al. (2013).   
Institutional ownership (institutions) is defined as the proportion of stock owney by institutions. According to Aghion et al. (2013), an institutional owner is defined as an institution that files a Form 13-F with the Securities and Exchange Commission (SEC).   
Future cite-weighted patents (cites) are used as a proxy for innovation. They are calculated using ultimately granted patent, dated by year of application, and weight these by future citations through 2002 (see Aghion et al. (2013)).   
The presample average of cite-weighted patents (precites) is used by Aghion et al. (2013) as a proxy for unobserved heterogeneity, employing the ""presample mean scaling"" method of Blundell et al. (1999).   
The inverse Lerner index in the firm's three-digit industry is used as a time-varying measure for product market competition (competition), where the Lerner is calculated as the median gross margin from the entire Compustat database in the firm's three-digit industry (see Aghion et al. (2013)). A time-invariant measure for competition (acompetition) is constructed by averaging the Lerner over the sample period.   
The classification of institutions into ""quasiindexed"", ""transient"" and ""dedicated"" follows Bushee (1998) and distinguishes between institutional investors based on their type of investing. Quasiindexed institutions are do not trade much and are widely diversified, dedicated institution do not trade much and have more concentrated holdings, and transient institutions often trade and have diversified holdings (see Aghion et al. (2013) and Bushee (1998)).    Source  
Data and online appendix of Aghion et al. (2013).    References  
Aghion P, Van Reenen J, Zingales L (2013). “Innovation and Institutional Ownership.”  The American Economic Review , 103 (1), 277–304. doi: 10.1257/aer.103.1.277    
Berger S, Stocker H, Zeileis A (2017). “Innovation and Institutional Ownership Revisited: An Empirical Investigation with Count Data Models.”  Empirical Economics , 52 (4), 1675–1688. doi: 10.1007/s00181-016-1118-0    
Blundell R, Griffith R, Van Reenen J (1999). “Market Share, Market Value and Innovation in a Panel of British Manufacturing Firms.”  Review of Economic Studies , 66(3), 529–554.   
Bushee B (1998). “The Influence of Institutional Investors on Myopic R&D Investment Behavior.”  Accounting Review , 73 (3), 655–679.    Examples    ## Poisson models from Table I in Aghion et al. (2013) ## load data set data(""InstInnovation"", package = ""sandwich"") ## log-scale variable InstInnovation$lograndd <- log(InstInnovation$randd) InstInnovation$lograndd[InstInnovation$lograndd == -Inf] <- 0 ## regression formulas f1 <- cites ~ institutions + log(capital/employment) + log(sales) + industry + year f2 <- cites ~ institutions + log(capital/employment) + log(sales) + industry + year + lograndd + drandd f3 <- cites ~ institutions + log(capital/employment) + log(sales) + industry + year + lograndd + drandd + dprecites + log(precites) ## Poisson models tab_I_3_pois <- glm(f1, data = InstInnovation, family = poisson) tab_I_4_pois <- glm(f2, data = InstInnovation, family = poisson) tab_I_5_pois <- glm(f3, data = InstInnovation, family = poisson) ## one-way clustered covariances vCL_I_3 <- vcovCL(tab_I_3_pois, cluster = ~ company) vCL_I_4 <- vcovCL(tab_I_4_pois, cluster = ~ company) vCL_I_5 <- vcovCL(tab_I_5_pois, cluster = ~ company) ## replication of columns 3 to 5 from Table I in Aghion et al. (2013) cbind(coef(tab_I_3_pois), sqrt(diag(vCL_I_3)))[2:4, ] cbind(coef(tab_I_4_pois), sqrt(diag(vCL_I_4)))[c(2:4, 148), ] cbind(coef(tab_I_5_pois), sqrt(diag(vCL_I_5)))[c(2:4, 148), ]"
"sandwich-Investment","sandwich","Investment","US Investment Data",20,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/sandwich/Investment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sandwich/Investment.html","Investment R Documentation   US Investment Data   Description  
US data for fitting an investment equation.    Usage   data(Investment)   Format  
An annual time series from 1963 to 1982 with 7 variables.    GNP
nominal gross national product (in billion USD),   Investment
nominal gross private domestic investment (in billion USD),   Price
price index, implicit price deflator for GNP,   Interest
interest rate, average yearly discount rate charged by the New York Federal Reserve Bank,   RealGNP
real GNP (= GNP/Price),   RealInv
real investment (= Investment/Price),   RealInt
approximation to the real interest rate (= Interest - 100 * diff(Price)/Price).     Source  
Table 15.1 in Greene (1993)   References  
Greene W.H. (1993). Econometric Analysis , 2nd edition. Macmillan Publishing Company, New York.   
Executive Office of the President (1984). Economic Report of the President . US Government Printing Office, Washington, DC.    Examples    ## Willam H. Greene, Econometric Analysis, 2nd Ed. ## Chapter 15 ## load data set, p. 411, Table 15.1 data(Investment) ## fit linear model, p. 412, Table 15.2 fm <- lm(RealInv ~ RealGNP + RealInt, data = Investment) summary(fm) ## visualize residuals, p. 412, Figure 15.1 plot(ts(residuals(fm), start = 1964), type = ""b"", pch = 19, ylim = c(-35, 35), ylab = ""Residuals"") sigma <- sqrt(sum(residuals(fm)^2)/fm$df.residual) ## maybe used df = 26 instead of 16 ?? abline(h = c(-2, 0, 2) * sigma, lty = 2) if(require(lmtest)) { ## Newey-West covariances, Example 15.3 coeftest(fm, vcov = NeweyWest(fm, lag = 4)) ## Note, that the following is equivalent: coeftest(fm, vcov = kernHAC(fm, kernel = ""Bartlett"", bw = 5, prewhite = FALSE, adjust = FALSE)) ## Durbin-Watson test, p. 424, Example 15.4 dwtest(fm) ## Breusch-Godfrey test, p. 427, Example 15.6 bgtest(fm, order = 4) } ## visualize fitted series plot(Investment[, ""RealInv""], type = ""b"", pch = 19, ylab = ""Real investment"") lines(ts(fitted(fm), start = 1964), col = 4) ## 3-d visualization of fitted model if(require(scatterplot3d)) { s3d <- scatterplot3d(Investment[,c(5,7,6)], type = ""b"", angle = 65, scale.y = 1, pch = 16) s3d$plane3d(fm, lty.box = ""solid"", col = 4) }"
"sandwich-PetersenCL","sandwich","PetersenCL","Petersen's Simulated Data for Assessing Clustered Standard Errors",5000,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/sandwich/PetersenCL.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sandwich/PetersenCL.html","PetersenCL R Documentation   Petersen's Simulated Data for Assessing Clustered Standard Errors   Description  
Artificial balanced panel data set from Petersen (2009) for illustrating and benchmarking clustered standard errors.    Usage   data(""PetersenCL"")   Format  
A data frame containing 5000 observations on 4 variables.    firm
integer. Firm identifier (500 firms).   year
integer. Time variable (10 years per firm).   x
numeric. Independent regressor variable.   y
numeric. Dependent response variable.     Details  
This simulated data set was created to illustrate and benchmark clustered standard errors. The residual and the regressor variable both contain a firm effect, but no year effect. Thus, standard errors clustered by firm are different from the OLS standard errors and similarly double-clustered standard errors (by firm and year) are different from the standard errors clustered by year.    Source  
https://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm     References  
Petersen MA (2009). “Estimating Standard Errors in Finance Panel Data Sets: Comparing Approaches”,  The Review of Financial Studies , 22 (1), 435–480. doi: 10.1093/rfs/hhn053"
"sandwich-PublicSchools","sandwich","PublicSchools","US Expenditures for Public Schools",51,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/sandwich/PublicSchools.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sandwich/PublicSchools.html","PublicSchools R Documentation   US Expenditures for Public Schools   Description  
Per capita expenditure on public schools and per capita income by state in 1979.    Usage   data(PublicSchools)   Format  
A data frame containing 51 observations of 2 variables.    Expenditure
per capita expenditure on public schools,   Income
per capita income.     Source  
Table 14.1 in Greene (1993)   References  
Cribari-Neto F. (2004). “Asymptotic Inference Under Heteroskedasticity of Unknown Form.”  Computational Statistics \& Data Analysis ,  45 , 215-233.   
Greene W.H. (1993). Econometric Analysis , 2nd edition. Macmillan Publishing Company, New York.   
US Department of Commerce (1979). Statistical Abstract of the United States . US Government Printing Office, Washington, DC.    Examples    ## Willam H. Greene, Econometric Analysis, 2nd Ed. ## Chapter 14 ## load data set, p. 385, Table 14.1 data(PublicSchools) ## omit NA in Wisconsin and scale income ps <- na.omit(PublicSchools) ps$Income <- ps$Income * 0.0001 ## fit quadratic regression, p. 385, Table 14.2 fmq <- lm(Expenditure ~ Income + I(Income^2), data = ps) summary(fmq) ## compare standard and HC0 standard errors ## p. 391, Table 14.3 library(sandwich) coef(fmq) sqrt(diag(vcovHC(fmq, type = ""const""))) sqrt(diag(vcovHC(fmq, type = ""HC0""))) if(require(lmtest)) { ## compare t ratio coeftest(fmq, vcov = vcovHC(fmq, type = ""HC0"")) ## White test, p. 393, Example 14.5 wt <- lm(residuals(fmq)^2 ~ poly(Income, 4), data = ps) wt.stat <- summary(wt)$r.squared * nrow(ps) c(wt.stat, pchisq(wt.stat, df = 3, lower = FALSE)) ## Bresch-Pagan test, p. 395, Example 14.7 bptest(fmq, studentize = FALSE) bptest(fmq) ## Francisco Cribari-Neto, Asymptotic Inference, CSDA 45 ## quasi z-tests, p. 229, Table 8 ## with Alaska coeftest(fmq, df = Inf)[3,4] coeftest(fmq, df = Inf, vcov = vcovHC(fmq, type = ""HC0""))[3,4] coeftest(fmq, df = Inf, vcov = vcovHC(fmq, type = ""HC3""))[3,4] coeftest(fmq, df = Inf, vcov = vcovHC(fmq, type = ""HC4""))[3,4] ## without Alaska (observation 2) fmq1 <- lm(Expenditure ~ Income + I(Income^2), data = ps[-2,]) coeftest(fmq1, df = Inf)[3,4] coeftest(fmq1, df = Inf, vcov = vcovHC(fmq1, type = ""HC0""))[3,4] coeftest(fmq1, df = Inf, vcov = vcovHC(fmq1, type = ""HC3""))[3,4] coeftest(fmq1, df = Inf, vcov = vcovHC(fmq1, type = ""HC4""))[3,4] } ## visualization, p. 230, Figure 1 plot(Expenditure ~ Income, data = ps, xlab = ""per capita income"", ylab = ""per capita spending on public schools"") inc <- seq(0.5, 1.2, by = 0.001) lines(inc, predict(fmq, data.frame(Income = inc)), col = 4) fml <- lm(Expenditure ~ Income, data = ps) abline(fml) text(ps[2,2], ps[2,1], rownames(ps)[2], pos = 2)"
"sem-Bollen","sem","Bollen","Bollen's Data on Industrialization and Political Democracy",75,11,0,0,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/Bollen.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/Bollen.html","Bollen R Documentation    Bollen's Data on Industrialization and Political Democracy    Description  
This data set includes four measures of democracy at two points in time, 1960 and 1965, and three measures of industrialization in 1960, for 75 developing countries.    Usage   Bollen   Format  
A data frame with 75 observations on the following 11 variables.    y1
freedom of the press, 1960   y2
freedom of political opposition, 1960   y3
fairness of elections, 1960   y4
effectivness of elected legislature, 1960   y5
freedom of the press, 1965   y6
freedom of political opposition, 1965   y7
fairness of elections, 1965   y8
effectivness of elected legislature, 1965   x1
GNP per capita, 1960   x2
energy consumption per capita, 1960   x3
percentage of labor force in industry, 1960     Details  
Variables y1 through y4 are intended to be indicators of the latent variable political democracy in 1960 ;  y5 through y8 indicators of political democracy in 1965 ; and  x1 through x3 indicators of industrialization in 1960 .    Source  
personal communication from Ken Bollen.    References  
Bollen, K. A. (1989) Structural Equations With Latent Variables . Wiley."
"sem-CNES","sem","CNES","Variables from the 1997 Canadian National Election Study",1529,4,0,0,4,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/CNES.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/CNES.html","CNES R Documentation   Variables from the 1997 Canadian National Election Study   Description  
These variables are from the mailback questionnaire to the 1997 Canadian National Election Study, and are intended to tap attitude towards “traditional values.”    Usage   CNES   Format  
A data frame with 1529 observations on the following 4 variables.    MBSA2
an ordered factor with levels StronglyDisagree , Disagree , Agree , and StronglyAgree , in response to the statement, “We should be more tolerant of people who choose to live according to their own standards, even if they are very different from our own.”   MBSA7
an ordered factor with levels StronglyDisagree , Disagree , Agree , and StronglyAgree , in response to the statement, “Newer lifestyles are contributing to the breakdown of our society.”   MBSA8
an ordered factor with levels StronglyDisagree , Disagree , Agree , and StronglyAgree , in response to the statement, “The world is always changing and we should adapt our view of moral behaviour to these changes.”   MBSA9
an ordered factor with levels StronglyDisagree , Disagree , Agree , and StronglyAgree , in response to the statement, “This country would have many fewer problems if there were more emphasis on traditional family values.”     Source  
York University Institute for Social Research."
"sem-HS.data","sem","HS.data","Holizinger and Swineford's Data",301,32,3,0,2,0,30,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/HS.data.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/HS.data.html","HS.data R Documentation    Holizinger and Swineford's Data    Description  
This data set, for scores on a variety of tests, was originally in the MBESS package. A new version of the data set in that package doesn't appear to be identical to this one.    Usage   HS.data   Format  
A data frame with 301 observations on the following 32 variables.    id
a numeric vector   Gender
a factor with levels Female Male   grade
a numeric vector   agey
a numeric vector   agem
a numeric vector   school
a factor with levels Grant-White Pasteur   visual
a numeric vector   cubes
a numeric vector   paper
a numeric vector   flags
a numeric vector   general
a numeric vector   paragrap
a numeric vector   sentence
a numeric vector   wordc
a numeric vector   wordm
a numeric vector   addition
a numeric vector   code
a numeric vector   counting
a numeric vector   straight
a numeric vector   wordr
a numeric vector   numberr
a numeric vector   figurer
a numeric vector   object
a numeric vector   numberf
a numeric vector   figurew
a numeric vector   deduct
a numeric vector   numeric
a numeric vector   problemr
a numeric vector   series
a numeric vector   arithmet
a numeric vector   paperrev
a numeric vector   flagssub
a numeric vector     Source  
Originally from Holzinger and Swineford (1939). This copy is originally from version 4.6.0 of the MBESS package.    References  
Holzinger, K. J. and Swineford, F. A. (1939). A study in factor analysis: The stability of a bi-factor solution. Supplementary Education Monographs, 48. University of Chicago.    Examples    summary(HS.data)"
"sem-Klein","sem","Klein","Klein's Data on the U. S. Economy",22,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/Klein.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/Klein.html","Klein R Documentation   Klein's Data on the U. S. Economy   Description  
Data for Klein's (1950) simple econometric model of the U. S. economy.   
The Klein data frame has 22 rows and 10 columns.    Usage   Klein   Format  
This data frame contains the following columns:    Year
1921–1941   C
consumption.   P
private profits.   Wp
private wages.   I
investment.   K.lag
capital stock, lagged one year.   X
equilibrium demand.   Wg
government wages.   G
government non-wage spending.   T
indirect business taxes and net exports.     Source  
Greene, W. H. (1993)  Econometric Analysis, Second Edition.  Macmillan.    References  
Klein, L. (1950)  Economic Fluctuations in the United States 1921–1941.  Wiley.    Examples    Klein$P.lag <- c(NA, Klein$P[-22]) Klein$X.lag <- c(NA, Klein$X[-22]) summary(tsls(C ~ P + P.lag + I(Wp + Wg), instruments=~1 + G + T + Wg + I(Year - 1931) + K.lag + P.lag + X.lag, data=Klein)) summary(tsls(I ~ P + P.lag + K.lag, instruments=~1 + G + T + Wg + I(Year - 1931) + K.lag + P.lag + X.lag, data=Klein)) summary(tsls(Wp ~ X + X.lag + I(Year - 1931), instruments=~1 + G + T + Wg + I(Year - 1931) + K.lag + P.lag + X.lag, data=Klein))"
"sem-Kmenta","sem","Kmenta","Partly Artificial Data on the U. S. Economy",20,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/Kmenta.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/Kmenta.html","Kmenta R Documentation   Partly Artificial Data on the U. S. Economy   Description  
These are partly contrived data from Kmenta (1986), constructed to illustrate estimation of a simultaneous-equation model.   
The Kmenta data frame has 20 rows and 5 columns.    Usage   Kmenta   Format  
This data frame contains the following columns:    Q  
food consumption per capita.    P  
ratio of food prices to general consumer prices.    D  
disposable income in constant dollars.    F  
ratio of preceding year's prices received by farmers to general consumer prices.    A  
time in years.      Details  
The exogenous variables D , F , and A are based on real data; the endogenous variables P and Q were generated by simulation.    Source  
Kmenta, J. (1986)  Elements of Econometrics, Second Edition , Macmillan."
"sem-Tests","sem","Tests","Six Mental Tests",32,6,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/sem/Tests.csv","https://vincentarelbundock.github.io/Rdatasets/doc/sem/Tests.html","Tests R Documentation    Six Mental Tests    Description  
These data are from the SAS manual and consist of six mental tests for 32 students, with some missing data. The three x variables are intended to load on a verbal factor, and the three y variables on a math factor. The data can be used to illustrate the estimation of a confirmatory factor analysis model by multinormal full-information maximum-likelihood in the presence of missing data.    Usage   Tests   Format  
A data frame with 32 observations on the following 6 variables.    x1
score on verbal test 1.   x2
score on verbal test 2.   x3
score on verbal test 3.   y1
score on math test 1.   y2
score on math test 2.   y3
score on math test 3.     Source  
Example 25.13 from SAS/STAT 9.22 User's Guide , SAS Institute, 2010."
"Stat2Data-AccordPrice","Stat2Data","AccordPrice","Prices of Used Honda Accords (in 2017)",30,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AccordPrice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AccordPrice.html","AccordPrice R Documentation   Prices of Used Honda Accords (in 2017)   Description  
Age, price, and mileage of used Honda Accords in 2017    Format  
A data frame with 30 observations on the following 3 variables.    Age
Age of used Honda Accord car   Price
Price (in $1,000's)   Mileage
Mileage (in 1,000's of miles)     Details  
Information on used Honda Accords obtained from cars.com.    Source  
Cars.com, February 2017 using zip code 44107, Lakewood, Ohio"
"Stat2Data-AHCAvote2017","Stat2Data","AHCAvote2017","Congressional Votes on American Health Care Act (in 2017)",430,11,5,0,4,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AHCAvote2017.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AHCAvote2017.html","AHCAvote2017 R Documentation   Congressional Votes on American Health Care Act (in 2017)   Description  
Congressional votes on the American Health Care Act in 2017    Format  
A data frame with 430 observations on the following 11 variables.    STATE
State name   Dist
Congressional district   Party
Party affiliation ( D =Democrat, R =Republican)   Dem
1 =Democrat, 0 =Republican   Rep
1 =Republican, 0 =Democrat   uni2013
Percentage of citizens without health care in 2013   uni2015
Percentage of citizens without health care in 2015   uniChange
uni2015 - uni2013   Member
Name of representative   AHCAvote
1 =yes, 0 =no   Trump
1 =Trump won district, 0 =Clinton won district     Details  
On May 4, 2017, the U.S. House of Representatives voted, by the narrow margin of 217-213, to pass the American Health Care Act. Most Republicans voted Yes, while all Democrats voted No.    Source  
https://fivethirtyeight.com/features/obamacare-has-increased-insurance-coverage-everywhere/   
https://docs.google.com/spreadsheets/d/1VfkHtzBTP5gf4jAu8tcVQgsBJ1IDvXEHjuMqYlOgYbA/edit#gid=0   
https://www.nytimes.com/interactive/2017/05/04/us/politics/house-vote-republican-health-care-bill.html"
"Stat2Data-Airlines","Stat2Data","Airlines","Ontime Records for Two Airlines at Two Airports",10333,5,5,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Airlines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Airlines.html","Airlines R Documentation   Ontime Records for Two Airlines at Two Airports   Description  
Ontime arrivals for American and Delta airlines at LaGuardia and O'Hare airports    Format  
A data frame with 10333 observations on the following 5 variables.    airline
American or Delta   airport
LGA =LaGuardia ORD =O'Hare   OnTime
no or yes   IndOHare
Is the airport ORD? ( 1 =yes or 0 =no)   IndDelta
Is the airline Delta? ( 1 =yes or 0 =no)     Details  
Ontime/late data for individual flights to LaGuardia and O'Hare airports by American and Delta airlines.    Source  
Data collected on 9/20/16 from http://www.transtats.bts.gov/ot_delay/OT_DelayCause1.asp?pn=1"
"Stat2Data-Alfalfa","Stat2Data","Alfalfa","Alfalfa Growth",15,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Alfalfa.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Alfalfa.html","Alfalfa R Documentation    Alfalfa Growth    Description  
Growth of alfalfa sprouts in acidic conditions    Format  
A dataset with 15 observations on the following 3 variables.   
  Ht4 Height of alfalfa sprouts after four days
  Acid Amount of acid: 1.5HCl , 3.0HCl , or water
  Row a through e with a = closest to window and e =farthest from window
    Details  
Some students were interested in how an acidic environment might affect the growth of plants. They planted alfalfa seeds in 15 cups and randomly chose five to get plain water, five to get a moderate amount of acid (1.5M HCl), and five to get a stronger acid solution (3.0M HCl). The plants were grown in an indoor room so the students assumed that the distance from the main source of daylight (windows) might have an affect on growth rates. For this reason, they arranged the cups in five rows of three with one cup from each Acid level in each row. These are labeled in the data set as Row: a=farthest from the window through e=nearest to the window.    Source  
Neumann, A., Richards, A. L., and Randa, J. (2001). Effects of acid rain on alfalfa plants. Unpublished manuscript, Oberlin College.    Examples    data(Alfalfa)"
"Stat2Data-AlitoConfirmation","Stat2Data","AlitoConfirmation","US Senate Votes on Samuel Alito for the Supreme Court",100,6,3,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AlitoConfirmation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AlitoConfirmation.html","AlitoConfirmation R Documentation   US Senate Votes on Samuel Alito for the Supreme Court   Description  
US Senate party affiliatoin and votes on confirming Samuel Alito for the Supreme Court    Format  
A data frame with 100 observations on the following 6 variables.    State
State name   Senator
Senator's name   Party
Party affiliation ( D =Democrat, R =Republican)   ConfVote
Confirmation vote ( Nay =against or Yea =for)   StateOpinion
Percentage of state residents supporting the choice   Vote
1=for or 0=against     Details  
Data from the U.S. Senate vote on January 31, 2006 to confirm Samuel Alito to a position on the Supreme Court.    Source  
These numbers are taken from Kastellec, J.P., Lax, J.R., and Phillips, J. (2010), ""Public Opinion and Senate Confirmation of Supreme Court Nominees,"" Journal of Politics, 72(3): 767-84. In this paper the authors used opinion polls and an advanced statistical method known as multilevel regression and poststratification to determine the StateOpinion levels."
"Stat2Data-Amyloid","Stat2Data","Amyloid","Amyloid-beta and Cognitive Impairment",57,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Amyloid.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Amyloid.html","Amyloid R Documentation   Amyloid-beta and Cognitive Impairment   Description  
Amyloid-beta and cognitive impairment for a sample of Catholic priests    Format  
A data frame with 57 observations on the following 2 variables.    Group
mAD =Alzheimer's, MCI =mild impairment, NCI =no impairment   Abeta
Amount of Abeta from the posterior cingulate cortex (pmol/g tissue)     Details  
Amyloid-beta (Abeta) is a protein fragment that has been linked to Alzheimer's disease. Autopsies from a sample of Catholic priests included measurements of Abeta (pmol/g tissue from the posterior cingulate cortex) from three groups: subjects who had exhibited no cognitive impairment before death, subjects who had exhibited mild cognitive impairment, and subjects who had mild to moderate Alzheimer's disease.    Source  
Violetta N. Pivtoraiko, Eric E. Abrahamson, Sue E. Leurgans, Steven T. DeKosky, Elliott J. Mufson,, Milos D. Ikonomovic (2015) Cortical pyroglutamate amyloid-beta levels and cognitive decline in Alzheimer's disease. Neurobiology of Aging (36) 12-19. Data are read from Figure 1, panel d."
"Stat2Data-AppleStock","Stat2Data","AppleStock","Daily Price and Volume of Apple Stock",66,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AppleStock.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AppleStock.html","AppleStock R Documentation   Daily Price and Volume of Apple Stock   Description  
Daily prices and trading volume of Apple stock from July 21st to August 21st in 2016    Format  
A data frame with 66 observations on the following 4 variables.    Date
Date as mm/dd/yyyy   Price
Closing price of Apple stock   Change
Change in price from previous day   Volume
Number of shares traded (in millions)     Details  
Closing price of Apple stock (AAPL) for each trading day in a three month period from 7/21/2016 to 10/21/2016 as well as the change in stock price and number of shares traded.    Source  
Data downloaded from Nasdaq historical prices at http://www.nasdaq.com/symbol/aapl/historical"
"Stat2Data-ArcheryData","Stat2Data","ArcheryData","Scores in an Archery Class",18,7,2,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ArcheryData.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ArcheryData.html","ArcheryData R Documentation   Scores in an Archery Class   Description  
Score results from an archery class    Format  
A dataset with 18 observations on the following 7 variables.   
  Attendance Number of days in class
  Average Average score over all days
  Sex Coded as f or m
  Day1 Archery score on first day
  LastDay Archery score on last day
  Improvement Last day - first day score
  Improve 1=improved or 0=did not improve
    Details  
In 2002, Heather Tollerud, a Saint Olaf College student, undertook a study of the archery scores of students at the college who were enrolled in an archery course. Students taking the course record a score for each day they attend class from the first until the last day. Hopefully the instruction they receive helps them to improve their game.    Source  
Student project"
"Stat2Data-AthleteGrad","Stat2Data","AthleteGrad","Athletic Participation, Race, and Graduation",214555,3,3,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AthleteGrad.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AthleteGrad.html","AthleteGrad R Documentation   Athletic Participation, Race, and Graduation   Description  
Six-year graduation data for 214,555 students in 2004    Format  
A data frame with 214555 observations on the following 3 variables.    Student
Athlete or NonAthlete   Race
Black or White   Grad
1 =graduated within 6 years, otherwise 0     Details  
Six-year graduation data from 2004 for male non-athletes and for male athletes, where ""Athlete"""" means football or basketball player. These data show Simpson's Paradox.    Source  
Victor Matheson, College of the Holy Cross, collected the summary statistics.   
Data are derived from the summary tables in:   
Matheson, V., ""Research Note: Athletic Graduation Rates and Simpson's Paradox,"" Economics of Education Review, Vol. 26:4 (August 2007), 516-520."
"Stat2Data-AudioVisual","Stat2Data","AudioVisual","Reaction Times to Audio and Visual Stimuli",72,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AudioVisual.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AudioVisual.html","AudioVisual R Documentation   Reaction Times to Audio and Visual Stimuli   Description  
Data from an experiment on reaction times to audio or visual stimuli by Oberlin College students.    Format  
A data frame with 72 observations on the following 4 variables.    Subject
SubjectIDs coded s1 to s36   ResponseTime
Time to respond to a stimulus (in ms)   Stimulus
Type of stimulus ( auditory or visual )   Group
Musician or NonMusician     Details  
Subjects in a reaction time study were asked to press a button as fast as possible after being exposed to either an auditory stimulus (a burst of white noise) or a visual stimulus (a circle flashing on a computer screen). Average reaction times (ms) were recorded for between 10 and 20 trials for each type of stimulus for each subject. Data also identifies which subjects are musicians.    Source  
Arjuna Pettit, Jr. and Jeremy Potterfield at Oberlin College"
"Stat2Data-AutoPollution","Stat2Data","AutoPollution","Noise Levels of Filters to Reduce Automobile Pollution",36,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/AutoPollution.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/AutoPollution.html","AutoPollution R Documentation    Noise Levels of Filters to Reduce Automobile Pollution    Description  
Measurements of noise levels for different filters to reduce pollution levels of automobiles.    Format  
A dataset with 36 observations on the following 4 variables.   
  Noise Noise level (decibels)
  Size Vehicle size: 1 =small, 2 =medium, or 3 =large
  Type 1 =standard filter or 2 =new filter
  Side Side of vehicle: code1=right or 2 =left
    Details  
In a 1973 testimony before the Air and Water Pollution Subcommittee of the Senate Public Works Committee, John McKinley, President of Texaco discussed a new filter that had been developed to reduce pollution. Questions were raised about the effects of this filter on other measures of vehicle performance. The data set AutoPollution gives the results of an experiment on 36 different cars. The cars were randomly assigned to get either this new filter or a standard filter and the noise level for each car was measured.    Source  
Data explanation and link can be found at http://lib.stat.cmu.edu/DASL/Stories/airpollutionfilters.html.    References  
A.Y. Lewin and M.F. Shakun, Policy Sciences: Methodology and Cases, Pergammon Press, 1976, p 313."
"Stat2Data-Backpack","Stat2Data","Backpack","Weights of College Student Backpacks",100,9,3,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Backpack.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Backpack.html","Backpack R Documentation   Weights of College Student Backpacks   Description  
Backpack weights for a sample of college students    Format  
A data frame with 100 observations on the following 9 variables.   
  BackpackWeight Backpack weight (in pounds)
  BodyWeight Body weight (in pounds)
  Ratio BackpackWeight/BodyWeight
  BackProblems 0 =no or 1 =yes
  Major Code for academic major
  Year Year in school
  Sex a factor with levels Female Male
  Status Graduate or undergraduate? G or U
  Units Number of credits taken that quarter
    Details  
A survey of students at California Polytechnic State University (San Luis Obispo) collected data to investigate the question of whether back aches might be due to carrying heavy backpacks,    Source  
Mintz J., Mintz J., Moore K., and Schuh K., ""Oh, My Aching Back! A Statistical Analysis of Backpack Weights,"" Stats: The Magazine for Students of Statistics, vol. 32, 2002, pp. 1719."
"Stat2Data-BaseballTimes","Stat2Data","BaseballTimes","Baseball Game Times of One Day in 2008",15,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BaseballTimes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BaseballTimes.html","BaseballTimes R Documentation   Baseball Game Times of One Day in 2008   Description  
Game times and boxscore information for baseball games    Format  
A data frame with 15 observations on the following 7 variables.   
  Game Code for opposing teams
  League AL = American League or NL =National League
  Runs Total number of runs scored (both teams)
  Margin Margin of victory (Winner-Loser score)
  Pitchers Total number of pitchers used (both teams
  Attendance Number of spectators at the game
  Time Total time for the game (in minutes)
    Details  
Data were collected for 15 Major League Baseball (MLB) games played on August 26, 2008.   
This dataset was used in first edition, but updated to BaseballTimes2017 for the second edition.    Source  
Data from boxscores at www.baseball-reference.com"
"Stat2Data-BaseballTimes2017","Stat2Data","BaseballTimes2017","Baseball Game Times of One Day in 2017",14,7,0,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BaseballTimes2017.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BaseballTimes2017.html","BaseballTimes2017 R Documentation   Baseball Game Times of One Day in 2017   Description  
Times for one day's major league baseball games    Format  
A data frame with 14 observations on the following 7 variables.    Game
MLB teams that played   League
AL =American League, IL =Interleague, or NL =National League   Runs
Runs scored by the two teams combined   Margin
Winning margin   Pitchers
Number of pitchers used total for two teams   Attendance
Announced attendance   Time
Time in minutes to play the game     Details  
Data from all MLB games played on August 11, 2017. There were no extra-innings game nor any rain delays.    Source  
https://www.baseball-reference.com/boxes/?month=8&day=11&year=2017"
"Stat2Data-BeeStings","Stat2Data","BeeStings","Do Bee Stings Depend on Previous Stings?",18,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BeeStings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BeeStings.html","BeeStings R Documentation   Do Bee Stings Depend on Previous Stings?   Description  
Data from an experiment to see it the number of bee stings depends on previous stings.    Format  
A data frame with 18 observations on the following 3 variables.   
  Occasion Trial: I to IX
  Treatment Fresh or Stung
  Stingers Number of stingers
    Details  
If you are stung by a bee, does that make you more likely to get stung again? Might bees leave behind a chemical message that tells other bees to attack you? To test this hypothesis, scientists dangled a 4x4 array of 16 muslin-wrapped cotton balls over a beehive. Eight of 16 balls had been previously stung; the other eight were fresh. The response was the total number of new stingers left behind by the bees. The process was repeated for a total of nine trials.   
Used in first edition, but not second edition.    Source  
Free, J.B. (1961) ""The stinging response of honeybees,"" Animal Behavior, Vol. 9, pp 193-196."
"Stat2Data-BirdCalcium","Stat2Data","BirdCalcium","Effect of a Hormone on Bird Calcium Levels",20,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BirdCalcium.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BirdCalcium.html","BirdCalcium R Documentation   Effect of a Hormone on Bird Calcium Levels   Description  
An experiment on the effects of a hormone on blood calcium levels in robins    Format  
A data frame with 20 observations on the following 5 variables.    Bird
ID number for each bird (1 to 20)   Sex
female or male   Hormone
Treated with hormone ( no or yes )   Group
Combined Sex and Hormone ( F No , F Yes , M No , or M Yes )   Ca
Blood calcium level (mg per 100 ml)     Details  
An experiment looked at the effects of treatment with a hormone for increasing the concentration of calcium in birds. Twenty birds (robins) were used in the study, ten male and ten female, equally divided between the hormone and no hormone treatments.    Source  
Bliss, Chester (1970), Statistics in Biology, McGraw-Hill"
"Stat2Data-BirdNest","Stat2Data","BirdNest","Nest Characteristics for Different Bird Species",84,12,2,0,4,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BirdNest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BirdNest.html","BirdNest R Documentation    Nest Characteristics for Different Bird Species    Description  
Nest and species characteristics for North American passerines    Format  
A data frame with 84 observations on the following 12 variables.   
  Species Latin species name
  Common Common species name
  Page Page in a bird manual describing the species
  Length Mean body length for the species (in cm)
  Nesttype Type of nest
  Location Location of nest
  No.eggs Number of eggs
  Color Egg color ( 0 =plain/solid or 1 =speckled/spotted)
  Incubate Mean length of time (in days) the species incubates eggs in the nest
  Nestling Mean length of time (in days) the species cares for babies in the nest until fledged
  Totcare Total care time = Incubate+Nestling
  Closed 1=closed nest (pendant, spherical, cavity, crevice, burrow), 0=open nest (saucer, cup)
    Details  
Amy R. Moore, as a student at Grinnell College in 1999, wanted to study the relationship between species characteristics and the type of nest a bird builds, using data collected from available sources. For the study, she collected data by species for 84 separate species of North American passerines.    Source  
Project by Amy Moore at Grinnell College    References  
The Birders Handbook, by Ehrlich, et al. (1988)"
"Stat2Data-Blood1","Stat2Data","Blood1","Blood Pressure, Weight, and Smoking Status",500,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Blood1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Blood1.html","Blood1 R Documentation   Blood Pressure, Weight, and Smoking Status   Description  
Systolic blood pressure, weight and smoking status for a sample of 500 adults    Format  
A data frame with 500 observations on the following 3 variables.   
  SystolicBP Systolic blood pressure (mm of Hg)
  Smoke Y =smoker or N =non-smoker
  Overwt 1 =normal, 2 =overweight, or 3 =obese
    Details  
Data on systolic blood pressure, along with smoker status and weight status, for a sample of 500 adults.    Source  
Data are part of a larger case study for the 2003 Annual Meeting of the Statistical Society of Canada.
 http://www.ssc.ca/en/education/archived-case-studies/case-studies-for-the-2003-annual-meeting-blood-pressure."
"Stat2Data-BlueJays","Stat2Data","BlueJays","Blue Jay Measurements",123,9,2,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BlueJays.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BlueJays.html","BlueJays R Documentation   Blue Jay Measurements   Description  
Body measurements for a sample of blue jays    Format  
A data frame with 123 observations on the following 9 variables.   
  BirdID ID tag for bird
  KnownSex Sex coded as F or M
  BillDepth Thickness of the bill measured at the nostril (in mm)
  BillWidth Width of the bill (in mm)
  BillLength Length of the bill (in mm)
  Head Distance from tip of bill to back of head (in mm)
  Mass Body mass (in grams)
  Skull Distance from base of bill to back of skull (in mm)
  Sex Sex coded as 0=female or 1=male
    Details  
Body measurements for captured blue jays. Values are averaged for birds captured more than once.    Source  
Data from Keith Tarvin, Department of Biology, Oberlin College"
"Stat2Data-BrainpH","Stat2Data","BrainpH","Brain pH Measurements",54,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BrainpH.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BrainpH.html","BrainpH R Documentation   Brain pH Measurements   Description  
Brain tissue pH at time of death    Format  
A data frame with 54 observations on the following 5 variables.    pH
Brain tissue pH   Sex
F or M   Ethnicity
AfricanAmerican , Asian , Caucasian , or PacificIslander   Age
Age at death   DeathType
Cause of death ( Cardiac , Other , or Suicide )     Details  
These are data from a PNAS article (supplemental file) on pH in brain tissue samples for controls and for people who had Major Depressive Disorder. We extracted just the controls (roughly 3/4 of whom died of cardiac arrest).    Source  
Jun Z. Li et al. (2013), ""Circadian patterns of gene expression in the human brain and disruption in major depressive disorder,"" PNAS, vol 110, no. 24, www.pnas.org/cgi/doi/10.1073/pnas.1305814110   
Data extracted from Supporting Information, Table S4: Li et al. www.pnas.org/cgi/content/short/1305814110"
"Stat2Data-BreesPass","Stat2Data","BreesPass","Drew Brees Passing Statistics (2016)",16,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BreesPass.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BreesPass.html","BreesPass R Documentation   Drew Brees Passing Statistics (2016)   Description  
Passing statistics for football quarterback Drew Brees in 2016    Format  
A data frame with 16 observations on the following 5 variables.    Game
Game number (1 is the first game of the regular season)   Opponent
Opponent abbreviation   Completed
Number of completed passes   Attempts
Pass attempts   Yards
Passing yards     Details  
Drew Brees was the quarterback for the NFL's New Orleans Saints football team in 2016. This dataset shows some of his passing statistics for each of the 16 regular season games.    Source  
http://www.espn.com/nfl/player/gamelog/_/id/2580/year/2016"
"Stat2Data-BritishUnions","Stat2Data","BritishUnions","Attitudes Towards British Trade Unions",17,7,1,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/BritishUnions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/BritishUnions.html","BritishUnions R Documentation   Attitudes Towards British Trade Unions   Description  
Poll attitudes towards British trade unions    Format  
A data frame with 17 observations on the following 7 variables.   
  Date Month of the poll Aug-77 to Sep-79
  AgreePct Percent who agree (unions have too much power)
  DisagreePct Percent who disagree
  NetSupport DisagreePct-AgreePct
  Months Months since August 1975
  Late 1 =after 1986 or 0 =before 1986
  Unemployment Unemployment rate
    Details  
The British polling company Ipsos MORI conducted several opinion polls in the UK between 1975 and 1995 in which they asked whether people agree or disagree with the statement ""Trade unions have too much power in Britain today"".    Source  
Data from the Ipsos MORI website at
 http://www.ipsos-mori.com/researchpublications/researcharchive/poll.aspx?oItemID=94"
"Stat2Data-ButterfliesBc","Stat2Data","ButterfliesBc","Butterfly (Boloria chariclea) Measurements",32,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ButterfliesBc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ButterfliesBc.html","ButterfliesBc R Documentation   Butterfly (Boloria chariclea) Measurements   Description  
Measurements for a sample of butterflies in Greenland    Format  
A data frame with 32 observations on the following 4 variables.    Temp
Average temperature for preceding summer (Celsius)   Wing
Average wing length (mm)   Sex
Female or Male   Species
all are Bc , Boloria chariclea     Details  
Scientists measured wing length of a species of butterfly, Boloria chariclea (Bc), in Greenland each year from 1996 through 2013. They also recorded summer temperatures.    Source  
Digitized data from plots in Bowden, J. et al., ""High-Arctic butterflies become smaller with rising temperatures"", published in Biology Letters 11: 20150574"
"Stat2Data-CAFE","Stat2Data","CAFE","US Senate Votes on Corporate Average Fuel Economy Bill",100,7,2,0,3,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CAFE.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CAFE.html","CAFE R Documentation   US Senate Votes on Corporate Average Fuel Economy Bill   Description  
Senate votes for Corporate Average Fuel Economy (CAFE) bill    Format  
A data frame with 100 observations on the following 7 variables.   
  Senator Senator's name
  State Code for senator's state
  Party party affiliation: D =Democrat, I =Independent, R =Republican
  Contribution Contributions from car manufactures (dollars)
  LogContr Log of (Contribution+1)
  Dem 1 =Democrat/Independent 0 =Republican
  Vote 1 =yes or 0 =no
    Details  
The Corporate Average Fuel Economy (CAFE) Bill was proposed by Senators John McCain and John Kerry to improve the fuel economy of cars and light trucks sold in the United States. However a critical vote on an amendment in March of 2002 threatened to indefinitely postpone CAFE. The amendment charged the National Highway Traffic Safety Administration to develop a new standard, the effect being to put on indefinite hold the McCain-Kerry bill. It passed by a vote of 62-38. A political question of interest is whether there is evidence of monetary influence on a senator's vote. Scott Preston, a professor of statistics at SUNY, Oswego, collected data on this vote which includes the vote of each senator (1=Yes or 0=No) and monetary contributions that each of the 100 senators received over his or her lifetime from the car manufacturers.    Source  
Thanks to Prof. Scott Preston from SUNY Oswego for the data."
"Stat2Data-CalciumBP","Stat2Data","CalciumBP","Do Calcium Supplements Lower Blood Pressure?",21,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CalciumBP.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CalciumBP.html","CalciumBP R Documentation   Do Calcium Supplements Lower Blood Pressure?   Description  
An experiment on calcium supplements and blood pressure in 21 men    Format  
A data frame with 21 observations on the following 2 variables.   
  Treatment Calcium or Placebo
  Decrease Beginning-ending blood pressure
    Details  
The purpose of this study was to see whether daily calcium supplements can lower blood pressure. The subjects were 21 men; each was randomly assigned either to a treatment group or to a control group. Those in the treatment group took a daily pill containing calcium. Those in the control group took a daily pill with no active ingredients. Each subject's blood pressure was measured at the beginning of the 12-week study, and again at the end. The decrease in blood pressure (begin-end) was recorded (so a negative value means blood pressure increased).    Source  
Dataset downloaded from online data source Data and Story Library,
 http://lib.stat.cmu.edu/DASL/Stories/CalciumandBloodPressure.html"
"Stat2Data-CanadianDrugs","Stat2Data","CanadianDrugs","Canadian Drugs Senate Vote",94,6,3,0,5,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CanadianDrugs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CanadianDrugs.html","CanadianDrugs R Documentation   Canadian Drugs Senate Vote   Description  
US Senate vote on Klobuchar amendment to lower drug prices    Format  
A data frame with 94 observations on the following 6 variables.    Senator
Name of the Senator   Contributions
Amount of money received from the pharmaceutical industry over 6 years   Party
D =Democrat or R =Republican   State
Abbreviation for Senator's state   RollCall
Nay or Yea   Vote
Against or With what drug makers wanted     Details  
January 2017 vote in the U.S. Senate related to repeal part of ObamaCare. The ""Klobuchar amendment"" to a bill was introduced with the purpose of lowering drug prices by allowing prescription drugs to be imported from Canada.   
The data exclude two senators who did not vote on the amendment and four senators who were new to Congress and thus had received no money from the drug industry. The remaining 94 senators represent 49 states (every state except California) and each of these senators had received at least $3,000.    Source  
Data obtained from:   
http://www.senate.gov/legislative/LIS/roll_call_lists/roll_call_vote_cfm.cfm?congress=115&session=1&vote=00020   
http://maplight.org/us-congress/interest/H4300/view/all"
"Stat2Data-CancerSurvival","Stat2Data","CancerSurvival","Survival Times for Different Cancers",64,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CancerSurvival.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CancerSurvival.html","CancerSurvival R Documentation   Survival Times for Different Cancers   Description  
Cancer survival with ascorbate supplement    Format  
A dataset with 64 observations on the following 2 variables.   
  Survival Survival time (in days)
  Organ Breast , Bronchus , Colon , Ovary , or Stomach
    Details  
In the 1970's doctors wondered if giving terminal cancer patients a supplement of ascorbate would prolong their lives. They designed an experiment to compare cancer patients who received ascorbate to cancer patients who did not receive the supplement. The result of that experiment was that, in fact, ascorbate did seem to prolong the lives of these patients. But then a second question arose. Was the effect of the ascorbate different when different organs were affected by the cancer? The researchers took a second look at the data. This time they concentrated only on those patients who received the ascorbate and divided the data up by which organ was affected by the cancer. They had 5 different organs represented among the patients (all of whom only had one organ affected): Stomach, bronchus, colon, ovary, and breast.    Source  
From the article ""Supplemental Ascorbate in the Supportive Treatment of Cancer: Reevaluation of Prolongation of Survival Times in Terminal Human Cancer"" by Ewan Cameron and Linus Pauling, Proceedings of the National Academy of Sciences of the United States of America, Vol. 75, No. 9 (Sep., 1978), pp. 4538-4542."
"Stat2Data-Caterpillars","Stat2Data","Caterpillars","Measurements of Manduca Sexta Caterpillars",267,18,3,0,3,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Caterpillars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Caterpillars.html","Caterpillars R Documentation   Measurements of Manduca Sexta Caterpillars   Description  
Measurements on a sample of Manduca Sexta caterpillars    Format  
A data frame with 267 observations on the following 18 variables.   
  Instar Coded from 1 (smallest) to 5 (largest) indicating stage of the caterpillar's life
  ActiveFeeding Indicator ( Y or N ) of whether or not the animal is actively feeding
  Fgp Indicator ( Y or N ) of whether or not the animal is in a free growth period
  Mgp Indicator ( Y or N ) of whether or not the animal is in a maximum growth period
  Mass Body mass (in grams)
  LogMass Log (base 10) of body mass
  Intake Wet food intake (in grams/day)
  LogIntake Log (base 10) of Intake
  WetFrass Amount of frass (solid waste) produced (in grams/day)
  LogWetFrass Log (base 10) of WetFrass
  DryFrass Amount of frass, after drying, produced (in grams/day)
  LogDryFrass Log (base 10) of DryFrass
  Cassim CO2 assimilation (ingestion - excretion)
  LogCassim Log (base 10) of Cassim
  Nfrass Nitrogen in frass
  LogNfrass Log (base 10) of Nfrass
  Nassim Nitrogen assimilation (ingestion - excretion)
  LogNassim Log (base 10) of Nassim
    Details  
Student and faculty researchers at Kenyon College conducted numerous experiments with Manduca Sexta caterpillars to study biological growth.    Source  
We thank Professors Harry Itagaki, Drew Kerkhoff, Chris Gillen, and Judy Holdener and their students for sharing this data from research supported by NSF InSTaRs grant #0827208."
"Stat2Data-CavsShooting","Stat2Data","CavsShooting","Cleveland Cavalier's Shooting (2016-2017)",1940,3,3,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CavsShooting.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CavsShooting.html","CavsShooting R Documentation   Cleveland Cavalier's Shooting (2016-2017)   Description  
Shooting percentages for two Cav players    Format  
A data frame with 1940 observations on the following 3 variables.    Player
Frye or Irving   ShotType
Two or Three   Hit
1 =made or 0 =missed     Details  
Shooting success on 2-point shots and 3-point shots for the 2016-17 NBA season for two Cleveland Cavalier basketball players, Kyrie Irving and Channing Frye. Each case is a shot attempt. These data show Simpson's Paradox.    Source  
http://www.espn.com/nba/player/splits/_/id/6442/kyrie-irving http://www.espn.com/nba/player/splits/_/id/2754/type/total/channing-frye"
"Stat2Data-Cereal","Stat2Data","Cereal","Nutrition Content of Breakfast Cereals",36,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Cereal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Cereal.html","Cereal R Documentation   Nutrition Content of Breakfast Cereals   Description  
Nutrition content for a sample of 36 different brands of breakfast cereals    Format  
A data frame with 36 observations on the following 4 variables.   
  Cereal Brandname of cereal
  Calories Calories per serving
  Sugar Grams of sugar per serving
  Fiber Grams of fiber per serving
    Details  
Data give nutrition contents (per serving) for 36 breakfast cereals.    Source  
These data were collected by Patricia Benedict, Ronald Brahler, and Kenneth Motz, who read the nutritional labels on the boxes, in an attempt to learn whether cereals high in fiber are also high in sugar and calories. The cereals are all of those that were sold at Russo Stop & Shop in University Heights, OH, in July, 1990."
"Stat2Data-ChemoTHC","Stat2Data","ChemoTHC","THC for Antinausea Treatment in Chemotherapy",2,4,4,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ChemoTHC.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ChemoTHC.html","ChemoTHC R Documentation   THC for Antinausea Treatment in Chemotherapy   Description  
Comparison of two treatments for nausea in chemotherapy    Format  
A data frame with 2 observations on the following 4 variables.   
  Drug Prochlorperazine or THC
  Effective Count of effective cases
  NotEffective Count of noneffective cases
  Patients Number of patients in the treatment
    Details  
An article in the New England Journal of Medicine described a study on the effectiveness of medications for combatting nausea in patients undergoing chemotherapy treatments for cancer. In the experiment, 157 patients were divided at random into two groups. One group of 78 patients was given a standard antinausea drug called prochlorperazine, while the other group of 79 patients received THC (the active ingredient in marijuana). Both medications were delivered orally and no patients were told which of the two drugs they were taking. The response measured was whether or not the patient experienced relief from nausea when undergoing chemotherapy. Dataset is a 2 x 2 table of counts.    Source  
Sallan SE, Cronin C, Zelen M, Zinberg NE (1980), ""Antiemetics in patients receiving chemotherapy for cancer: a randomized comparison of delta-9-tetrahydrocannabinol and prochlorperazine,"" New England Journal of Medicine, 302(3) p.135-138."
"Stat2Data-ChildSpeaks","Stat2Data","ChildSpeaks","Age at First Speaking",21,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ChildSpeaks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ChildSpeaks.html","ChildSpeaks R Documentation   Age at First Speaking   Description  
Age at first speaking and aptitude test scores    Format  
A data frame with 21 observations on the following 3 variables.   
  Child ID for each child
  Age Age at first speaking (in months)
  Gesell Gesell Aptitude Test Score
    Details  
The data are from a study about whether there is a relationship between the age at which a child first speaks (in months) and his or her score on a Gesell Aptitude Test taken later in childhood.    Source  
These data were originally collected by L.M. Linde of UCLA but were first published by M.R. Mickey, O.J. Dunn, and V. Clark, ""Note on the use of stepwise regression in detecting outliers,"" Computers and Biomedical Research, 1 (1967), pp. 105-111. The data have been used by several authors. We found them in David Moore's Basic Practice of Statistics, WH Freeman (2004)"
"Stat2Data-ClintonSanders","Stat2Data","ClintonSanders","Clinton/Sanders Primary Results (2016)",31,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ClintonSanders.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ClintonSanders.html","ClintonSanders R Documentation   Clinton/Sanders Primary Results (2016)   Description  
2016 US Democratic Presidential primary results    Format  
A data frame with 31 observations on the following 5 variables.    State
ID for primary state   Delegates
Percentage of delegates won by Clinton   PaperTrail
Was a paper trail available for votes cast? ( No Paper Trail or Paper Trail )   PopularVote
Percentage of votes won by Clinton   AfAmPercent
Percentage of African-Americans in the state     Details  
In 2016 Hillary Clinton won the Democratic nomination for U.S. President over Bernie Sanders. A paper was circulated that claimed to show evidence of election fraud based, among other things, on Clinton doing better in states that don't have a paper trail for votes cast in a primary election than she did in states that have a paper trail. Data is for the 31 states that held Democratic primaries in 2016.    Source  
https://docs.google.com/spreadsheets/d/1cszGOhbmHDTHH5ntaGPmeX55RgMMaoBhgqO1Wx-9TRk/ edit#gid=0   
http://kff.org/other/state-indicator/distribution-by-raceethnicity/ ?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D"
"Stat2Data-Clothing","Stat2Data","Clothing","Sales for a Clothing Retailer",60,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Clothing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Clothing.html","Clothing R Documentation   Sales for a Clothing Retailer   Description  
Data on 60 customers at a clothing retailer    Format  
A data frame with 60 observations on the following 8 variables.   
  ID Case ID
  Amount Net dollar amount spent by customers in their latest purchase from this retailer
  Recency Number of months since the last purchase
  Freq12 Number of purchases in the last 12 months
  Dollar12 Dollar amount of purchases in the last 12 months
  Freq24 Number of purchases in the last 24 months
  Dollar24 Dollar amount of purchases in the last 24 months
  Card 1 for customers who have a private-label credit card with the retailer, 0 if not
    Details  
This dataset represents a random sample of 60 customers from a large clothing retailer. The manager of the store is interested in predicting how much a customer will spend on his or her next purchase based on one or more of the available explanatory variables.    Source  
Personal communication with David Cameron who completed a more extensive consulting project for the retailer."
"Stat2Data-CloudSeeding","Stat2Data","CloudSeeding","Cloud Seeding Experiment (Winter Only)",28,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CloudSeeding.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CloudSeeding.html","CloudSeeding R Documentation   Cloud Seeding Experiment (Winter Only)   Description  
Rainfall amounts from a cloud seeding experiment (winter only)    Format  
A data frame with 28 observations on the following 7 variables.   
  Seeded Treatment coded as S =seeded or U =unseeded
  Season All in Winter
  TE Rainfall in East (treatment)
  TW Rainfall in West (treatment
  NC Rainfall in North (control)
  SC Rainfall in South (control)
  NWC Rainfall in Northwest (control)
    Details  
Researchers were interested in whether seeded clouds would produce more rainfall. An experiment was conducted in Tasmania between 1964 and 1971 and rainfall amounts were measured in inches per rainfall period. The researchers measured the amount of rainfall in two target areas: East (TE) and West (TW). They also measured the amount of rainfall in three control locations. Clouds were coded as being either seeded (treatment) or unseeded (control). This is a subset (only Winter months) of the larger CloudSeeding2 dataset. All rainfall amounts are in inches.    Source  
Data were accessed from the website www.statsci.org/data/oz/cloudtas.html. This is the web home of the Australasian Data and Story Library (OzDASL).    References  
A.J. Miller, D.E. Shaw, L.G. Veitch, and E.J. Smith, (1979) ""Analyzing the results of a cloud-seeding experiment in Tasmania"" in Communications in Statistics: Theory and Methods, A8 (10), pp. 1017-1047."
"Stat2Data-CloudSeeding2","Stat2Data","CloudSeeding2","Cloud Seeding Experiment (Four Seasons)",108,8,1,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CloudSeeding2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CloudSeeding2.html","CloudSeeding2 R Documentation   Cloud Seeding Experiment (Four Seasons)   Description  
Rainfall amounts from a cloud seeding experiment    Format  
A data frame with 108 observations on the following 8 variables.   
  Period ID for time period
  Seeded Treatment coded as S =seeded or U =unseeded
  Season Coded as Autumn , Spring , Summer , or Winter
  TE Rainfall in East (treatment)
  TW Rainfall in West (treatment
  NC Rainfall in North (control)
  SC Rainfall in South (control)
  NWC Rainfall in Northwest (control)
    Details  
Researchers were interested in whether seeded clouds would produce more rainfall. An experiment was conducted in Tasmania between 1964 and 1971 and rainfall amounts were measured in inches per rainfall period. The researchers measured the amount of rainfall in two target areas: East (TE) and West (TW). They also measured the amount of rainfall in three control locations. Clouds were coded as being either seeded (treatment) or unseeded (control). A subset (only Winter months) of these data is stored in CloudSeeding. All rainfall amounts are in inches.    Source  
Data were accessed from the website www.statsci.org/data/oz/cloudtas.html. This is the web home of the Australasian Data and Story Library (OzDASL).    References  
A.J. Miller, D.E. Shaw, L.G. Veitch, and E.J. Smith, (1979) ""Analyzing the results of a cloud-seeding experiment in Tasmania"" in Communications in Statistics: Theory and Methods, A8 (10), pp. 1017-1047."
"Stat2Data-CO2","Stat2Data","CO2","Daily CO2 Measurements in Germany",237,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CO2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CO2.html","CO2 R Documentation   Daily CO2 Measurements in Germany   Description  
Daily carbon dioxide measurements for April through November 2011    Format  
A data frame with 237 observations on the following 2 variables.    CO2
Carbon dioxide (CO2) level (in parts per million)   Day
Number of day in 2011 (April 1 = day 91)     Details  
Scientists at a research station in Brotjacklriegel, Germany recorded CO2 levels, in parts per million, in the atmosphere for each day from the start of April through November in 2011.   
This dataset was renamed to CO2Germany for the second edition.    Source  
http://gaw.empa.ch/gawsis/reports.asp?StationID=-739519191"
"Stat2Data-CO2Germany","Stat2Data","CO2Germany","Daily CO2 Measurements in Germany",237,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CO2Germany.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CO2Germany.html","CO2Germany R Documentation   Daily CO2 Measurements in Germany   Description  
Daily carbon dioxide measurements for April through November 2011    Format  
A data frame with 237 observations on the following 2 variables.    CO2
Carbon dioxide (CO2) level (in parts per million)   Day
Number of day in 2011 (April 1 = day 91)     Details  
Scientists at a research station in Brotjacklriegel, Germany recorded CO2 levels, in parts per million, in the atmosphere for each day from the start of April through November in 2011.    Source  
http://gaw.empa.ch/gawsis/reports.asp?StationID=-739519191"
"Stat2Data-CO2Hawaii","Stat2Data","CO2Hawaii","CO2 Readings in Hawaii",360,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CO2Hawaii.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CO2Hawaii.html","CO2Hawaii R Documentation   CO2 Readings in Hawaii   Description  
Monthly carbon dioxide readings at Mauna Loa, Hawaii    Format  
A data frame with 360 observations on the following 4 variables.    Year
Year (1988 - 2017)   Month
Month (1=Jan. to 12=Dec.)   CO2
Atmospheric carbon dioxide level (ppm)   t
Time interval (t=1 to 360)     Details  
Monthly average carbon dioxide readings (1988 - 2017) at the Mauna Loa Observatory in Hawaii. Data collected and disseminated by ERSL (Earth System Research Laboratory) of the U.S. NOAA (National Oceanic and Atmospheric Administration.    Source  
Data downloaded for MOL (Mauna Loa) from the ESRL/GMD data page at https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html"
"Stat2Data-CO2SouthPole","Stat2Data","CO2SouthPole","CO2 Readings at the South Pole",348,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CO2SouthPole.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CO2SouthPole.html","CO2SouthPole R Documentation   CO2 Readings at the South Pole   Description  
Monthly carbon dioxide readings at the South Pole    Format  
A data frame with 348 observations on the following 4 variables.    Year
Year (1988 - 2016)   Month
Month (1=Jan. to 12=Dec.)   CO2
Atmospheric carbon dioxide level (ppm)   t
Time interval (t=1 to 348)     Details  
Monthly average carbon dioxide readings (1988 - 2016) at the South Pole. Data collected and disseminated by ERSL (Earth System Research Laboratory) of the U.S. NOAA (National Oceanic and Atmospheric Administration.    Source  
Data downloaded for SPO (South Pole) from the ESRL/GMD data page at https://www.esrl.noaa.gov/gmd/dv/data/"
"Stat2Data-Contraceptives","Stat2Data","Contraceptives","Drug Interaction with Contraceptives",44,6,2,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Contraceptives.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Contraceptives.html","Contraceptives R Documentation   Drug Interaction with Contraceptives   Description  
Drug interaction study with oral contraceptives    Format  
A data frame with 44 observations on the following 6 variables.    ID
ID number for each of the women   StudyPeriod
1=first or 2 =second   Treatment
Drug or Placebo   EE
Bioavailability of the ethinyl estradiol component of the oral contraceptive (in pg*hr/ml)   ComparisonValues
Comparison values used for a Tukey nonadditivity plot   Residuals
Residuals used for a Tukey nonadditivity plot     Details  
Twenty-two female subjects were allocated randomly to one of two treatment sequences in a two period crossover design. The two treatments were a new Drug D or placebo, both given concomitantly with a standard oral contraceptive which was given in both study periods. The oral contraceptive has two components, ethinyl estradiol (EE) and norethindrone (NET). The purpose of the study was to evaluate whether the presence of Drug D affected the bioavailability of each of the oral contraceptive components. Note that our dataset does not include the NET variable.    Source  
Thomas E. Bradstreet & Deborah L. Panebianco (2017) ""An Oral Contraceptive Drug Interaction Study"", Journal of Statistics Education, 12:1, DOI: 10.1080/10691898.2004.11910719"
"Stat2Data-CountyHealth","Stat2Data","CountyHealth","County Health Resources",53,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CountyHealth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CountyHealth.html","CountyHealth R Documentation   County Health Resources   Description  
Medical facilities and doctors in a sample of counties.    Format  
A data frame with 53 observations on the following 4 variables.    County
County name, state   MDs
Number of medical doctors   Hospitals
Number of community hospitals   Beds
Number of beds in the hospitals     Details  
Data compiled from information provided by the American Medical Association on the availability of health care in counties in the United States. A random sample of 53 counties was chosen from among counties with at least two community hospitals.    Source  
Physicians–American Medical Association, Chicago, IL, Physician Characteristics and Distribution in the U.S., annual (copyright), accessed May 17, 2006. Community hospitals–Health Forum LLC, an American Hospital Association (AHA) Company, Chicago, IL, Hospital Statistics, and unpublished data (copyright), e-mail accessed May 4, 2006 (related Internet site http://www.healthforum.com).   
Other web sources:
 http://www.ama-assn.org/ http://www.healthforum.com/healthforum/html/data_statistics/data_statistics.html http://www.cms.hhs.gov http://www.ssa.gov"
"Stat2Data-CrabShip","Stat2Data","CrabShip","Crab Oxygen Intake",34,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CrabShip.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CrabShip.html","CrabShip R Documentation   Crab Oxygen Intake   Description  
Oxygen intake of crabs with different noise sources    Format  
A data frame with 34 observations on the following 3 variables.    Mass
Oxygen intake of crabs with different noise sources   Oxygen
Rate of oxygen consumption (mu moles h^-1)   Noise
Source of noise ( ambient or ship )     Details  
Animals that are stressed might increase their oxygen consumption. Biologists measured oxygen consumption of shore crabs that were either exposed to 7.5 minutes of ship noise or 7.5 minutes of ambient harbor noise.    Source  
Wale MA, Simpson SD, Radford AN. (2013) ""Size-dependent physiological responses of shore crabs to single and repeated playback of ship noise"", Biol Lett 9: 20121194. http://dx.doi.org/10.1098/rsbl.2012.1194"
"Stat2Data-CrackerFiber","Stat2Data","CrackerFiber","Effects of Cracker Fiber on Digested Calories",48,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CrackerFiber.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CrackerFiber.html","CrackerFiber R Documentation   Effects of Cracker Fiber on Digested Calories   Description  
Digested calories with different types of fiber in crackers    Format  
A data frame with 48 observations on the following 3 variables.   
  Subj ID for the subject
  Fiber Type of fiber: bran , combo , control , or gum
  Calories Digested calories
    Details  
Twelve female subjects were fed a controlled diet, with crackers before every meal. There were four different kinds of crackers: control, bran fiber, gum fiber, and a combination of both bran and gum fiber. Over the course of the study, each subject ate all four kinds of crackers, one kind at a time, for a stretch of several days. The order was randomized. The response is the number of digested calories, measured as the difference between calories eaten and calories passed through the system.    Source  
Subset of the data at http://lib.stat.cmu.edu/DASL/Datafiles/Fiber.html."
"Stat2Data-CreditRisk","Stat2Data","CreditRisk","Overdrawn Checking Account?",450,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/CreditRisk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/CreditRisk.html","CreditRisk R Documentation   Overdrawn Checking Account?   Description  
Variables that might be related to whether students overdraw a checking account.    Format  
A data frame with 450 observations on the following 4 variables.   
  Age Age of the student (in years)
  Sex 0 =male or 1 =female
  DaysDrink Number of days drinking alcohol (in past 30 days)
  Overdrawn Has student overdrawn a checking account? 0 =no or 1 =yes
    Details  
Researchers conducted a survey of 450 undergraduates in large introductory courses at either Mississippi State University or the University of Mississippi. There were close to 150 questions on the survey, but only four of these variables are included in this dataset. (You can consult the paper to learn how the variables beyond these 4 affect the analysis.) The primary interest for the researchers was factors relating to whether or not a student has ever overdrawn a checking account.    Source  
Worthy S.L., Jonkman J.N., Blinn-Pike L. (2010), ""Sensation-Seeking, Risk-Taking, and Problematic Financial Behaviors of College Students,"" Journal of Family and Economic Issues, 31: 161-170"
"Stat2Data-Cuckoo","Stat2Data","Cuckoo","Measurements of Cuckoo Eggs",120,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Cuckoo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Cuckoo.html","Cuckoo R Documentation   Measurements of Cuckoo Eggs   Description  
Lengths of cuckoo eggs laid in other birds' nests    Format  
A data frame with 120 observations on the following 2 variables.   
  Bird Type of bird nest: mdw_pipit (meadow pipit), tree_pipit ,
  hedge_sparrow , robin , wagtail , or wren
  Length Cuckoo egg length (in mm)
    Details  
Cuckoos are knows to lay their eggs in the nests of other (host) birds. The eggs are then adopted and hatched by the host birds. The data give the lengths of cuckoo eggs found in nests of various other bird species.    Source  
Downloaded from DASL at http://lib.stat.cmu.edu/DASL/Datafiles/cuckoodat.html    References  
""The Egg of Cuculus Canorus. An Enquiry into the Dimensions of the Cuckoo's Egg and the Relation of the Variations to the Size of the Eggs of the Foster-Parent, with Notes on Coloration"", by Oswald H. Latter, Biometrika, Vol. 1, No. 2 (Jan., 1902), pp. 164-176."
"Stat2Data-Day1Survey","Stat2Data","Day1Survey","First Day Survey of Statistics Students",43,13,2,0,3,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Day1Survey.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Day1Survey.html","Day1Survey R Documentation   First Day Survey of Statistics Students   Description  
Data from a first day class survey in an introductory statistics course    Format  
A data frame with 43 observations on the following 13 variables.   
  Section Section: 1 or 2
  Class Year in school: Freshman , Sophomore , Junior , or Senior
  Sex F =female or M =male
  Distance Distance (in miles) to get to campus
  Height Height (in inches)
  Handedness  Left , Right , or Ambidextrous
  Coins Value of coins student has (in class)
  WhiteString Estimated length of a white string (in inches)
  BlackString Estimated length of a black string (in inches)
  Reading Expected amount of reading during the semester (pages/week)
  TV Hours of TV watched per week
  Pulse Resting pulse rate (beats per minute)
  Texting Number of text messages in past 24 hours
    Details  
An instructor at a small liberal arts college distributed a data survey on the first day of class. The data for two different sections of the course are given in this dataset.    Source  
Student survey in an introductory statistics class."
"Stat2Data-DiabeticDogs","Stat2Data","DiabeticDogs","Lactic Acid Turnover in Dogs",20,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/DiabeticDogs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/DiabeticDogs.html","DiabeticDogs R Documentation   Lactic Acid Turnover in Dogs   Description  
The rate of lactic acid turnover was measured by two methods for normal and diabetic dogs.    Format  
A data frame with 20 observations on the following 4 variables.    Dog
Code for individual dogs ( d1 through d10 )   Method
Tracer method to measure response ( infuse or inject )   Operation
Pancreas removed to make the dog diabetic? ( no or yes )   Response
Rate for biochemical turnover of lactic acid     Details  
Five dogs had their pancreas removed to make them diabetic (Operation=yes), the other five were normal (Operation=no). The rate of turnover of lactic acid was measured for each dog by two methods, infusion and injection.    Source  
Forbath, N., A. B. Kenshole, and G. Hetenyi, Jr. (1967),""Turnover lactic acid in normal and diabetic dogs calculated by two tracer methods,"" Am. J. Physiol. v. 212, pp.1179 - 1183."
"Stat2Data-Diamonds","Stat2Data","Diamonds","Characteristics of a Sample of Diamonds",351,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Diamonds.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Diamonds.html","Diamonds R Documentation   Characteristics of a Sample of Diamonds   Description  
Price and characteristics for a sample of 351 diamonds    Format  
A data frame with 351 observations on the following 6 variables.   
  Carat Size of the diamond (in carats)
  Color Coded as D (most white/bright) through J
  Clarity Coded as IF , VVS1 , VVS2 , VS1 , VS2 , SI1 , SI2 , or SI3
  Depth Depth (as a percentage of diameter)
  PricePerCt Price per carat
  TotalPrice Price for the diamond (in dollars)
    Details  
Data for a sample of diamonds. The clarity of the diamonds ranges from IF (internally flawless) through VVS1 (very,very slightly included), VS1 (very slightly included), to SI3 (slightly included) in the order listed above.    Source  
Diamond data obtained from AwesomeGems.com on July 28, 2005."
"Stat2Data-Diamonds2","Stat2Data","Diamonds2","Characteristics of a Subset of the Diamond Sample",307,6,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Diamonds2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Diamonds2.html","Diamonds2 R Documentation   Characteristics of a Subset of the Diamond Sample   Description  
A subset of 307 cases with the most frequent colors from the Diamonds data    Format  
A data frame with 307 observations on the following 6 variables.   
  Carat Size of the diamond (in carats)
  Color Coded as D (most white/bright) through G
  Clarity Coded as IF , VVS1 , VVS2 , VS1 , VS2 , SI1 , SI2 , or SI3
  Depth Depth (as a percentage of diameter)
  PricePerCt Price per carat
  TotalPrice Price for the diamond (in dollars)
    Details  
A subset of the Diamonds data, containing only those with most frequent colors D, E, F, and G. The clarity of the diamonds ranges from IF (internally flawless) through VVS1 (very,very slightly included), VS1 (very slightly included), to SI3 (slightly included) in the order listed above.    Source  
Diamond data obtained from AwesomeGems.com on July 28, 2005."
"Stat2Data-Dinosaurs","Stat2Data","Dinosaurs","Iridium Levels in Rock Layers to Investigate Dinosaur Extinction",28,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Dinosaurs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Dinosaurs.html","Dinosaurs R Documentation   Iridium Levels in Rock Layers to Investigate Dinosaur Extinction   Description  
Iridium levels in prehistoric rock layers    Format  
A data frame with 28 observations on the following 4 variables.    ID
Sample identifier   Source
Type of rock ( Limestone Shale )   Depth
Depth of the sample (in meters)   Iridium
Iridium concentration (ppb)     Details  
The question of interest is whether a volcanic eruption or asteroid strike had created a dust cloud that led to extinction of most dinosaurs. Rock samples taken in Gubbio, Italy were measured for the concentration of iridium (a rare metal which is more common in asteroids). The deeper the sample, the older the rocks are. A sudden increase in iridium at some point in time would lend support for the asteroid hypothesis.    Source  
Ramsey, Fred L. and Daniel W. Schafer (2002). The Statistical Sleuth, 2nd ed., Pacific Grove, CA, Duxbury, pp.405-407."
"Stat2Data-Election08","Stat2Data","Election08","2008 U.S. Presidential Election",51,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Election08.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Election08.html","Election08 R Documentation   2008 U.S. Presidential Election   Description  
State-by-state information from the 2008 U.S. presidential election    Format  
A dataframe with 51 observations on the following 7 variables.   
  State Name of the state
  Abr Abbreviation for the state
  Income Per capita income in the state as of 2007 (in dollars)
  HS Percentage of adults with at least a high school education
  BA Percentage of adults with at least a college education
  Dem.Rep Difference in %Democrat and %Republican (according to 2008 Gallup survey)
  ObamaWin 1 = Obama (Democrat) wins state in 2008 or 0 =McCain (Republican) wins
    Details  
This dataset contains information from all 50 states and the District of Columbia for the 2008 U.S. presidential election.    Source  
State income data from: Census Bureau Table 659. Personal Income Per Capita (in 2007)
 High school data from: U.S. Census Bureau, 1990 Census of Population,
 http://nces.ed.gov/programs/digest/d08/tables/dt08_011.asp
 College data from: Census Bureau Table 225. Educational Attainment by State (in 2007)
 % Democrat and %Republican:
 http://www.gallup.com/poll/114016/state-states-political-party-affiliation.aspx#1"
"Stat2Data-Election16","Stat2Data","Election16","2016 U.S. Presidential Election",50,8,1,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Election16.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Election16.html","Election16 R Documentation   2016 U.S. Presidential Election   Description  
2016 presidential election and state demographic data    Format  
A data frame with 50 observations on the following 8 variables.    State
State name   Abr
Abbreviation for state name   Income
Per capita income in the state   HS
Percent high school grads   BA
Percent college grads   Adv
Percent with advanced degrees   Dem.Rep
Democratic lean - Republican lean in 2015 Gallup poll   TrumpWin
Trump won the state? ( 1 =yes or 0 =no)     Details  
This dataset contains information from all 50 states and the District of Columbia for the 2016 U.S. presidential election. It is similar to Election08 for the 2008 election.    Source  
Income data from
 https://www.census.gov/search-results.html?q=per+capita+income+by+state&search.x=0 &search.y=0&search=submit&page=1&stateGeo=none&searchtype=web&cssp=SERP   
2015 data via American Community Survey
 https://en.wikipedia.org/wiki/List_of_U.S._states_by_educational_attainment from Bureau, U.S. Census. ""2011-2015 American Community Survey 5-Year Estimates. factfinder.census.gov. Retrieved 2017-01-19.   
http://www.gallup.com/poll/188969/red-states-outnumber-blue-first-time-gallup-tracking.aspx"
"Stat2Data-ElephantsFB","Stat2Data","ElephantsFB","Measurements of Male African Elephants",138,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ElephantsFB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ElephantsFB.html","ElephantsFB R Documentation   Measurements of Male African Elephants   Description  
Age and height of male African elephants    Format  
A data frame with 138 observations on the following 3 variables.    Age
Age (in years)   Height
Shoulder height (in cm)   Firstborn
Firstborn? ( 1 =yes, 0 =no)     Details  
Data on 138 male African elephants that lived through droughts in the first two years of life.    Source  
Data are from Phyllis Lee, Stirling University, and are related to Lee, P., et al. (2013), ""Enduring consequences of early experiences: 40-year effects on survival and success among African elephants (Loxodonta Africana),"" Biology Letters, 9: 20130011."
"Stat2Data-ElephantsMF","Stat2Data","ElephantsMF","Measurements of African Elephants",288,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ElephantsMF.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ElephantsMF.html","ElephantsMF R Documentation   Measurements of African Elephants   Description  
Age and height of African elephants    Format  
A data frame with 288 observations on the following 3 variables.    Age
Age (in years)   Height
Shoulder height (in cm)   Sex
F =female or M =male     Details  
Data on 288 African elephants that lived through droughts in the first two years of life.    Source  
Data are from Phyllis Lee, Stirling University, and are related to Lee, P., et al. (2013), ""Enduring consequences of early experiences: 40-year effects on survival and success among African elephants (Loxodonta Africana),"" Biology Letters, 9: 20130011."
"Stat2Data-Ethanol","Stat2Data","Ethanol","Effects of Oxygen on Sugar Metabolism",16,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Ethanol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Ethanol.html","Ethanol R Documentation   Effects of Oxygen on Sugar Metabolism   Description  
Experiment on the effects of oxygen on sugar metabolism by bacteria    Format  
A data frame with 16 observations on the following 3 variables.   
  Sugar Type of sugar: Galactose or Glucose
  O2Conc Oxygen concentration
  Ethanol Ethanol concentration
    Details  
Many biochemical reactions are slowed or prevented by the presence of oxygen. For example, there are two simple forms of fermentation, one which converts each molecule of sugar to two molecules of lactic acid, and a second which converts each molecule of sugar to one each of lactic acid, ethanol, and carbon dioxide. This experiment was designed to compare the inhibiting effect of oxygen on the metabolism of two different sugars, glucose and galactose, by Streptococcus bacteria. In this case there were four levels of oxygen that were applied to the two kinds of sugar.   
Renamed to SugarEthanol in second edition.    Source  
Data are found in Statistics: The Exploration and Analysis of Data by Jay Devore and Roxy Peck (2008). St. Paul, MN: West.   
The original article is Yamada T., Takahashi-Abbe S., Abbe K. (1985) ""Effects of oxygen concentration on pyruvate formatelyase in situ and sugar metabolism of Streptocucoccus mutans and Streptococcus samguis,"" Infection and Immunity, pp. 129-134."
"Stat2Data-Eyes","Stat2Data","Eyes","Pupil Dilation and Sexual Orientation",106,4,3,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Eyes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Eyes.html","Eyes R Documentation   Pupil Dilation and Sexual Orientation   Description  
Data from an experiment relating pupil dilation to sexual orientation.    Format  
A data frame with 106 observations on the following 4 variables.    DilateDiff
Difference in pupil dilation when looking at same-sex and opposite-sex nude photographs   Sex
F =female or M =male   Gay
1 =gay or 0 =not, based on Kinsey scale score greater than 3   SexMale
0 =female or 1 =male     Details  
DilateDiff is, essentially, the difference in pupil dilation when looking at (a) same-sex nudes and (b) opposite-sex nude photographs. More specifically, multiple measurements of pupil size were taken under each of the two conditions, together with a third condition that involved a neutral stimulus. Within-subject z-scores were then computed, which led to the DilateDiff numbers used here.    Source  
G. Rieger and R.C. Savin-Williams (2012),""The Eyes Have It: Sex and Sexual Orientation Differences in Pupil Dilation Patterns,"" in PLoS ONE. The full study included 325 students. Here we are analyzing a subset of the data that excludes White students."
"Stat2Data-Faces","Stat2Data","Faces","Facial Attractiveness of Men",38,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Faces.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Faces.html","Faces R Documentation   Facial Attractiveness of Men   Description  
Grip strength, attractiveness, and shoulder-hip ratio for men    Format  
A data frame with 38 observations on the following 5 variables.    MaxGripStrength
Measurement of strength of hand grip   SHR
Shoulder to hip ratio   Partners
Number of sexual partners (lifetime)   Attractive
Attractiveness rating   AgeFirstSex
Age of first sex     Details  
Facial attractiveness of several men was rated by female college students. Maximum grip strength was also measured, along with shoulder to hip ratio, age of first sex, and number of sex partners.    Source  
Shoup, M. L. and Gallup, G.G., Jr. (2008), ""Men's Faces Convey Information about Their Bodies and Their Behavior: What You See is What You Get,"" Evolutionary Psychology, 6(3): 469-479."
"Stat2Data-FaithfulFaces","Stat2Data","FaithfulFaces","Faithfulness from a Photo?",170,7,3,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FaithfulFaces.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FaithfulFaces.html","FaithfulFaces R Documentation   Faithfulness from a Photo?   Description  
Ratings from a facial photo and actual faithfulness.    Format  
A data frame with 170 observations on the following 7 variables.    SexDimorph
Rating of sexual dimorphism (masculinity for males, femininity for females)   Attract
Rating of attractiveness   Cheater
Was the face subject unfaithful to a partner? ( 1 =yes or 0 =no)   Trust
Rating of trustworthiness   Faithful
Rating of faithfulness   FaceSex
Sex of face ( F =female or M =male)   RaterSex
Sex of rater ( F =female or M =male)     Details  
College students were asked to look at a photograph of an opposite-sex adult face and to rate the person, on a scale from 1 (low) to 10 (high), for attractiveness. They were also asked to rate trustworthiness, faithfulness, and sexual dimorphism (i.e., how masculine a male face is and how feminine a female face is). Overall, 68 students (34 males and 34 females) rated 170 faces (88 men and 82 women).    Source  
This dataset is based on G. Rhodes et al. (2012), ""Women can judge sexual unfaithfulness from unfamiliar men's faces,"" Biology Letters, November 2012. All of the 68 raters were heterosexual Caucasians, as were the 170 persons who were rated. (We have deleted 3 subjects with missing values and 16 subjects who were over age 35.)"
"Stat2Data-FantasyBaseball","Stat2Data","FantasyBaseball","Selection Times in a Fantasy Baseball Draft",24,9,0,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FantasyBaseball.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FantasyBaseball.html","FantasyBaseball R Documentation   Selection Times in a Fantasy Baseball Draft   Description  
Draft selection times for a fantasy baseball league    Format  
A data frame with 24 observations on the following 9 variables.   
  Round Round of the draft (1 to 24)
  DJ Draft time (in seconds) for D.J.
  AR Draft time (in seconds) for A.R.
  BK Draft time (in seconds) for B.K.
  JW Draft time (in seconds) for J.W.
  TS Draft time (in seconds) for T.S.
  RL Draft time (in seconds) for R.L.
  DR Draft time (in seconds) for D.R.
  MF Draft time (in seconds) for M.F.
    Details  
Time (in seconds) for participants in a draft for a fantasy baseball league to make a selection at each round.    Source  
Mathematical Science Baseball League historical records (online)."
"Stat2Data-FatRats","Stat2Data","FatRats","Diet and Weight of Rats",60,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FatRats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FatRats.html","FatRats R Documentation   Diet and Weight of Rats   Description  
Experiment on effects of diets on weight gain of rats    Format  
A data frame with 60 observations on the following 3 variables.    Gain
Weight gain (in grams per week)   Protein
Level of protein ( Hi or Lo )   Source
Source of protein ( Beef , Cereal , or Pork )     Details  
Data from this experiment compared weight gain for 60 baby rats that were fed different diets. Half of the rats had low-protein diets (Lo) and the rest had high-protein (Hi). The source of protein was either beef, cereal, or pork.    Source  
C. P. Wilsie, Iowa State College Agricultural Station (1944) via Snedecor and Cochran"
"Stat2Data-Fertility","Stat2Data","Fertility","Fertility Data for Women Having Trouble Getting Pregnant",333,10,0,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Fertility.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Fertility.html","Fertility R Documentation   Fertility Data for Women Having Trouble Getting Pregnant   Description  
Fertility measurements for a sample of women who have difficulty getting pregnant    Format  
A data frame with 333 observations on the following 10 variables.   
  Age Age (in years)
  LowAFC Smallest antral follicle count
  MeanAFC Average antral follicle count
  FSH Maximum follicle stimulating hormone level
  E2 Fertility level
  MaxE2 Maximum fertility level
  MaxDailyGn Maximum daily gonadotropin level
  TotalGn Total gonadotropin level
  Oocytes Number of egg cells
  Embryos Number of embryos
    Details  
A medical doctor and her team of researchers collected a variety of data on women who were having trouble getting pregnant. A key method for assessing fertility is a count of antral follicles (LowAFC or MeanAFC) that can be performed with noninvasive ultrasound. Researchers are interested in how the other variables are related to these counts.    Source  
We thank Dr. Priya Maseelall and her research team for sharing these data."
"Stat2Data-FGByDistance","Stat2Data","FGByDistance","Results of NFL Field Goal Attempts",51,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FGByDistance.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FGByDistance.html","FGByDistance R Documentation   Results of NFL Field Goal Attempts   Description  
Field goal results in the National Football League (NFL) by distance    Format  
A data frame with 51 observations on the following 7 variables.   
  Row Case ID
  Dist Distance of the attempt (in yards)
  N Number of kicks attempted from that distance
  Makes Number of kicks made from that distance
  PropMakes Proportion of attempts made
  Blocked Number of kicks blocked
  PropBlocked Proportion of kicks blocked
    Details  
This dataset summarizes all 8520 field goals attempted by place kickers in the National Football League (NFL) during regular season games for the 2000 through the 2008 seasons. Results are counts (attempted, made, and blocked) and proportions (made and blocked) for each distance.    Source  
We thank Sean Forman and Doug Drinen of Sports Reference LLC for providing us with the NFL field goal data set."
"Stat2Data-Film","Stat2Data","Film","Film Data from Leonard Maltin's Guide",100,9,2,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Film.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Film.html","Film R Documentation   Film Data from Leonard Maltin's Guide   Description  
Film data from Maltin's Movie and Video Guide    Format  
A data frame with 100 observations on the following 9 variables.   
  Title Movie title
  Year Year the movie was released
  Time Running time (in minutes)
  Cast Number of cast members listed in the guide
  Rating Maltin rating (range is 1 to 4, in steps of 0.5)
  Description Number of lines of text Maltin uses to describe the movie
  Origin Country: 0 = USA, 1 = Great Britain, 2 = France, 3 = Italy, 4 = Canada
  Time_code long =90 minutes or longer short =under 90 minutes
  Good 1 =rating of 3 stars or better 0 =any lower rating
    Details  
One statistician movie fan decided to use statistics to study the movie ratings in his favorite movie guide, Movie and Video Guide (1996), by Leonard Maltin. Maltin rates movies on a one-star to four-star system, in increments of half-stars, with higher numbers being better. The guide also includes additional information on each film. The statistician used a random number generator to select a simple random sample of 100 movies rated by the Guide.    Source  
Data from Leonard Maltin's Movie and Video Guide (1996)"
"Stat2Data-FinalFourIzzo","Stat2Data","FinalFourIzzo","NCAA Final Four by Seed and Tom Izzo (through 2010)",1664,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourIzzo.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourIzzo.html","FinalFourIzzo R Documentation   NCAA Final Four by Seed and Tom Izzo (through 2010)   Description  
NCAA Final Four by seed with indicator for Tom Izzo's teams from 1985 - 2010.    Format  
A dataset with 1664 observations on the following 4 variables.   
  Year Year (1985 - 2010)
  Seed Seed in NCAA men's basketball tournament: 1 to 16
  Final4 1 =made Final Four or 0 =did not make Final Four
  Izzo 1 =team coached by Tom Izzo or 0 =not an Izzo team
    Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset is the same as FinalFourLong, except the data starts in 1985 and we have a extra column that is an indicator for Michigan State teams coached by Tom Izzo.   
Updated to FinalFourIzzo17 in second edition.    Source  
Final Four teams and their seed can be found at
 http://www.championshiphistory.com/ncaahoops.php."
"Stat2Data-FinalFourIzzo17","Stat2Data","FinalFourIzzo17","NCAA Final Four by Seed and Tom Izzo (through 2017)",2112,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourIzzo17.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourIzzo17.html","FinalFourIzzo17 R Documentation   NCAA Final Four by Seed and Tom Izzo (through 2017)   Description  
NCAA Final Four by seed with indicator for Tom Izzo's teams for 1985 - 2017    Format  
A data frame with 2112 observations on the following 4 variables.    Year
Year 1985 - 2017   Seed
Seed in NCAA men's basketball tournament: 1 to 16   Final4
1 =made Final Four or 0 =did not make Final Four   Izzo
1 =team coached by Tom Izzo or 0 =not an Izzo team     Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset is an extention of FinalFourIzzo (that ended in 2017) and the same as FinalFourLong2017, except the data starts in 1985 and we have an extra column that is an indicator for Michigan State teams coached by Tom Izzo.    Source  
Final Four teams and their seed can be found at http://www.championshiphistory.com/ncaahoops.php"
"Stat2Data-FinalFourLong","Stat2Data","FinalFourLong","NCAA Final Four by Seed (Long Version through 2010)",2048,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourLong.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourLong.html","FinalFourLong R Documentation   NCAA Final Four by Seed (Long Version through 2010)   Description  
NCAA Final Four by seed with individual cases for each team each year    Format  
A data frame with 2048 observations on the following 3 variables.   
  Year Year (1979 - 2010)
  Seed Seed in NCAA men's basketball tournament: 1 to 16
  Final4 1 =made Final Four or 0 =did not make Final Four
    Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset has a row (case) for each team in the NCAA Division I Men's Basketball tournament from 1979 to 2010 along with its seed and an indicator for whether the team made the Final Four that year.   
Updated to FinalFourLong17 in second edition.    Source  
Final Four teams and their seed can be found at
 http://www.championshiphistory.com/ncaahoops.php."
"Stat2Data-FinalFourLong17","Stat2Data","FinalFourLong17","NCAA Final Four by Seed (Long Version through 2017)",2496,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourLong17.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourLong17.html","FinalFourLong17 R Documentation   NCAA Final Four by Seed (Long Version through 2017)   Description  
NCAA Final Four by seed with individual cases for each team each year    Format  
A data frame with 2496 observations on the following 4 variables.    Year
Year (1979 - 2017)   Seed
Seed in NCAA men's basketball tournament: 1 to 16   Final4
1 =made Final Four or 0 =did not make Final Four     Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset has a row (case) for each team in the NCAA Division I Men's Basketball tournament from 1979 to 2017 along with its seed and an indicator for whether the team made the Final Four that year. This dataset is an extention of FinalFourLong (that went through 2010).    Source  
Final Four teams and their seed can be found at
 http://www.championshiphistory.com/ncaahoops.php"
"Stat2Data-FinalFourShort","Stat2Data","FinalFourShort","CAA Final Four by Seed (Short Version through 2010)",512,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourShort.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourShort.html","FinalFourShort R Documentation   CAA Final Four by Seed (Short Version through 2010)   Description  
NCAA Final Four participation summarized each year by seed    Format  
A data frame with 512 observations on the following 4 variables.   
  Year Year (1979 - 2010)
  Seed Seed in NCAA men's basketball tournament: 1 to 16
  In Number of teams at that seed who made the Final Four that year
  Out Number of teams at that seed who did not made the Final Four that year
    Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset is similar to FinalFourLong, except that each row combines the count of the results (make/don't make the Final Four) for each seed, so that In+Out= 4 for each row.   
Updated to FinalFourShort17 in second edition.    Source  
Final Four teams and their seed can be found at
 http://www.championshiphistory.com/ncaahoops.php."
"Stat2Data-FinalFourShort17","Stat2Data","FinalFourShort17","NCAA Final Four by Seed (Short Version through 2017)",624,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FinalFourShort17.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FinalFourShort17.html","FinalFourShort17 R Documentation   NCAA Final Four by Seed (Short Version through 2017)   Description  
NCAA Final Four participation summarized each year by seed    Format  
A data frame with 624 observations on the following 4 variables.    Year
Year 1979 to 2017   Seed
Seed in NCAA men's basketball tournament: 1 to 16   In
Number of teams at that seed who made the Final Four that year   Out
Number of teams at that seed who did not made the Final Four that year     Details  
Each year 64 college teams are selected for the NCAA Division I Men's Basketball tournament, with 16 teams placed in each of four regions. Within each region the teams are seeded from 1 to 16, with the (presumed) best team as the 1 seed and the (presumed) weakest team as the 16 seed; this practice of seeding teams began in 1979 for the NCAA tournament. Only one team from each region (so four teams each year) advances to the Final Four. This dataset is similar to FinalFourLong2017, except that each row combines the count of the results (make/don't make the Final Four) for each seed, so that In+Out= 4 for each row. This dataset is an extention of FinalFourShort (that went though 2010).    Source  
Final Four teams and their seed can be found at
 http://www.championshiphistory.com/ncaahoops.php"
"Stat2Data-Fingers","Stat2Data","Fingers","Finger Tap Rates",12,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Fingers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Fingers.html","Fingers R Documentation   Finger Tap Rates   Description  
Finger tap rates after drug administration    Format  
A data frame with 12 observations on the following 4 variables.    Subject
Subject code ( I , II , III , or IV )   Drug
Drug administered ( Ca =caffeine, Pl =placebo, or Th =theobromine)   TapRate
Finger taps in a fixed time interval     Details  
Scientists Scott and Chen, published research that compared the effects of caffeine with those of theobromine (a similar chemical found in chocolate) and with those of a placebo. Their experiment used four human subjects, and took place over several days. Each day each subject swallowed a tablet containing one of caffeine, theobromine, or the placebo. Two hours later they were timed while tapping a finger in a specified manner (that they had practiced earlier, to control for learning effects). The response is the number of taps in a fixed time interval.   
Renamed FranticFingers in second edition.    Source  
The data was found in Statistics in Biology, Vol. 1, by C. I. Bliss (1967), New York: McGraw Hill.   
The original article is Scott, C. and Chen, K. (1944) ""Comparison of the action of 1-ethyl theobromine and caffeine in animals and man,"" Journal of Pharmacological Experimental Therapy, v. 82, pp 89-97."
"Stat2Data-FirstYearGPA","Stat2Data","FirstYearGPA","First Year GPA for College Students",219,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FirstYearGPA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FirstYearGPA.html","FirstYearGPA R Documentation   First Year GPA for College Students   Description  
Predicting first-year college GPA    Format  
A data frame with 219 observations on the following 10 variables.   
  GPA First-year college GPA on a 0.0 to 4.0 scale
  HSGPA High school GPA on a 0.0 to 4.0 scale
  SATV Verbal/critical reading SAT score
  SATM Math SAT score
  Male 1 = male, 0 = female
  HU Number of credit hours earned in humanities courses in high school
  SS Number of credit hours earned in social science courses in high school
  FirstGen 1 = student is the first in her or his family to attend college, 0 =otherwise
  White 1 = white students, 0 = others
  CollegeBound 1 =attended a high school where >=50% students intended to go on to college, 0 =otherwise
    Details  
The data in FirstYearGPA contains information from a sample of 219 first year students at a midwestern college that might be used to build a model to predict their first year GPA.    Source  
A sample from a larger set of data collected in 1996 by a professor at this college."
"Stat2Data-FishEggs","Stat2Data","FishEggs","Fertility of Fish Eggs",35,4,2,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FishEggs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FishEggs.html","FishEggs R Documentation   Fertility of Fish Eggs   Description  
Fertility measurement for eggs from a sample of 35 lake trout    Format  
A data frame with 35 observations on the following 4 variables.   
  Age Age of the fish (in years)
  PctDM Percentage of the total egg material that is solid
  Month Month fish was caught: Sep =September or Nov =November
  Sept Indicator with 1 =September or 0 =November
    Details  
Researchers collected samples of female lake trout from Lake Ontario in September and November of 2002 through 2004. A goal of the study was to investigate the fertility of fish that had been stocked in the lake. One measure of the viability of fish eggs is percent dry mass (PctDM) which reflects the energy potential stored in the eggs by recording the percentage of the total egg material that is solid. Values of the PctDM for a sample of 35 lake trout (14 in September and 21 in November) are given in this dataset along with the age (in years) of the fish.    Source  
Lantry, OGorman, and Machut (2008) ""Maternal Characteristics versus Egg Size and Energy Density,"" Journal of Great Lakes Research 34(4): 661-674."
"Stat2Data-Fitch","Stat2Data","Fitch","Body Measurements of Mammal Species",28,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Fitch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Fitch.html","Fitch R Documentation   Body Measurements of Mammal Species   Description  
Body measurements for a sample of 28 mammal species from a Fitch paper on acoustic allometry    Format  
A data frame with 28 observations on the following 5 variables.    Species
species of mammal   Order
Order ( Carnivora or Primates )   Wt
Body weight (in kg)   Skull
Skull length (in cm)   Palate
Palate length (in cm)     Details  
Data on mammal species from a Zoology paper about acoustic allometry by W. Tecumseh Fitch.    Source  
Fitch, W. Tecumseh (2000), ""Skull dimensions in relation to body size in nonhuman mammals: The causal bases for acoustic allometry,"" Zoology, 103, 40-58."
"Stat2Data-FlightResponse","Stat2Data","FlightResponse","Response of Migratory Geese to Helicopter Overflights",464,7,1,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FlightResponse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FlightResponse.html","FlightResponse R Documentation   Response of Migratory Geese to Helicopter Overflights   Description  
Flight response of Pacific Brant to overflights of helicopters    Format  
A dataset with 464 observations on the following 7 variables.   
  FlockID Flock ID
  Altitude Altitude of the overflight by the helicopter (in 100m)
  Lateral Lateral distance (in 100m) between the aircraft and flock
  Flight 1 =more than 10% of flock flies away or 0 =otherwise
  AltLat Product of Altitude x Lateral
  AltCat Altitude categories: low =under 3, mid =3 to 6, high =over 6
  LatCat Lateral categories: 1 under 10 to 4 =over 30
    Details  
A 1994 study collected data on the effects of air traffic on the behavior of the Pacific Brant (a small migratory goose). The data represent the flight response to helicopter ""overflights"" to see what the relationship between the proximity of a flight, both lateral and altitudinal, would be to the propensity of the Brant to flee the area. For this experiment, air traffic was restricted to helicopters because previous study had ascertained that helicopters created more radical flight response than other aircraft. The data are in FlightResponse. Each case represents a flock of Brant that has been observed during one overflight in the study. Flocks were determined observationally as contiguous collections of Brants, flock sizes varying from 10 to 30,000 birds.    Source  
Data come from the book Statistical Case Studies: A Collaboration Between Academe and Industry, Roxy Peck, Larry D. Haugh, and Arnold Goodman, editors; SIAM and ASA, 1998."
"Stat2Data-FloridaDP","Stat2Data","FloridaDP","Florida Death Penalty Cases",326,4,4,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FloridaDP.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FloridaDP.html","FloridaDP R Documentation   Florida Death Penalty Cases   Description  
Florida death penalty cases by race of defendant and victim    Format  
A data frame with 326 observations on the following 4 variables.    Penalty
Was death penalty given? ( No or Yes )   Defendant
Race of the defendant ( Black or White )   White.Victim
Was the victim white? ( 1 =yes or 0 =no)   Black.Victim
Was the victim black? ( 1 =yes or 0 =no)     Details  
Mike Radelet's data on imposition of the death penalty for murderers in Florida broken down by race of the victim and defendant.    Source  
Radelet, M. (1981), ""Racial Characteristics and Imposition of the Death Penalty,"" American Sociological Review, 46, 918-927."
"Stat2Data-Fluorescence","Stat2Data","Fluorescence","Measuring Calcium Binding to Proteins",51,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Fluorescence.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Fluorescence.html","Fluorescence R Documentation   Measuring Calcium Binding to Proteins   Description  
Data from an experiment on calcium binding to proteins    Format  
A data frame with 51 observations on the following 2 variables.   
  Calcium Log of free calcium concentration
  ProteinProp Proportion of protein bound to calcium
    Details  
Suzanne Rohrback used a novel approach in a series of experiments to examine calcium binding proteins.    Source  
Thanks to Suzanne Rohrback for providing these data from her honors experiments at Kenyon College."
"Stat2Data-FranticFingers","Stat2Data","FranticFingers","Finger Tap Rates",12,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FranticFingers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FranticFingers.html","FranticFingers R Documentation   Finger Tap Rates   Description  
Finger tap rates after drug administration    Format  
A data frame with 12 observations on the following 4 variables.    ID
Case ID   Rate
Finger taps in a fixed time interval   Subj
Subject code ( A , B , C , or D )   Drug
Drug administered ( Ca =caffeine, Pl =placebo, or Th =theobromine)     Details  
Scientists Scott and Chen published research that compared the effects of caffeine with those of theobromine (a similar chemical found in chocolate) and with those of a placebo. Their experiment used four human subjects and took place over several days. Each day each subject swallowed a tablet containing one of caffeine, theobromine, or the placebo. Two hours later they were timed while tapping a finger in a specified manner (that they had practiced earlier, to control for learning effects). The response is the number of taps in a fixed time interval.    Source  
The data was found in Statistics in Biology, Vol. 1, by C. I. Bliss (1967), New York: McGraw Hill.   
The original article is Scott, C.C. and Chen, K. K. (1944), ""Comparison of the action of 1-ethyl theobromine and caffeine in animals and man,"" Journal of Pharmacological Experimental Therapy, v. 82, pp 89-97."
"Stat2Data-FruitFlies","Stat2Data","FruitFlies","Fruit Fly Sexual Activity and Longevity",125,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FruitFlies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FruitFlies.html","FruitFlies R Documentation   Fruit Fly Sexual Activity and Longevity   Description  
Sexual activity and lifetimes of fruit flies    Format  
A data frame with 125 observations on the following 7 variables.   
  ID a numeric vector
  Partners Number of female partners: 0, 1, or 8
  Type 0 =pregnant, 1 =virgin, 9 =none
  Longevity Lifespan (in days)
  Thorax Length of thorax (in mm)
  Sleep Percent of day sleeping
  Treatment 1 pregnant , 1 virgin , 8 pregnant , 8 virgin , or none
    Details  
Hanley and Shapiro (1994) report on a study conducted by Partridge and Farquhar (1981) about the sexual behavior of fruit flies. It was already known that increased reproduction leads to shorter life spans for female fruit flies. But the question remained whether an increase in sexual activity would also reduce the life spans of male fruit flies. The researchers designed an experiment to answer this question. They had a total of 125 male fruit flies to use and they randomly assigned each of the 125 to one of the following five groups.    Source  
The data are given as part of the data archive on the Journal of Statistics Education website and can be found on the page
 http://www.amstat.org/publications/jse/jse_data_archive.htm.    References  
Hanley and Shapiro, (1994) ""Sexual Activity and the Lifespan of Male Fruitflies: A Dataset That Gets Attention,"" Journal of Statistics Education v.2, n.1
 http://www.amstat.org/publications/jse/v2n1/datasets.hanley.html"
"Stat2Data-FruitFlies2","Stat2Data","FruitFlies2","Fruit Fly Sexual Activity and Male Competition",201,7,2,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FruitFlies2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FruitFlies2.html","FruitFlies2 R Documentation   Fruit Fly Sexual Activity and Male Competition   Description  
Results from an experiment on male fruit flies with different levels of sexual activity and competition from other males    Format  
A data frame with 201 observations on the following 7 variables.    Mated
Was the fly allowed mating opportunities? ( n or y )   Alone
Did the fly live alone? ( y =yes or n = no, lived near another male)   Mating
How many mating opportunities was the fly given?   Total
Total duration of mating time over all opportunities (in seconds)   Size
Size of the thorax (in mm)   Lifespan
Lifespan (in hours, starting at the 12th day)   Activity
Number of times a movement detector was tripped starting in the 12th day     Details  
Researchers randomly assigned virgin male fruit flies to one of two treatments: live alone or live in an environment where they can sense one other male fly. Flies were randomly allocated to either have mating opportunities with female flies or to not have such opportunities. Those flies that were given mating opportunities were given 3, 4, or 5 opportunities to mate (Mating measures this number). Researchers also measured size, lifespan and activity levels of the fruit flies.    Source  
The file we are using is the link called survival at
 http://rsbl.royalsocietypublishing.org/content/suppl/2013/02/25/rsbl.2012.1188.DC1.html   
The article talking about the data is at
 http://rsbl.royalsocietypublishing.org/content/9/2/20121188.full"
"Stat2Data-FunnelDrop","Stat2Data","FunnelDrop","Funnel Drop Times",120,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/FunnelDrop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/FunnelDrop.html","FunnelDrop R Documentation   Funnel Drop Times   Description  
Experiment with a ball swirling thorough a funnel    Format  
A data frame with 120 observations on the following 3 variables.    Funnel
Height of the funnel (inches)   Tube
Height of the drop tube (inches)   Time
Time (in seconds) for the ball to drop/swirl though the funnel     Details  
Data from a class experiment to see where a steel ball was rolled through a plastic tube into a long plastic funnel. The angle of the funnel and the angle of the tube with respect to the flat table could be adjusted by changing the height of either (Funnel measured from the table, Tube measured from the top of the funnel). The ball rolls down the tube, then swirls around the funnel until dropping out at the bottom. Total trip time was measured with a stopwatch. Heights were adjusted after every two drops in a randomized order.    Source  
The funnel dropping experiment was originally described in Gunter, B. (1993) ""Through a Funnel Slowly with Ball Bearing and Insight to Teach Experimental Design,"" The American Statistician, Vol. 47. These data come from a class experiment based on the setup in that article."
"Stat2Data-GlowWorms","Stat2Data","GlowWorms","Female Glow-worms",26,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/GlowWorms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/GlowWorms.html","GlowWorms R Documentation   Female Glow-worms   Description  
Brightness and fecundity of female glow-worms    Format  
A data frame with 26 observations on the following 2 variables.    Lantern
Length of glow lantern (in mm)   Eggs
Number of eggs laid     Details  
Data on 26 female glow-worms captured in Finland. Female glow-worms attract males by glowing with part of their abdomen (lantern). Researchers believe the brightness of glow might be related to mating success.    Source  
Hopkins J, Baudry G, Candolin U, Kaitala A. (2015), ""I'm sexy and I glow it: female ornamentation in a nocturnal capital breeder,"" Biol. Lett. 11: 20150599.
 http://dx.doi.org/10.1098/rsbl.2015.0599"
"Stat2Data-Goldenrod","Stat2Data","Goldenrod","Goldenrod Galls",1055,9,1,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Goldenrod.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Goldenrod.html","Goldenrod R Documentation   Goldenrod Galls   Description  
Measurements for a sample of goldenrod galls    Format  
A data frame with 1055 observations on the following 9 variables.   
  Gdiam03 Gall diameter in 2003 (in mm)
  Stdiam03 Stem diameter in 2003 (in mm)
  Wall03 Wall thickness in 2003 (in mm)
  Fate03 b =beetle present e =early death f =living fly larva g =living wasp o =pupal case u =unknown
  Gdiam04 Gall diameter in 2004 (in mm)
  Stdiam04 Stem diameter in 2004 (in mm)
  Wall04 Wall thickness in 2003 (in mm)
  Fate04 b =beetle present e =early death f =living fly larva g =living wasp o =pupal case u =unknown
  Fly04 Fly in 2004? n or y
    Details  
Biology students collected measurements on goldenrod galls at the Brown Family Environmental Center at Kenyon College.    Source  
Thanks to the Kenyon College Department of Biology for sharing these data."
"Stat2Data-GrinnellHouses","Stat2Data","GrinnellHouses","House Sales in Grinnell, Iowa",929,15,0,0,1,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/GrinnellHouses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/GrinnellHouses.html","GrinnellHouses R Documentation   House Sales in Grinnell, Iowa   Description  
Data on houses sold between 2005 and 2015 in Grinnell, Iowa    Format  
A data frame with 929 observations on the following 15 variables.    Date
Coded value for date of sale (Jan 1, 2005=16436)   Address
Street address of the house   Bedrooms
Number of bedrooms   Baths
Number of bathrooms   SquareFeet
The square footage of the home's living space   LotSize
Lot size (in acres)   YearBuilt
Year the house was built; many pre-1900 homes are listed as 1900   YearSold
The year the house was sold, for this case   MonthSold
The month the house was sold (1=Jan, 2=Feb, to 12=Dec)   DaySold
Day of the month the house was sold (1 to 31)   CostPerSqFt
SalePrice / SquareFeet (round to nearest penny)   OrigPrice
List price of the house when originally put on the market (dollars)   ListPrice
List price at the time of sale (dollars)   SalePrice
Sale price of the house (dollars)   SPLPPct
(Sale_Price / List_Price ) * 100     Details  
A local Grinnell realtor, Matt Karjalahti, put these data together to see what patterns might be found, perhaps with an improvement in how one sells houses or buys them. He asked Grinnell College economists, Lee Logan and Eric Ohrn, to help with the analysis and we obtained the data from them.    Source  
Thanks to Grinnell realtor Matt Karjalahti who originally collected the data and Grinnell College economists Lee Logan and Eric Ohrn who gave us the data."
"Stat2Data-Grocery","Stat2Data","Grocery","Grocery Sales and Discounts",36,5,0,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Grocery.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Grocery.html","Grocery R Documentation   Grocery Sales and Discounts   Description  
Grocery store sales with different discounts    Format  
A data frame with 36 observations on the following 5 variables.   
  Discount Amount of discount: 5.00% , 10.00% , or 15.00%
  Store Store number (1-12)
  Display Featured End of Aisl , Featured Middle of A , or Not Featured
  Sales Number sold during one week
  Price Wholesale price (in dollars)
    Details  
Grocery stores and product manufacturers are always interested in how well the products on the store shelves sell. An experiment was designed to test whether the amount of discount given on products affected the amount of sales of that product. There were three levels of discount, 5%, 10%, and 15%, and sales were held for a week. The total number of products sold during the week of the sale was recorded. The researchers also recorded the wholesale price of the item put on sale.    Source  
These data are not real, though they are simulated to approximate an actual study. The data come from John Grego, Director of the Stat Lab at University of South Carolina."
"Stat2Data-Gunnels","Stat2Data","Gunnels","Are Gunnels Present at Shoreline?",1592,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Gunnels.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Gunnels.html","Gunnels R Documentation   Are Gunnels Present at Shoreline?   Description  
Presence/absence of gunnels (eels) at shoreline quadrats    Format  
A data frame with 1592 observations on the following 10 variables.   
  Gunnel 1= gunnel present in the quadrat or 0=gunnel absent
  Time Minutes after midnight
  Fromlow Time in minutes from low tide
  Slope Slope (to nearest 10 degrees) perpendicular to waterline
  Rw Percentage cover in quadrat of rockweed/algae/plants
  Amphiso Density of crustacean food: 0=none to 4=high
  Subst Substratum: 1=solid rock, 2=rocky cobbles, 3=mixed pebbles/sand, 4=fine sand,
  5=mud, 6=mixed mud/shell detritus, 7=cobbles on solid rock, 8=cobbles on mixed pebbles/sand,
  9=cobbles on fine sand, 10=cobbles on mud, 11=cobbles on mixed mud/shell detritus,
  12=cobbles on shell detritus, 13=shell detritus
  Pool Standing water deep? 1=yes or 2=no
  Water Standing water in the quadrat? 1=yes or 2=no
  Cobble Rocky cobbles? 1=yes or 2=no
    Details  
This dataset comes from a study on the habitat preferences of a species of eel, called a gunnel. Biologist Jake Shorty sampled quadrats along a coastline and recorded whether or not the species was found in the quadrat.    Source  
Thanks to Jake Shorty, Bowdoin biology student, for this dataset."
"Stat2Data-Handwriting","Stat2Data","Handwriting","Guess Author's Sex from Handwriting?",204,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Handwriting.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Handwriting.html","Handwriting R Documentation   Guess Author's Sex from Handwriting?   Description  
Survey data to see if subjects can guess author's sex from handwriting specimens    Format  
A data frame with 204 observations on the following 8 variables.    Individual
Survey Respondent Number   Gender
Gender of Respondent ( 0 = male, 1 = female)   Survey1
Percent correct on Survey 1   Survey2
Percent correct on Survey 2   FemaleID
Percent correct in identifying female specimens on Survey 1   MaleID
Percent correct in identifying male specimens on Survey 1   Both
Percent correctly identified on Survey 1 AND Survey 2   DIFF
Survey1 - Survey2     Details  
Bradley and colleagues at Clarke University gave two identical surveys to a sample of 203 students (each student did the survey twice). Each survey contains 25 writing specimens and students were asked to identify whether the author is male or female. Of the 25 specimens, 12 are written by a female, 13 by a male.   
An example of the survey form can be found at
 https://docs.google.com/forms/d/1sO6vlsozsORbqaCTsA7Ta0qZL7_6_MCEPJ7tYeKYyvI/viewform    Source  
Bradley, S., (2015), ""Handwriting and Gender: A Multi-use Dataset"", JSE (Datasets and Stories). March 2015.   
http://www.amstat.org/publications/jse/v23n1/bradley.pdf"
"Stat2Data-Hawks","Stat2Data","Hawks","Measurements on Three Hawk Species",908,19,1,0,6,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Hawks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Hawks.html","Hawks R Documentation   Measurements on Three Hawk Species   Description  
Data for a samples of hawks from three different species    Format  
A data frame with 908 observations on the following 19 variables.   
  Month 8 =September to 12 =December
  Day Date in the month
  Year Year: 1992-2003
  CaptureTime Time of capture (HH:MM)
  ReleaseTime Time of release (HH:MM)
  BandNumber ID band code
  Species CH =Cooper's, RT =Red-tailed, SS =Sharp-Shinned
  Age A =Adult or I =Imature
  Sex F =Female or M =Male
  Wing Length (in mm) of primary wing feather from tip to wrist it attaches to
  Weight Body weight (in gm)
  Culmen Length (in mm) of the upper bill from the tip to where it bumps into the fleshy part of the bird
  Hallux Length (in mm) of the killing talon
  Tail Measurement (in mm) related to the length of the tail (invented at the MacBride Raptor Center)
  StandardTail Standard measurement of tail length (in mm)
  Tarsus Length of the basic foot bone (in mm)
  WingPitFat Amount of fat in the wing pit
  KeelFat Amount of fat on the breastbone (measured by feel
  Crop Amount of material in the crop, coded from 1 =full to 0 =empty
    Details  
Students and faculty at Cornell College in Mount Vernon, Iowa, collected data over many years at the hawk blind at Lake MacBride near Iowa City, Iowa. The data set that we are analyzing here is a subset of the original data set, using only those species for which there were more than 10 observations. Data were collected on random samples of three different species of hawks: Red-tailed, Sharp-shinned, and Cooper's hawks.    Source  
Many thanks to the late Professor Bob Black at Cornell College for sharing these data with us."
"Stat2Data-HawkTail","Stat2Data","HawkTail","Tail Lengths of Hawks",838,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HawkTail.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HawkTail.html","HawkTail R Documentation   Tail Lengths of Hawks   Description  
Tail lengths for two hawk species    Format  
A data frame with 838 observations on the following 2 variables.   
  Species RT =Red-tailed, SS =Sharp-shinned
  Tail Length of tail (in mm)
    Details  
Tail lengths measured for a sample of 838 hawks observed in Mount Vernon, Iowa. Note: HawkTail2 has these data in unstacked format and they are a subset of the data in Hawks which has a third species (Cooper's hawk).    Source  
Observations by students and faculty at Cornell College."
"Stat2Data-HawkTail2","Stat2Data","HawkTail2","Tail Lengths of Hawks (Unstacked)",577,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HawkTail2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HawkTail2.html","HawkTail2 R Documentation   Tail Lengths of Hawks (Unstacked)   Description  
Tail lengths for two hawk species    Format  
A data frame with observations on the following 2 variables.   
  Tail_RT Tail length (in mm) for a sample of Red-tailed hawks
  Tail_SS Tail length (in mm) for a sample of Sharp-shinned hawks
    Details  
Tail lengths measured for a sample of hawks observed in Mount Vernon, Iowa. Note: HawkTail has similar data in stacked format. The Hawks dataset has more variables and a third species (Cooper's hawk).    Source  
Observations by students and faculty at Cornell College."
"Stat2Data-HearingTest","Stat2Data","HearingTest","Correctly Identified Words in a Hearing Test",96,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HearingTest.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HearingTest.html","HearingTest R Documentation   Correctly Identified Words in a Hearing Test   Description  
Percentaged of correctly identified words in a hearing test    Format  
A data frame with 96 observations on the following 3 variables.   
  Subj Subject number (1 - 24)
  List List of words: L1 L2 L3  L4
  Percent Percent (out of 50) of words correctly identified
    Details  
Audiologists use standard lists of 50 words to test hearing; the words are calibrated, using subjects with normal hearing, to make all 50 words on the list equally hard to hear. The goal of the study described here was to see how four such lists, denoted by L1-L4 in this dataset, compared when played at low volume with a noisy background. The response is the percentage of words identified correctly.    Source  
Data downloaded from DASL at http://lib.stat.cmu.edu/DASL/Datafiles/Hearing.html.    References  
Loven, F. (1981), ""A Study of the Interlist Equivalency of the CID W-22 Word List Presented in Quiet and in Noise."" Unpublished MS Thesis, University of Iowa."
"Stat2Data-HeatingOil","Stat2Data","HeatingOil","Heating Oil Consumption",408,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HeatingOil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HeatingOil.html","HeatingOil R Documentation   Heating Oil Consumption   Description  
Monthly US residential consumption of fuel oil (1983-2016)    Format  
A data frame with 408 observations on the following 4 variables.    Year
Year (1983 to 2016)   Month
Month (1=Jan through 12=Dec)   t
Time index (1 to 408)   FuelOil
Residential consumption of fuel oil (in 1,000 barrels/day)     Details  
U.S. residential consumption of distillate fuel oil each month from January 1983 through December 2016.    Source  
U.S. Energy Information Administration website, https://www.eia.gov/totalenergy/data/monthly/index.php"
"Stat2Data-HighPeaks","Stat2Data","HighPeaks","Characteristics of Adirondack Hiking Trails",46,6,0,0,1,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HighPeaks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HighPeaks.html","HighPeaks R Documentation   Characteristics of Adirondack Hiking Trails   Description  
Data on hiking trails for each of the 46 ""High Peaks"" in the Adirondack mountains    Format  
A data frame with 46 observations on the following 6 variables.   
  Peak Name of the mountain
  Elevation Elevation at the highest point (in feet)
  Difficulty Rating of difficulty of the hike: 1 (easy) to 7 (most difficult)
  Ascent Vertical ascent (in feet)
  Length Length of hike (in miles)
  Time Expected trip time (in hours)
    Details  
Forty-six mountains in the Adirondacks of upstate New York are known as the High Peaks with elevations near or above 4000 feet (although modern measurements show a couple of the peaks are actually slightly under 4000 feet). A goal for hikers in the region is to become a ""46er"" by scaling each of these peaks. This dataset gives information about the hiking trails up each of these peaks.    Source  
High Peaks data avaialble at http://www.adirondack.net/tour/hike/highpeaks.cfm. Thanks to Jessica Chapman at St. Lawrence University for recommending this dataset."
"Stat2Data-Hoops","Stat2Data","Hoops","Grinnell College Basketball Games",147,22,4,0,1,0,21,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Hoops.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Hoops.html","Hoops R Documentation   Grinnell College Basketball Games   Description  
Data from games played by the Grinnell College men's basketball team between 1997 and 2006    Format  
A data frame with 147 observations on the following 22 variables.   
  Game An ID number assigned to each game
  Opp Name of the opponent school for the game
  Home Indicator variable where 1 = home game and 0 = away game
  OppAtt Number of field goal attempts by the opposing team
  GrAtt Number of field goal attempts by Grinnell
  Gr3Att Number of three-point field goal attempts by Grinnell
  GrFT Number of free throw attempts by Grinnell
  OppFT Number of free throw attempts by the opponent
  GrRB Total number of Grinnell rebounds
  GrOR Number of Grinnell offensive rebounds
  OppDR Number of defensive rebounds the opposing team had
  OppPoint Points scored in the game by the opponent
  GrPoint Points scored in the game by Grinnell
  GrAss Number of assists Grinnell had in the game
  OppTO Number of turnovers the opposing team gave up
  GrTO Number of turnovers Grinnell gave up
  GrBlocks Number of blocks Grinnell had in the game
  GrSteal Number of steals Grinnell had in the game
  X40Point Indicator variable that is 1 if some Grinnell player scored 40 or more points
  X30Point Indicator variable that is 1 if some Grinnell player scored 30 or more points
  WinLoss 1 =Grinnell win or 0 =Grinnell loss
  PtDiff Point differential for the game (Grinnell score minus Opponent's score)
    Details  
Since 1991, David Arseneault, men's basketball coach of Grinnell College, has developed a unique, fast-paced style of basketball that he calls ""the system."" This dataset comes from the 147 games the Grinnell team played within its athletics conference between the 1997-98 season through the 2005-06 season.    Source  
These data were collected by Grinnell College students Eric Ohrn and Ben Johannsen."
"Stat2Data-HorsePrices","Stat2Data","HorsePrices","Prices of Horses",50,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HorsePrices.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HorsePrices.html","HorsePrices R Documentation   Prices of Horses   Description  
Price and related characteristics of horses listed for sale on the internet    Format  
A data frame with 50 observations on the following 5 variables.   
  HorseID ID code for each horse
  Price Price (in dollars)
  Age Age of the horse (in years)
  Height Height of the horse (in hands)
  Sex f =female m =male
    Details  
Undergraduate students at Cal Poly collected data on prices of 50 horses advertised for sale on the internet. Predictor variables of price include the age and height of the horse (in hands), as well as its sex.    Source  
Cal Poly students using a horse sale website."
"Stat2Data-Houses","Stat2Data","Houses","House Prices, Sizes, and Lot Areas",20,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Houses.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Houses.html","Houses R Documentation   House Prices, Sizes, and Lot Areas   Description  
Selling price and characteristics for a sample of 20 houses in a small town    Format  
A data frame with 20 observations on the following 3 variables.   
  Price Selling price (in dollars)
  Size Size of the house (in square feet)
  Lot Area of the house's lot (in square feet)
    Details  
This dataset contains selling prices for 20 houses that were sold in 2008 in a small midwestern town. The file also contains data on the size of each house (in square feet) and the size of the lot (in square feet) that the house is on.   
Updated to HousesNY in second edition.    Source  
Data collected from zillow.com in June 2008."
"Stat2Data-HousesNY","Stat2Data","HousesNY","House Prices in Rural NY",53,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/HousesNY.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/HousesNY.html","HousesNY R Documentation   House Prices in Rural NY   Description  
House prices for a sample of houses in Canton NY    Format  
A data frame with 53 observations on the following 5 variables.    Price
Estimated price (in $1,000's)   Beds
Number of bedrooms   Baths
Number of bathrooms   Size
Floor area of the house (in 1,000 square feet)   Lot
Size of the lot (in acres)     Details  
Data scraped from Zillow.com for a sample of houses near the 13617 area code (Canton, NY a small town in upstate NY). Houses on lots bigger than five acres (often farms) were excluded.    Source  
Data scraped from the Zillow.com website using tools an app at http://myslu.stlawu.edu/~clee/dataset/zillow/ (April 2017)"
"Stat2Data-ICU","Stat2Data","ICU","Intensive Care Unit Patients",200,9,4,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ICU.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ICU.html","ICU R Documentation   Intensive Care Unit Patients   Description  
Data for a sample of 200 patients at an Intensive Care Unit (ICU)    Format  
A data frame with 200 observations on the following 9 variables.   
  ID Patient ID code
  Survive 1 =patient survived to discharge or 0 =patient died
  Age Age (in years)
  AgeGroup 1 = young (under 50), 2 = middle (50-69), 3 = old (70+)
  Sex 1 =female or 0 =male
  Infection 1 =infection suspected or 0 =no infection
  SysBP Systolic blood pressure (in mm of Hg)
  Pulse Heart rate (beats per minute)
  Emergency 1 =emergency admission or 0 =elective admission
    Details  
This dataset contains information for a sample of 200 patients who were part of a larger study conducted in a hospital's Intensive Care Unit (ICU). Since an ICU often deals with serious, life-threatening cases, a key variable to study is patient survival, which is coded in the Survive variable as 1 if the patient lived to be discharged and 0 if the patient died.    Source  
Data downloaded from The Data and Story Library (DASL), http://lib.stat.cmu.edu/DASL/Datafiles/ICU.html."
"Stat2Data-InfantMortality2010","Stat2Data","InfantMortality2010","Infant Mortality Rates",10,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/InfantMortality2010.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/InfantMortality2010.html","InfantMortality2010 R Documentation   Infant Mortality Rates   Description  
Infant mortality rates in the United States by decade (1920-2010)    Format  
A data frame with 10 observations on the following 2 variables.    Mortality
Deaths within one year of birth (per 1000 births)   Year
Year (1920-2010 by decades)     Details  
Infant mortality (deaths within one year of birth per 1,000 births) in the US from 1920 - 2010 (by decade).    Source  
CDC National Vital Statistics Reports at http://www.cdc.gov/nchs/data/nvsr/nvsr57/nvsr57_14.pdf and https://www.cdc.gov/nchs/data/nvsr/nvsr64/nvsr64_09.pdf"
"Stat2Data-Inflation","Stat2Data","Inflation","Monthly Consumer Price Index (2009-2016)",96,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Inflation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Inflation.html","Inflation R Documentation   Monthly Consumer Price Index (2009-2016)   Description  
Consumer Price Index (CPI) each month for 2009 through 2016    Format  
A data frame with 96 observations on the following 5 variables.    Month
Month: 1 =January to 12 =December   Year
Year (2009 to 2016)   CPI
Consumer Price Index (base=100 in 1984)   CPIPctDiff
Monthly percent change in CPI   t
Time index (1 to 96)     Details  
Monthly Consumer Price Index for 2009 to 2016 as produced by the Bureau of Labor Statistics (Series Id. CUUR0000SA0). Based on prices for all items in U.S. city average for all consumers (not seasonally) Base period is 1982-1984-100.    Source  
Data downloaded from Bureau of Labor Statistics at
 https://www.bls.gov/data/"
"Stat2Data-InsuranceVote","Stat2Data","InsuranceVote","Congressional Votes on a Health Insurance Bill",435,9,5,0,2,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/InsuranceVote.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/InsuranceVote.html","InsuranceVote R Documentation   Congressional Votes on a Health Insurance Bill   Description  
Congressional votes on an ObamaCare health insurance bill in 2009    Format  
A dataset with 435 observations on the following 9 variables.   
  Party Party affiliation: D =Democrat or R =Republican
  Dist. Congressional district (State-Number)
  InsVote Vote on the health insurance bill: 1 =yes or 0 =no
  Rep Indicator for Republicans
  Dem Indicator for Democrats
  Private Percentage of non-senior citizens in district with private health insurance
  Public Percentage of non-senior citizens in district with public health insurance
  Uninsured Percentage of non-senior citizens in district with no health insurance
  Obama District winner in 2008 presidential election: 1 =Obama 0 =McCain
    Details  
On 7 November 2009 the U.S. House of Representatives voted, by the narrow margin of 220-215, for a bill to enact health insurance reform. Most Democrats voted yes while almost all Republicans voted no. This dataset contains data for each of the 435 representatives.    Source  
Insurance data are from the American Community Survey
 (http://www.census.gov/acs/www/data_documentation/data_main/). Roll call of congressional votes on this bill can be found at
 http://clerk.house.gov/evs/2009/roll887.xml."
"Stat2Data-IQGuessing","Stat2Data","IQGuessing","Guess IQ from a Photo?",40,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/IQGuessing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/IQGuessing.html","IQGuessing R Documentation   Guess IQ from a Photo?   Description  
True IQ and guessed IQ (from a photo) for 40 women    Format  
A data frame with 40 observations on the following 3 variables.    Age
Age of woman   GuessIQ
Guessed IQ   TrueIQ
Actual IQ     Details  
One hundred sixty raters (75 men and 85 women) took part in judging intelligence (on a 1=high to 7=low scale) based on photographs of students. The ratings were converted to z-scores and then put on an IQ scale to compare to actual measured IQ. There were photos of 80 students, 40 men and 40 women. This data set contains data for the 40 women.    Source  
Kleisner K, Chvatalova V, Flegr J (2014), ""Perceived Intelligence Is Associated with Measured Intelligence in Men but Not Women,"" PLoS ONE 9(3): e81237. doi:10.1371/journal.pone.0081237."
"Stat2Data-Jurors","Stat2Data","Jurors","Reporting Rates for Jurors",52,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Jurors.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Jurors.html","Jurors R Documentation   Reporting Rates for Jurors   Description  
Reporting rates for bi-weekly jury pools in Franklin County Court (Columbus, OH).    Format  
A data frame with 52 observations on the following 4 variables.   
  Period Sequential 2-week periods ove the course of a year
  PctReport Percentage of selected jurors who report
  Year 1998 or 2000
  I2000 Indicator for data from the year 2000
    Details  
Tom Shields, jury commissioner for the Franklin County Municipal Court in Columbus, Ohio, is responsible for making sure that the judges have enough potential jurors to conduct jury trials. Jury duty for this court is two weeks long, so Tom must bring together a new group of potential jurors twenty-six times a year. Random sampling methods are used to obtain a sample of registered voters in Franklin County every two weeks, and these individuals are sent a summons to appear for jury duty. One of the most difficult aspects of Tom's job is to get those registered voters who receive a summons to actually appear at the courthouse for jury duty. This dataset contains the 1998 and 2000 data for the percentages of individuals who reported for jury duty after receiving a summons. The reporting dates vary slightly from year to year, so they are coded sequentially from 1, the first group to report in January, to 26, the last group to report in December. A variety of methods were used after 1998 to try to increase participation rates.    Source  
Franklin County Municipal Court"
"Stat2Data-Kershaw","Stat2Data","Kershaw","Kershaw Pitch Data",3402,24,4,0,11,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Kershaw.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Kershaw.html","Kershaw R Documentation   Kershaw Pitch Data   Description  
Pitch-by-pitch data for baseball pitcher Clayton Kershaw in the 2013 season    Format  
A data frame with 3402 observations on the following 24 variables.    BatterNumber
Number of batters faced so far that game   Outcome
One of 14 possible results for a pitch (e.g. Ball , Ball In Dirt , Called Strike , ..., Swinging Strike (Blocked))   Class
One of three classifications ( B =ball, S =strike, or X =in play)   Result
From pitcher's perspective ( Neg =ball or hit, Pos =strike or out)   Swing
Did the batter swing at the pitch? ( No or Yes )   Time
Date and time of the pitch (format yyyy-mm-ddThh:mm:ssZ )   StartSpeed
Speed leaving the pitcher's hand (in mph)   EndSpeed
Speed crossing home plate (in mph)   HDev
Horizontal movement (inches)   VDev
Vertical movement (inches)   HPos
Horizontal position at home plate (inches from center, positive is catcher's right)   VPos
Vertical position at home plate (inches above the ground)   PitchType
Code for pitch type ( CH =changeup, CU =curve, FF =fastball, or SL =slider)   Zone
1-9 in theoretical strike zone (upper left to lower right), 11-14 are out of strike zone   Nasty
A measure on a 0-100 scale of difficulty of the pitch to hit (100 is most difficult)   Count
Ball strike count ( 0-0 , 0-1 , 0-2 , 1-1 , 1-2 , 2-1 , 2-2 , 3-1 , or 3-2 )   BallCount
Number of balls before the pitch (0, 1, 2, or 3)   StrikeCount
Number of strikes before the pitch (0, 1, or 2)   Inning
Inning of the game   InningSide
Portion of the inning ( bottom = pitcher at home or top =pitcher away)   Outs
Number of outs when the pitch is thrown   BatterHand
Batter's stance ( L =left or R =right)   ABEvent
Result of the at bat (several possibilities)   Batter
Name of the batter faced     Details  
Dataset includes information for 3,402 individual pitches thrown by Los Angeles Dodger baseball pitcher Clayton Kershaw during the 2013 regular season when he won the Cy Young award as the best pitcher in the National League. Many variables are measured using Major League Baseball's PITCHf/x system that uses camera systems in each ballpark to track characteristics of each pitch thrown.    Source  
Data scraped from the MLB GameDay website (http://gd2.mlb.com/components/game/mlb/) using pitchRx"
"Stat2Data-KeyWestWater","Stat2Data","KeyWestWater","Key West Water Temperatures",6572,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/KeyWestWater.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/KeyWestWater.html","KeyWestWater R Documentation   Key West Water Temperatures   Description  
Hourly water temperatures from Gulf of Mexico near Key West, Florida    Format  
A data frame with 6572 observations on the following 3 variables.    DateTime
Date and time of reading (format mm/dd/yyyy h:00 )   WaterTemp
Water temperature (in degrees Fahrenheit)   t
Time index (1 to 673)     Details  
Hourly readings of water temperatures from a measuring device in the Gulf of Mexico near Key West, Florida. The hourly temperatures are provided from October 3, 2016 to October 3, 2017 and were obtained from station 8724580. A few missing values have been interpolated to provide a complete series.    Source  
National Oceanographic and Atmospheric Administration (2017), Key West Ocean Temperature Data, October 3, 2016 to October 3, 2017, https://www.nodc.noaa.gov, Accessed on October 4, 2017   
Data were obtained by Kyle Johnston for his Senior Exercise (a capstone project)."
"Stat2Data-Kids198","Stat2Data","Kids198","Body Measurements of Children",198,5,2,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Kids198.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Kids198.html","Kids198 R Documentation   Body Measurements of Children   Description  
Body measurements for a sample of 198 children    Format  
A data frame with 198 observations on the following 5 variables.   
  Height Height (in inches)
  Weight Weight (in pounds)
  Age Age (in months)
  Sex 0 =male or 1 =female
  Race 0 =white or 1 =other
    Details  
This dataset comes from a 1977 anthropometric study of body measurements for children. Subjects in this sample are between the ages of 8 and 18 years old, selected at random from the much larger dataset of the original study.    Source  
A sample of 198 cases from the NIST's AnthroKids dataset at http://ovrt.nist.gov/projects/anthrokids/"
"Stat2Data-Leafhoppers","Stat2Data","Leafhoppers","Leafhopper Diet and Longevity",8,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Leafhoppers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Leafhoppers.html","Leafhoppers R Documentation   Leafhopper Diet and Longevity   Description  
Lifetimes for potato leafhoppers on various sugar diets    Format  
A data frame with 8 observations on the following 2 variables.   
  Diet Control , Fructose , Glucose , or Sucrose
  Days Number of days until half the leafhoppers in a dish died
    Details  
The goal of this study was to compare the effects of four diets on the lifespan of small insects called potato leafhoppers. One of the four was a control diet: just distilled water with no nutritive value. Each of the other three diets had a particular sugar added to the distilled water, one of glucose, sucrose, or fructose. Leafhoppers were sorted into groups of eight and each group was put into one of eight lab dishes. Each of the four diets was added to two dishes, chosen using chance.    Source  
""Survival and behavioral responses of the potato leafhopper, Empoasca Fabae (Harris), on synthetic media,"" MS thesis by Douglas Dahlman (1963), Iowa State University. The data can be found in Analyzing Experimental Data by Regression by David M. Allen and Foster B. Cady, Belmont, CA: Lifetime Learning (Wadsworth)."
"Stat2Data-LeafWidth","Stat2Data","LeafWidth","Leaf Measurements",252,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LeafWidth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LeafWidth.html","LeafWidth R Documentation   Leaf Measurements   Description  
Measurements of Dodonaea viscosa leaves    Format  
A data frame with 252 observations on the following 5 variables.    Width
Average width (in mm)   Length
Average length (in mm)   LWRatio
Length divided by Width   Area
Area (in sq. mm)   Year
Year the leaves were collected     Details  
Data on samples of leaves from the species Dodonaea viscosa subsp. angustissima (common name hopbush), which have been collected in a certain region of South Australia for many years.    Source  
Guerin, G., Wen, H., Lowe, A. (2012), ""Leaf morphology shift linked to climate change,"" Biol. Lett., 8, doi: 10.1098/rsbl.2012.0458"
"Stat2Data-Leukemia","Stat2Data","Leukemia","Responses to Treatment for Leukemia",51,9,2,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Leukemia.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Leukemia.html","Leukemia R Documentation   Responses to Treatment for Leukemia   Description  
Treatment results for leukemia patients    Format  
A data frame with 51 observations on the following 9 variables.   
  Age Age at diagnosis (in years)
  Smear Differential percentage of blasts
  Infil Percentage of absolute marrow leukemia infiltrate
  Index Percentage labeling index of the bone marrow leukemia cells
  Blasts Absolute number of blasts, in thousands
  Temp Highest temperature of the patient prior to treatment, in degrees Fahrenheit
  Resp 1 =responded to treatment or 0 =failed to respond
  Time Survival time from diagnosis (in months)
  Status 0 =dead or 1 =alive
    Details  
A study involved 51 untreated adult patients with acute myeloblastic leukemia who were given a course of treatment, after which they were assessed as to their response.    Source  
Data come from Statistical Analysis Using S-Plus (Brian S. Everitt; first edition 1994, Chapman & Hall)."
"Stat2Data-LeveeFailures","Stat2Data","LeveeFailures","Levee Failures along the Mississippi River",82,14,4,0,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LeveeFailures.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LeveeFailures.html","LeveeFailures R Documentation   Levee Failures along the Mississippi River   Description  
Factors relating to Mississippi River levee failure    Format  
A data frame with 82 observations on the following 14 variables.    Failure
Did the levee fail? ( 1 =yes or 0 =no)   Year
Year   RiverMile
Location along the river (mile marker)   Sediments
Sediments present? ( 1 =yes or 0 =no)   BorrowPit
Borrow pit present? ( 1 =yes or 0 =no)   Meander
Type of meander ( 1 =inside bend, 2 =outside bend, 3 =chute, 4 =straight)   ChannelWidth
Width of the river channel (in meters)   FloodwayWidth
Width of floodway (in meters, levee to levee, levee to bluff, or bluff to bluff, as appropriate)   ConstrictionFactor
Constriction of the floodway over time (1880s to present)   LandCover
1 =open water, 2 =grassy, 3 =agricultural, 4 =forest   VegWidth
Vegative buffer width (in meters)   Sinuosity
River length divided by valley length for 10 miles up- and down-valley from levee site   Dredging
Dredging intensity   Revetement
Is there a stone structure (wall) meant to hold up the bank? ( 1 =yes or 0 =no)     Details  
The goal of this investigation was to test the relative importance of geologic, geomorphic, and other physical factors that have led to levee failures through the past century along much of the Mississippi River.    Source  
A. Flor, N. Pinter, W.F. Remo (2010), ""Evaluating Levee Failure Susceptibility on the Mississippi River Using Logistic Regression Analysis,"" Engineering Geology, Vol. 116, pp. 139-148"
"Stat2Data-LewyBody2Groups","Stat2Data","LewyBody2Groups","Lewy Bodies and Dimentia",39,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LewyBody2Groups.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LewyBody2Groups.html","LewyBody2Groups R Documentation   Lewy Bodies and Dimentia   Description  
Dementia study comparing two groups of patients    Format  
A data frame with 39 observations on the following 3 variables.    Type
DLB =Dementia with Lewy Bodies or DLB/AD =DLB and Alzheimer's Disease   APC
Annualized Percentage Change from baseline volume of the brain   MMSE
Change in functional performance on the Mini Mental State Examination     Details  
Brain MRIs were used to study the brains of patients with Dementia with Lewy Bodies, some of whom also were diagnosed with Alzheimer's Disease.    Source  
Z. Nedelksa et al. (2015), ""Pattern of brain atrophy rates in autopsy-confirmed dementia with Lewy bodies,"""" Neurobiology of Aging, 36: 452-461."
"Stat2Data-LewyDLBad","Stat2Data","LewyDLBad","Lewy Bodies and Dimentia with Alzheimer's",20,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LewyDLBad.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LewyDLBad.html","LewyDLBad R Documentation   Lewy Bodies and Dimentia with Alzheimer's   Description  
Dementia Study with Lewy Bodies    Format  
A data frame with 20 observations on the following 3 variables.    group
DLB/AD =DLB and Alzheimer's Disease   APC
Annualized Percentage Change from baseline volume of the brain   MMSE
Change in functional performance on the Mini Mental State Examination     Details  
Brain MRIs were used to study the brains of patients with Dementia with Lewy Bodies. These are the cases that were also diagnosed with Alzheimer's Disease. This is a subset of LewBody2Groups    Source  
Z. Nedelksa et al. (2015), ""Pattern of brain atrophy rates in autopsy-confirmed dementia with Lewy bodies,"" Neurobiology of Aging, 36: 452-461."
"Stat2Data-LongJumpOlympics","Stat2Data","LongJumpOlympics","Olympic Men's Long Jump Gold Medal Distance (1900 - 2008)",26,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LongJumpOlympics.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LongJumpOlympics.html","LongJumpOlympics R Documentation   Olympic Men's Long Jump Gold Medal Distance (1900 - 2008)   Description  
Winning distances in men's Olympic long jump competitions (1900 - 2008)    Format  
A data frame with 26 observations on the following 2 variables.   
  Year Year of the Olympics (1900 - 2008)
  Gold Winning men's long jump distance (in meters)
    Details  
Gold medal winning distances for the men's long jump at the Olympics from 1900 to 2008.   
Updated to LongJumpOlympics2016 in second edition.    Source  
Historical Olympic long ump results at http://trackandfield.about.com/od/longjump/qt/olymlongjumpmen.htm"
"Stat2Data-LongJumpOlympics2016","Stat2Data","LongJumpOlympics2016","Olympic Men's Long Jump Gold Medal Distance (1900 - 2016)",28,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LongJumpOlympics2016.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LongJumpOlympics2016.html","LongJumpOlympics2016 R Documentation   Olympic Men's Long Jump Gold Medal Distance (1900 - 2016)   Description  
Gold medal distance for Olympic men's long jump    Format  
A data frame with 28 observations on the following 2 variables.    Year
Olympic Year (1900-2016)   Gold
Gold medal distance (in meters)     Details  
Gold medal winning distances for the men's long jump at the Olympics from 1900 to 2016.    Source  
Historical Olympic long jump results at http://trackandfield.about.com/od/longjump/qt/olymlongjumpmen.htm"
"Stat2Data-LosingSleep","Stat2Data","LosingSleep","Sleep Hours for Teenagers",446,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LosingSleep.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LosingSleep.html","LosingSleep R Documentation   Sleep Hours for Teenagers   Description  
Hours of sleep for teenagers    Format  
A data frame with 446 observations on the following 3 variables.    Person
Cased ID number   Age
Age (in years)   Outcome
Average at least 7 hours of sleep? ( 1=yes or 0 =no)     Details  
Data from a sample of 446 teens, aged 14 to 18, who answer the question, ""On an average school night, how many hours of sleep do you get?"" The outcome variable records whether or not each person averages at least 7 hours of sleep.    Source  
Wahlstrom, K., Dretzke, B., Gordon, M., Peterson, K., Edwards, K., & Gdula, J. (2014) ""Examining the Impact of Later School Start Times on the Health and Academic Performance of High School Students: A Multi-Site Study,"" Center for Applied Research and Educational Improvement. St Paul, MN: University of Minnesota."
"Stat2Data-LostLetter","Stat2Data","LostLetter","Return Rates for ""Lost"" Letters",140,8,7,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/LostLetter.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/LostLetter.html","LostLetter R Documentation   Return Rates for ""Lost"" Letters   Description  
Which ""lost"" letters will be returned by the public?    Format  
A data frame with 140 observations on the following 8 variables.   
  Location Where letter was ""lost"": DesMoines , GrinnellCampus , or GrinnellTown
  Address Address on the letter: Confederacy or Peaceworks
  Returned 1 =letter was returned or 0 =letter was not returned
  DesMoines Indicator for letters left in Des Moines
  GrinnellTown Indicator for letters left in the town of Grinnell
  GrinellCampus Indicator for letters left on the Grinnell campus
  Peaceworks Indicator for letters addressed to Iowa Peaceworks
  Confederacy Indicator for letters addressed to Friends of the Confederacy
    Details  
In 1999 Grinnell College students Laurelin Muir and Adam Gratch conducted an experiment for an introductory statistics class. They intentionally ""lost"" 140 letters in either the city of Des Moines, the town of Grinnell, or on the Grinnell College campus. Half of each sample were addressed to Friends of the Confederacy and the other half to Iowa Peaceworks. The students kept track of which letters were eventually returned.    Source  
Student project at Grinnell College"
"Stat2Data-Marathon","Stat2Data","Marathon","Daily Training for a Marathon Runner",1127,9,2,0,4,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Marathon.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Marathon.html","Marathon R Documentation   Daily Training for a Marathon Runner   Description  
Training records for a marathon runner    Format  
A dataset with 1128 observations on the following 9 variables.   
  Date Training date
  Miles Miles for training run
  Time Training time (in minutes:seconds:hundredths)
  Pace Running pace (in minutes:seconds:hundredths per mile)
  ShoeBrand Addidas , Asics , Brooks , Izumi , Mizuno , or New Balance
  TimeMin Training time (in minutes)
  PaceMin Running pace (in minutes per mile)
  Short 1 = 5 miles or less or 0 =more than 5 miles
  After2004 1 = for runs after 2004 or 0 =for earlier runs
    Details  
Information from training records of a marathoner over a five-year period from 2002-2006.    Source  
Data from training records of one of the Stat2 authors."
"Stat2Data-Markets","Stat2Data","Markets","Daily Change in Dow Jones and Nikkei Stock Market Indices",56,5,1,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Markets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Markets.html","Markets R Documentation   Daily Change in Dow Jones and Nikkei Stock Market Indices   Description  
Daily changes in two stock market indices    Format  
A dataset with 56 observations on the following 5 variables.   
  DJIAch Change in Dow Jones Industrial Average
  Date Date: 06-Aug-09 to 02-Nov-09
  Nik225ch Change in Nikkei 225 stock average
  Up Indicator for positive Nikkei change
  lagNik Previous day's Nikkei change
    Details  
This dataset contains data on daily changes from two stock markets over 56 days from 06-Aug-09 to 02-Nov-09. The Dow Jones Industrial Average is based in New York and the Nikkei 225 is a stock index in Japan.    Source  
Dow Jones Industrial Average:
 http://markets.cbsnews.com/cbsnews/quote/historical?
 Month=11&Symbol=310%3A998313&Year=2009&Range=12&tag=cbsnewsSectionsArea
 Historical Nikkei 225 index:
 http://markets.cbsnews.com/cbsnews/quote/historical?
 Month=11&Symbol=992%3A1900000035&Year=2009&Range=12&tag=cbsnewsSectionsArea"
"Stat2Data-MathEnrollment","Stat2Data","MathEnrollment","Enrollments in Math Courses",11,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MathEnrollment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MathEnrollment.html","MathEnrollment R Documentation   Enrollments in Math Courses   Description  
Semester enrollments in mathematics courses    Format  
A dataset with 11 observations on the following 3 variables.   
  AYear Academic year (for the fall)
  Fall Fall semester total enrollments
  Spring Spring semester total enrollments
    Details  
Total enrollments in mathematics courses at a small liberal arts college were obtained for each semester from Fall 2001 to Spring 2012.    Source  
The data were obtained from http://Registrar.Kenyon.edu on June 1, 2012."
"Stat2Data-MathPlacement","Stat2Data","MathPlacement","Math Placement Exam Results",2696,16,5,0,2,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MathPlacement.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MathPlacement.html","MathPlacement R Documentation   Math Placement Exam Results   Description  
Results from a Math Placement exam at a liberal arts college    Format  
A dataset with 2696 observations on the following 16 variables.   
  Student Identification number for each student
  Gender 0=Female, 1=Male
  PSATM PSAT score in Math
  SATM SAT score in Math
  ACTM ACT Score in Math
  Rank Adjusted rank in HS class
  Size Number of students in HS class
  GPAadj Adjusted GPA
  PlcmtScore Score on math placement exam
  Recommends Recommended course: R0 R01 R1 R12 R2 R3 R4 R6 R8
  Course Actual course taken
  Grade Course grade
  RecTaken 1=recommended course, 0=otherwise
  TooHigh 1=took course above recommended, 0=otherwise
  TooLow 1=took course below recommended, 0=otherwise
  CourseSuccess 1=B or better grade, 0=grade below B
    Details  
Scores and course results for students taking a math placement exam at a college.    Source  
Personal correspondence"
"Stat2Data-MedGPA","Stat2Data","MedGPA","GPA and Medical School Admission",55,11,3,0,2,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MedGPA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MedGPA.html","MedGPA R Documentation   GPA and Medical School Admission   Description  
Medical school admission status and information on GPA and standardized test scores    Format  
A dataset with 55 observations on the following 11 variables.   
  Accept Status: A =accepted to medical school or D =denied admission
  Acceptance Indicator for Accept: 1 =accepted or 0 =denied
  Sex F =female or M =male
  BCPM Bio/Chem/Physics/Math grade point average
  GPA College grade point average
  VR Verbal reasoning (subscore)
  PS Physical sciences (subscore)
  WS Writing sample (subcore)
  BS Biological sciences (subscore)
  MCAT Score on the MCAT exam (sum of CR+PS+WS+BS)
  Apps Number of medical schools applied to
    Details  
This dataset has information gathered on 55 medical school applicants from a liberal arts college in the Midwest.    Source  
Data collected at a midwestern liberal arts college."
"Stat2Data-Meniscus","Stat2Data","Meniscus","Meniscus Repair Methods",18,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Meniscus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Meniscus.html","Meniscus R Documentation   Meniscus Repair Methods   Description  
Comparing meniscus repair methods on cadaver knees    Format  
A data frame with 18 observations on the following 4 variables.    Method
Meniscus repair method ( 1 = Vertical Suture, 2 = Meniscus Arrow, 3 = FasT-Fix)   FailureLoad
Load at failure (in Newtons)   Displacement
Displacement (in mm)   Stiffness
Stiffness (Newtons/mm)     Details  
Eighteen, lightly embalmed, cadaveric knee specimens were used in a study to compare three different methods of meniscus repair. The specimens were randomly assigned to one of the three treatments: vertical suture, meniscus arrow, FasT-Fix. They were evaluated on three different response variables: load at failure, stiffness, and displacement.    Source  
P. Borden, J. Nyland, D.N.M. Caborn, D. Pienkowski (2003), ""Biomechanical Comparison of the FasT-Fix Meniscal Repair Suture System with Vertical Mattress Sutures and Meniscus Arrows,"" The American Journal of Sports Medicine, Vol. 31, #3, pp. 374-378   
Dataset downloaded from http://www.stat.ufl.edu/~winner/data/meniscus.txt"
"Stat2Data-MentalHealth","Stat2Data","MentalHealth","Mental Health Admissions",36,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MentalHealth.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MentalHealth.html","MentalHealth R Documentation   Mental Health Admissions   Description  
Admissions to a mental health emergency room and full moons    Format  
A dataset with 36 observations on the following 3 variables.   
  Month Month of the year
  Moon Relationship to full moon: After , Before , or During
  Admission Number of emergency room admissions
    Details  
Some researchers in the early 1970s set out to study whether there is a ""full-moon"" effect on emergency room admissions at a mental health hospital. They separated the data over 12 months into rates before the full moon (mean number of patients seen 4-13 days before the full moon), during the full moon (the number of patients seen on the full moon day), and after the full moon (mean number of patients seen 4-13 days after the full moon).    Source  
Introduction to Mathematical Statistics and its Applications by Richard J. Larsen and Morris L. Marx. Prentice Hall:Englewood Cliffs, NJ, 1986.    References  
The original discussion of the study is in Blackman, S., and Catalina, D. (1973). ""The moon and the emergency room."" Perceptual and Motor Skills 37, 624-626."
"Stat2Data-MetabolicRate","Stat2Data","MetabolicRate","Metabolic Rate of Caterpillars",305,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MetabolicRate.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MetabolicRate.html","MetabolicRate R Documentation   Metabolic Rate of Caterpillars   Description  
Body size and metabolic rate of Manduca Sexta caterpillars    Format  
A dataset with 305 observations on the following 7 variables.   
  Computer ID number of the computer used to measure metabolic rate
  BodySize Size of the caterpillar (in grams)
  LogBodySize Log (base 10) of BodySize
  Instar Number from 1 (smallest) to 5 (largest) indicating stage of the caterpillar's life
  CO2ppm Carbon dioxide concentration (in ppm)
  Mrate Metabolic rate
  LogMrate Log (base 10) of metabolic rate
    Details  
Marisa Stearns collected and analyzed body size and metabolic rates for Manduca Sexta caterpillars.    Source  
We thank Professor Itagaki and his research students for sharing these data."
"Stat2Data-MetroCommutes","Stat2Data","MetroCommutes","Commute Times",2000,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MetroCommutes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MetroCommutes.html","MetroCommutes R Documentation   Commute Times   Description  
Commute times for four cities    Format  
A data frame with 2000 observations on the following 3 variables.    City
Boston , Houston , Minneapolis , or Washington   Distance
Distance of commute (in miles)   Time
Time of commute (in minutes)     Details  
The data are distances (miles) and times (minutes) of daily commute (one-way) for random samples of 500 commuters in each of four cities (Boston, Houston, Minneapolis, Washington) in 2007. The random samples were taken from the Metropolitan Public Use File of the 2007 American Housing Survey    Source  
2007 American Housing Survey https://www.census.gov/programs-surveys/ahs/data/2007/ahs-2007-public-use-file–puf-.html"
"Stat2Data-MetroHealth83","Stat2Data","MetroHealth83","Health Services in Metropolitan Areas",83,16,0,0,1,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MetroHealth83.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MetroHealth83.html","MetroHealth83 R Documentation   Health Services in Metropolitan Areas   Description  
Health services data for 83 metropolitan areas    Format  
A dataset with 83 observations on the following 16 variables.   
  City Name of the metropolitan area
  NumMDs Number of physicians
  RateMDs Number of physicians per 100,000 people
  NumHospitals Number of community hospitals
  NumBeds Number of hospital beds
  RateBeds Number of hospital beds per 100,000 people
  NumMedicare Number of Medicare recipients in 2003
  PctChangeMedicare Percent change in Medicare recipients (2000 to 2003)
  MedicareRate Number of Medicare recipients per 100,000 people
  SSBNum Number of Social Security recipients in 2004
  SSBRate Number of Social Security recipients per 100,000 people
  SSBChange Percent change in Social Security recipients (2000 to 2004)
  NumRetired Number of retired workers
  SSINum Number of Supplemental Security Income recipients in 2004
  SSIRate Number of Supplemental Security Income recipients per 100,000 people
  SqrtMDs Square root of number of physicians
    Details  
The U.S. Census Bureau regularly collects information for many metropolitan areas in the United States, including data on number of physicians and number (and size) of hospitals. This dataset has such information for 83 different metropolitan areas.   
This dataset is in the first edition, but replaced by CountyHealth in the second edition.    Source  
U.S. Census Bureau: 2006 State and Metropolitan Area Data Book (Table B-6)
 http://www.census.gov/prod/2006pubs/smadb/smadb-06.pdf"
"Stat2Data-Migraines","Stat2Data","Migraines","Migraines and TMS",2,4,3,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Migraines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Migraines.html","Migraines R Documentation   Migraines and TMS   Description  
Effects of transcranial magnetic stimulation (TMS) on migraine headaches    Format  
A data frame with 2 observations on the following 4 variables.    Group
Treatment group ( Placebo or TMS )   Yes
Count of number of patients that were pain-free in each group   No
Count of number of patients that had pain in each group   Trials
Number of patients in each group     Details  
A study investigated whether a handheld device that sends a magnetic pulse into a person's head might be an effective treatment for migraine headaches. Researchers recruited 200 subjects who suffered from migraines and randomly assigned them to receive either the TMS (transcranial magnetic stimulation) treatment or a sham (placebo) treatment from a device that did not deliver any stimulation. Subjects were instructed to apply the device at the onset of migraine symptoms and then assess how they felt two hours later. This dataset is a two-way table of the results.   
This dataset was called TMS in the first edition.    Source  
Based on results in R. B. Lipton, et al, (2010) ""Single-pulse Transcranial Magnetic Stimulation for Acute Treatment of Migraine with Aura: A Randomised, Double-blind, Parallel-group, Shamcontrolled Trial,"" Lancet Neurology, 9(4):373-380."
"Stat2Data-Milgram","Stat2Data","Milgram","Ethics and a Milgram Experiment",37,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Milgram.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Milgram.html","Milgram R Documentation   Ethics and a Milgram Experiment   Description  
Attitudes towards ethics of a famous Milgram experiment    Format  
A dataset with 37 observations on the following 2 variables.   
  Results Treatment group: Actual , Complied , or Refused
  Score Ethical score from 1 (not at all ethical) to 9 (completely ethical)
    Details  
One of the most famous and most disturbing psychological studies of the twentieth century took place in the laboratory of Stanley Milgram at Yale University. Milgram's subjects were asked to monitor the answers of a ""learner"" and to push a button to deliver shocks whenever the learner gave a wrong answer. The more wrong answers, the more powerful the shock. Even Milgram himself was surprised by the results: Every one of his subjects ended up delivering what they thought was a dangerous 300-volt shock to a slow ""learner"" as punishment for repeated wrong answers.
   
Even though the ""shocks"" were not real and the ""learner"" was in on the secret, the results triggered a hot debate about ethics and experiments with human subjects. To study attitudes on this issue, Harvard graduate student Maryann de Mateo conducted a randomized comparative experiment. Her subjects were 37 high school teachers who did not know about the Milgram study. Using chance, Maryann assigned each teacher to one of three treatment groups:
   
Group 1: Actual results. Each subject in this group read a description of Milgram's study, including the actual results that every subject delivered the highest possible ""shock.""
   
Group 2: Many complied. Each subject read the same description given to the subjects in Group 1, except that the actual results were replaced by fake results, that many but not all subjects complied.
   
Group 3. Most refused. For subjects in this group, the fake results said that most subjects refused to comply.
   
After reading the description, each subject was asked to rate the study according to how ethical they thought it was, from 1 (not at all ethical) to 9 (completely ethical.)    Source  
""An experimental study of attitudes toward deception"" by Mary Ann DiMatteo. Unpublished manuscript, Department of Psychology and Social Relations, Harvard University (1972)."
"Stat2Data-MLB2007Standings","Stat2Data","MLB2007Standings","Standings and Team Statistics from the 2007 Baseball Season",30,21,1,0,2,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MLB2007Standings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MLB2007Standings.html","MLB2007Standings R Documentation   Standings and Team Statistics from the 2007 Baseball Season   Description  
Data for Major League Baseball teams from the 2007 regular season    Format  
A dataset with 30 observations on the following 21 variables.   
  Team Name of the team
  League League: AL or NL
  Wins Number of wins for the season (out of 162 games)
  Losses Number of losses for the season
  WinPct Proportion of games won (Wins/162)
  BattingAvg Team batting average
  Runs Number of runs runs scored
  Hits Number of hits
  HR Number of home runs hit
  Doubles Number of doubles hit
  Triples Number of triple hit
  RBI Number of runs batted in
  SB Number of stolen bases
  OBP On base percentage
  SLG Slugging percentage
  ERA Earned run average (earned runs allowed per 9 innings)
  HitsAllowed Number of hits against the team
  Walks Number of walks allowed
  StrikeOuts Number of strikeouts (by the team's pitchers)
  Saves Number of games saved (by the team's pitchers)
  WHIP Number of walks and hits per inning pitched
    Details  
Data for all 30 Major League Baseball (MLB) teams for the 2007 regular season. This includes team batting statistics (BattingAvg through SLG) and team pitching statistics (ERA through WHIP)   
Updated to MLBStandings2016 in second edition.    Source  
Data downloaded from baseball-reference.com:
 http://www.baseball-reference.com/leagues/MLB/2007-standings.shtml
 http://www.baseball-reference.com/leagues/MLB/2007.shtml"
"Stat2Data-MLBStandings2016","Stat2Data","MLBStandings2016","MLB Standings in 2016",30,21,1,0,2,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MLBStandings2016.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MLBStandings2016.html","MLBStandings2016 R Documentation   MLB Standings in 2016   Description  
Major League Baseball (MLB) standings and team statistics for the 2016 season    Format  
A data frame with 30 observations on the following 21 variables.    Team
Team name   League
AL =American or NL =National   Wins
Number of wins for the season (out of 162 games)   Losses
Number of losses for the season   WinPct
Proportion of games won   BattingAverage
Team batting average   Runs
Number of runs scored   Hits
Number of hits   HR
Number of home runs hit   Doubles
Number of doubles hit   Triples
Number of triples hit   RBI
Number of runs batted in   SB
Number of stolen bases   OBP
On base percentage   SLG
Slugging percentage   ERA
Earned run average (earned runs allowed per 9 innings)   HitsAllowed
Number of hits against the team   Walks
Number of walks allowed   StrikeOuts
Number of strikeouts (by the team's pitchers)   Saves
Number of games saved (by the team's pitchers)   WHIP
Number of walks and hits per inning pitched     Details  
Data for all 30 Major League Baseball (MLB) teams for the 2016 regular season. This includes team batting statistics (BattingAvg through SLG) and team pitching statistics (ERA through WHIP)    Source  
Data downloaded from baseball-reference.com:
 http://www.baseball-reference.com/leagues/MLB/2016-standings.shtml
 http://www.baseball-reference.com/leagues/MLB/2016.shtml"
"Stat2Data-MothEggs","Stat2Data","MothEggs","Moth Eggs",39,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MothEggs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MothEggs.html","MothEggs R Documentation   Moth Eggs   Description  
Body size and eggs produced for a species of moths    Format  
A dataset with 39 observations on the following 2 variables.   
  BodyMass Log of body size measured in grams
  Eggs Number of eggs present
    Details  
Researchers were interested in an association between body size and the number of eggs produced by a species of moths.    Source  
We thank Professor Itagaki and his students for sharing this data from experiments on Manduca Sexta."
"Stat2Data-MouseBrain","Stat2Data","MouseBrain","Effects of Serotonin in Mice",48,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MouseBrain.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MouseBrain.html","MouseBrain R Documentation   Effects of Serotonin in Mice   Description  
Effects of altering serotonin levels on social interactions of mice    Format  
A data frame with 48 observations on the following 3 variables.    Contacts
Number of social contacts the mouse had during the experiment   Sex
F =female or M =male   Genotype
Minus , Mixed , or Plus (see description below)     Details  
Serotonin is a chemical that influences mood balance in humans. But how does it affect mice? Scientists genetically altered mice by ""knocking out"" the expression of a gene, tryptophan hydroxylase 2 (Tph2), that regulates serotonin production. With careful breeding, the scientists produced three types of mice that we label as “Minus” for Tph2-/-, “Plus” for Tph2+/+, “Mixed” for Tph2+/-. The variable Genotype records Minus/Plus/Mixed. The variable Contacts is the number of social contacts that a mouse had with other mice during an experiment and the variable Sex is “M” for males and “F” for females.    Source  
Beis D, Holzwarth K, Flinders M, Bader M, Wohr M, Alenina N., (2015) ""Brain serotonin deficiency leads to social communication deficits in mice,"" Biol. Lett. 11:20150057.
 http://dx.doi.org/10.1098/rsbl.2015.0057   
Once you go to the above link, to get the data, click on the ""Figures and Data"" tab. Then click on the ""Juvenile SocInter Behavior Data"" link to download a hairy data file that needs to be cleaned a great deal to get our data."
"Stat2Data-MusicTime","Stat2Data","MusicTime","Estimating Time with Different Music Playing",60,6,2,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MusicTime.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/MusicTime.html","MusicTime R Documentation   Estimating Time with Different Music Playing   Description  
Estimates of 45 seconds with different music playing    Format  
A data frame with 60 observations on the following 6 variables.    MusicBg
Music playing in the background ( no or yes )   Subject
Code for each subject ( subj1 through subj20 )   Sex
Subject's sex ( f =female or m =male)   TimeGuess
Subject's time estimating 45 seconds (in seconds)   Music
Type of music ( calm , control , or upbeat )   Accuracy
Absolute value of TimeGuess minus 45     Details  
Participants were asked to judge when 45 seconds had passed in silence (control), while listening to an upbeat song (Metropolis, by David Guetta and Nicky Romero), and while listening to a calm song (Bach's Das Wohltemperierte Klavier, Prelude in C Major). The order in which the three conditions were experienced was randomized for each participant. Time until subject guessed 45 seconds had elapsed (TimeGuess) and the magnitude of the difference from 45 (Accuracy) were recorded.    Source  
Data collected by Ksenia Vlasov at Oberlin College."
"Stat2Data-NCbirths","Stat2Data","NCbirths","North Carolina Birth Records",1450,15,5,0,2,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/NCbirths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/NCbirths.html","NCbirths R Documentation   North Carolina Birth Records   Description  
Data from births in North Carolina in 2001    Format  
A dataset with 1450 observations on the following 15 variables.   
  ID Patient ID code
  Plural 1 =single birth, 2 =twins, 3 =triplets
  Sex Sex of the baby 1 =male 2 =female
  MomAge Mother's age (in years)
  Weeks Completed weeks of gestation
  Marital Marital status: 1 =married or 2 =not married
  RaceMom Mother's race: 1 =white, 2 =black, 3 =American Indian, 4 =Chinese
  5 =Japanese, 6 =Hawaiian, 7 =Filipino, or 8 =Other Asian or Pacific Islander
  HispMom Hispanic origin of mother: C =Cuban, M =Mexican, N =not Hispanic
  O =Other Hispanic, P =Puerto Rico, S =Central/South America
  Gained Weight gained during pregnancy (in pounds)
  Smoke Smoker mom? 1 =yes or 0 =no
  BirthWeightOz Birth weight in ounces
  BirthWeightGm Birth weight in grams
  Low Indicator for low birth weight, 1 =2500 grams or less
  Premie Indicator for premature birth, 1 =36 weeks or sooner
  MomRace Mother's race: black , hispanic , other , or white
    Details  
This dataset contains data on a sample of 1450 birth records that statistician John Holcomb selected from the North Carolina State Center for Health and Environmental Statistics.    Source  
Thanks to John Holcomb at Cleveland State University for sharing these data."
"Stat2Data-NFL2007Standings","Stat2Data","NFL2007Standings","NFL Standings for 2007 Regular Season",32,10,1,0,3,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/NFL2007Standings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/NFL2007Standings.html","NFL2007Standings R Documentation   NFL Standings for 2007 Regular Season   Description  
Standings for National Football League teams in 2007    Format  
A dataset with 32 observations on the following 10 variables.   
  Team Team name
  Conference Conference: AFC or NFC
  Division Division within conference: ACE , ACN , ACS , ACW , NCE , NCN , NCS , NCW
  Wins Number of wins (out of 16 games)
  Losses Number of losses
  WinPct Proportion of games won (Wins/16)
  PointsFor Total points scored by the team
  PointsAgainst Total points scored against the team
  NetPts PointsFor minus PointsAgainst
  TDs Number of touchdowns scored by the team
    Details  
Data for all 32 National Football League (NFL) teams for the 2007 regular season.   
Updated to NFLStandings2016 in the second edition.    Source  
Data downloaded from www.nfl.com"
"Stat2Data-NFLStandings2016","Stat2Data","NFLStandings2016","NFL Standings for 2016 Regular Season",32,11,1,0,1,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/NFLStandings2016.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/NFLStandings2016.html","NFLStandings2016 R Documentation   NFL Standings for 2016 Regular Season   Description  
Standings and team statistics for National Football League (NFL) teams in the 2016 season    Format  
A data frame with 32 observations on the following 11 variables.    Team
Team name   Wins
Wins in the 2016 regular season (out of 16 games)   Losses
Losses in the 2016 regular season   Ties
Ties in the 2016 regular season (ties are very rare in the NFL)   WinPct
Winning percentage = (Wins+0.5*Ties)/16 games   PointsFor
Points scored   PointsAgainst
Points allowed   NetPts
Points scored minus Points allowed   YardsFor
Offensive yards gained by the team   YardsAgainst
Offensive yards against the team   TDs
Touchdowns scored     Details  
Standings for the 2016 regular season of the National Football League (NFL) along with points and scored and allowed for each team in its16 games.    Source  
Data downloaded from:
 http://www.pro-football-reference.com/years/2016/"
"Stat2Data-Nursing","Stat2Data","Nursing","Nursing Homes",52,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Nursing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Nursing.html","Nursing R Documentation   Nursing Homes   Description  
Characteristics of nursing homes in New Mexico.    Format  
A dataset with 52 observations on the following 7 variables.   
  Beds Number of beds in the nursing home
  InPatientDays Annual medical in-patient days (in hundreds)
  AllPatientDays Annual total patient days (in hundreds)
  PatientRevenue Annual patient care revenue (in hundreds of dollars)
  NurseSalaries Annual nursing salaries (in hundreds of dollars)
  FacilitiesExpend Annual facilities expenditure (in hundreds of dollars)
  Rural 1= rural or 0= non-rural
    Details  
The data were collected by the Department of Health and Social Services of the State of New Mexico and cover 52 of the 60 licensed nursing facilities in New Mexico in 1988.    Source  
Downloaded from DASL at http://lib.stat.cmu.edu/DASL/Datafiles/Nursingdat.html    References  
Howard L. Smith, Niell F. Piland, and Nancy Fisher, ""A Comparison of Financial Performance, Organizational Characteristics, and Management Strategy Among Rural and Urban Nursing Facilities,"" Journal of Rural Health, Winter 1992, pp 27-40."
"Stat2Data-OilDeapsorbtion","Stat2Data","OilDeapsorbtion","Effect of Ultrasound on Oil Deapsorbtion",40,4,3,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/OilDeapsorbtion.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/OilDeapsorbtion.html","OilDeapsorbtion R Documentation   Effect of Ultrasound on Oil Deapsorbtion   Description  
Experiment to measure the effect of ultrasound on deapsorbing oil from sand    Format  
A data frame with 40 observations on the following 4 variables.    Salt
Type of water ( 1 =salt water or 0 =distilled water)   Ultra
Amount of time each sample was exposed to ultrasound (5 or 10 minutes)   Oil
Amount of oil in the sample (5ml or 10 ml)   Diff
Difference in the amount of oil removed between the ultrasound run and an equivalent control run (no ultrasound) ( Diff = Treatment - Control )     Details  
This data set is the result of a science fair experiment run by a high school student. The basic question was whether exposing sand with oil in it (think oil spill) to ultrasound could help the oil deapsorb from it better than sand that was not exposed to ultrasound. There were two levels of ultrasound tested (5 minutes and 10 minutes) and two levels of oil (5 ml and 10 ml). There was also a question of whether exposure to salt water or fresh water made a difference so half the samples had salt water, the others distilled water. Each combination of factor levels was replicated 5 times. There were also an equivalent number of control observations run, all factors being the same but without any exposure to ultrasound. Each experimental run was paired with an appropriate control run and the response variable is the difference in the amount of oil removed in the experimental run and the control run.    Source  
Experiment run by Las Vegas high school student Chris Mathews for a science fair project in spring 2016."
"Stat2Data-Olives","Stat2Data","Olives","Fenthion in Olive Oil",18,7,1,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Olives.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Olives.html","Olives R Documentation   Fenthion in Olive Oil   Description  
Measurements of the pesticide fenthion in olive oil over time    Format  
A dataset with 18 observations on the following 7 variables.   
  SampleNumber Code (1-6) for sample of olive oil
  Group Code for group: 1 or 2
  Day Time (in days) when sample was measured: 0 , 281 , or 365
  Fenthion Amount of fenthion (pesticide)
  FenthionSulphoxide Amount of fenthion sulfide
  FenthionSulphone Amount of fenthion sulphone
  Time Code (0, 3, or 4) for the number of days
    Details  
Fenthion is a pesticide used against the olive fruit fly in olive groves. It is toxic to humans so it is important that there be no residue left on the fruit or in olive oil that will be consumed. One theory was that if there is residue of the pesticide left in the olive oil, it would dissipate over time. Chemists set out to test that theory by taking a random sample of small amounts of olive oil with fenthion residue and measuring the amount of fenthion in the oil at three different times over the year - day 0, day 281 and day 365.    Source  
Data provided by Rosemary Roberts and discussed in ""Persistence of fenthion residues in olive oil"" by Chaido Lentza-Rizos, Elizabeth J. Avramides, and Rosemary A. Roberts in Pest Management Science, Vol. 40, Issue 1, Jan. 1994, pp. 63-69."
"Stat2Data-Orings","Stat2Data","Orings","Space Shuttle O-Rings",24,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Orings.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Orings.html","Orings R Documentation   Space Shuttle O-Rings   Description  
Number of damaged O-rings on space shuttle launches and launch temperature    Format  
A dataset with 24 observations on the following 2 variables.   
  Temp Code for temperature (in degrees F): Above65 Below65
  Failures Number of O-ring failures
    Details  
The space shuttle Challenger exploded shortly after liftoff in 1987. The subsequent investigation focused on the failure of O-ring seals, which allowed liquid hydrogen and oxygen to mix and explode. These failures might be related to temperature at the launch site which was near freezing (32 degrees F) on that day. This dataset shows the number of O-ring failures on previous shuttle launches, along with an indicator for whether the temperature was above or below 65 degrees F.    Source  
Data can be found in ""Risk analysis of the space shuttle: Pre-challenger prediction of failure"" by Siddhartha R. Dalal, Edward B. Fowlke, and Bruce Hoadley in Journal of the American Statistical Association, Vol. 84, No. 408 (Dec. 1989), pp 945-957"
"Stat2Data-Overdrawn","Stat2Data","Overdrawn","Overdrawn Checking Account?",450,4,2,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Overdrawn.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Overdrawn.html","Overdrawn R Documentation   Overdrawn Checking Account?   Description  
Survey of college students to took at factors related to having overdrawn a checking account.    Format  
A dataset with 450 observations on the following 4 variables.   
  Age Age of the student (in years)
  Sex 0 =male or 1 =female
  DaysDrink Number of days drinking alcohol (in past 30 days)
  Overdrawn Has student overdrawn a checking account? 0 =no or 1 =yes
    Details  
Researchers conducted a survey of 450 undergraduates in large introductory courses at either Mississippi State University or the University of Mississippi. There were close to 150 questions on the survey, but only four of these variables are included in this dataset. (You can consult the paper to learn how the variables beyond these 4 affect the analysis.) The primary interest for the researchers was factors relating to whether or not a student has ever overdrawn a checking account.   
Renamed as CreditRisk in second edition.    Source  
Worthy S.L., Jonkman J.N., Blinn-Pike L. (2010), ""Sensation-Seeking, Risk-Taking, and Problematic Financial Behaviors of College Students,"" Journal of Family and Economic Issues, 31: 161-170"
"Stat2Data-Oysters","Stat2Data","Oysters","Size of Oysters",30,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Oysters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Oysters.html","Oysters R Documentation   Size of Oysters   Description  
Comparing methods for measuring the size of oysters    Format  
A data frame with 30 observations on the following 5 variables.    ID
ID number of each oyster   Weight
Weight (in grams)   Volume
Volume (in cubic centimeters)   ThreeD
Measurement from a 3D system (pixels)   TwoD
Measurement from a 2D cross-section (pixels)     Details  
In 2001 engineers at an R&D lab Agri-Tech, Inc, in Woodstock, Virginia, designed a 3-D system that they hoped would improve on the existing 2-D system for measuring the size of oysters. The 3-D system used computer scanning to estimate an oyster volume, whereas the old 2-D system estimated a cross-sectional area. Data shows the result of both systems, as well as the actual weight and volume of each oyster used in calibration.    Source  
Data found at JSE data archive: http://ww2.amstat.org/publications/jse/jse_data_archive.htm with the filenames of 30oysters. Contributors are G. Andy Chang, G. Jay Kerns, D. J. Lee, and Gary L. Stanek.   
Original article is: Lee, D., Lane, R., and Chang, G., (2001) ""Three-dimension Reconstruction for High-speed Volume Measurement,"" Proceedings of the International Society for Optical Engineering, Machine Vision and Three-Dimensional Imaging Systems for Inspection and Metrology, Volume 4189, p.258-267."
"Stat2Data-PalmBeach","Stat2Data","PalmBeach","Palm Beach Butterfly Ballot",67,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PalmBeach.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PalmBeach.html","PalmBeach R Documentation   Palm Beach Butterfly Ballot   Description  
Votes for Geroge Bush and Pat Buchanan in Florida counties for the 2000 U.S. presidential election    Format  
A dataset with 67 observations on the following 3 variables.   
  County Name of the Florida county
  Buchanan Number of votes for Pat Buchanan
  Bush Number of votes for George Bush
    Details  
The race for the presidency of the United States in the fall of 2000 was very close, with the electoral votes from Florida determining the outcome. In the disputed final tally in Florida, George W. Bush won by just 537 votes over Al Gore, out of almost 6 million votes cast. About 2.3% of the votes cast in Florida were awarded to other candidates. One of those other candidates was Pat Buchanan, who did much better in Palm Beach County than he did anywhere else. Palm Beach County used a unique ""butterfly ballot"" that had candidate names on either side of the page with ""chads"" to be punched in the middle. This non-standard ballot seemed to confuse some voters, who punched votes for Buchanan that may have been intended for a different candidate. This dataset shows the number of votes for Bush and Buchanan in each Florida county.    Source  
Florida county data for the 2000 presidential election can be found at
 http://election.dos.state.fl.us/elections/resultsarchive/Index.asp?ElectionDate=11/7/00"
"Stat2Data-PeaceBridge2003","Stat2Data","PeaceBridge2003","Monthly Peace Bridge Traffic ( 2003-2015)",156,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PeaceBridge2003.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PeaceBridge2003.html","PeaceBridge2003 R Documentation   Monthly Peace Bridge Traffic ( 2003-2015)   Description  
Monthly traffic (in 1,000's) across the Peace Bridge between Canada and the U.S.    Format  
A data frame with 156 observations on the following 4 variables.    Year
Year (2003 to 2015)   Month
Month (1 to 12)   Traffic
Vehicles (in 1,000's)   t
Time frame (1 to 156)     Details  
Monthly traffic (in thousands of vehicles) across the Peace Bridge between the U.S. and Canada near Niagara Falls between January 2003 and December 2015. Note PeaceBridge2012 has only the last four years of this series.    Source  
http://www.peacebridge.com/index.php/historical-traffic-statistics/yearly-volumes"
"Stat2Data-PeaceBridge2012","Stat2Data","PeaceBridge2012","Monthly Peace Bridge Traffic ( 2012-2015)",48,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PeaceBridge2012.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PeaceBridge2012.html","PeaceBridge2012 R Documentation   Monthly Peace Bridge Traffic ( 2012-2015)   Description  
Monthly traffic (in 1,000's) across the Peace Bridge between Canada and the U.S.    Format  
A data frame with 48 observations on the following 4 variables.    Year
Year (2012 to 2015)   Month
Month (1 to 12)   Traffic
Vehicles (in 1,000's)   t
Time frame (1 to 48)     Details  
Monthly traffic (in thousands of vehicles) across the Peace Bridge between the U.S. and Canada near Niagara Falls between January 2012 and December 2015. Note PeaceBridge2003 has similar data starting in 2003.    Source  
http://www.peacebridge.com/index.php/historical-traffic-statistics/yearly-volumes"
"Stat2Data-Pedometer","Stat2Data","Pedometer","Pedometer Walking Data",68,8,1,0,3,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Pedometer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Pedometer.html","Pedometer R Documentation   Pedometer Walking Data   Description  
Daily walking amounts recorded on a personal pedometer from September-December 2011    Format  
A dataset with 68 observations on the following 8 variables.   
  Steps Total number of steps for the day
  Moderate Number of steps at a moderate walking speed
  Min Number of minutes walking at a moderate speed
  kcal Number of calories burned walking at a moderate speed
  Mile Total number of miles walked
  Rain Type of weather ( rain or shine )
  Day Day of the week ( U =Sunday, M =Monday,  T =Tuesday, W =Wednesday, R =Thursday, F =Friday, S =Saturday
  DayType Coded as Weekday or Weekend
    Details  
A statistics professor regularly keeps a pedometer in his pocket. It records not only the number of steps taken each day, but also the number of steps taken at a moderate pace, the number of minutes walked at a moderate pace, and the number of miles total that he walked. He also added to the data set the day of the week, whether it was rainy, sunny, or cold (on sunny days he often biked, but on rainy or cold days he did not), and whether it was a weekday or weekend.    Source  
One of the Stat2 authors"
"Stat2Data-Perch","Stat2Data","Perch","Perch Sizes",56,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Perch.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Perch.html","Perch R Documentation   Perch Sizes   Description  
Size of perch caught in a Finnish lake    Format  
A dataset with 56 observations on the following 4 variables.   
  Obs Observation number
  Weight Weight (in grams)
  Length Length (in centimeters)
  Width Width (in centimeters
    Details  
This dataset comes from a sample of fish (perch) caught at Lake Laengelmavesi in Finland.    Source  
JSE Data Archive, http://www.amstat.org/publications/jse/jse_data_archive.htm, submitted by Juha Puranen."
"Stat2Data-PigFeed","Stat2Data","PigFeed","Additives in Pig Feed",12,3,2,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PigFeed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PigFeed.html","PigFeed R Documentation   Additives in Pig Feed   Description  
Effects of additives to pig feed on weight gain    Format  
A dataset with 12 observations on the following 3 variables.   
  WgtGain Daily weight gain (hundredths of a pound over 1.00)
  Antibiotic Antibiotic in the feed? No or Yes
  B12 Vitamin B12 in the feed? No or Yes
    Details  
A scientist in Iowa was interested in additives to standard pig chow that might increase the rate at which the pigs gained weight. Two factors of interest were vitamin B12 and antibiotics. To perform the experiment, the scientist randomly assigned 12 pigs, three to each of the diet combinations (Antibiotic only, B12 only, both, and neither).    Source  
Data are found in Statistical Methods by George W. Snedecor and William G. Cochran (1967). Ames, IA: The Iowa State University Press.    References  
Original source is Iowa Agricultural Experiment Station (1952). Animal Husbandry Swine Nutrition Experiment No. 577."
"Stat2Data-Pines","Stat2Data","Pines","Measurements of Pine Tree Seedlings",1000,15,4,0,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Pines.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Pines.html","Pines R Documentation   Measurements of Pine Tree Seedlings   Description  
Data from pine seedlings planted in 1990    Format  
A dataset with 1000 observations on the following 15 variables.   
  Row Row number in pine plantation
  Col Column number in pine plantation
  Hgt90 Tree height at time of planting (cm)
  Hgt96 Tree height in September 1996 (cm)
  Diam96 Tree trunk diameter in September 1996 (cm)
  Grow96 Leader growth during 1996 (cm)
  Hgt97 Tree height in September 1997 (cm)
  Diam97 Tree trunk diameter in September 1997 (cm)
  Spread97 Widest lateral spread in September 1997 (cm)
  Needles97 Needle length in September 1997 (mm)
  Deer95 Type of deer damage in September 1995: 0 = none, 1 = browsed
  Deer97 Type of deer damage in September 1997: 0 = none, 1 = browsed
  Cover95 Thorny cover in September 1995: 0 = none; 1 = some; 2 = moderate; 3 = lots
  Fert Indicator for fertilizer: 0 = no, 1 = yes
  Spacing Distance (in feet) between trees (10 or 15)
    Details  
This dataset contains data from an experiment conducted by the Department of Biology at Kenyon College at a site near the campus in Gambier, Ohio. In April 1990, student and faculty volunteers planted 1000 white pine (Pinus strobes) seedlings at the Brown Family Environmental Center. These seedlings were planted in two grids, distinguished by 10- and 15-foot spacings between the seedlings. Several variables were measured and recorded for each seedling over time (in 1990, 1996, and 1997).    Source  
Thanks to the Kenyon College Department of Biology for sharing these data."
"Stat2Data-PKU","Stat2Data","PKU","Dopamine levels with PKU in diets",20,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PKU.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PKU.html","PKU R Documentation   Dopamine levels with PKU in diets   Description  
Dopamine levels with different amounts of phenylalanine in diets    Format  
A data frame with 20 observations on the following 4 variables.    Subject
Initials to identify each subject   Diet
Level of phenylalanine in diet ( Low or Normal )   DietControl
Ability to follow prescribed diet ( Good or Poor )   Y
Concentration of dopamine (micrograms per milligram of creatinine)     Details  
Phenylketonuria (PKU) is an enzyme deficiency that keeps a person from being able to synthesize enough dopamine. The amino acid phenylalanine inhibits the enzyme needed to synthesize dopamine, and so to some extent, a diet low in phenylalanine can moderate the symptoms of PKU. In short, less phenylalanine in the diet should lead to more dopamine in the brain. The dopamine level for each patient was measured after a normal diet and after a week on a low phenylalanine diet.    Source  
Krause, Halminski, McDonald, Dembure, Salvo, Freides, and Elsas (1985) ""Biochemical and Neuropsychological Effects of Elevated Plasma Phenylalanine in Patients with Treated Phenylketonuria,"" J. of Clinical Investigation, Volume 75, January 1985, 40-48   
Several of the values were altered slightly in ways that would not change the analysis except to simplify the arithmetic."
"Stat2Data-Political","Stat2Data","Political","Political Behavior of College Students",59,9,3,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Political.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Political.html","Political R Documentation   Political Behavior of College Students   Description  
Survey of political activity for Grinnell College students    Format  
A dataset with 59 observations on the following 9 variables.   
  Year Class year (1 to 4)
  Sex 0 =male or 1 =female
  Vote Voting status: 0 =not eligible, 1 =eligible/not registered, 2 =registered/didn't vote, 4 =voted
  Paper Read news (per week): 0 =never, 1 =less than once, 2 =once, 3 =2 or 3 times, 4 =daily
  Edit Read editorial page? 0 =no or 1 =yes
  TV Watch TV news: 0 =never, 1 =less than once, 2 =once, 3 =2 or 3 times, 4 =daily
  Ethics Politics should be ruled by: 1 =ethical considerations to 5 =practical power
  Inform How informed are you about politics? 1 =uninformed to 5 =very well informed
  Participate Missing if Vote=0, 0 if Vote=1 or 2, 1 if Vote=3
    Details  
Students Jennifer Wolfson and Meredith Goulet conducted a survey in the spring of 1992 of Grinnell College students to ascertain patterns of political behavior. They took a simple random sample of 60 students who were U.S. citizens and conducted phone interviews. Using several ""call backs"" they obtained 59 responses.    Source  
Student survey at Grinnell College"
"Stat2Data-Pollster08","Stat2Data","Pollster08","2008 U.S. Presidential Election Polls",102,11,2,0,4,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Pollster08.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Pollster08.html","Pollster08 R Documentation   2008 U.S. Presidential Election Polls   Description  
Polls for 2008 U.S. presidential election    Format  
A dataset with 102 observations on the following 11 variables.   
  PollTaker Polling organization
  PollDates Dates the poll data were collected
  MidDate Midpoint of the polling period
  Days Number of days after August 28th (end of Democratic convention)
  n Sample size for the poll
  Pop A =all, LV =likely voters, RV =registered voters
  McCain Percent supporting John McCain
  Obama Percent supporting Barack Obama
  Margin Obama percent minus McCain percent
  Charlie Indicator for polls after Charlie Gibson interview with VP candidate Sarah Palin (9/11)
  Meltdown Indicator for polls after Lehman Brothers bankruptcy (9/15)
    Details  
The file Pollster08 contains data from 102 polls that were taken during the 2008 U.S. Presidential campaign. These data include all presidential polls reported on the internet site pollster.com that were taken between August 29th, when John McCain announced that Sarah Palin would be his running mate as the Republican nominee for vice president, and the end of September.    Source  
Downloaded from pollster.com"
"Stat2Data-Popcorn","Stat2Data","Popcorn","Popcorn Popping Success",12,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Popcorn.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Popcorn.html","Popcorn R Documentation   Popcorn Popping Success   Description  
Unpopped kernels in bags of microwave popcorn    Format  
A dataset with 12 observations on the following 3 variables.   
  Unpopped Number of unpopped kernels (adjusted for size difference)
  Brand Orville or Seaway
  Trial Trial number
    Details  
Two students, Lara and Lisa, conducted an experiment to compare Orville Redenbacher's Light Butter Flavor vs. Seaway microwave popcorn. They made 12 batches of popcorn, 6 of each type, cooking each batch for four minutes. They noted that the microwave oven seemed to get warmer as they went along so they kept track of six trials and randomly chose which brand would go first for each trial. For a response variable they counted the number of unpopped kernels and then adjusted the count for Seaway for having more ounces per bag of popcorn (3.5 vs 3.0).    Source  
Student project"
"Stat2Data-PorscheJaguar","Stat2Data","PorscheJaguar","Porsche and Jaguar Prices",60,5,2,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PorscheJaguar.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PorscheJaguar.html","PorscheJaguar R Documentation   Porsche and Jaguar Prices   Description  
Compare prices for Porsche and Jaguar cars offered for sale at an internet site    Format  
A dataset with 60 observations on the following 5 variables.   
  Car Car model: Jaguar or Porsche
  Price Price (in $1,000's)
  Age Age of the car (in years)
  Mileage Previous miles driven (in 1,000's)
  Porsche Indicator for Porsche ( 1 ) or Jaguar ( 0 )
    Details  
Two students collected samples of Porsche and Jaguar cars that were offered for sale at an internet site. In addition to asking price, they recorded the model year (converting to age) and mileage of each advertised car.    Source  
Student project data collected from autotrader.com in Spring 2007."
"Stat2Data-PorschePrice","Stat2Data","PorschePrice","Porsche Prices",30,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/PorschePrice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/PorschePrice.html","PorschePrice R Documentation   Porsche Prices   Description  
Prices for Porsche cars offered for sale at an internet site.    Format  
A dataset with 30 observations on the following 3 variables.   
  Price Asking price for the car (in $1,000's)
  Age Age of the car (in years)
  Mileage Previous miles driven (in 1,000's)
    Details  
A student was interested in prices for used Porsche sports cars being sold on the internet. He selected a random sample of 30 Porsches from the ones being advertised at autotrader.com. For each car he recorded the asking price, mileage, and model year (which he converted to age).   
This dataset was replaced by AccordPrice for second edition.    Source  
Data collected for a student project from autotrader.com in February 2007."
"Stat2Data-Pulse","Stat2Data","Pulse","Pulse Rates and Exercise",232,7,2,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Pulse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Pulse.html","Pulse R Documentation   Pulse Rates and Exercise   Description  
Pulse rates before and after exercise for a sample of statistics students    Format  
A dataset with 232 observations on the following 7 variables.   
  Active Pulse rate (beats per minute) after exercise
  Rest Resting pulse rate (beats per minute)
  Smoke 1 =smoker or 0 =nonsmoker
  Sex 1 =female or 0 =male
  Exercise Typical hours of exercise (per week)
  Hgt Height (in inches)
  Wgt Weight (in pounds)
    Details  
Students in a Stat2 class recorded resting pulse rates (in class), did three ""laps"" walking up/down a nearby set of stairs, and then measured their pulse rate after the exercise. They provided additional information about height, weight, exercise, and smoking habits via a survey.    Source  
Data compiled over several semesters from students taking a Stat2 course."
"Stat2Data-Putts1","Stat2Data","Putts1","Putting Success by Length (Long Form)",587,2,1,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Putts1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Putts1.html","Putts1 R Documentation   Putting Success by Length (Long Form)   Description  
Putting results for a golfing statistician    Format  
A dataset with 587 observations on the following 2 variables.   
  Length Length of the putt (in feet)
  Made 1 =made the putt or 0 =missed the putt
    Details  
A statistician golfer kept careful records of every putt he attempted when playing golf, recording the length of the putt and whether or not he was successful in making the putt. This dataset has one case for each of the 587 attempted putts. A different form of the same data (Putts2) accumulates counts of makes and misses for each putt length.    Source  
Personal observations by one of the Stat2 authors"
"Stat2Data-Putts2","Stat2Data","Putts2","Putting Success by Length (Short Form)",5,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Putts2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Putts2.html","Putts2 R Documentation   Putting Success by Length (Short Form)   Description  
Putting results for a golfing statistician (by length of the putts)    Format  
A dataset with 5 observations on the following 4 variables.   
  Length Length of the attempted putt (in feet)
  Made Number of putts made at this length
  Missed Number of putts missed at this length
  Trials Total number of putts attempted at this length
    Details  
A statistician golfer kept careful records of every putt he attempted when playing golf, recording the length of the putt and whether or not he was successful in making the putt. For each different length, this dataset records the number of putts made, missed, and the total number of attempts from that length. A similar dataset, Putts1, has one case for each of the 587 attempted putts, showing the length and outcome.    Source  
Personal observations by one of the Stat2 authors"
"Stat2Data-Putts3","Stat2Data","Putts3","Hypothetical Putting Data (Short Form)",5,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Putts3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Putts3.html","Putts3 R Documentation   Hypothetical Putting Data (Short Form)   Description  
Hypothetical putting results for a golfing statistician    Format  
A data frame with 5 observations on the following 4 variables.    Length
Length of the attempted putt (in feet)   Made
Number of putts made at this length   Missed
Number of putts missed at this length   Trials
Total number of putts attempted at this length     Details  
This is a hypothetical revision of the table of putting success in Putts2 that helps demonstrate overdispersion.    Source  
Modified from personal observations by one of the Stat2 authors."
"Stat2Data-RacialAnimus","Stat2Data","RacialAnimus","Racial Animus and City Demgraphics",196,7,0,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RacialAnimus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RacialAnimus.html","RacialAnimus R Documentation   Racial Animus and City Demgraphics   Description  
Demographics and a measurement of racial animus in cities based on Google searches    Format  
A data frame with 196 observations on the following 7 variables.    MediaMarket
City (State)   Age65Plus
Percentage 65 and older   BachPlus
Percentage with a bachelor's degree   Black
Percentage of African-Americans   Hispanic
Percentage of Hispanics   ObamaKerry
Percentage of vote won by Obama in 2008 minus Kerry percentage in 2004   Animus
Measurement (0-250) of racial animus     Details  
Professor Seth Stephens-Davidowitz studies the level of racial animus across different areas in America by measuring the percent of Google search queries that include racially charged language. A measurement, Animus, is derived from his algorithm and is scaled to be between 0 (low racial animus) and 250 (high racial animus). The dataset includes those values along with demographic information about each media market.    Source  
Chae DH, Clouston S, Hatzenbuehler ML, Kramer MR, Cooper HLF, Wilson SM, et al. (2015) ""Association between an Internet-Based Measure of Area Racism and Black Mortality, PLoS ONE 10(4): e0122963. doi:10.1371/journal.pone.0122963"
"Stat2Data-RadioactiveTwins","Stat2Data","RadioactiveTwins","Comparing Twins Ability to Clear Radioactive Particles",30,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RadioactiveTwins.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RadioactiveTwins.html","RadioactiveTwins R Documentation   Comparing Twins Ability to Clear Radioactive Particles   Description  
Experiment comparing twins (one urban, one rural) ability to clear airborne radioactive particles from their lungs    Format  
A data frame with 30 observations on the following 3 variables.    TwinPair
Identifies the twin pairs (1 to 15)   Env
Residential environment ( Rural or Urban )   Rate
Clearance rate (percentage radioactive particles remaining after one hour)     Details  
To assess lung health, the scientists measured ""tracheobronchial clearance rate,"" that is, in English, ""How fast do your lungs get rid of nasty stuff?"" Each subject agreed to inhale an aerosol of radioactive Teflon particles. A Geiger counter held to the chest measured the radioactivity just after inhaling, and again one hour later. The clearance rate was the percentage of radioactivity remaining – the lower the better. Subjects were 15 sets of identical twins, each pair with one twin living in an urban environment and the other in a rural environment.    Source  
Per Camner MD & Klas Philipson MSc (1973) ""Urban Factor and Tracheobronchial Clearance,"" Archives of Environmental Health: An International Journal, 27:2, 81-84, DOI: 10.1080/00039896.1973.10666323 Link to the article: https://doi.org/10.1080/00039896.1973.10666323"
"Stat2Data-RailsTrails","Stat2Data","RailsTrails","Homes in Northampton MA Near Rail Trails",104,30,6,0,6,0,24,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RailsTrails.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RailsTrails.html","RailsTrails R Documentation   Homes in Northampton MA Near Rail Trails   Description  
Sample of homes in Northampton, MA to see whether being close to a bike trail enhances the value of the home    Format  
A data frame with 104 observations on the following 30 variables.    HouseNum
Unique house number   Acre
Lot size for the house (in acres)   AcreGroup
Lot size groups ( <= 1/4 acre or > 1/4 acre )   Adj1998
Estimated 1998 price (in thousands of 2014 dollars)   Adj2007
Estimated 2007 price (in thousands of 2014 dollars)   Adj2011
Estimated 2011 price (in thousands of 2014 dollars)   BedGroup
Bedroom groups ( 1-2 beds , 3 beds , or 4+ beds )   Bedrooms
Number of bedrooms   BikeScore
Bike friendliness (0-100 score, higher scores are better)   Diff2014
Difference in price between 2014 estimate and adjusted 1998 estimate (in thousands of dollars)   Distance
Distance (in feet) to the nearest entry point to the rail trail network   DistGroup
Distance groups, compared to 1/2 mile ( Closer or Farther Away )   GarageSpaces
Number of garage spaces (0-4)   GarageGroup
Any garage spaces? ( no or yes )   Latitude
Latitude (for mapping)   Longitude
Longitude (for mapping)   NumFullBaths
Number of full baths (includes shower or bathtub)   NumHalfBaths
Number of half baths (no shower or bathtub)   NumRooms
Number of rooms   PctChange
Percentage change from adjusted 1998 price to 2014 (value of zero means no change)   Price1998
Zillow 10 year estimate from 2008 (in thousands of dollars)   Price2007
Zillow price estimate from 2007 (in thousands of dollars)   Price2011
Zillow price estimate from 2011 (in thousands of dollars)   Price2014
Zillow price estimate from 2014 (in thousands of dollars)   SFGroup
SquareFeet group ( <= 1500 sf or > 1500 sf )   SquareFeet
Square footage of interior finished space (in thousands of sf)   StreetName
Street name   StreetNum
House number on street   WalkScore
Walk friendliness (0-100 score, higher scores are better)   Zip
Location ( 1060 = Northampton or 1062 = Florence)     Details  
This dataset comprises 104 homes in Northampton, MA that were sold in 2007. The authors measured the shortest distance from each home to a railtrail on streets and pathways with Google maps and recorded the Zillow.com estimate of each home's price in 1998 and 2011. Additional attributes such as square footage, number of bedrooms and number of bathrooms are available from a realty database from 2007. We divide the houses into two groups based on distance to the trail (DistGroup).    Source  
From July 2015 JSE Datasets and Stories: ""Rail Trails and Property Values: Is There an Association?"", Ella Hartenian, Smith College and Nicholas J. Horton, Amherst College.   
http://www.amstat.org/publications/jse/v23n2/horton.pdf"
"Stat2Data-Rectangles","Stat2Data","Rectangles","Measurements of Rectangles",9,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Rectangles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Rectangles.html","Rectangles R Documentation   Measurements of Rectangles   Description  
Measurements for a hypothetical set of nine rectangles.    Format  
A data frame with 9 observations on the following 5 variables.    Case
ID number for each rectangle   Width
Width (1, 4, or 10)   Length
Length (1, 4, or 10)   Area
Area   logArea
Log (base 10) of area     Details  
Areas for rectangles of width 1, 4, or 10 and length of 1, 4, or 10.    Source  
Areas computed for a hypothetical set of rectangles."
"Stat2Data-ReligionGDP","Stat2Data","ReligionGDP","Religion and GDP for Countries",44,9,6,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ReligionGDP.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ReligionGDP.html","ReligionGDP R Documentation   Religion and GDP for Countries   Description  
Data on religiosity of countries from the Pew Global Attitudes Project    Format  
A dataset with 44 observations on the following 9 variables.   
  Country Name of country
  Religiosity A measure of degree of religiosity for residents of the country
  GDP Per capita Gross Domestic Product in the country
  Africa Indicator for countries in Africa
  EastEurope Indicator for countries in Eastern Europe
  MiddleEast Indicator for countries in the Middle East
  Asia Indicator for countries in Asia
  WestEurope Indicator for countries in Western Europe
  Americas Indicator for countries in North/South America
    Details  
The Pew Research Center's Global Attitudes Project surveyed people around the world and asked (among many other questions) whether they agreed that ""belief in God is necessary for morality,"" whether religion is very important in their lives, and whether they pray at least once per day. The variable Religiosity is the sum of the percentage of positive responses on these three items, measured in each of 44 countries. The dataset also includes the per capita GDP for each country and indicator variables that record the part of the world the country is in.    Source  
Data from the 2007 Spring Survey conducted through the Pew Global Attitudes Project at http://www.pewglobal.org."
"Stat2Data-RepeatedPulse","Stat2Data","RepeatedPulse","Pulse Rates at Various Times of Day",104,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RepeatedPulse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RepeatedPulse.html","RepeatedPulse R Documentation   Pulse Rates at Various Times of Day   Description  
A student measured her pulse several times a day over 26 days.    Format  
A data frame with 104 observations on the following 3 variables.    Pulse
Pulse rate (beats per minute)   Time
Time of day ( evening , morning , noon , one )   Day
Day1 to Day26     Details  
A student measured her pulse in the morning, at noon, at 1:00, and in the evening for each of 26 days.    Source  
Data supplied by a student at Oberlin College."
"Stat2Data-ResidualOil","Stat2Data","ResidualOil","US Residual Oil Production (Quarterly 1983-2016)",136,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ResidualOil.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ResidualOil.html","ResidualOil R Documentation   US Residual Oil Production (Quarterly 1983-2016)   Description  
Quarterly production of residual oil in the U.S. from 1983 to 2016    Format  
A data frame with 136 observations on the following 7 variables.    Year
Year (1983 to 2016)   Qtr
Month ( 1 =Jan-Mar, 2 =Apr-June, 3 =July-Sep, 4 =Oct-Dec)   t
Time index (1 to 136)   Oil
Residual fuel oil distribution (in million gallons/day)   LogOil
Natural logarithm of Oil     Details  
The U.S. Energy Information Administration tracks the production and distribution of various types of petroleum products. The category for this dataset is called residual oil, which are heavier oils (often called No. 5. and No. 6) that remain after lighter oils (such as No. 4 home heating oil) are distilled away in the refining process. It is used in steam-powered ships, power plants, and other industrial applications.    Source  
U.S. Energy Information Administration website - Refiner sales volumes for residual fuel oil and No. 4 heating oil at https://www.eia.gov/petroleum/data.php#consumption. Specific webpage is
https://www.eia.gov/dnav/pet/pet_cons_refres_d_nus_VTR_mgalpd_m.htm."
"Stat2Data-Retirement","Stat2Data","Retirement","Yearly Contributions to a Supplemental Retirement Account",16,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Retirement.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Retirement.html","Retirement R Documentation   Yearly Contributions to a Supplemental Retirement Account   Description  
Contributions to a supplemental retirement account (1997-2012)    Format  
A dataset with 16 observations on the following 2 variables.   
  Year 1997-2012
  SRA Annual contribution to the Supplemental Retirement Account
    Details  
A faculty member opened a supplemental retirement account (SRA) in 1997 to invest money for retirement. This dataset shows the annual contributions to that account. Annual contributions were adjusted downward during sabbatical years in order to maintain a steady family income.    Source  
Individual records kept by the faculty member."
"Stat2Data-Ricci","Stat2Data","Ricci","Firefighter Promotion Exam Scores",118,5,1,0,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Ricci.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Ricci.html","Ricci R Documentation   Firefighter Promotion Exam Scores   Description  
Data on firefighter promotion exams as part of the Ricci v. DeStafano court case    Format  
A data frame with 118 observations on the following 5 variables.    Race
Race of firefighter ( B =black, H =Hispanic, or W =white)   Position
Promotion desired ( Captain or Lieutenant )   Oral
Oral exam score   Written
Written exam score   Combine
Combined score (written exam gets 60% weight)     Details  
The city of New Haven, Connecticut administered exams (both written and oral) in November and December of 2003 to firefighters hoping to qualify for promotion to either Lieutenant or Captain in the city fire department. A final score consisting of a 60% weight for the written exam and a 40% weight for the oral exam was computed for each person who took the exam. For each person who took the exams, there are measurements on their race (black, white, or Hispanic), which position they were trying for (Lieutenant, Captain), scores on the oral and written exams, and the combined score. These data were used as part of a court case (Ricci v.DeStefano) dealing with racial discrimination    Source  
Data (RicciData.csv ) and documentation (Ricci.txt) downloaded from
 http://www.amstat.org/publications/jse/jse_data_archive.htm   
An article on using these data: Miao, W. (2011) ""Did the Results of Promotion Exams Have a Disparate Impact on Minorities? Using Statistical Evidence in Ricci v. DeStefano,"" JSE 19:1 at
www.amstat.org/publications/jse/v19n1/wilson.pdf"
"Stat2Data-RiverElements","Stat2Data","RiverElements","Elements in River Water Samples",12,27,0,0,1,0,26,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RiverElements.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RiverElements.html","RiverElements R Documentation   Elements in River Water Samples   Description  
Concentrations of elements in river water samples from upstate NY    Format  
A dataset with 12 observations on the following 27 variables.   
  River One of four rivers: Grasse , Oswegatchie , Raquette , or St. Regis
  Site Location: 1=UpStream, 2=MidStream, 3=Downstream
  Al Aluminum
  Ba Barium
  Br Bromine
  Ca Calcium
  Ce Cerium
  Cu Copper
  Dy Dysprosium
  Er Erbim
  Fe Iron
  Gd Gadolinium
  Ho Holmum
  K Potassium
  La Lathanum
  Li Lithium
  Mg Magnesium
  Mn Manganese
  Nd Neodymium
  Pr Proseyodymium
  Rb Rubidium
  Si Silicon
  Sr Strontium
  Y Yttrium
  Yb Ytterbium
  Zn Zinc
  Zr Zirconium
    Details  
Some geologists were interested in the water chemistry of rivers in upstate New York. They took water samples at three different locations in four rivers (Grasse, Oswegatchie, Raquette, and St. Regis). The sampling sites were chosen to investigate how the composition of the water changes as it flows from the source to the mouth of each river. The sampling sites were labeled as upstream, midstream, and downstream. This dataset contains the concentrations (parts per million) of a variety of elements in those water samples. The dataset RiverIron contains the information for iron (FE) alone, along with the log of the concentration.    Source  
Thanks to Dr. Jeff Chiarenzelli of the St. Lawrence University Geology Department for the data.    References  
Chiarenzelli, Lock, Cady, Bregani and Whitney, ""Variation in river multi-element chemistry related to bedrock buffering: an example from the Adirondack region of northern New York, USA"", Environmental Earth Sciences, Volume 67, Number 1 (2012), 189-204"
"Stat2Data-RiverIron","Stat2Data","RiverIron","Iron in River Water Samples",12,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/RiverIron.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/RiverIron.html","RiverIron R Documentation   Iron in River Water Samples   Description  
Amounts of iron in water samples of four rivers    Format  
A dataset with 12 observations on the following 4 variables.   
  River One of four rivers: Grasse , Oswegatchie , Raquette , or St. Regis
  Site Location of the site: DownStream , MidStream or Upstream
  Iron Iron concentration in the water sample (parts per million)
  LogIron Log (base 10) of iron concentration
    Details  
Some geologists were interested in the water chemistry of rivers in upstate New York. They took water samples at three different locations in four rivers (Grasse, Oswegatchie, Raquette, and St. Regis). The sampling sites were chosen to investigate how the composition of the water changes as it flows from the source to the mouth of each river. The sampling sites were labeled as upstream, midstream, and downstream. This dataset contains the concentrations of iron in the samples. The dataset RiverElements has similar concentration data for many other elements.    Source  
Thanks to Dr. Jeff Chiarenzelli of the St. Lawrence University Geology Department for the data.    References  
Chiarenzelli, Lock, Cady, Bregani and Whitney, ""Variation in river multi-element chemistry related to bedrock buffering: an example from the Adirondack region of northern New York, USA"", Environmental Earth Sciences, Volume 67, Number 1 (2012), 189-204"
"Stat2Data-SampleFG","Stat2Data","SampleFG","Field Goal Attempts in the NFL",30,13,1,0,4,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SampleFG.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SampleFG.html","SampleFG R Documentation   Field Goal Attempts in the NFL   Description  
A sample of 30 field goal attempts in the National Football League    Format  
A dataset with 30 observations on the following 13 variables.   
  ID ID number
  PlayerID Code for player
  LastName Last name
  FirstName First name
  Year Year
  Team Abbreviation for team name
  Date Code for date: mmddyy
  FGAttempts Field goals attempted by the kicker that game
  FGMade Field goals made by the kicker that game
  Attempt Which attempt during the game?
  Result 1 =made the field goal or 0 =missed
  Yards Number of yards for the field goal attempt
  Block 1 =attempt blocked or 0 =not blocked
    Details  
This is a subset of just 30 field goal attempts selected at random from the larger sample of attempts made by NFL kickers that is summarized in FGByDistance.    Source  
We thank Sean Forman and Doug Drinen of Sports Reference LLC for providing us with the NFL field goal data set."
"Stat2Data-SandwichAnts","Stat2Data","SandwichAnts","Ants on Sandwiches",48,5,1,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SandwichAnts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SandwichAnts.html","SandwichAnts R Documentation   Ants on Sandwiches   Description  
Ant counts on samples of different kinds of sandwiches    Format  
A dataset with 48 observations on the following 5 variables.   
  Trial Trial number
  Bread Type of bread: Multigrain , Rye , White , or Wholemeal
  Filling Type of filling: HamPickles , PeanutButter , or Vegemite
  Butter Butter on the sandwich? no or yes
  Ants Number of ants on the sandwich
    Details  
As young students, Dominic Kelly and his friends enjoyed watching ants gather on pieces of sandwiches. Later, as a university student, Dominic decided to study this with a more formal experiment. He chose three types of sandwich fillings (vegemite, peanut butter, and ham & pickles), four types of bread (multigrain, rye, white, and wholemeal), and put butter on some of the sandwiches.
 To conduct the experiment he randomly chose a sandwich, broke off a piece, and left it on the ground near an ant hill. After several minutes he placed a jar over the sandwich bit and counted the number of ants. He repeated the process, allowing time for ants to return to the hill after each trial, until he had two samples for each combination of the three factors.    Source  
Margaret Mackisack, “Favourite Experiments: An Addendum to What is the Use of Experiments Conducted by Statistics Students?"", Journal of Statistics Education (1994)
 http://www.amstat.org/publications/jse/v2n1/mackisack.supp.html"
"Stat2Data-SATGPA","Stat2Data","SATGPA","SAT Scores and GPA",24,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SATGPA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SATGPA.html","SATGPA R Documentation   SAT Scores and GPA   Description  
A sample of SAT scores and grade point averages for statistics students    Format  
A dataset with 24 observations on the following 3 variables.   
  MathSAT Score (out of 800) on the mathematics portion of the SAT exam
  VerbalSAT Score (out of 800) on the verbal portion of the SAT exam
  GPA Grade point average (0.0-4.0 scale)
    Details  
In recent years many colleges have re-examined the traditional role the scores on the Scholastic Aptitude Tests (SAT's) play in making decisions on which students to admit. Do SAT scores really help predict success in college? To investigate this question a group of 24 introductory statistics students supplied the data in this dataset showing their score on the Verbal and Math portions of the SAT as well as their current grade point average (GPA) on a 0.0-4.0 scale.    Source  
Student survey in an introductory statistics course."
"Stat2Data-SeaIce","Stat2Data","SeaIce","Arctic Sea Ice (1979-2015)",37,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SeaIce.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SeaIce.html","SeaIce R Documentation   Arctic Sea Ice (1979-2015)   Description  
Area of sea ice in the Arctic measured yearly in September (1979 to 2015)    Format  
A data frame with 37 observations on the following 4 variables.    Year
Year (1979 - 2015)   Extent
Extent of arctic sea ice (in million square km)   Area
Area of arctic sea ice (in million square km)   t
Index for year (t=1 in 1979)     Details  
Climatologists have been measuring the amount of sea ice in both the Arctic and Antarctic regions for a number of years. This datafile gives information about the amount of sea ice in the arctic region as measured in September (the time when the amount of ice is at its least) since 1979. The basic research question is to see if we can use time to model the amount of sea ice.   
In fact, there are two ways to measure the amount of sea ice: Area and Extent. Area measures the actual amount of space taken up by ice. Extent measures the area inside the outer boundaries created by the ice. If there are areas inside the outer boundaries that are not ice (think about a slice of swiss cheese), then the Extent will be a larger number than the Area. In fact, this is almost always true.    Source  
Data from ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/Sep/N_09_areaV2.txt updated data from   
Witt, G. (2103) ""Using Data from Climate Science to Teach Introductory Statistics,"" JSE 21:1 available at www.amstat.org/publications/jse/v21n1/witt.pdf"
"Stat2Data-SeaSlugs","Stat2Data","SeaSlugs","Sea Slug Larvae",36,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SeaSlugs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SeaSlugs.html","SeaSlugs R Documentation   Sea Slug Larvae   Description  
Metamorphose rates for sea slugs exposed to different water samples    Format  
A dataset with 36 observations on the following 2 variables.   
  Time Minutes after tide come in
  Percent Proportion of 15 sea slug larvae that metamorphose
    Details  
Sea slugs, common on the coast of southern California, live on vaucherian seaweed. The larvae from these sea slugs need to locate this type of seaweed to survive. A study was done to try to determine whether chemicals that leach out of the seaweed attract the larvae. Seawater was collected over a patch of this kind of seaweed at 5-minute intervals as the tide was coming in and, presumably, mixing with the chemicals. The idea was that as more seawater came in, the concentration of the chemicals was reduced. Each sample of water was divided into 6 parts. Fifteen larvae were then introduced to this seawater to see what percentage metamorphosed (an indication that the desired chemical was detected).    Source  
Data downloaded from http://www.stat.ucla.edu/projects/datasets/seaslug-explanation.html    References  
A paper based on these data: Krug, P.J. and R.K. Zimmer. 2000b. Larval settlement: chemical markers for tracing production, transport, and distribution of a waterborne cue. Marine Ecology Progress Series, vol. 207: 283-296."
"Stat2Data-SleepingShrews","Stat2Data","SleepingShrews","Shrew Heart Rates at Stages of Sleep",18,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SleepingShrews.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SleepingShrews.html","SleepingShrews R Documentation   Shrew Heart Rates at Stages of Sleep   Description  
Heart rates for a sample of six tree shrews at each of three stages of sleep.    Format  
A data frame with 18 observations on the following 4 variables.    ID
Row ID   Shrew
Shrew ID ( A through F )   Phase
Phase of sleep ( DSW =deep wave, LSW =light wave, or REM =dreaming)   Rate
Heart rate (beats per minute)     Details  
Heart rates were recorded for a sample of six tree shrews at each of three stages of sleep.    Source  
Berger, R. J. and Walker, J. M. (1972) ""The Polygraphic Study of Sleep in the Tree Shrew,"" Brain, Behavior, and Evolution, v. 5, pp. 62"
"Stat2Data-Sparrows","Stat2Data","Sparrows","Sparrow Measurements",116,3,0,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Sparrows.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Sparrows.html","Sparrows R Documentation   Sparrow Measurements   Description  
Weight and wing length for a sample of Savannah sparrows    Format  
A dataset with 116 observations on the following 3 variables.   
  Treatment Nest adjustment: control , enlarged , or reduced
  Weight Weight (in grams)
  WingLength Wing length (in mm)
    Details  
Priscilla Erickson from Kenyon College collected data on a stratified random sample of 116 Savannah sparrows at Kent Island. Nests that were reduced, controlled (no change), or enlarged.    Source  
We thank Priscilla Erickson and Professor Robert Mauck from the Department of Biology at Kenyon College for allowing us to use these data."
"Stat2Data-SpeciesArea","Stat2Data","SpeciesArea","Land Area and Mammal Species",14,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SpeciesArea.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SpeciesArea.html","SpeciesArea R Documentation   Land Area and Mammal Species   Description  
Land area and number of mammal species for islands in Southeast Asia    Format  
A dataset with 14 observations on the following 5 variables.   
  Name Name of the island
  Area Area (in sq. km)
  Species Number of mammal species
  logArea Natural logarithm (base e) of Area
  logSpecies Natural logarithm (base e) of Species
    Details  
This dataset shows the number of mammal species and the area for 13 islands in Southeast Asia. Biologists have speculated that the number of species is related to the size of an island and would like to be able to predict the number of species given the size of an island.    Source  
Heaney, Lawrence R. (1984) ""Mammalian species richness on islands on the Sunda Shelf, Southeast Asia,"" Oecologia, 61:11 17."
"Stat2Data-Speed","Stat2Data","Speed","Highway Fatality Rates (Yearly)",21,3,1,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Speed.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Speed.html","Speed R Documentation   Highway Fatality Rates (Yearly)   Description  
Highway fatality rates 1987-2007    Format  
A dataset with 21 observations on the following 3 variables.   
  Year Year (1987-2007)
  FatalityRate Number of fatalities on interstate highways (per 100 million vehicle-miles)
  StateControl 0 =1987-1994 or 1 =1995-2007
    Details  
In 1987 the federal government allowed the speed limit on interstate highways to be 65 mph in most areas. In 1995 federal restrictions were eliminated, so that states assumed control of setting speed limits on interstate highways. This data set compares fatality rates for years before and after the states assumed control for highway speed limits.    Source  
Data from the National Highway Safety Administration website at
 http://www-fars.nhtsa.dot.gov/Main/index.aspx"
"Stat2Data-SugarEthanol","Stat2Data","SugarEthanol","Effects of Oxygen on Sugar Metabolism",16,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SugarEthanol.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SugarEthanol.html","SugarEthanol R Documentation   Effects of Oxygen on Sugar Metabolism   Description  
Experiment on the effects of oxygen on sugar metabolism by bacteria    Format  
A data frame with 16 observations on the following 3 variables.    Sugar
Type of sugar ( Galactose or Glucose )   Oxygen
Oxygen concentration   Ethanol
Ethanol concentration     Details  
Many biochemical reactions are slowed or prevented by the presence of oxygen. For example, there are two simple forms of fermentation, one which converts each molecule of sugar to two molecules of lactic acid, and a second which converts each molecule of sugar to one each of lactic acid, ethanol, and carbon dioxide. This experiment was designed to compare the inhibiting effect of oxygen on the metabolism of two different sugars, glucose and galactose, by Streptococcus bacteria. In this case there were four levels of oxygen that were applied to the two kinds of sugar.    Source  
Data are found in Statistics: The Exploration and Analysis of Data by Jay Devore and Roxy Peck (2008). St. Paul, MN: West.   
The original article is Yamada T., Takahashi-Abbe S., Abbe K. (1985) ""Effects of oxygen concentration on pyruvate formatelyase in situ and sugar metabolism of Streptocucoccus mutans and Streptococcus samguis,"" Infection and Immunity, pp. 129-134."
"Stat2Data-SuicideChina","Stat2Data","SuicideChina","Suicide Attempts in Shandong, China",2571,11,3,0,7,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/SuicideChina.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/SuicideChina.html","SuicideChina R Documentation   Suicide Attempts in Shandong, China   Description  
Data on serious suicide attempts in Shandong, China    Format  
A data frame with 2571 observations on the following 11 variables.    Person_ID
ID number   Hospitalised
Hospitalised? ( no or yes )   Died
Died? ( no or yes )   Urban
Urban area? ( no , unknown , or yes )   Year
Year (2009, 2010, or 2011)   Month
Month ( 1 =Jan through 12 =December)   Sex
Sex ( female or male )   Age
Age (years)   Education
Education level ( iliterate , primary , Secondary , Tertiary , or unknown )   Occupation
One of ten occupation categories   method
One of nine possible methods     Details  
Data from a study of serious suicide attempts over three years in a predominantly rural population in Shandong, China.    Source  
Sun J, Guo X, Zhang J, Wang M, Jia C, Xu A (2015) ""Incidence and fatality of serious suicide attempts in a predominantly rural population in Shandong, China: a public health surveillance study,"" BMJ Open 5(2): e006762. https://doi.org/10.1136/bmjopen-2014-006762   
Data downloaded via Dryad Digital Repository. https://doi.org/10.5061/dryad.r0v35"
"Stat2Data-Swahili","Stat2Data","Swahili","Attitudes Towards Swahili in Kenyan Schools",480,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Swahili.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Swahili.html","Swahili R Documentation   Attitudes Towards Swahili in Kenyan Schools   Description  
Attitudes towards the Swahili language among Kenyan school children    Format  
A dataset with 480 observations on the following 4 variables.   
  Province NAIROBI or PWANI
  Sex female or male
  Attitude.Score Score (out a possible 200 points) on a survey of attitude towards the Swahili language
  School Code for the school: A through L
    Details  
Hamisi Babusa, a Kenyan scholar, administered a survey to 480 students from Pwani and Nairobi provinces about their attitudes towards the Swahili language. In addition, the students took an exam on Swahili. From each province, the students were from 6 schools (3 girls schools and 3 boys schools) with 40 students sampled at each school, so half of the students from each province were males and the other half females. The survey instrument contained 40 statements about attitudes towards Swahili and students rated their level of agreement to each. Of these questions, 30 were positive questions and the remaining 10 were negative questions. On an individual question the most positive response would be assigned a value of 5 while the most negative response would be assigned a value of 1. By summing (adding) the responses to each question, we can find an overall Attitude Score for each student. The highest possible score would be 200 (an individual who gave the most positive possible response to every question). The lowest possible score would be 40 (an individual who gave the most negative response to every question).    Source  
Thanks to Dr. Babusi of Kenyatta University for sharing these data."
"Stat2Data-Tadpoles","Stat2Data","Tadpoles","Effects of a Fungus on Tadpoles",27,4,1,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Tadpoles.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Tadpoles.html","Tadpoles R Documentation   Effects of a Fungus on Tadpoles   Description  
Comparing intestine lengths for tadpoles with and without exposure to Bd fugus    Format  
A data frame with 27 observations on the following 4 variables.    Treatment
Exposed to fungus ( Bd =yes or Control =no)   Body
Length of body (in mm)   GutLength
Length of intestine (in mm)   MouthpartDamage
Measure of damage to the mouth (e.g. missing teeth)     Details  
Biologists wondered whether tadpoles can adjust the relative length of their intestines if they are exposed to a fungus called Batrachochytrium dendrobatidis (Bd).    Source  
Venesky MD, Hanlon SM, Lynch K, Parris MJ, Rohr JR. (2013) ""Optimal digestion theory does not predict the effect of pathogens on intestinal plasticity,"" Biol Lett 9: 20130038. http://dx.doi.org/10.1098/rsbl.2013.0038"
"Stat2Data-TechStocks","Stat2Data","TechStocks","Daily Prices of Three Tech Stocks",504,5,0,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TechStocks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TechStocks.html","TechStocks R Documentation   Daily Prices of Three Tech Stocks   Description  
Daily closing prices of Apple, Google, and Microsoft stocks (12/1/2015 to 12/1/2017)    Format  
A data frame with 504 observations on the following 5 variables.    Date
Date (coded as mm/dd/yyyy )   AAPL
Apple Inc. closing price   GOOG
Alphabet Inc. (Google) closing price   MSFT
Microsoft Corp. closing price   t
Time index (1 to 505)     Details  
Closing price of Apple (AAPL), Google/Alphabet (GOOG) and Microsoft (MSFT) stocks for each trading day in a two-year period from 12/1/2015 to 12/1/2017.    Source  
Data downloaded using the Quandl R package (12/2/2017)"
"Stat2Data-TeenPregnancy","Stat2Data","TeenPregnancy","State Teen Pregnancy Rates",50,4,0,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TeenPregnancy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TeenPregnancy.html","TeenPregnancy R Documentation   State Teen Pregnancy Rates   Description  
State teen pregnancy rates, Civil War participation, and church attendance.    Format  
A data frame with 50 observations on the following 4 variables.    State
State abbreviation   CivilWar
Role in Civil War ( B =border, C =Confederate, O =other, or U =union)   Church
Percentage who attended church in previous week (from a state survey)   Teen
Number of pregnancies per 1000 teenage girls in state     Details  
State level data on teen pregnancies, church attendance, and role in the U.S. Civil War.    Source  
2010 teen pregnancy rate, per 1000 teenage women, per year. Source: Guttmacher Institute, via Tanya Lewis (5 May 2014) ""Teen pregnancy rates by state,"" https://www.livescience.com"
"Stat2Data-TextPrices","Stat2Data","TextPrices","Textbook Prices",30,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TextPrices.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TextPrices.html","TextPrices R Documentation   Textbook Prices   Description  
Prices and number of pages for a sample of college textbooks    Format  
A dataset with 30 observations on the following 2 variables.   
  Pages Number of pages in the textbook
  Price Price of the textbook (in dollars)
    Details  
Two undergraduate students at Cal Poly - San Luis Obispo took a random sample of 30 textbooks from the campus bookstore in the fall of 2006. They recorded the price and number of pages in each book, in order to investigate the question of whether number of pages can be used to predict price.    Source  
Student project"
"Stat2Data-ThomasConfirmation","Stat2Data","ThomasConfirmation","US Senate Votes on Clarence Thomas Confirmation",100,6,3,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ThomasConfirmation.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ThomasConfirmation.html","ThomasConfirmation R Documentation   US Senate Votes on Clarence Thomas Confirmation   Description  
Votes in the US Senate on Clarence Thomas nomination for the US Supreme Court    Format  
A data frame with 100 observations on the following 6 variables.    State
State name   Senator
Senator name   Party
Party affiliation ( D =Democrat or R =Republican)   ConfVote
Confirmation vote ( Nay or Yea )   StateOpinion
Percentage of state residents supporting the choice   Vote
Numeric coding for vote ( 1 =for or 0 =against)     Details  
Data from the U.S. Senate vote on October 15, 1991 to confirm Clarence Thomas to a position on the Supreme Court.    Source  
These numbers are taken from Kastellec, J.P., Lax, J.R., and Phillips, J. (2010), ""Public Opinion and Senate Confirmation of Supreme Court Nominees,"" Journal of Politics, 72(3): 767-84. In this paper the authors used opinion polls and an advanced statistical method known as multilevel regression and poststratification to determine the StateOpinion levels."
"Stat2Data-ThreeCars","Stat2Data","ThreeCars","Prices of Three Used Car Models (2007)",90,8,3,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ThreeCars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ThreeCars.html","ThreeCars R Documentation   Prices of Three Used Car Models (2007)   Description  
Compare prices for Porsche, Jaguar, and BMW cars offered for sale at an internet site    Format  
A dataset with 90 observations on the following 8 variables.   
  CarType BMW , Jaguar , or Porsche
  Price Asking price (in $1,000's)
  Age Age of the car (in years)
  Mileage previous miles driven (in 1,000's)
  Car 0 =Porsche, 1 =Jaguar, 2 =BMW
  Porsche Indicator with 1 = Porsche and 0 =otherwise
  Jaguar Indicator with 1 = Jaguar and 0 =otherwise
  BMW Indicator with 1 = BMW and 0 =otherwise
    Details  
Two students collected samples of Porsche, Jaguar, and BMW cars that were offered for sale at an internet site. In addition to asking price, they recorded the model year (converting to age) and mileage of each advertised car. The PorschePrice dataset (from the first edition) has only the Porsche data and the PorscheJaguar dataset has the data for those two models.   
This dataset has been updated (with different car models) to ThreeCars2017 for the second edition.    Source  
Student project data collected from autotrader.com in Spring 2007."
"Stat2Data-ThreeCars2017","Stat2Data","ThreeCars2017","Price, Age, and Mileage of Three Used Car Models",90,7,3,0,1,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ThreeCars2017.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/ThreeCars2017.html","ThreeCars2017 R Documentation   Price, Age, and Mileage of Three Used Car Models   Description  
Data from cars.com for a sample of three different models of used cars in 2017    Format  
A data frame with 90 observations on the following 7 variables.    CarType
Model ( Accord , Maxima , or Mazda6 )   Age
Age of used car (years)   Price
Price (in thousands of dollars)   Mileage
Mileage (in thousands of miles)   Mazda6
Is the car a Mazda6? ( 1 =yes or 0 =no)   Accord
Is the car an Accord? ( 1 =yes or 0 =no)   Maxima
Is the car a Maxima? ( 1 =yes or 0 =no)     Details  
Data for a sample of cars from three models (Mazda6, Honda Accord, Toyota Maxima) from a website. The dataset AccordPrice is a subset of this file.    Source  
Data obtained from cars.com, February 2017 using zip code 44107, Lakewood, Ohio."
"Stat2Data-TipJoke","Stat2Data","TipJoke","Improve Chances of Getting a Tip?",211,5,4,0,1,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TipJoke.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TipJoke.html","TipJoke R Documentation   Improve Chances of Getting a Tip?   Description  
Effect of a waiter leaving a joke or an advertisement on getting a tip    Format  
A dataset with 211 observations on the following 5 variables.   
  Card Type of card used: Ad , Joke , or None
  Tip 1 =customer left a tip or 0 =no tip
  Ad Indicator for Ad card ( 1 =ad card left or 0 =no ad card)
  Joke Indicator for Joke card ( 1 =joke card left or 0 =no joke card)
  None Indicator for no card ( 1 =no card left or 0 =ad or joke card left)
    Details  
Can telling a joke affect whether or not a waiter in a coffee bar receives a tip from a customer? A study investigated this question at a coffee bar at a famous resort on the west coast of France. The waiter randomly assigned coffee-ordering customers to one of three groups: When receiving the bill one group also received a card telling a joke, another group received a card containing an advertisement for a local restaurant, and a third group received no card at all. He recorded whether or not each customer left a tip.    Source  
Gueguen, Nicholas (2002), ""The Effects of a Joke on Tipping When it is Delivered at the Same Time as the Bill,"" Journal of Applied Social Psychology, 32, 1955-1963."
"Stat2Data-Titanic","Stat2Data","Titanic","Passengers on the Titanic",1313,6,3,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Titanic.html","Titanic R Documentation   Passengers on the Titanic   Description  
List and outcomes for passengers on the Titanic    Format  
A dataset with 1313 observations on the following 6 variables.   
  Name Passenger name
  PClass Passenger class: * =missing, 1st , 2nd , or 3rd
  Age Age (in years)
  Sex female or male
  Survived 1 =survived or 0 =died
  SexCode 1 =female or 0 =male
    Details  
The Titanic was a British luxury ocean liner that sank famously in the icy North Atlantic on its maiden voyage in April of 1912. Of the approximately 2200 passengers on board, 1500 died. The high death rate was blamed largely on the inadequate supply of lifeboats, a result of the manufacturer's claim that the ship was ""unsinkable."" A partial data set of the passenger list was compiled by Philip Hinde in his Encyclopedia Titanica and is given in this dataset.    Source  
Philip Hinde's Encyclopedia Titanica, http://www.encyclopedia-titanica.org/. Data may also be downloaded from the Australasian Data and Story Library (OzDASL) at
 http://www.statsci.org/data/general/titanic.html."
"Stat2Data-TMS","Stat2Data","TMS","Migraines and TMS",2,4,3,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TMS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TMS.html","TMS R Documentation   Migraines and TMS   Description  
Effects of transcranial magnetic stimulation (TMS) on migraine headaches    Format  
A dataset with 2 observations on the following 4 variables.   
  Group Treatment group: Placebo or TMS
  Yes Count of number of patients that were pain-free
  No Count of number of patients that had pain
  Trials Number of patients in the group
    Details  
A study investigated whether a handheld device that sends a magnetic pulse into a person's head might be an effective treatment for migraine headaches. Researchers recruited 200 subjects who suffered from migraines and randomly assigned them to receive either the TMS (transcranial magnetic stimulation) treatment or a sham (placebo) treatment from a device that did not deliver any stimulation. Subjects were instructed to apply the device at the onset of migraine symptoms and then assess how they felt two hours later. This dataset is a two-way table of the results.   
This dataset renamed as Migraines in second edition.    Source  
Based on results in R. B. Lipton, et. al. (2010) “Single-pulse Transcranial Magnetic Stimulation for Acute Treatment of Migraine with Aura: A Randomised, Double-blind, Parallel-group, Sham-controlled Trial,"" 9(4):373-380."
"Stat2Data-TomlinsonRush","Stat2Data","TomlinsonRush","LaDainian Tomlinson Rushing Yards",16,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TomlinsonRush.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TomlinsonRush.html","TomlinsonRush R Documentation    LaDainian Tomlinson Rushing Yards    Description  
Rushing yards for each game LaDainian Tomlinson played in the 2006 National Football League (NFL regular) season.    Format  
A dataset with 16 observations on the following 4 variables.   
  Game Week number in the 2006 season
  Opponent Name of opposing team
  Attempts Number of rushing attempts
  Yards Total yards gained rushing for the game
    Details  
For each of the sixteen games the San Diego Chargers played in the 2006 NFL regular season we have the number of times LaDainian Tomlinson ran the ball and the total yards he gained.   
This data set from the first edition was replaced by BreesPass in the second edition.    Source  
Data downloaded from http://www.pro-football-reference.com/players/T/TomlLa00/gamelog/2006/"
"Stat2Data-TwinsLungs","Stat2Data","TwinsLungs","Comparing Twins Ability to Clear Radioactive Particles",14,3,1,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/TwinsLungs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/TwinsLungs.html","TwinsLungs R Documentation   Comparing Twins Ability to Clear Radioactive Particles   Description  
Experiment comparing twins (one urban, one rural) ability to clear airborne radioactive particles from their lungs    Format  
A dataset with 14 observations on the following 3 variables.   
  Pair Code for the twin pair: A - G
  Environ Living environment: Rural or Urban
  Percent Percentage of radioactivity remaining in lungs
    Details  
This dataset is from a study to compare the effect of living environment (rural or urban) on human lung function, where the researchers were able to locate seven pairs of twins with one twin in each pair living in the country, the other in a city. To measure lung function, twins inhaled an aerosol of radioactive Teflon particles. By measuring the level of radioactivity immediately and then again after an hour, the scientists could measure the rate of “tracheobronchial clearance."" The percentage of radioactivity remaining in the lungs after an hour told how quickly subjects' lungs cleared the inhaled particles.   
This dataset was renamed as RadioactiveTwins for the second edition.    Source  
“Urban factor and tracheobronchial clearance"" by Per Camner and Klas Philipson in Archives of Environmental Health, V. 27 (1973), page 82. Data can be found in Introduction to Mathematical Statistics and its Applications, 2nd Edition by Richard J. Larson and Morris L. Marx. Englewood Cliffs, NJ: Prentice Hall, p. 548."
"Stat2Data-Undoing","Stat2Data","Undoing","Defense of Undoing OCD Symptoms in Psychotherapy",44,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Undoing.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Undoing.html","Undoing R Documentation   Defense of Undoing OCD Symptoms in Psychotherapy   Description  
Ratings of an OCD symptom in psychotherapy sessions    Format  
A data frame with 44 observations on the following 3 variables.    Group
Time frame of the session ( I =early through VI =late)   Score
Rating of OCD symptom on a 1 to 4 scale   Symbol
Indicator for groups I, III, and IV     Details  
A patient had been diagnosed with OCD (obsessive/compulsive disorder) and underwent a series of psychotherapy sessions. Notes from the sessions were presented to three different experienced therapists who rated sessions with a particular OCD symptom (defense of undoing) on a 1 to 4 scale (smaller values indicating worse symptoms). If all three judges agreed on the stage of a session, that determined the category. Otherwise, they discussed until they reached a consensus. The sessions were also grouped into six groups with I being the earliest sessions and VI being the latest.    Source  
Sampson, Harold, Joseph Weiss, L. Mlodansky, and Edward Hause (1972) ""Defense analysis and the emergence of warded off mental contents,"" Archives of General Psychiatry, v. 26, pp. 524-532."
"Stat2Data-USstamps","Stat2Data","USstamps","Price of US Stamps",25,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/USstamps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/USstamps.html","USstamps R Documentation   Price of US Stamps   Description  
Price of US stamp for first class mail 1885-2012    Format  
A dataset with 25 observations on the following 2 variables.   
  Year Years when stamp price changed
  Price Cost of a US first class stamp (in cents)
    Details  
The data record the year and price for each change in price for a US first class (1 ounce, domestic letter) stamp since 1885.    Source  
http://about.usps.com/who-we-are/postal-history/domestic-letter-rates-1863-2011.htm"
"Stat2Data-VisualVerbal","Stat2Data","VisualVerbal","Visual versus Verbal Performance",80,5,2,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/VisualVerbal.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/VisualVerbal.html","VisualVerbal R Documentation   Visual versus Verbal Performance   Description  
Experiment to compare visual and verbal performance    Format  
A data frame with 80 observations on the following 5 variables.    Subject
Subject number ( s1 to s20 )   Task
Follow a letter ( Visual ) or a sentence ( Verbal )   Report
Point response ( Visual ) or say response ( Verbal )   Group
Combination of Task+Report ( Letter Point , Letter Say , Sentence Point , or Sentence Say )   Time
Response time (in seconds)     Details  
Subjects carried out two kinds of tasks, one visual (identify letters), one verbal (identify sentences); and to report the results in either of two ways, one visual (pointing at a response), one verbal (speaking a response). Time to complete each task was recorded in seconds.    Source  
Original experiment from Brooks, L., R. (1968) ""Spatial and verbal components of the act of recall,"" Canadian J. Psych. V 22, pp. 349 - 368. These data collected from a Mount Holyoke College psychology class."
"Stat2Data-Volts","Stat2Data","Volts","Voltage Drop for a Discharging Capacitor",50,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Volts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Volts.html","Volts R Documentation   Voltage Drop for a Discharging Capacitor   Description  
Voltage drop over time as a capacitor discharges    Format  
A dataset with 50 observations on the following 2 variables.   
  Voltage Voltage (in volts)
  Time Time after charging (in seconds)
    Details  
A capacitor was charged with a nine-volt battery and then a voltmeter recorded the voltage as the capacitor was discharged. Measurements were taken every 0.02 seconds.    Source  
Measurements recorded by one of the authors."
"Stat2Data-WalkingBabies","Stat2Data","WalkingBabies","Effects of Exercise on First Walking",24,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WalkingBabies.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WalkingBabies.html","WalkingBabies R Documentation   Effects of Exercise on First Walking   Description  
An experiment to see if special exercises help babies learn to walk sooner    Format  
A dataset with 24 observations on the following 2 variables.   
  Group Treatments: exercise control , final report , special exercises , or weekly report
  Age Age (in months) when first walking
    Details  
Scientists wondered if they could get babies to walk sooner by prescribing a set of special exercises. Their experimental design included four groups of babies and the following treatments:
   
Special exercises: Parents were shown the special exercises and encouraged to use them with their children. They were phoned weekly to check on their child's progress.
   
Exercise control: These parents were not shown the special exercises, but they were told to make sure their babies spent at least 15 minutes a day exercising.
   
Weekly report: Parents in this group were not given instructions about exercise. Like the parents in the treatment group, however, they received a phone call each week to check on progress.
   
Final report: These parents were not given weekly phone calls or instructions about exercises. They reported at the end of the study.    Source  
Zelazo, Phillip R., Nancy Ann Zelazo, and Sarah Kolb (1972), “Walking in the Newborn,"" Science, v. 176, pp. 314-315."
"Stat2Data-WalkTheDogs","Stat2Data","WalkTheDogs","Did the Author Walk the Dogs Today?",223,7,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WalkTheDogs.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WalkTheDogs.html","WalkTheDogs R Documentation   Did the Author Walk the Dogs Today?   Description  
Daily pedometer data for one of the authors    Format  
A data frame with 223 observations on the following 7 variables.    StepCount
Number of steps taken in the day   Kcal
Calories burned (according to pedometer)   Miles
Miles walked   Weather
cold , rain , or shine   Day
Day of week ( F =Friday, M =Monday, R =Thursday, S =Saturday, T =Tuesday, U =Sunday, W =Wednesday)   Walk
Were the dogs walked? ( 1 =yes or 0 =no)   Steps
Steps in units of 1,000 (so StepCount/1000)     Details  
One of the authors recorded daily pedometer data, the weather, and whether or not he walked the dogs.    Source  
One of the author's pedometer records."
"Stat2Data-WeightLossIncentive","Stat2Data","WeightLossIncentive","Do Financial Incentives Improve Weight Loss?",38,3,1,0,1,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WeightLossIncentive.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WeightLossIncentive.html","WeightLossIncentive R Documentation   Do Financial Incentives Improve Weight Loss?   Description  
An experiment to see if financial incentives improve weight loss    Format  
A dataset with 38 observations on the following 3 variables.   
  WeightLoss Weight loss (in pounds) after four months
  Group Treatment group: Control or Incentive
  Month7Loss Weight loss (in pounds) after seven months
    Details  
Researchers investigated whether financial incentives would help people lose weight more successfully. Some participants in the study were randomly assigned to a treatment group that was offered financial incentives for achieving weight loss goals, while others were assigned to a control group that did not use financial incentives. All participants were monitored over a four month period and the net weight change (Before - After in pounds) at the end of this period was recorded for each individual. Then the individuals were left alone for three months with a followup weight check at the seven-month mark to see whether weight losses persisted after the original four months of treatment.
 The 4-month data alone (with missing values omitted) is stored in WeightLossIncentive4.
 The 7-month data alone (with missing values omitted) is stored in WeightLossIncentive7.    Source  
“Financial incentive-based approaches for weight loss,"" Journal of the American Medical Association by Volpp, John, Troxel, et. al., Vol. 200, no. 22, pp 2631-2637, (Dec. 2008)"
"Stat2Data-WeightLossIncentive4","Stat2Data","WeightLossIncentive4","Do Financial Incentives Improve Weight Loss? (4 Months)",36,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WeightLossIncentive4.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WeightLossIncentive4.html","WeightLossIncentive4 R Documentation   Do Financial Incentives Improve Weight Loss? (4 Months)   Description  
Weight loss after four months with/without a financial incentive    Format  
A dataset with 36 observations on the following 2 variables.   
  WeightLoss weight loss (in pounds) after 4 months
  Group Treatment group: Control or Incentive
    Details  
Researchers investigated whether financial incentives would help people lose weight more successfully. Some participants in the study were randomly assigned to a treatment group that was offered financial incentives for achieving weight loss goals, while others were assigned to a control group that did not use financial incentives. All participants were monitored over a four month period and the net weight change (Before - After in pounds) at the end of this period was recorded for each individual. Then the individuals were left alone for three months with a followup weight check at the seven-month mark to see whether weight losses persisted after the original four months of treatment. This dataset has only the non-missing 4-month data. The 7-month data are in WeightLossIncentive7 and both measurements (including missing values) are in WeightLossIncentive.    Source  
“Financial incentive-based approaches for weight loss,"" Journal of the American Medical Association by Volpp, John, Troxel, et. al., Vol. 200, no. 22, pp 2631-2637, (Dec. 2008)"
"Stat2Data-WeightLossIncentive7","Stat2Data","WeightLossIncentive7","Do Financial Incentives Improve Weight Loss? (7 Months)",33,2,1,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WeightLossIncentive7.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WeightLossIncentive7.html","WeightLossIncentive7 R Documentation   Do Financial Incentives Improve Weight Loss? (7 Months)   Description  
Weight loss after seven months with/without a financial incentive    Format  
A dataset with 33 observations on the following 2 variables.   
  Group Treatment group: Control or Incentive
  Month7Loss Weight loss (in pounds) after seven months
    Details  
Researchers investigated whether financial incentives would help people lose weight more successfully. Some participants in the study were randomly assigned to a treatment group that was offered financial incentives for achieving weight loss goals, while others were assigned to a control group that did not use financial incentives. All participants were monitored over a four month period and the net weight change (Before - After in pounds) at the end of this period was recorded for each individual. Then the individuals were left alone for three months with a followup weight check at the seven-month mark to see whether weight losses persisted after the original four months of treatment. This dataset has only the non-missing 7-month data. The 4-month data are in WeightLossIncentive4 and both measurements (including missing values) are in WeightLossIncentive.    Source  
“Financial incentive-based approaches for weight loss,"" Journal of the American Medical Association by Volpp, John, Troxel, et. al., Vol. 200, no. 22, pp 2631-2637, (Dec. 2008)"
"Stat2Data-Whickham2","Stat2Data","Whickham2","Whickham Health Study",1314,5,4,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Whickham2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Whickham2.html","Whickham2 R Documentation   Whickham Health Study   Description  
Morality data over 20 years for 1314 women from Whickham, England    Format  
A data frame with 1314 observations on the following 5 variables.    Outcome
Status at 20-year follow-up ( Alive or Dead )   Smoker
Smoker at baseline? ( No or Yes )   Age
Age (in years at baseline)   AgeGroup
Age group ( 18-64 or 65+ )   Alive
Numeric code for Outcome ( 1 =alive or 0 =dead)     Details  
Twenty-year mortality, smoking status, and age for 1314 women in Whickham, England. We have named this Whickham2 to distinguish it from Whickham, which is a file in the mosaicData package.    Source  
A version of these data are in the mosaicData package but originally are from:   
Appleton, D. R., French, J. M., and Vanderpump, M.P. (1996), ""Ignoring a Covariate: An Example of Simpson's Paradox,"" The American Statistician, 50, 340-341."
"Stat2Data-WordMemory","Stat2Data","WordMemory","Experiment on Word Memory",40,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WordMemory.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WordMemory.html","WordMemory R Documentation   Experiment on Word Memory   Description  
Percentage of different types of words recalled    Format  
A dataset with 40 observations on the following 4 variables.   
  Subject Code to identify each subject: A to J
  Abstract Words were abstract? No or Yes
  Frequent Words were common? No or Yes
  Percent Percentage of words recalled (out of 25)
    Details  
One hundred words were presented to each subject in a randomized order. The goal of the experiment was to see whether some kinds of words were easier to remember than others. In particular, are common words like potato, love, diet, and magazine easier to remember than less common words like manatee, hangnail, fillip, and apostasy? Are concrete words like coffee, dog, kale, and tamborine easier than abstract words like beauty, sympathy, fauna, and guile? There were 25 words each of four kinds, obtained by crossing the two factors of interest, Abstraction (concrete or abstract) and Frequency (common or rare).   
This dataset appears in the first edition, but is not used in the second edition.    Source  
Data from a student laboratory project, Department of Psychology and Education, Mount Holyoke College."
"Stat2Data-WordsWithFriends","Stat2Data","WordsWithFriends","Words with Friends Scores",444,11,5,0,2,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/WordsWithFriends.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/WordsWithFriends.html","WordsWithFriends R Documentation   Words with Friends Scores   Description  
Results from the online game Words with Friends (solo play)    Format  
A data frame with 444 observations on the following 11 variables.    Points
Number of points scored by the author   OppPoints
Number of points scored by opponent (""solo"")   WinMargin
Points minus OppPoints, so margin of victory (or loss)   Start
Did the author go first or pass? ( first or pass )   Ss
Number of S tiles (0 to 5)   BlanksNumber
Number of Blank tiles (0 to 2)   J
Did the author get the J tile? ( 1 =yes, 0 =no)   Q
Did the author get the Q tile? ( 1 =yes, 0 =no)   X
Did the author get the X tile? ( 1 =yes, 0 =no)   Z
Did the author get the Z tile? ( 1 =yes, 0 =no)   Blanks
Number of Blank tiles ( 0blanks , 1blank , or 2blanks )     Details  
Results collected from one of the authors playing the ""solo"" mode of Words with Friends.    Source  
Author's iPhone"
"Stat2Data-Wrinkle","Stat2Data","Wrinkle","Moving Wet Objects with Wrinkled Fingers",80,7,4,0,4,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Wrinkle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Wrinkle.html","Wrinkle R Documentation   Moving Wet Objects with Wrinkled Fingers   Description  
Results from an experiment to move wet/dry objects with wrinkled/dry fingers    Format  
A data frame with 80 observations on the following 7 variables.    Participant
Participant ID ( p1 to p20 )   Time
Time to move objects (seconds)   Condition
non-wrinkled/dry , non-wrinkled/wet , wrinkled/dry , or wrinkled/wet   Fingers
Status of fingers ( non or wrinkled )   Objects
Status of objects ( dry or wet )   WrinkledThenNon
Wrinkled first? ( 1 =yes or 1 =no)   DryThenWet
Dry first? ( 1 =yes or 1 =no)     Details  
Each of 20 participants were measured doing a ""transfer task"" several times under each of four conditions. The transfer task was to pick up an item with the right hand thumb and index finger, pass the item through a small hole and grab it with the left hand, and then put the item into a box that had a hole in the lid. Sometimes the participant's fingers were wrinkled; sometimes the items were sitting in water.    Source  
Kareklas, Nettle, and Smulders (2013) ""Water-induced finger wrinkles improve handling of wet objects"", Biology Letters, http://dx.doi.org/10.1098/rsbl.2012.0999"
"Stat2Data-YouthRisk","Stat2Data","YouthRisk","Annual survey of health-risk youth behaviors",13387,6,4,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/YouthRisk.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/YouthRisk.html","YouthRisk R Documentation   Annual survey of health-risk youth behaviors   Description  
Data from the Youth Risk Behavior Surveillance System    Format  
A data frame with 13387 observations on the following 6 variables.    ride.alc.driver
1 =rode with a drinking driver in past 30 days or 0 =did not   female
1 =female or 0 =male   grade
Year in high school: 9 , 10 , 11 , or 12   age4
Age (in years)   smoke
Ever smoked? 1 =yes or 0 =no   DriverLicense
Have a driver's license? 1 =yes or 0 =no     Details  
This dataset is derived from the 2007 Youth Risk Behavior Surveillance System (YRBSS), which is an annual survey conducted by the Centers for Disease Control and Prevention (CDC) to monitor the prevalence of health-risk youth behaviors. This dataset focuses on whether or not youths have recently (in past 30 days) ridden with a drunk driver.    Source  
http://www.cdc.gov/HealthyYouth/yrbs/index.htm"
"Stat2Data-YouthRisk2007","Stat2Data","YouthRisk2007","Riding with a Driver Who Has Been Drinking",13387,6,4,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/YouthRisk2007.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/YouthRisk2007.html","YouthRisk2007 R Documentation   Riding with a Driver Who Has Been Drinking   Description  
Risky behavior (riding with a drinking driver) in youths    Format  
A dataset with 13387 observations on the following 6 variables.   
  ride.alc.driver 1 =rode with a drinking driver in past 30 days or 0 =did not
  female 1 =female or 0 =male
  grade Year in high school: 9 , 10 , 11 , or 12
  age4 Age (in years)
  smoke Ever smoked? 1 =yes or 0 =no
  DriverLicense Have a driver's license? 1 =yes or 0 =no
    Details  
This dataset is derived from the 2007 Youth Risk Behavior Surveillance System (YRBSS), which is an annual survey conducted by the Centers for Disease Control and Prevention (CDC) to monitor the prevalence of health-risk youth behaviors. This dataset focuses on whether or not youths have recently (in past 30 days) ridden with a drunk driver.   
This dataset renamed as YouthRisk for the second edition.    Source  
The article ""Which Young People Accept a Lift From a Drunk or Drugged Driver?"" in Accident Analysis and Prevention (July 2009. pp. 703-9) provides more details.    References  
A more recent version of the full dataset is available at http://www.cdc.gov/brfss/technical_infodata/surveydata.htm."
"Stat2Data-YouthRisk2009","Stat2Data","YouthRisk2009","Youth Risk Survey",500,6,2,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/YouthRisk2009.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/YouthRisk2009.html","YouthRisk2009 R Documentation   Youth Risk Survey   Description  
Survey of students in grades 9-12 concerning health-risk behiviors    Format  
A dataset with 500 observations on the following 6 variables.    Sleep
Average hours sleep on school night ( 10 or more hours , 9 hours , down to  4 or less hours )   Sleep7
Seven or more hours of sleep? ( 0 =no or 1 =yes)   SmokeLife
Ever smoked? ( No or Yes )   SmokeDaily
Regular smoker? ( No or Yes )   MarijuaEver
Ever smoked marijuana? ( 0 =no or 1 =yes)   Age
Age (in years)     Details  
Data from the Centers for Disease Control's Youth Risk Behavior Surveillance System (YRBSS).   
This data set is from the first edition, but not used in the second edition.    Source  
http://www.cdc.gov/HealthyYouth/yrbs/index.htm"
"Stat2Data-Zimmerman","Stat2Data","Zimmerman","Stand Your Ground Simpson's Paradox",220,5,5,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Zimmerman.csv","https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Zimmerman.html","Zimmerman R Documentation   Stand Your Ground Simpson's Paradox   Description  
Data from 220 cases in Florida where a ""Stand your ground"" defense was used.    Format  
A data frame with 220 observations on the following 5 variables.    Convicted
Was the defendant Convicted? ( No or Yes )   IndWhiteVictim
Was the victim white? ( 1 =yes or 0 =no)   IndWhiteDefendant
Was the defendant white? ( 1 =yes or 0 =no)   VictimRace
Race of the victim ( Minority or White )   DefendantRace
Race of the defendant ( Minority or White )     Details  
Inspired by the Travon Martin case, combined fatal and non-fatal cases of assault in Florida for which the defendant used the Stand Your Ground law in defense. These data show Simpson's Paradox. Race of the victim is more important than race of the defendant.    Source  
Data from Tampa Bay Times, male plus female cases, as of 2/8/15 – final posted data http://www.tampabay.com/stand-your-ground-law/nonfatal-cases http://www.tampabay.com/stand-your-ground-law/fatal-cases"
"stevedata-af_crime93","stevedata","af_crime93","Statewide Crime Data (1993)",51,8,0,1,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/af_crime93.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/af_crime93.html","af_crime93 R Documentation   Statewide Crime Data (1993)   Description  
These data are in Table 9.1 of the 3rd edition of Agresti and Finlay's *Statistical Methods for the Social Sciences*. The data are from *Statistical Abstract of the United States* and most variables were measured in 1993.    Usage    af_crime93    Format  
A data frame with 51 observations on the following 8 variables.    state
a character vector for the state   violent
a numeric vector for the violent crime rate (per 100,000 people in population)   murder
a numeric vector for the murder rate (per 100,000 people in population)   poverty
a numeric vector for the percent with income below the poverty level   single
a numeric vector for the percent of families headed by a single parent   metro
a numeric vector for the percent of population in metropolitan areas   white
a numeric vector for the percentage of the state that is white   highschool
a numeric vector for the percent of state that graduated from high school     Details  
The data are from Statistical Abstract of the United States and most variables were measured in 1993. These data should result in regressions that would flunk a Breusch-Pagan test for heteroskedasticity.    References  
Agresti, Alan and Barbara Finley. 1997. Statistical Methods for the Social Sciences . Prentice Hall. (3rd Edition)"
"stevedata-aluminum_premiums","stevedata","aluminum_premiums","LME Aluminum Premiums Data",3664,3,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/aluminum_premiums.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/aluminum_premiums.html","aluminum_premiums R Documentation   LME Aluminum Premiums Data   Description  
A near daily data set on the price of aluminum premiums (USD/MT) for LME in the U.S., Western Europe, East Asia, and Southeast Asia. I like these data as illustrative of some of the shortsightedness of the aluminum tariffs that Donald Trump announced in March 2018. The tariffs had no discernible effect on manufacturing employment or earnings, but they created a supply shock that made aluminum more expensive.    Usage    aluminum_premiums    Format  
A data frame with 2,812 observations on the following 3 variables.    date
a date   group
a factor with levels of East Asia , Southeast Asia ,  United States , and Western Europe   price
a numeric vector for the price of the LME aluminum premium     Details  
LME aluminum premiums (monthly contracts going out to 15 months) work alongside LME aluminum contracts to allow market participants to hedge the all-in price and physically deliver or receive premium aluminum warrants in non-queued LME premium warehouses."
"stevedata-anes_partytherms","stevedata","anes_partytherms","Major Party (Democrat, Republican) Thermometer Index Data (1978-2012)",33830,19,2,1,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/anes_partytherms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/anes_partytherms.html","anes_partytherms R Documentation   Major Party (Democrat, Republican) Thermometer Index Data (1978-2012)   Description  
A data set on thermometer ratings for the Democratic party, Republican party, ""both major parties"", and a major party thermometer index from the American National Election Studies (1978-2012).    Usage    anes_partytherms    Format  
A data frame with 33830 observations on the following 19 variables.    year
the survey year   uid
a unique identifier for each respondent, taken directly from the time-series files for potential merging   stateabb
the two-character abbreviation for the state of residence for the respondent   therm_dem
the respondent's thermometer rating of the Democratic party   therm_gop
the respondent's thermometer rating of the Republican party   therm_bmp
the respondent's thermometer rating of ""both major parties""   mpti
the ""major party thermometer index"" score for the respondent. See details for more.   age
the age of the respondent   educat
the education-level of the respondent. 1 = 8 grades or less. 2 = high school, no diploma. 3 = high school diploma. 4 = high school ""plus non-academic training"". 5 = Some college, no degree (includes AA holders). 6 = BA-level degree. 7 = advanced degree, including Bachelor of Laws degrees.   urbanism
1 = central cities. 2 = suburban areas. 3 = rural/small towns/outlying areas.   pid7
1 = Strong Democrat. 2 = Weak Democrat. 3 = Independent, lean Democrat. 4 = Independent. 5 = Independent, lean Republican. 6 = Weak Republican. 7 = Strong Republican   incomeperc
respondent's household income percentile. 1 = 0-16 percentile. 2 = 17-33. 3 = 34-67. 4 = 68-95. 5 = 96-100.   race4
respondent's race-ethnicity summary. 1 = White, non-hispanic. 2 = Black, non-hispanic. 3 = Hispanic. 4 = Other.   unemployed
a binary numeric vector for if the respondent is temporarily unemployed.   polint
the respondent's self-reported interest in public affairs. 1 = Hardly at all. 2 = Only now and then. 3 = Some of the time. 4 = Most of the time.   distrust_govt
the respondent's self-reported (dis)trust in the federal government's ability to do what's right. 1 = Just about always (trust the government). 2 = Most of the time. 3 = Some of the time. 4 = None of the time/never.   govt_crooked
the respondent's assessment of how many government officials are crooked. 1 = Hardly any. 2 = Not many. 3 = Quite a few; quite a lot.   govt_waste
the respondent's assessment of how much the government wastes in tax money. 1 = Not very much. 2 = Some. 3 = A lot.   govt_biginterests
the respondent's assessment of whether the government is run by a few big interests. 0 = Run for the benefit of all people. 1 = Run by a few big interests.     Details  
The major party thermometer index is calculated as the thermometer rating for the Democratic party minus the thermometer rating for the Republican party. 100 is then added to that difference, which is then divided by 2. Fractional results are rounded to the next highest integer. Also note the coding of the ""government distrust"" measures. These are reverse-coded from their original scales.    Source  
Data come from ANES's time series file."
"stevedata-anes_prochoice","stevedata","anes_prochoice","Abortion Attitudes (ANES, 2012)",5914,14,1,1,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/anes_prochoice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/anes_prochoice.html","anes_prochoice R Documentation   Abortion Attitudes (ANES, 2012)   Description  
A simple data set for in-class illustration about how to estimate and interpret interactive relationships. The data here are deliberately minimal for that end.    Usage    anes_prochoice    Format  
A data frame with 5914 observations on the following 14 variables.    version
version identifier from ANES   caseid
time-series case identifier from ANES   health
oppose/""NFNO""/favor [0:2] abortion if pregnancy would hurt woman   fatal
oppose/""NFNO""/favor [0:2] abortion if pregnancy would cause woman to die   incest
oppose/""NFNO""/favor [0:2] abortion if pregnancy was caused by incest   rape
oppose/""NFNO""/favor [0:2] abortion if pregnancy was caused by rape   bd
oppose/""NFNO""/favor [0:2] abortion if fetus would be born with serious birth defect   fin
oppose/""NFNO""/favor [0:2] abortion if having child would impose financial hardship   sex
oppose/""NFNO""/favor [0:2] abortion if the child will not be the sex the woman wants   choice
oppose/""NFNO""/favor [0:2] abortion if woman chooses to have one   pid
respondent's partisanship [0:2] (Democrat, Independent, Republican)   knowspeaker
was the respondent able to correctly identify the Speaker of the House (John Boehner)   addchoice
an additive scale of the abortion scores [0:16]   lchoice
a continuous latent scale of pro-choice scores (from a simple graded response model)     Details  
""NFNO"" = ""Neither Favor Nor Oppose""    Source  
Data come from ANES's (2012) time series."
"stevedata-anes_vote84","stevedata","anes_vote84","Simple Data for a Simple Model of Individual Voter Turnout (ANES, 1984)",2257,9,4,1,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/anes_vote84.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/anes_vote84.html","anes_vote84 R Documentation   Simple Data for a Simple Model of Individual Voter Turnout (ANES, 1984)   Description  
This is a simple data set for estimating a simple model on voter turnout from the 1984 American National Election Studies (ANES) 1984 time-series.    Usage    anes_vote84    Format  
A data frame with 2257 observations on the following 9 variables.    uid
a unique identifier for the respondent   stateabb
the state where the respondent lives (as an abbreviation)   vote
whether the respondent voted (1 = yes; 0 = no)   age
the age of the respondent   educ
the education-level of the respondent. See details section for more.   female
whether the respondent is a woman (1 = female; 0 = male)   south
does the respondent live in the south (1 = yes; 0 = no)   polint
the political interest of the respondent in the campaigns (-1 = not much interested; 0 = somewhat interested; 1 = very much interested)   govrace
did the respondent's state have a gubernatorial election that same November (1 = yes; 0 = no)     Details  
The vote variable is deliberately coded where those with a value of 1 are respondents who said they voted and the ANES was able to confirm that with voter registration records. There are purportedly 85 responses in this raw variable where the respondent said they voted, but this could not be confirmed from registration records. Those cases are recorded as NA . The educ variable ranges from 1 (finished 8th grade or less than that) to 10 (respondent holds an advanced degree). The uid variable is a simple sequence variable ranging from 1 to 2257 and is calculated on the original 1984 time-series study (May 3, 1999 version) before other recoding was done. This should allow some reproducibility for an interested user.    Source  
Data come from ANES's (1984) time series."
"stevedata-Arca","stevedata","Arca","NYSE Arca Steel Index data, 2017–present",966,5,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Arca.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Arca.html","Arca R Documentation   NYSE Arca Steel Index data, 2017–present   Description  
Daily data on the NYSE Arca Steel Index. These data are useful for me in teaching how Trump's 2018 steel tariffs didn't do much good for the steel industry.    Usage    Arca    Format  
A data frame with 966 observations on the following 6 variables.    date
the date   close
the closing price   open
the opening price   high
the daily high in that day's trading   low
the daily low in that day's trading     Details  
These data are taken from investing.com . See: https://www.investing.com/indices/arca-steel-historical-data"
"stevedata-arcticseaice","stevedata","arcticseaice","Arctic Sea Ice Extent Data, 1901-2015",115,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/arcticseaice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/arcticseaice.html","arcticseaice R Documentation   Arctic Sea Ice Extent Data, 1901-2015   Description  
This data set from Connelly et al. (2017) measures the Arctic sea ice extent in 10^6 square kilometers. It includes lower bounds and upper bounds on annual averages.    Usage    arcticseaice    Format  
A data frame with 115 observations on the following 4 variables.    year
the year   value
the annual Arctic sea ice extent (in 10^6 sq km)   ub
The upper bound of the value, provided by Connelly et al.   lb
The lower bound of the value, provided by Connelly et al.     Details  
This is for illustration of climate change for my intro students. Connelly et al. (2017) are in part a methodological paper. The data I present here are from the ""rescaled (unadjusted T)"" data in the second sheet from their replication files.    References  
Connolly et al. (2017), ”Re-calibration of Arctic sea ice extent datasets using Arctic surface air temperature records”. *Hydrological Sciences Journal* 62(8): 1317–40."
"stevedata-arg_tariff","stevedata","arg_tariff","Simple Mean Tariff Rate for Argentina",39,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/arg_tariff.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/arg_tariff.html","arg_tariff R Documentation   Simple Mean Tariff Rate for Argentina   Description  
Simple mean tariff rate for Argentina, starting in 1980. The goal is to keep these data current.    Usage    arg_tariff    Format  
A data frame with three variables:    country
country name (Argentina)   year
the year   tariffrate
the simple mean tariff rate for Argentina on all products (as a percentage)     Details  
Data come from various sources. World Bank estimates are used for 1980-1984 and 2010-2018, but see also Lora's (2012) report for the Inter-American Development Bank. The 1980-1984 estimates are actually means for 1980-1 and 1982-4 via Laird and Nogues' (1989) article in the World Bank Economic Review."
"stevedata-asn_stats","stevedata","asn_stats","Aviation Safety Network Statistics, 1942-2019",78,7,0,0,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/asn_stats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/asn_stats.html","asn_stats R Documentation   Aviation Safety Network Statistics, 1942-2019   Description  
These are yearly counts on air accidents and fatalities, including measures for corporate jet accidents and hijackings. The hijackings are of particular interest to me, at least from a historical terrorism perspective.    Usage    asn_stats    Format  
A data frame with 78 observations on the following 7 variables.    year
numeric vector for the year   airacc
a numeric vector for the number of airliner accidents   airfatal
a numeric vector for the number of fatalities from airliner accidents   corpjetacc
a numeric vector for the number of corporate jet accidents   corpjetfatal
a numeric vector for the number of fatalities from corporate jet accidents   hijack
a numeric vector for the number of hijackings/skyjackings   hijackfatal
a numeric vector for the number of fatalities from hijackings/skyjackings     Details  
All fatality estimates exclude ground fatalities. All accidents are hull-loss accidents. The airliner figures are for those flights with at least 14 passengers. Check https://aviation-safety.net/statistics/period/stats.php?cat=H2 for more.    Source  
Aviation Safety Network, a service provided by the Flight Safety Foundation."
"stevedata-CFT15","stevedata","CFT15","Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate",1390,9,1,0,0,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/CFT15.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/CFT15.html","CFT15 R Documentation   Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate   Description  
This is the replication data for ""Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate"", published in 2015 in Journal of Causal Inference . I use these data to teach about regression discontinuity designs.    Usage    CFT15    Format  
A data frame with 1390 observations on the following 9 variables.    state
a numeric vector for the state. This is ultimately a categorical variable.   year
a numeric vector for the year of the election.   vote
a numeric vector for the Democratic vote share in the next election (i.e. six years later).   margin
a numeric vector for the Democratic party's margin of victory in the statewide election. This is the running variable, in RDD parlance.   class
a numeric vector for the class to which each Senate seat belongs.   termshouse
a numeric vector for the Democratic candidate's cumulative number of terms previously served in the U.S. House.   termssenate
a numeric vector for the Democratic candidate's cumulative number of terms previously served in the U.S. Senate.   population
a numeric vector for the population of the Senate seat's state.   treatment
a numeric vector that is 1 if margin > 0 and is 0 if margin < 0.     Source  
Cattaneo, Matias D. and Brigham R. Frandsen and Rocio Titiunik. 2015. ""Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate"". Journal of Causal Inference 3(1): 1–24.    References  
Cattaneo, Matias D. and Brigham R. Frandsen and Rocio Titiunik. 2015. ""Randomization Inference in the Regression Discontinuity Design: An Application to Party Advantages in the U.S. Senate"". Journal of Causal Inference 3(1): 1–24.   
Calonico, Sebastian and Matias D. Cattaneo and Max H. Farrell and Rocio Titiunik. 2017. "" rdrobust : Software for regression-discontinuity designs"". The Stata Journal 17(2):372–404."
"stevedata-clemson_temps","stevedata","clemson_temps","Daily Clemson Temperature Data",33143,7,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/clemson_temps.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/clemson_temps.html","clemson_temps R Documentation   Daily Clemson Temperature Data   Description  
This data set contains daily temperatures (highs) for Clemson, South Carolina from Jan. 1, 1930 to the end of the most recent calendar year. The goal is to update this periodically with new data for as long as I live in this town.    Usage    clemson_temps    Format  
A data frame with 32,777 observations on the following 8 variables.    date
the date   year
the year   month
the month   day
the day of the month   yd
the day of the year   station
the unique station identifier for NOAA   value
the daily high in Celsius*10. I don't know why NOAA does it this way, but there you go.   tmax
the daily high, adjusted to Fahrenheit     Details  
Data obtained from NOAA, via the rnoaa package."
"stevedata-co2emissions","stevedata","co2emissions","Carbon Dioxide Emissions Data",3099,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/co2emissions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/co2emissions.html","co2emissions R Documentation   Carbon Dioxide Emissions Data   Description  
This is a sample data set, cobbled from various sources, about carbon dioxide emissions in the history of the planet from 800,000 BCE to the most recently concluded calendar year. I use this for a data visualization example for a lecture on climate change and international politics. Data communicate yearly averages/estimates.    Usage    co2emissions    Format  
A data frame with 3,099 observations on the following 2 variables.    year
the year (negative values = BCE)   value
estimated carbon dioxide emissions (in ppm)     Details  
The data come from many sources. Before 0 CE, the data come from 10 sources described here by the EPA ( https://www.epa.gov/climate-indicators/climate-change-indicators-atmospheric-concentrations-greenhouse-gases ). Observations from 0 CE to 2014 come from Meinshausen et al. (2017) ( https://gmd.copernicus.org/articles/10/2057/2017/ ). Observations from 2015 forward come from NASA ( https://climate.nasa.gov/vital-signs/carbon-dioxide/ ).    References  
EPICA Dome C and Vostok Station, Antarctica: approximately 796,562 BCE to 1813 CE Lüthi, D., M. Le Floch, B. Bereiter, T. Blunier, J.-M. Barnola, U. Siegenthaler, D. Raynaud, J. Jouzel, H. Fischer, K. Kawamura, and T.F. Stocker. 2008. High-resolution carbon dioxide concentration record 650,000–800,000 years before present. Nature 453:379–382.  https://www.ncdc.noaa.gov/paleo-search/ .   
Law Dome, Antarctica, 75-year smoothed: approximately 1010 CE to 1975 CE Etheridge, D.M., L.P. Steele, R.L. Langenfelds, R.J. Francey, J.-M. Barnola, and V.I. Morgan. 1998. Historical CO2 records from the Law Dome DE08, DE08-2, and DSS ice cores. In: Trends: A compendium of data on global change. Oak Ridge, TN: U.S. Department of Energy. https://cdiac.ess-dive.lbl.gov/trends/co2/lawdome.html .   
Siple Station, Antarctica: approximately 1744 CE to 1953 CE Neftel, A., H. Friedli, E. Moor, H. Lötscher, H. Oeschger, U. Siegenthaler, and B. Stauffer. 1994. Historical carbon dioxide record from the Siple Station ice core. In: Trends: A compendium of data on global change. Oak Ridge, TN: U.S. Department of Energy.  https://cdiac.ess-dive.lbl.gov/trends/co2/siple.html    
Mauna Loa, Hawaii: 1959 CE to 2015 CE NOAA (National Oceanic and Atmospheric Administration). 2016. Annual mean carbon dioxide concentrations for Mauna Loa, Hawaii.   
Barrow, Alaska: 1974 CE to 2014 CE Cape Matatula, American Samoa: 1976 CE to 2014 CE South Pole, Antarctica: 1976 CE to 2014 CE NOAA (National Oceanic and Atmospheric Administration). 2016. Monthly mean carbon dioxide concentrations for Barrow, Alaska; Cape Matatula, American Samoa; and the South Pole.   
Cape Grim, Australia: 1992 CE to 2006 CE Shetland Islands, Scotland: 1993 CE to 2002 CE Steele, L.P., P.B. Krummel, and R.L. Langenfelds. 2007. Atmospheric CO2 concentrations (ppmv) derived from flask air samples collected at Cape Grim, Australia, and Shetland Islands, Scotland. Commonwealth Scientific and Industrial Research Organisation.  https://cdiac.ess-dive.lbl.gov/trends/co2/sio-keel-flask/sio-keel-flaskmlo_c.html .   
Lampedusa Island, Italy: 1993 CE to 2000 CE Chamard, P., L. Ciattaglia, A. di Sarra, and F. Monteleone. 2001. Atmospheric carbon dioxide record from flask measurements at Lampedusa Island. In: Trends: A compendium of data on global change. Oak Ridge, TN: U.S. Department of Energy.  https://cdiac.ess-dive.lbl.gov/trends/co2/lampis.html .   
Meinshausen, M., Vogel, E., Nauels, A., Lorbacher, K., Meinshausen, N., Etheridge, D. M., Fraser, P. J., Montzka, S. A., Rayner, P. J., Trudinger, C. M., Krummel, P. B., Beyerle, U., Canadell, J. G., Daniel, J. S., Enting, I. G., Law, R. M., Lunder, C. R., O'Doherty, S., Prinn, R. G., Reimann, S., Rubino, M., Velders, G. J. M., Vollmer, M. K., Wang, R. H. J., and Weiss, R.: Historical greenhouse gas concentrations for climate modelling (CMIP6), Geosci. Model Dev., 10, 2057-2116, 2017.  https://gmd.copernicus.org/articles/10/2057/2017/ ."
"stevedata-coffee_imports","stevedata","coffee_imports","Coffee Imports for Select Importing Countries",30,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/coffee_imports.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/coffee_imports.html","coffee_imports R Documentation   Coffee Imports for Select Importing Countries   Description  
A simple time series on coffee imports for select importing countries (i.e. European Union + Japan + Russia + Tunisia + United States).    Usage    coffee_imports    Format  
A data frame with 29 observations on the following 3 variables.    year
the year   imports
coffee imports for all select importing countries (in thousand 60-kg bags)   usaimports
coffee imports for just the United States (in thousand 60-kg bags)     Details  
Data come from the International Coffee Organization, of which I feel I should be a member."
"stevedata-coffee_price","stevedata","coffee_price","The Primary Commodity Price for Coffee (Arabica, Robustas)",499,3,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/coffee_price.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/coffee_price.html","coffee_price R Documentation   The Primary Commodity Price for Coffee (Arabica, Robustas)   Description  
This is primary commodity price data for coffee (Arabica, Robustas) from 1980 to the present. I manually update these data since FRED's coverage since 2017 has been spotty.    Usage    coffee_price    Format  
A data frame with 489 observations on the following 3 variables.    date
the date (year-month)   arabica
the price (monthly average) of mild Arabica, via International Coffee Organization data, in nominal US cents per pound   robustas
the price (monthly average) of Robustas, via International Coffee Organization data, in nominal US cents per pound     Details  
Data come from International Monetary Fund (Primary Commodity Prices) and International Coffee Organization. The IMF adds these prices are global and the New York cash price, ex-dock"
"stevedata-CP77","stevedata","CP77","Education Expenditure Data (Chatterjee and Price, 1977)",50,6,0,2,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/CP77.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/CP77.html","CP77 R Documentation   Education Expenditure Data (Chatterjee and Price, 1977)   Description  
This is a simple data set provided by Chatterjee and Price (1977, p. 108) that serves as a known example of heteroscedasticity.    Usage    CP77    Format  
A data frame with 50 observations on the following 6 variables.    state
a character vector for the state   region
a character vector for the Census region   urbanpop
a numeric vector for the number of residents (per thousand) living in urban areas in 1970   incpc
a numeric vector for income per capita in 1973   pop
a numeric vector for residents (per thousand) under 18 years of age in 1974   edexppc
a numeric vector for per capita public school expenditures in a state, projected for 1975.     Details  
I copied these data from the robustbase package. I just didn't want to make my students install it. Note: I'm pretty sure ""NB"" was suppose to be ""NE"" and that ""DY"" is supposed to be ""KY"". I made those changes.    References  
P. J. Rousseeuw and A. M. Leroy (1987) Robust Regression and Outlier Detection; Wiley, p.110, table 16."
"stevedata-Datasaurus","stevedata","Datasaurus","The Datasaurus Dozen",1846,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Datasaurus.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Datasaurus.html","Datasaurus R Documentation   The Datasaurus Dozen   Description  
An illustrative exercise in never trusting the summary statistics without also visualizing them.    Usage    Datasaurus    Format  
A data frame with 1,846 observations on the following 3 variables.    dataset
the particular data set, one of 12   x
a random variable   y
another random variable     Details  
Data were created by Alberto Cairo to illustrate you should always visualize your data beyond the summary statistics. These are 12 data sets, in long form, each with a mean of x about 54.26, a mean of y  about 47.83. The standard deviation for x is about 16.76 and the standard deviation of y is about 26.93. x and y will correlate weakly, about -.06.    Author(s)  
Alberto Cairo, Justin Matejka, George Fitzmaurice    References  
Cairo, Alberto. 2016. “Download the Datasaurus: Never trust summary statistics alone; always visualize your data”.  URL: http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html    
Matejka, Justin and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing.”  ACM SIGCHI Conference on Human Factors in Computing Systems .  URL: https://www.autodesk.com/research/publications/same-stats-different-graphs"
"stevedata-Dee04","stevedata","Dee04","Are There Civics Returns to Education?",9227,8,6,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Dee04.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Dee04.html","Dee04 R Documentation   Are There Civics Returns to Education?   Description  
This should be a data set for a (partial?) replication of Dee's (2004) article on the purported civics returns to education. I use these data for in-class illustration about instrumental variable analyses.    Usage    Dee04    Format  
A data frame with 9227 observations on the following 8 variables.    schoolid
a numeric vector that should be understood as categorical   hispanic
a numeric vector for if the person is Hispanic   college
a numeric vector for if the person went to college   black
a numeric vector for if the person is black   otherrace
a numeric vector for if the person is another race   female
a numeric vector for if the person is a woman   register
a numeric vector for if the person is registered to vote   distance
a numeric vector for the distance to college     Details  
I should note I acquired this data set in Mexico City sitting on a two-week program at IPSA-FLACSO Mexico Summer School in 2019. The sample size here (9,227) is about two thousand short of what Dee reports in his article. It'll do, though.    References  
Dee, Thomas S. 2004. ""Are there civics returns to education?"" Journal of Public Economics 88: 1697–1720"
"stevedata-DJIA","stevedata","DJIA","Dow Jones Industrial Average, 1885-Present",36951,2,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/DJIA.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/DJIA.html","DJIA R Documentation   Dow Jones Industrial Average, 1885-Present   Description  
This data set contains the value of the Dow Jones Industrial Average on daily close for all available dates (to the best of my knowledge) from 1885 to the most recently concluded calendar year. Extensions shouldn't be too difficult with existing packages.    Usage    DJIA    Format  
A data frame with 36951 observations on the following 2 variables.    date
the date   value
the value of the the Dow Jones Industrial Average at daily close     Details  
Observations before October 7, 1896 are from the single Dow Jones Average. Observations from October 7, 1896 to July 30, 1914 are from the first DJIA. Observations before the 1914 closure of the first DJIA in July 1914 come from MeasuringWorth. Observations from its reopening in Dec. 12, 1914 to January 28, 1985 come from Pinnacle Systems. Observations from January 29, 1985 to the most recent observation come from a quantmod call.    References  
Samuel H. Williamson, 'Daily Closing Value of the Dow Jones Average, 1885 to Present,' MeasuringWorth, 2019.   
Jeffrey A. Ryan and Joshua M. Ulrich, ' quantmod : Quantitative Financial Modelling Framework,' 2018."
"stevedata-DST","stevedata","DST","Casualties/Fatalities in the U.S. for Drunk-Driving, Suicide, and Terrorism",49,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/DST.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/DST.html","DST R Documentation   Casualties/Fatalities in the U.S. for Drunk-Driving, Suicide, and Terrorism   Description  
These are fatalities (and, in the case of terrorism, casualties as well) for drunk-driving, suicide, and acts of terrorism in the U.S. spanning 1970 to 2018. Only one of these is sufficiently important to command public attention despite being the least severe public bad. Do you want to guess which one?    Usage    DST    Format  
A data frame with 49 observations on the following 5 variables.    year
the year   nkill
a numeric vector for the number killed in acts of terrorism   terrtotal
a numeric vector for the number killed or wounded in acts of terrorism   suicides
a numeric vector for the number of suicides   ddfat
a numeric vector for the number of drunk-driving fatalities     Details  
Following my own work in Political Research Quarterly , terror incidents with unknown fatalities or number wounded were imputed to be 1. In those cases, the GTD has reason to believe at least one person died or was wounded, but doesn't know how many. GTD is weird about 1993, so perhaps treat those observations with some care (though it does well to capture the WTC bombing that year). Suicides include only those who passed, not those who survived a suicide attempt. Drunk-driving fatalities seem to include those who were killed in a drunk-driving accident despite not being drunk themselves.    Source  
Global Terrorism Database (Sept. 2019 update), Centers for Disease Control, U.S. Department of Transportation"
"stevedata-eight_schools","stevedata","eight_schools","The Effect of Special Preparation on SAT-V Scores in Eight Randomized Experiments",8,6,0,1,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/eight_schools.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/eight_schools.html","eight_schools R Documentation   The Effect of Special Preparation on SAT-V Scores in Eight Randomized Experiments   Description  
You've all seen these before. These are the ""eight schools"" that everyone gets when being introduced to Bayesian programming. Here are the full data for your consideration, which you can use instead of awkwardly searching where the data are and copy-pasting them as a list. Every damn time, Steve.    Usage    eight_schools    Format  
A data frame with 8 observations on the following 6 variables.    school
a letter denoting the school   num_treat
the number of students in the school receiving the treatment   num_control
the number of students in the school in the control group   est
the estimated treatment effect   se
the standard error of the effect estimate   rvar
the residual variance     Details  
Data copy-pasted from Table 1 in Rubin (1981).    References  
Rubin, Donald B. 1981. ""Estimation in Parallel Randomized Experiments."" Journal of Educational Statistics 6(4): 377-401."
"stevedata-election_turnout","stevedata","election_turnout","State-Level Education and Voter Turnout in 2016",51,14,2,3,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/election_turnout.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/election_turnout.html","election_turnout R Documentation   State-Level Education and Voter Turnout in 2016   Description  
A simple data set on education and state-level (+ DC) turnout in the 2016 presidential election. This is inspired by what Pollock (2012) does in his book.    Usage    election_turnout    Format  
A data frame with 51 observations on the following 13 variables.    year
the year of the presidential election (2016)   state
the state abbreviation   region
the state's Census region   division
the state's Census division   turnoutho
voter turnout for the highest office as percent of voting-eligible population (VEP)   perhsed
the percentage of the state that completed high school   percoled
the percentage of the state that completed college   gdppercap
an estimate of the state's GDP per capita   ss
is it a “swing state?”   trumpw
did Trump win the state?   trumpshare
the share of the vote Trump received   sunempr
the state-level unemployment rate entering Nov. 2016   sunempr12md
the state-level unemployment rate (12-month difference) entering Nov. 2016   gdp
an estimate of the state's GDP     Details  
Data were created in early 2017 for an upper-division course on quantitative methods. Educational attainment and division/region data come from the Census. Voter turnout/share data come from the Elections Project at George Mason University. GDP per capita estimates come from Bureau of Economic Analysis. Unemployment data come from the Bureau of Labor Statistics and code to generate it was derived from a forthcoming publication of mine."
"stevedata-eq_passengercars","stevedata","eq_passengercars","Export Quality Data for Passenger Cars, 1963-2014",60424,6,0,1,2,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/eq_passengercars.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/eq_passengercars.html","eq_passengercars R Documentation   Export Quality Data for Passenger Cars, 1963-2014   Description  
Data from the International Monetary Fund for the export quality and unit/trade value of passenger cars for all available countries and years from 1963 to 2014.    Usage    eq_passengercars    Format  
A data frame with 60424 observations on the following 6 variables.    country
a character vector for the country/area.   ccode
a numeric vector for the Correlates of War country code.   category
a factor with levels Export Quality Index ,  Export quality 95 percent interval - lower bound ,  Export quality 95 percent interval - upper bound   Unit value of exports , Unit value 95 percent interval - lower bound ,  Unit value 95 percent interval - upper bound ,  Trade value of exports   type
a factor with levels 51. Transport equipment, Passenger cars . This is a constant. I just felt like making it a factor.   year
a numeric vector for the year   value
a numeric vector for the value of the particular category."
"stevedata-ESS9GB","stevedata","ESS9GB","British Attitudes Toward Immigration (2018-19)",1905,19,2,4,0,0,13,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/ESS9GB.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/ESS9GB.html","ESS9GB R Documentation   British Attitudes Toward Immigration (2018-19)   Description  
This is a replication data originally set to accompany a blog post and presentation to students at the University of Nottingham in March 2020. However, COVID-19 led to the cancellation of the talk.    Usage    ESS9GB    Format  
A data frame with 1,905 observations on the following 19 variables.    name
a character for the name of the survey   essround
a numeric for the ESS round   edition
a character for the particular edition of the ESS round   idno
a numeric/unique identifier   cntry
a character vector for the country (i.e. the UK)   region
a character vector for the region of the UK the respondent lives   brncntr
a numeric vector for if the respondent was born in the UK   stintrvw
a Date for the interview start date   endintrvw
a Date for the interview end date   imbgeco
a numeric vector for if respondent thinks immigrants are generally good or bad for UK's economy. Higher values = good   imueclt
a numeric vector for if respondent thinks immigrants enrich or undermine UK's culture. Higher values = enrich more than undermine   imwbcnt
a numeric vector for if respondent thinks immigrants make UK a better place to live. Higher values = better place to live   immigsent
a numeric vector for immigration sentiment (i.e. imbgeco +  imueclt + imwbcnt ). Higher values = more pro-immigration sentiment   agea
a numeric vector for the respondent's age in years   female
a numeric vector for whether the respondent is a woman   eduyrs
a numeric vector for total years of education for the respondent   uempla
a numeric vector for whether the respondent is currently unemployed but seeking work   hinctnta
a numeric vector for household income in deciles   lrscale
a numeric vector for the ideology of the respondent on an 11-point [0:10] scale     Details  
See accompanying blog post at http://svmiller.com/blog/2020/03/what-explains-british-attitudes-toward-immigration-a-pedagogical-example/ .    Source  
European Social Survey, Round 9"
"stevedata-ESSBE5","stevedata","ESSBE5","Trust in the Police in Belgium (European Social Survey, Round 5)",1704,10,1,2,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/ESSBE5.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/ESSBE5.html","ESSBE5 R Documentation   Trust in the Police in Belgium (European Social Survey, Round 5)   Description  
This is a sample data set cobbled from the fifth round of European Social Survey data for Belgium. It offers a means to do a basic replication of some of Chapter 5 of The SAGE Handbook of Regression Analysis and Causal Inference.    Usage    ESSBE5    Format  
A data frame with 1704 observations on the following 10 variables.    essround
a numeric for the ESS round   edition
a character for the edition number of the fifth round   idno
a numeric id number   cntry
a character vector for the country (i.e. Belgium, or BE )   trstplc
a numeric vector for trust in the police on an 11-point scale. Higher values indicate more trust. 0 = ""no trust at all"". 10 = ""complete trust""   agea
a numeric vector for the respondent's age   female
a numeric vector for whether the respondent is a woman or not.   eduyrs
a numeric vector for years of education.   hincfel
a numeric vector for the respondent's feeling about their household income. 1 = ""living comfortably"", 2 = ""coping on present income"", 3 = ""difficult on present income"", 4 = ""very difficult on present income""   plcpvcr
a numeric vector for how successful police are at preventing crimes in a country on an 11-point scale. 0 = ""extremely unsuccessful"". 10 = ""extremely successful.""     Details  
See Chapter 5 of The SAGE Handbook of Regression Analysis and Causal Inference for more information.    Source  
European Social Survey (Round 5)"
"stevedata-eustates","stevedata","eustates","EU Member States (Current as of 2019)",28,3,0,2,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/eustates.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/eustates.html","eustates R Documentation   EU Member States (Current as of 2019)   Description  
European Union membership by accession date    Usage    eustates    Format  
A data frame with 28 observations on the following 3 variables.    date
a date indicating accession   country
a character vector for the country   iso2c
a character vector for iso2c     Details  
Data come from https://europa.eu/european-union/about-eu/countries_en ."
"stevedata-fakeAPI","stevedata","fakeAPI","Hypothetical (Fake) Data on Academic Performance",10000,11,0,3,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/fakeAPI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/fakeAPI.html","fakeAPI R Documentation   Hypothetical (Fake) Data on Academic Performance   Description  
This is a hypothetical universe of schools in a given territorial unit, patterned off the apipop data available in the survey package.    Usage    fakeAPI    Format  
A data frame with 10000 observations on the following 8 variables.    uid
a numeric vector as a unique identifier for schools   schooltype
a character vector for school type. E = elementary school. M = middle school. H = high school   county
a character vector for the county, named after an Ohio State All-American. “County” incidence is weighted by how many All-American honors the Ohio State player had. It's my fake data. You make your own if you have a problem with it.   community
a character vector for the school's community, either rural, suburban, or urban.   api
a numeric vector vector an academic performance index for the school   meals
a numeric vector for the percentage of school students eligible for subsidized meals   colgrad
a numeric vector for the percentage of school parents with college degrees   fullqual
a numeric vector for the percentage of the school with teachers that are fully qualified   sbase
a numeric vector for some base differences between schools, patterned off the school type means for api00 in the apipop data.   cbase
a numeric vector for some base differences between counties, randomly drawn from a uniform distribution   e
a numeric vector for random errors     Details  
These data were generated for a blog post on my website.    References  
Miller, Steven V. 2020. ""Some Parlor Tricks with Survey-Type Analyses in R."" URL: http://svmiller.com/blog/2020/08/some-parlor-tricks-with-survey-type-analyses-in-r/"
"stevedata-fakeLogit","stevedata","fakeLogit","Fake Data for a Logistic Regression",10000,2,1,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/fakeLogit.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/fakeLogit.html","fakeLogit R Documentation   Fake Data for a Logistic Regression   Description  
This is a simple fake data set to illustrate a logistic regression.    Usage    fakeLogit    Format  
A data frame with 10000 observations on the following 2 variables.    x
a five-item functionally ordered categorical variable   y
a binary variable that is either 0 or 1     Details  
The data are generated such that the outcome y is a logistic function of the x variable and come from a rbinom() call. The estimated natural logged odds of y when x is 0 is -2.8. Each unit increase in x is simulated to increase the natural logged odds of  y by 1.4. This example is very much patterned off a similar fake data set that Pollock (2012) uses to teach about logistic regression. In his case,  x is a stand-in for hypothetical education categories and y is whether this fake person voted or not."
"stevedata-fakeTSCS","stevedata","fakeTSCS","Fake Data for a Time-Series Cross-Section",2500,8,1,1,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/fakeTSCS.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/fakeTSCS.html","fakeTSCS R Documentation   Fake Data for a Time-Series Cross-Section   Description  
This is a toy (i.e. ""fake"") data set created by the fabricatr package. There are 100 observations for 25 hypothetical countries. The outcome y  is a linear function of a baseline for each hypothetical country, plus a yearly growth trend as well as varying growth errors for each country. x1 is supposed to have a linear effect of .5 on y , all things considered.  x2 is supposed to have a linear effect of 1 on y for each unit change in x2 , all things considered.    Usage    fakeTSCS    Format  
A data frame with 2500 observations on the following 8 variables.    year
a numeric vector for the year   country
a character vector for the country   y
a numeric vector for the outcome.   x1
a continuous variable   x2
a binary variable   base
a numeric vector for the baseline starting point for each country   growth_units
a numeric vector for the growth units for each country   growth_error
a numeric vector for the growth errors for each country     Details  
x1 is generated by a normal distribution with a mean of 5 and a standard deviation of 2. x2 is drawn from a Bernoulli distribution with a probability of .5 of observing a 1."
"stevedata-fakeTSD","stevedata","fakeTSD","Fake Data for a Time-Series",100,5,1,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/fakeTSD.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/fakeTSD.html","fakeTSD R Documentation   Fake Data for a Time-Series   Description  
This is a toy (i.e. ""fake"") data set created by the fabricatr package. There are 100 observations. The outcome y is a linear function of 20 + (.25 * year) + .(25 * x1) + (1 * x2) + e . This clearly implies some autocorrelation in the data. I.e. it's a time-series.    Usage    fakeTSD    Format  
A data frame with 100 observations on the following 5 variables.    year
the year   y
an outcome   x1
a continuous variable   x2
a binary variable   e
randomly generated errors     Details  
Errors are random-normal with a mean of 0 and a standard deviation of 1.  x1 is generated by a normal distribution with a mean of 5 and a standard deviation of 2. x2 is drawn from a Bernoulli distribution with a probability of .5 of observing a 1."
"stevedata-ghp100k","stevedata","ghp100k","Gun Homicide Rate per 100,000 People, by Country",561,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/ghp100k.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/ghp100k.html","ghp100k R Documentation   Gun Homicide Rate per 100,000 People, by Country   Description  
This is the yearly rate of gun homicides per 100,000 people in the population, selecting on ""Western"" countries of interest.    Usage    ghp100k    Format  
A data frame with 561 observations on the following 3 variables.    country
the country   year
the year   value
a numeric vector for the estimated rate of gun homicide per 100,000 people     Details  
The reported, or calculated annual crude rate of completed, intentional homicide committed with a firearm, per 100,000 population, in years descending.   
Where a jurisdiction's published count of 'annual homicide' includes cases of attempted (uncompleted) homicide, these figures have been disaggregated wherever possible.   
In the United States, this category is confused by inaccurate and conflicting data published, suppressed or labeled as unreliable by the Centers for Disease Control and Prevention (CDC) and the Federal Bureau of Investigation (FBI). Suppression can result in zero values where in fact homicides did occur.   
Incomplete classification by local agencies can also result in a significant proportion of events being categorized as 'unknown cause' or similar.   
Before quoting these datasets, please follow the citation links for a description of the considerable differences between them and the reasons for data suppression.   
Where a rate is calculated by GunPolicy.org , a matched population estimate is also cited.    Source  
https://www.gunpolicy.org"
"stevedata-gss_abortion","stevedata","gss_abortion","Abortion Opinions in the General Social Survey",64814,18,9,3,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/gss_abortion.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/gss_abortion.html","gss_abortion R Documentation   Abortion Opinions in the General Social Survey   Description  
This is a toy data set derived from the General Social Survey that I intend to use for several purposes. First, the battery of abortion items can serve as toy data to illustrate mixed effects modeling as equivalent to a one-parameter (Rasch) model. Second, I include some covariates to also do some basic regressions. I think abortion opinions are useful learning tools for statistical inference for college students. Third, there's a time-series component as well for understanding how abortion attitudes have changed over time.    Usage    gss_abortion    Format  
A data frame with 64,814 observations on the following 18 variables.    id
a unique respondent identifier   year
the survey year   age
the respondent's age in years   race
the respondent's race, as character variable   sex
the respondent's gender, as character variable   hispaniccat
the respondent's Hispanic ethnicity, as character variable   educ
how many years the respondent spent in school   partyid
the respondent's party identification, as character variable   relactiv
the self-reported religious activity of the respondent on a 1:11 scale   abany
a binary variable that equals 1 if the respondent thinks abortion should be legal for any reason. 0 indicates no support for abortion for any reason.   abdefect
a numeric vector that equals 1 if the respondent thinks abortion should be legal if there is a serious defect in the fetus. 0 indicates no support for abortion in this circumstance.   abnomore
a numeric vector that equals 1 if the respondent thinks abortion should be legal if a woman is pregnant but wants no more children. 0 indicates no support for abortion in this circumstance.   abhlth
a numeric vector that equals 1 if the respondent thinks abortion should be legal if a pregnant woman's health is in danger. 0 indicates no support for abortion in this circumstance.   abpoor
a numeric vector that equals 1 if the respondent thinks abortion should be legal if a pregnant woman is poor and cannot afford more children. 0 indicates no support for abortion in this circumstance.   abrape
a numeric vector that equals 1 if the respondent thinks abortion should be legal if the woman became pregnant because of a rape. 0 indicates no support for abortion in this circumstance.   absingle
a numeric vector that equals 1 if the respondent thinks abortion should be legal if a pregnant woman is single and does not want to marry the man who impregnated her. 0 indicates no support for abortion in this circumstance.   pid
partyid recoded so that 7 = NA   hispanic
a dummy variable that equals 1 if the respondent is any way Hispanic     Details  
Data include all General Social Survey observations from 1972 to 2018 for these variables. Be mindful of missing data."
"stevedata-gss_spending","stevedata","gss_spending","Attitudes Toward National Spending in the General Social Survey (2018)",2348,33,1,0,0,0,33,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/gss_spending.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/gss_spending.html","gss_spending R Documentation   Attitudes Toward National Spending in the General Social Survey (2018)   Description  
This is a toy data set that collects attitudes on toward national spending for various things in the General Social Survey for 2018. I use these data for in-class illustration about ordinal variables and ordinal models.    Usage    gss_spending    Format  
A data frame with 2348 observations on the following 33 variables.    year
a numeric constant for the GSS survey year (2018)   id
a unique identifier for the survey respondent   age
a numeric vector for the age of the respondent (min: 18, max: 89)   sex
a numeric vector for the respondent's sex (1 = female, 0 = male)   educ
a numeric vector for the highest year of school completed (min: 0, max: 20)   degree
a numeric vector for the respondent's highest degree (0 = did not graduate high school, 1 = high school, 2 = junior college, 3 = bachelor degree, 4 = graduate degree)   race
a numeric vector for the respondent's race (1 = white, 2 = black, 3 = other)   rincom16
a numeric vector for the respondent's yearly income (min: 1 (under $1,000), max: 26 ($170,000 or over))   partyid
a numeric vector for the respondent's party identification on the familiar seven-point scale. NOTE: D to R partisanship in this variable goes from 0 to 6. 7 = supporters of other parties. You may want to recode this if you want an interval-level measure of partisanship.   polviews
a numeric vector for the respondent's ideology (min: 1 (extremely liberal), max: 7 (extremely conservative))   xnorcsiz
a numeric vector for the NORC size code. This is a measure of what kind of area in which the respondent took the survey (i.e. lives). 1 = city, greater than 250k residents. 2 = city, between 50k-250k residents. 3 = suburbs of a large city. 4 = suburbs of a medium-sized city. 5 = unincorporated area of a large city. 6 = unincorporated area of a medium city. 7 = city, between 10-50k residents. 8 = town, greater than 2,500 residents. 9 = smaller areas. 10 = open country.   news
a numeric vector for how often the respondent reads the newspapers. 1 = everyday. 2 = a few times a week. 3 = once a week. 4 = less than once a week. 5 = never.   wrkstat
a numeric vector for the respondent's work status. 1 = working full-time. 2 = working part-time. 3 = temporarily not working. 4 = unemployed/laid off. 5 = retired. 6 = in school. 7 = house-keeping work. 8 = other.   natspac
a numeric vector for attitudes toward spending on the space program. See details below for this variable and all other variables beginning with nat .   natenvir
a numeric vector for attitudes toward spending on improving/protecting the environment.   natheal
a numeric vector for attitudes toward spending on improving/protecting the nation's health.   natcity
a numeric vector for attitudes toward spending on solving the big city's problems.   natcrime
a numeric vector for attitudes toward spending on halting the ""rising crime rate."" This question is subtly hilarious.   natdrug
a numeric vector for attitudes toward spending on dealing with drug addiction.   nateduc
a numeric vector for attitudes toward spending on improving the nation's education system.   natrace
a numeric vector for attitudes toward spending on improving the condition of black people.   natarms
a numeric vector for attitudes toward spending on the military/armaments/defense.   nataid
a numeric vector for attitudes toward spending on foreign aid.   natfare
a numeric vector for attitudes toward spending on welfare.   natroad
a numeric vector for attitudes toward spending on highways and bridges.   natsoc
a numeric vector for attitudes toward spending on social security.   natmass
a numeric vector for attitudes toward spending on mass transportation.   natpark
a numeric vector for attitudes toward spending on parks and recreation.   natchld
a numeric vector for attitudes toward spending on assistance for child care.   natsci
a numeric vector for attitudes toward spending on scientific research.   natenrgy
a numeric vector for attitudes toward spending on alternative sources of energy.   sumnat
a numeric vector for the sum total of responses to all the aforementioned spending variables (i.e. those that begin with nat ). This creates an interval-ish measure with a nice and mostly normal distribution.   sumnatsoc
a numeric vector for the sum of all responses toward various ""social"" prompts (i.e. natenvir , natheal , natdrug , nateduc , natrace , natfare , natroad , natmass , natpark , natsoc , natchld ). This creates an interval-ish measure with a mostly normal (but small left skew) distribution.     Details  
For all the variables beginning with nat , note that I rescaled the original data so that -1 = respondent thinks country is spending too much on this topic, 0 = respondent thinks country is spending ""about (the) right"" amount, and 1 = respondent thinks country is spending too little on this topic. I do this to facilitate reading each nat prompt as increasing support for more spending (the extent to which increasing values means the respondent thinks the country spends too little on a given prompt). I think this is more intuitive.   
Also, the natspac , natenvir , natheal , natcity , natcrime , natdrug , nateduc , natrace , natarms , nataid , and natfare have ""alternate"" prompts in later GSS waves in which a subset of respondents get a slightly different prompt. For example, one set of respondents for natcity gets a prompt of ""Solving the problems of the big cities"" (the legacy prompt) whereas another set of respondents gets a prompt of ""Assistance to big cities"" (typically noted as ""version y"" in the GSS). I, perhaps problematically if I were interested in publishing analyses on these data, combine both prompts into a single variable. I don't think it's a huge problem for what I want the data to do, but FYI.    Source  
General Social Survey, 2018"
"stevedata-gss_wages","stevedata","gss_wages","The Gender Pay Gap in the General Social Survey",61697,11,1,5,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/gss_wages.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/gss_wages.html","gss_wages R Documentation   The Gender Pay Gap in the General Social Survey   Description  
Wage data from the General Social Survey (1974-2018) to illustrate wage discrepancies by gender (while also considering respondent occupation, age, and education).    Usage    gss_wages    Format  
A data frame with 11 variables:    year
the survey year   realrinc
the respondent's base income (in constant 1986 USD)   age
the respondent's age in years   occ10
respondent's occupation code (2010)   occrecode
recode of the occupation code into one of 11 main categories   prestg10
respondent's occupational prestige score (2010)   childs
number of children (0-8)   wrkstat
the work status of the respondent (full-time, part-time, temporarily not working, unemployed (laid off), retired, school, housekeeper, other)   gender
respondent's gender (male or female)   educcat
respondent's degree level (Less Than High School, High School, Junior College, Bachelor, or Graduate)   maritalcat
respondent's marital status (Married, Widowed, Divorced, Separated, Never Married)     Details  
For further details, see https://gssdataexplorer.norc.org . Consult https://census.gov for more information about occupation codes."
"stevedata-Guber99","stevedata","Guber99","School Expenditures and Test Scores for 50 States, 1994-95",50,8,0,1,0,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Guber99.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Guber99.html","Guber99 R Documentation   School Expenditures and Test Scores for 50 States, 1994-95   Description  
A data set for a canonical case of a Simpson's paradox, useful for in-class instruction on the topic.    Usage    Guber99    Format  
A data frame with 50 observations on the following 8 variables.    state
a character vector for the state   expendpp
a numeric vector for the current expenditure per pupil in average daily attendance in public elementary and secondary schools, 1994-95 (in thousands of dollars)   ptratio
a numeric vector for the average pupil/teacher ratio in public elementary and secondary schools, Fall 1994   tsalary
a numeric vector for the estimated average annual salary of teachers in public elementary and secondary schools, 1994-95 (in thousands of dollars)   perctakers
a numeric vector for the percentage of all eligible students taking the SAT, 1994-95   verbal
a numeric vector for the average verbal SAT score, 1994-95   math
a numeric vector for the average math SAT score, 1994-95   total
a numeric vector for the average total SAT score, 1994-95     References  
Guber, Deborah Lynne. 1999. ""Getting What You Pay For: The Debate Over Equity in Public School Expenditures."" Journal of Statistics Education 7(2)."
"stevedata-illiteracy30","stevedata","illiteracy30","Illiteracy in the Population 10 Years Old and Over, 1930",49,11,0,1,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/illiteracy30.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/illiteracy30.html","illiteracy30 R Documentation   Illiteracy in the Population 10 Years Old and Over, 1930   Description  
This is perhaps the canonical data set for illustrating the ecological fallacy.    Usage    illiteracy30    Format  
A data frame with 40 observations on the following 11 variables.    state
a character for the state   pop
a numeric vector for the total population   pop_il
a numeric vector for the total population that is illiterate   nwhite
a numeric vector for the total native white population   nwhite_il
a numeric vector for the total native white population that is illiterate   fpwhite
a numeric vector for the total white population with ""foreign or mixed parentage""   fpwhite_il
a numeric vector for the total white population with ""foreign or mixed parentage"" that is illiterate   fbwhite
a numeric vector for the total foreign-born white population   fbwhite_il
a numeric vector for the total foreign-born white population that is illiterate   black
a numeric vector for the total black population.   black_il
a numeric vector for the total black population that is illiterate     Details  
All population totals reflect those 10 years or older. The 1930 Census (along with Robinson (1950)) uses ""negro"" in lieu of black, but the variable names here eschew that older label. Note that some states are not yet states in the 1930 Census.    Source  
U.S. Census Bureau (1933). Fifteenth Census of the United States: 1930. Population, Volume II.    References  
Grotenhuis, Manfred Te, Rob Eisinga, and SV Subramanian. 2011. ""Robinson's Ecological Correlations and the Behavior of Individuals: methodological corrections."" Internatoinal Journal of Epidemiology 40(4): 1123-25.   
Robinson, WS. 1950. ""Ecological Correlations and the Behavior of Individuals."" American Sociological Review 15(3): 351–57."
"stevedata-LOTI","stevedata","LOTI","Land-Ocean Temperature Index, 1880-2020",1692,2,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/LOTI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/LOTI.html","LOTI R Documentation   Land-Ocean Temperature Index, 1880-2020   Description  
These data contain monthly mean temperature anomalies expressed as deviations from the corresponding 1951-1980 means. They are useful for showing how we can measure climate change.    Usage    LOTI    Format  
A data frame with 1,692 observations on the following 2 variables.    date
a date, mostly to contain information for the year and month   value
the mean temperature anomaly as deviation from corresponding 1951-1980 mean     Details  
Data are updated through most recent month, at least for last time I updated it. Data represent combined land-surface air and sea-surface water temperature anomalies. Of note: the day value in the date column has no real value. It was just a way of combining data that are aggregated by year and month.    Source  
https://data.giss.nasa.gov/gistemp/"
"stevedata-LTPT","stevedata","LTPT","Long-Term Price Trends for Computers, TVs, and Related Items",1704,3,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/LTPT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/LTPT.html","LTPT R Documentation   Long-Term Price Trends for Computers, TVs, and Related Items   Description  
These data are a monthly time-series of changes in the consumer price index relative to a Dec. 1997 starting date for televisions, computers, and related items. I use this as in-class illustration that globalization has made consumer electronics cheaper across the board for Americans.    Usage    LTPT    Format  
A data frame with 1,704 observations on the following 3 variables.    date
a date   category
the particular category (e.g. all items, televisions, etc.)   value
the consumer price index (Dec. 1997 = 100)     Details  
This is a web-scraping job from the U.S. Bureau of Labor Statistics. Post is titled ""Long-term price trends for computers, TVs, and related items"" and was published on Oct. 13, 2015.    Source  
U.S. Bureau of Labor Statistics."
"stevedata-LTWT","stevedata","LTWT","""Let Them Watch TV""",2377,3,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/LTWT.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/LTWT.html","LTWT R Documentation   ""Let Them Watch TV""   Description  
""Let Them Watch TV"": These data contain price indices for various items for the general urban consumer. Categories include medical services, college tuition, college textbooks, child care, housing, food and beverages, all items (i.e. general CPI), new vehicles, apparel, and televisions. The base period in value was originally the 1982-4 average, but I converted the base period to January 2000. I use these data for in-class discussion about how liberalized trade has made consumer electronics (like TVs) fractions of their past prices. Yet, young adults face mounting costs for college, child-raising, and health care that government policy has failed to address.    Usage    LTWT    Format  
A data frame with 2377 observations on the following 3 variables.    date
a date   category
a factor for the particular category   value
the price index. Base: January 2000     Details  
Inspiration comes from a blog post titled ""Chart of the day (century?): Price changes 1997 to 2017"", which was published by the American Enterprise Institute on Feb. 2, 2018.    Source  
Bureau of Labor Statistics, via the blscrapeR package."
"stevedata-min_wage","stevedata","min_wage","History of Federal Minimum Wage Rates Under the Fair Labor Standards Act, 1938-2009",23,2,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/min_wage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/min_wage.html","min_wage R Documentation   History of Federal Minimum Wage Rates Under the Fair Labor Standards Act, 1938-2009   Description  
A data set on the various federal minimum wage rates.    Usage    min_wage    Format  
A data frame with 23 observations on the following 5 variables.    date
a date for when a new minimum wage was introduced   wage
the (nominal) value of the wage     Details  
Data come from the Department of Labor. Wages are taken from wage adjustments from the 1938 act.    Source  
Department of Labor"
"stevedata-mm_mlda","stevedata","mm_mlda","Minimum Legal Drinking Age Fatalities Data",50,19,0,0,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/mm_mlda.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/mm_mlda.html","mm_mlda R Documentation   Minimum Legal Drinking Age Fatalities Data   Description  
These are data you can use to replicate the regression discontinuity design analyses throughout Chapter 4 of Mastering 'Metrics . Original analyses come from Carpenter and Dobkin (2009, 2011).    Usage    mm_mlda    Format  
A data frame with 50 observations on the following 19 variables.    agecell
a numeric   all
a numeric   allfitted
a numeric   internal
a numeric   internalfitted
a numeric   external
a numeric   externalfitted
a numeric   alcohol
a numeric   alcoholfitted
a numeric   homicide
a numeric   homicidefitted
a numeric   suicide
a numeric   suicidefitted
a numeric   mva
a numeric   mvafitted
a numeric   drugs
a numeric   drugsfitted
a numeric   externalother
a numeric   externalotherfitted
a numeric     Details  
These data are not well-documented. You guys are on your own here. Good luck.    References  
Carpenter, Christopher and Carlos Dobkin. 2009. ""The Effect of Alcohol Consumption on Mortality: Regression Discontinuity Evidence from the Minimum Drinking Age"". American Economic Journal: Applied Economics 1(1): 164–182.   
Carpenter, Christopher and Carloss Dobkin. 2011. ""The Minimum Legal Drinking Age and Public Health"". Journal of Economic Perspectives 25(2): 133–156."
"stevedata-mm_nhis","stevedata","mm_nhis","Data from the 2009 National Health Interview Survey (NHIS)",18790,10,4,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/mm_nhis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/mm_nhis.html","mm_nhis R Documentation   Data from the 2009 National Health Interview Survey (NHIS)   Description  
These are data from the 2009 NHIS survey. People who have read  Mastering 'Metrics should recognize these data. They're featured prominently in that book and the authors' discussion of random assignment and experiments.    Usage    mm_nhis    Format  
A data frame with 18790 observations on the following 10 variables.    fml
is the respondent a woman?   hi
a numeric vector for whether respondent has at least some health insurance   hlth
a numeric vector for a health index, broadly understood   nwhite
is the respondent not white?   age
the respondent's age in years   yedu
the respondent's total years of education   famsize
the size of the respondent's family   empl
is the respondent employed   inc
the respondent's household/family income   perweight
a numeric vector for weight     Details  
Data are already cleaned in a way that facilitates an easy replication of Table 1.1 in Mastering 'Metrics . Check  http://www.masteringmetrics.com for more information.    Source  
National Health Interview Survey (2009)."
"stevedata-mvprod","stevedata","mvprod","Motor Vehicle Production by Country, 1950-2019",1206,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/mvprod.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/mvprod.html","mvprod R Documentation   Motor Vehicle Production by Country, 1950-2019   Description  
Data, largely from Organisation Internationale des Constructeurs d'Automobiles (OICA), on motor vehicle production in various countries (and the world totals) from 1950 to 2019 at various intervals. Tallies include production of passenger cars, light commercial vehicles, minibuses, trucks, buses and coaches.    Usage    mvprod    Format  
A data frame with three variables    country
the country's name   year
the year   value
the total motor vehicles produced that year     Details  
This is a Wikipedia web-scraping job. See:  https://en.wikipedia.org/wiki/List_of_countries_by_motor_vehicle_production     Source  
Organisation Internationale des Constructeurs d'Automobiles (OICA)"
"stevedata-nesarc_drinkspd","stevedata","nesarc_drinkspd","The Usual Daily Drinking Habits of Americans (NESARC, 2001-2)",43093,8,1,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/nesarc_drinkspd.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/nesarc_drinkspd.html","nesarc_drinkspd R Documentation   The Usual Daily Drinking Habits of Americans (NESARC, 2001-2)   Description  
This toy data set is loosely modified from Wave I of the NESARC data set. Here, my main interest is the number of drinks consumed on a usual day drinking alcohol in the past 12 months, according to respondents in the nationally representative survey of 43,093 Americans.    Usage    nesarc_drinkspd    Format  
A data frame with 43093 observations on the following 8 variables.    idnum
a numeric vector and sequence from 1 to the number of rows in the data   ethrace2a
a numeric vector for the ethnicity/race. 1 = White, not Hispanic. 2 = Black, not Hispanic. 3 = AI/AN. 4 = Asian, Native Hawaiian, Pacific Islander. 5 = Hispanic or Latino.   region
a numeric vector for the Census region. 1 = Northeast. 2 = Midwest. 3 = South. 4 = West   age
a numeric vector for age in years   sex
a numeric vector for sex. 1 = female. 0 = male   marital
a numeric vector for marital status. 1 = married. 2 = living with someone as married. 3 = widowed. 4 = divorced. 5 = separated. 6 = never married   educ
a numeric vector for education level, recoded from s1q6a in the original data. 1 = did not make it to/finish high school. 2 = high school graduate or equivalency. 3 = some college, but no four-year degree. 4 = four-year college degree or more.   s2aq8b
a numeric vector for the number of drinks of any alcohol consumed on days drinking alcohol in the past 12 months. This variable is “as-is” from the original data set.     Details  
You will not want to use the s2aq8b variable without recoding it first. Those who cannot recall how much they typically drink (i.e. true “don't knows” or missing info) are coded as 99. Non-drinkers are coded as NA in the s2aq8b  variable and should be recoded as 0. Any value between 1 and 98 in the variable represents the, for lack of better term, “true” number of alcoholic drinks a respondent says s/he typically consumes on a day drinking alcohol in the past 12 months, though this is evidently preposterous as a count variable. A person drinking 42 alcoholic drinks a day would not be alive to tell you they did this. The researcher may want to employ some sensible right censoring here.    Source  
National Epidemiologic Survey on Alcohol and Related Conditions (NESARC)—Wave 1 (2001–2002)"
"stevedata-Newhouse77","stevedata","Newhouse77","Medical-Care Expenditure: A Cross-National Survey (Newhouse, 1977)",13,5,0,1,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Newhouse77.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Newhouse77.html","Newhouse77 R Documentation   Medical-Care Expenditure: A Cross-National Survey (Newhouse, 1977)   Description  
These are the data in Newhouse's (1977) simple OLS model from 1977. In his case, he's trying to explain medical care expenditures as a function of GDP per capita for these countries. It's probably the easiest OLS model I can find in print because Newhouse helpfully provides all the data in one simple table.    Usage    Newhouse77    Format  
A data frame with 13 observations on the following 5 variables.    country
a character vector for the country   year
a numeric vector for the year   gdppc
a numeric vector for the per capita GDP in USD   medsharegdp
a numeric vector for the medical care share as percentage of GDP   medexppc
a numeric vector for per capita medical care expenditure (in USD)     Details  
Table 1 in Newhouse (1977) is well-annotated with background information.    References  
Newhouse, Joseph P. 1977. ""Medical-Care Expenditure: A Cross-National Survey."" Journal of Human Resources 12(1): 115-125."
"stevedata-ODGI","stevedata","ODGI","Ozone Depleting Gas Index Data, 1992-2019",56,16,1,1,0,0,15,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/ODGI.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/ODGI.html","ODGI R Documentation   Ozone Depleting Gas Index Data, 1992-2019   Description  
The NOAA Earth System Research Laboratory has an ""ozone depleting gas index"" (ODGI) data set from 1992 to 2018. This dataset summarizes Table 1 and Table 2 from its website. The primary interest here (for my purposes) is the ODGI indices (including the new 2012 measure). The data set includes constituent greenhouse gases/chlorines as well in parts per trillion. The primary use here is for in-class illustration.    Usage    ODGI    Format  
A data frame with 56 observations on the following 16 variables.    year
the year   cat
categorical variable for the Antarctic or Mid-Latitudes measurements   cfc12
CFC-12 concentration in parts per trillion   cfc11
CFC-11 concentration in parts per trillion   ch3cl
chloromethane concentration in parts per trillion   ch3br
bromomethane concentration in parts per trillion   ccl4
carbon tetrachloride concentration in parts per trillion   ch3ccl3
methyl chloroform concentration in parts per trillion   halons
aggregate concentration in parts per trillion of H-1211, H-1301 and H-2402   cfc113
trichlorotrifluoroethane concentration in parts per trillion   hcfcs
aggregate concentration in parts per trillion of HCFC-22, HCFC-141b, and HCFC-142b   wmo_minor
aggregate concentration in parts per trillion of CFC-114, CFC-115, halon 2402 and halon 1201   sum
the sum of all greenhouse gas concentration measurements   eesc
includes consideration of lag times for transport and mixing associated with transport. New as of 2012   odgi_old
old greenhouse gas index, no longer supported as of 2012   odgi_new
new greenhouse gas index, as of 2012     Source  
https://www.esrl.noaa.gov/gmd/odgi/"
"stevedata-Presidents","stevedata","Presidents","U.S. Presidents and Their Terms in Office",45,3,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/Presidents.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/Presidents.html","Presidents R Documentation   U.S. Presidents and Their Terms in Office   Description  
This should be self-evident. Here are all U.S. presidents who have completed their terms in office (i.e. excluding the current one).    Usage    Presidents    Format  
A data frame with 45 observations on the following 3 variables.    president
the president   start
the start date of the term, as a date   end
the end date of the term, as a date     Details  
I scraped this from https://www.presidentsusa.net/presvplist.html . Data frame is capital-P ""Presidents"" to avoid a conflict with the  presidents data frame from the datasets package."
"stevedata-pwt_sample","stevedata","pwt_sample","Penn World Table (9.1) Macroeconomic Data for Select Countries, 1950-2017",1428,7,0,2,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/pwt_sample.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/pwt_sample.html","pwt_sample R Documentation   Penn World Table (9.1) Macroeconomic Data for Select Countries, 1950-2017   Description  
These are some macroeconomic data for 21 select (rich) countries. I've used these data before to discuss issues of grouping and skew in cross-sectional data.    Usage    pwt_sample    Format  
A data frame with 1428 observations on the following 7 variables.    country
the country name   isocode
The country's ISO code   year
a numeric vector for the year   pop
Population in millions   hc
Index of human capital per person, based on years of schooling and returns to education   rgdpna
Real GDP at constant 2011 national prices (in million 2011 USD)   labsh
Share of labor compensation in GDP at current national prices     Source  
Taken from the pwt9 package. See: http://www.ggdc.net/pwt/"
"stevedata-quartets","stevedata","quartets","Anscombe's (1973) Quartets",44,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/quartets.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/quartets.html","quartets R Documentation   Anscombe's (1973) Quartets   Description  
These are four x-y data sets, combined into a long format, which have the same traditional statistical properties (mean, variance, correlation, regression line, etc.). However, they look quite different.    Usage    quartets    Format  
A data frame with 44 observations on the following 3 variables.    group
a categorical identifier for the quartet   x
a continuous variable   y
a continuous variable     Details  
Data come default in R, but I elected to change the format to be a bit more accessible.    References  
Anscombe, Francis J. (1973). ""Graphs in Statistical Analysis."" The American Statistician 27: 17–21."
"stevedata-recessions","stevedata","recessions","United States Recessions, 1855-present",35,8,0,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/recessions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/recessions.html","recessions R Documentation   United States Recessions, 1855-present   Description  
Data on U.S. recessions, past to present. Data include information on contraction, expansion, and cycle.    Usage    recessions    Format  
A data frame with 35 observations on the following 8 variables.    peak
the year-month of the peak, as a date   trough
the year-month of the trough, as a date   peakq
the peak quarter   troughq
the trough quarter   p2t
peak to trough (in months)   prev_t2p
previous trough to this peak (in months)   tfpt
trough from previous trough (in months)   pfpp
peak from previous peak (in months)     Details  
Data come from via scraping job of https://www.nber.org/research/data/us-business-cycle-expansions-and-contractions     Source  
National Bureau of Economic Research (NBER)"
"stevedata-SCP16","stevedata","SCP16","South Carolina County GOP/Democratic Primary Data, 2016",46,15,0,1,0,0,14,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/SCP16.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/SCP16.html","SCP16 R Documentation   South Carolina County GOP/Democratic Primary Data, 2016   Description  
County-level data on vote share and various background/demographic information for the 2016 South Carolina GOP/Democratic primaries.    Usage    SCP16    Format  
A data frame with 46 observations on the following 15 variables.    county
the county   clinton
Hillary Clinton's county-level vote share in the 2016 party primary   sanders
Bernie Sanders' county-level vote share in the 2016 party primary   trump
Donald Trump's county-level vote share in the 2016 party primary   cruz
Ted Cruz' county-level vote share in the 2016 party primary   rubio
Marco Rubio's county-level vote share in the 2016 party primary   percapinc
A county-level estimate for per capita income   medhouseinc
A county-level estimate for the median household income   medfaminc
A county-level estimate for the median family income   illiteracy
An estimate of the percent of the county lacking ""basic"" prose literacy skills   perblack
Percentage of the county that is black   population
An estimate of the county-level population   romneyshare2012
Mitt Romney's vote share at the county-level from the 2012 general election   perhsgrad
Percentage of the county whose residents 25 years and older have at least a high school education   unemployment
Unemployment rate for the county for January 2016     Details  
The illiteracy estimate comes from a Department of Education report from 2003. The unemployment rate data come from the Bureau of Labor Statistics. A Github repository contains more information: https://github.com/svmiller/sc-primary-2016 ."
"stevedata-sealevels","stevedata","sealevels","Global Average Absolute Sea Level Change, 1880–2015",136,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/sealevels.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/sealevels.html","sealevels R Documentation   Global Average Absolute Sea Level Change, 1880–2015   Description  
These data describe how sea level has changed over time, in both relative and absolute terms. Absolute sea level change refers to the height of the ocean surface regardless of whether nearby land is rising or falling.    Usage    sealevels    Format  
A data frame with 136 observations on the following 5 variables.    year
the year   adjlev
adjusted sea level (in inches)   lb
the lower bound of the estimate (in inches)   ub
the upper bound of the estimate (in inches)   adjlev_noaa
NOAA's adjusted sea level (in inches)     Source  
https://www.epa.gov/climate-indicators/climate-change-indicators-sea-level     References  
CSIRO (Commonwealth Scientific and Industrial Research Organisation). 2015 update to data originally published in: Church, J.A., and N.J. White. 2011. Sea-level rise from the late 19th to the early 21st century. Surv. Geophys. 32:585–602. http://www.cmar.csiro.au/sealevel/sl_data_cmar.html .   
NOAA (National Oceanic and Atmospheric Administration). 2016. Laboratory for Satellite Altimetry: Sea level rise. Accessed June 2016.  http://www.star.nesdis.noaa.gov/sod/lsa/SeaLevelRise/LSA_SLR_timeseries_global.php ."
"stevedata-so2concentrations","stevedata","so2concentrations","Sulfur Dioxide Emissions, 1980-2020",41,4,0,0,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/so2concentrations.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/so2concentrations.html","so2concentrations R Documentation   Sulfur Dioxide Emissions, 1980-2017   Description  
This data set contains yearly observations by the Environmental Protection Agency on the concentration of sulfur dioxide in parts per billion, based on 35 sites. I use this for in-class illustration. Note that the national standard is 75 parts per billion.    Usage    so2concentrations    Format  
A data frame with 40 observations on the following 4 variables.    year
the year   value
the mean concentration of sulfur dioxide in the air based on 35 trend sites, in parts per billion   ub
the lower bound of the value (10th percentile)   lb
the upper bound of the value (90th percentile)     Source  
Environmental Protection Agency, 2020. https://www.epa.gov/air-trends/sulfur-dioxide-trends"
"stevedata-steves_clothes","stevedata","steves_clothes","Steve's (Professional) Clothes, as of March 3, 2019",79,4,0,4,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/steves_clothes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/steves_clothes.html","steves_clothes R Documentation   Steve's (Professional) Clothes, as of March 3, 2019   Description  
I cobbled together this data set of the professional clothes (polos, long-sleeve dress shirts, pants) in my closet, largely for illustration on the origins of apparel in the U.S. for an intro lecture on trade.    Usage    steves_clothes    Format  
A data frame with 79 observations on the following 4 variables.    type
Type of clothing   brand
The brand of clothing (e.g. Apt. 9, Saddlebred)   color
the color (and/or pattern) of the article of clothing   origin
The country that produced the garment.     Details  
If you must know, I do most of my clothes shopping at major retailers in the U.S. (mostly Belk, J.C. Penney, and Kohl's). If that's you as well, the odds are good the distribution of my clothes will closely resemble yours.)    Source  
Steve's closet. Hey, that's me!"
"stevedata-sugar_price","stevedata","sugar_price","IMF Primary Commodity Price Data for Sugar",1316,3,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/sugar_price.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/sugar_price.html","sugar_price R Documentation   IMF Primary Commodity Price Data for Sugar   Description  
This is primary commodity price data for sugar globally, in the United States, and in Europe for every month from 1980 to (roughly) the present. Prices are nominal U.S. cents per pound and are not seasonally adjusted (""NSA"").    Usage    sugar_price    Format  
A data frame with 1,298 observations on the following 3 variables.    date
a date   category
the category (either the U.S., global, or Europe)   value
the price of sugar in U.S. cents per pound (NSA, nominal)     Details  
The price data for Europe do not appear to be updated as regularly as the global and U.S. prices. Thus, the last month in the data for Europe are June 2017. For that reason, I elected to make a data set of these data for posterity's sake.    Source  
International Monetary Fund"
"stevedata-therms","stevedata","therms","Thermometer Ratings for Donald Trump and Barack Obama",3080,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/therms.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/therms.html","therms R Documentation   Thermometer Ratings for Donald Trump and Barack Obama   Description  
A data set on thermometer ratings for Donald Trump and Barack Obama in 2020. I use these data for in-class illustration of central limit theorem. Basically: the sampling distribution of a population is normal, even if the underlying population is decidedly not.    Usage    therms    Format  
A data frame with 3080 observations on the following 2 variables.    fttrump1
a thermometer rating for Donald Trump [0:100]   ftobama1
a thermometer rating for Barack Obama [0:100]     Details  
The survey period was April 10-18, 2020 and was done entirely online.    Source  
American National Election Studies (ANES) Exploratory Testing Survey (ETS)"
"stevedata-turnips","stevedata","turnips","Turnip prices in Animal Crossing (New Horizons)",278,3,0,1,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/turnips.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/turnips.html","turnips R Documentation   Turnip prices in Animal Crossing (New Horizons)   Description  
A data set on turnip prices from my experience with Animal Crossing (New Horizons)    Usage    turnips    Format  
A data frame with the following 3 variables.    date
a date   time
a character vector referring to the particular time period of observation   price
a numeric vector for the price of turnips, in bells     Details  
Sunday prices are set for purchase and do not fluctuate. Tommy and Timmy do not accept turnips on Sunday either. Daily prices fluctuate both at opening on Nook's Cranny and at noon. This amounts to three time periods in the data. ""5:00 a.m."" is reserved only for Sunday purchases (i.e. when Daisy Mae arrives on the island). 8:00 a.m. is the morning price because that is when Nook's Cranny opens. 12:00 p.m. is when the price changes for the day."
"stevedata-TV16","stevedata","TV16","The Individual Correlates of the Trump Vote in 2016",64600,21,4,2,0,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/TV16.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/TV16.html","TV16 R Documentation   The Individual Correlates of the Trump Vote in 2016   Description  
These data come from the 2016 CCES and allow interested students to model the individual correlates of the Trump vote in 2016. Code/analysis heavily indebted to a 2017 analysis I did on my blog (see references).    Usage    TV16    Format  
A data frame with 64600 observations on the following 21 variables.    uid
a numeric vector, a unique identifier for the respondent as they first appear in the CCES data.   state
a character vector for the state in which the respondent resides   votetrump
a numeric that equals 1 if the respondent voted says s/he voted for Trump in 2016.   age
a numeric vector for age that is roughly calculated as 2016 - birthyr , as it's coded in the CCES data.   female
a numeric that equals 1 if the respondent is a woman   collegeed
a numeric vector that equals 1 if the respondent says s/he has a college degree   racef
a character vector for the race of the respondent   famincr
a numeric vector for the respondent's household income. Ranges from 1 (Less than $10,000) to 12 ($150,000 or more).   ideo
a numeric vector for the respondent's ideology on a liberal-conservative discrete scale. 1 = very liberal. 5 = very conservative.   pid7na
a numeric vector for the respondent's partisanship on the familiar 1-7 scale. 1 = Strong Democrat. 7 = Strong Republican. Other party supporters (e.g. libertarians) are coded as NA.   bornagain
a numeric vector for whether the respondent self-identifies as a born-again Christian.   religimp
a numeric vector for the importance of religion to the respondent. 1 = not at all important. 4 = very important.   churchatd
a numeric vector for the extent of church attendance for the respondent. 1 = never. 6 = more than once a week.   prayerfreq
a numeric vector for the frequency of prayer for the respondent. 1 = never. 7 = several times a day.   angryracism
a numeric vector for how angry the respondent is that racism exists. 1 = strongly agree (i.e. is angry racism exists). 5 = strongly disagree.   whiteadv
a numeric vector for agreement with statement that white people have advantages over others in the U.S. 1 = strongly agree. 5 = strongly disagree.   fearraces
a numeric vector for agreement with statement that the respondent fears other races. 1 = strongly disagree. 5 = strongly agree.   racerare
a numeric vector for agreement with statement that racism is rare in the U.S. 1 = strongly disagree. 5 = strongly agree.   lrelig
a numeric vector that serves as a latent estimate for religiosity from the bornagain , religimp , churchatd , and prayerfreq variables. Higher values = more religiosity.   lcograc
a numeric vector that serves as a latent estimate for cognitive racism. This is derived from the racerare and whiteadv variables.   lemprac
a numeric vector that serves as a latent estimate for empathetic racism. This is derived from the fearraces and angryracism variables.     Details  
The latent estimates for religiosity, cognitive racism, and empathetic racism come from a graded response model estimated in mirt . The concepts of ""cognitive racism"" and ""empathetic racism"" come from DeSante and Smith.    Source  
Cooperative Congressional Election Study, 2016    References  
http://svmiller.com/blog/2017/04/age-income-racism-partisanship-trump-vote-2016/    
https://github.com/svmiller/2016-cces-trump-vote/blob/master/1-2016-cces-trump.R"
"stevedata-ukg_eeri","stevedata","ukg_eeri","United Kingdom Effective Exchange Rate Index Data, 1990-2019",7583,2,0,1,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/ukg_eeri.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/ukg_eeri.html","ukg_eeri R Documentation   United Kingdom Effective Exchange Rate Index Data, 1990-2019   Description  
This is a (near) daily data set on the effective exchange rate index for the United Kingdom's pound sterling from 1990 to 2018. The data are indexed, such that 100 equals the monthly average in January 2005. This is useful for illustrating devaluations of the pound after Black Wednesday, the financial crisis, and, more recently, the UK's efforts to leave the European Union.    Usage    ukg_eeri    Format  
A data frame with 7583 observations on the following 2 variables.    date
a date   value
a numeric vector for the effective exchange rate index (Jan. 2005 = 100)     Details  
Credit to the Bank of England for making these data readily available and accessible. The Bank of England's website ( https://www.bankofengland.co.uk/ ) has these data with a code of XUDLBK67 .    Source  
Bank of England"
"stevedata-uniondensity","stevedata","uniondensity","Cross-National Rates of Trade Union Density",20,5,0,1,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/uniondensity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/uniondensity.html","uniondensity R Documentation   Cross-National Rates of Trade Union Density   Description  
Cross-national data on relative size of the trade unions and predictors in 20 countries. This is a data set of interest to replicating Western and Jackman (1994), who themselves were addressing a debate between Wallerstein and Stephens on which of two highly correlated predictors explains trade union density.    Usage    uniondensity    Format  
A data frame with 20 observations on the following 5 variables.    country
a character vector for the country   union
a numeric vector for the percentage of the total number of wage and salary earners plus the unemployed who are union members, measured between 1975 and 1980, with most of the data drawn from 1979.   left
a numeric vector tapping the extent to which parties of the left have controlled governments since 1919, due to Wilensky (1981).   size
a numeric vector measuring the log of labor force size, defined as the number of wage and salary earners, plus the unemployed.   concen
a numeric vector measuring the percentage of employment, shipments, or production accounted for by the four largest enterprises in a particular industry, averaged over industries (with weights proportional to the size of the industry) and the resulting measure is normalized such that the United States scores a 1.0, and is due to Pryor (1973). Some of the scores on this variable are imputed using procedures described in Stephens and Wallerstein (1991, 945).     Details  
Data documentation are derived from Simon Jackman's pscl package. I just tidied up the presentation a bit.    Source  
Pryor, Frederic. 1973. Property and Industrial Organization in Communist and Capitalist Countries. Bloomington: Indiana University Press.   
Stephens, John and Michael Wallerstein. 1991. Industrial Concentration, Country Size and Trade Union Membership. American Political Science Review 85:941-953.   
Western, Bruce and Simon Jackman. 1994. Bayesian Inference for Comparative Research. American Political Science Review 88:412-423.   
Wilensky, Harold L. 1981. Leftism, Catholicism, Democratic Corporatism: The Role of Political Parties in Recemt Welfare State Development. In The Development of Welfare States in Europe and America, ed. Peter Flora and Arnold J. Heidenheimer. New Brunswick: Transaction Books.    References  
Jackman, Simon. 2009. Bayesian Analysis for the Social Sciences. Wiley: Hoboken, New Jersey."
"stevedata-usa_chn_gdp_forecasts","stevedata","usa_chn_gdp_forecasts","United States-China GDP and GDP Forecasts, 1960-2050",182,12,1,1,0,0,11,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/usa_chn_gdp_forecasts.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/usa_chn_gdp_forecasts.html","usa_chn_gdp_forecasts R Documentation   United States-China GDP and GDP Forecasts, 1960-2050   Description  
This is a toy data set to examine the time in which we should expect China to overtake the United States in total gross domestic product (GDP), given current trends. It includes an OECD long-term GDP forecast from 2014, and forecasts from the forecast and prophet packages in R.    Usage    usa_chn_gdp_forecasts    Format  
A data frame with 182 observations on the following 12 variables.    country
a character vector (United States, China)   year
a numeric vector for the year   p_gdp
y-hats (forecasted GDP) from a prophet forecast   p_lo80
lower bound (80%) of y-hats (forecasted GDP) from a prophet forecast   p_hi80
upper bound (80%) of y-hats (forecasted GDP) from a prophet forecast   gdp
observed GDP, made available to the World Bank and OECD national accounts data. Available from 1960 to 2019.   f_gdp
forecasted GDP from 2020 to 2050, from the forecast package   f_lo80
lower bound (80%) forecasted GDP from 2018 to 2050, from the forecast package   f_hi80
upper bound (80%) forecasted GDP from 2018 to 2050, from the forecast package   f_lo95
lower bound (95%) forecasted GDP from 2018 to 2050, from the forecast package   f_hi95
upper bound (95%) forecasted GDP from 2018 to 2050, from the forecast package   oecd_ltgdpf
long-term GDP forecast from the OECD via the OECD Outlook No 95 - May 2014     Details  
Forecasts from the forecast package and prophet  package are rudimentary and bare minimum forecasts based on previous values to that point. Notice the forecast forecasts have a prefix of  f_ and the prophet forecasts have a prefix of  p_ . Forecasts are not meant to be exhaustive (clearly), only illustrative for in-class discussion about the ""Rise of China."" Forecasts made in R on Nov. 20, 2020.    Source  
OECD Outlook No 95 - May 2014 - Long-term baseline projections provided by Organisation for Economic Co-operation and Development (OECD)"
"stevedata-usa_computers","stevedata","usa_computers","Percentage of U.S. Households with Computer Access, by Year",19,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/usa_computers.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/usa_computers.html","usa_computers R Documentation   Percentage of U.S. Households with Computer Access, by Year   Description  
This is a simple and regrettably incomplete time-series on the percentage of U.S. households with access to a computer, by year.    Usage    usa_computers    Format  
A data frame with 19 observations on the following 2 variables.    year
the year   value
the estimated percentage of households with access to a computer     Details  
Data are spotty and regrettably this is not a perfect time-series. However, it is useful for an in-class exercise to show that the proliferation of household computers (over time) in the United States comes in part because of globalization. Use it for that purpose. The data are reasonably faithful, but don't treat it as gospel. Exact sourcing available upon request.    Source  
Various: U.S. Census Bureau, Current Population Survey, and American Community Survey"
"stevedata-usa_migration","stevedata","usa_migration","U.S. Inbound/Outbound Migration Data, 1990-2017",3535,5,1,3,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/usa_migration.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/usa_migration.html","usa_migration R Documentation   U.S. Inbound/Outbound Migration Data, 1990-2017   Description  
This data set contains counts/estimates for the number of inbound migrants in the U.S as well as outbound migrants of American origin to other countries from 1990 to 2017.    Usage    usa_migration    Format  
A data frame with 3535 observations on the following 5 variables.    year
a numeric vector for 1990, 1995, 2000, 2005, 2010, 2015, 2017   country
a character vector/constant for the United States   category
a character vector for whether the count is inbound to the U.S. from the area variable or outbound (i.e. American expats) to the area variable in a given year.   area
a character vector for the area of origin (if category == ""Inbound"") or destination for American migrants (if category == ""Outbound"")   count
a numeric vector for the count of inbound/outbound migrants     Source  
United Nations Population Division (DESA)"
"stevedata-usa_states","stevedata","usa_states","State Abbreviations, Names, and Regions/Divisions",51,4,0,4,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/usa_states.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/usa_states.html","usa_states R Documentation   State Abbreviations, Names, and Regions/Divisions   Description  
A simple data set from state.abb , state.name , state.region , and  state.division (+ District of Columbia). I'd rather just have all these in one place.    Usage    usa_states    Format  
A data frame with 51 observations on the following 4 variables.    stateabb
the state abbreviation   statename
the state's name   region
the state's Census region   division
the state's Census division"
"stevedata-usa_tradegdp","stevedata","usa_tradegdp","U.S. Trade and GDP, 1790-2018",229,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/usa_tradegdp.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/usa_tradegdp.html","usa_tradegdp R Documentation   U.S. Trade and GDP, 1790-2018   Description  
A yearly data set on U.S. trade and GDP from 1790 to 2018. Data also include a population variable to facilitate per capita adjustments, if the user sees it useful.    Usage    usa_tradegdp    Format  
A data frame with 229 observations on the following 5 variables.    year
the year   gdpb
U.S. GDP (nominal, in billions)   pop
Population of the U.S. (in thousands)   impo
The value of U.S. imports (in billions)   expo
The value of U.S. exports (in billions)     Details  
Data come from various sources (see, especially: http://econdataus.com/tradeall.html ). Post-1989 data come from the U.S. Census Bureau. 2018 GDP comes from the IMF. 2018 population estimate comes from the U.S. Census Bureau."
"stevedata-wvs_ccodes","stevedata","wvs_ccodes","Syncing Word Values Survey Country Codes with CoW Codes",112,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_ccodes.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_ccodes.html","wvs_ccodes R Documentation   Syncing Word Values Survey Country Codes with CoW Codes   Description  
A simple data set that syncs World Values Survey country codes ( s003 ) with corresponding country codes from the Correlates of War state system membership data.    Usage    wvs_ccodes    Format  
A data frame with 112 observations on the following 3 variables.    s003
the World Values Survey country code   country
a character vector for the corresponding country name   ccode
the equivalent country code from the Correlates of War state system membership data     Details  
http://svmiller.com/blog/2015/06/syncing-word-values-survey-country-codes-with-cow-codes/"
"stevedata-wvs_immig","stevedata","wvs_immig","Attitudes about Immigration in the World Values Survey",310388,6,0,1,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_immig.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_immig.html","wvs_immig R Documentation   Attitudes about Immigration in the World Values Survey   Description  
A data set on attitudes about immigration for all observations in the third to sixth wave of the World Values Survey. I use these data for in-class illustration.    Usage    wvs_immig    Format  
A data frame with 310,388 observations on the following 6 variables.    s002
the World Values Survey wave   s003
the World Values Survey country code   country
the country name   s020
the survey year   uid
a unique identifier for the survey respondent   e143
an attitude about immigration policy in the World Values Survey     Details  
1 = ""let anyone come"". 2 = ""as long as jobs are available"". 3 = ""strict limits"". 4 = ""Prohibit people from coming"" for the e143 variable. See ?wvs_ccodes for more information about naming/identifying countries."
"stevedata-wvs_justifbribe","stevedata","wvs_justifbribe","Attitudes about the Justifiability of Bribe-Taking in the World Values Survey",348532,6,0,1,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_justifbribe.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_justifbribe.html","wvs_justifbribe R Documentation   Attitudes about the Justifiability of Bribe-Taking in the World Values Survey   Description  
A data set on attitudes about the justifiability of bribe-taking for all observations in the third to sixth wave of the World Values Survey. I use these data for in-class illustration about seemingly interval-level, but information-poor measurements.    Usage    wvs_justifbribe    Format  
A data frame with 348532 observations on the following 6 variables.    s002
the World Values Survey wave   s003
the World Values Survey country code   country
the country name   s020
the survey year   uid
a unique identifier for the survey respondent   f117
an attitude about the justifiability of bribe-taking in the World Values Survey     Details  
1 = ""never justifiable"". 10 = ""always justifiable"". Increasing values on this 1-10 scale imply increasing permissiveness for the respondent toward this particular/blatant form of corruption."
"stevedata-wvs_usa_abortion","stevedata","wvs_usa_abortion","Attitudes on the Justifiability of Abortion in the United States (World Values Survey, 1982-2011)",10387,16,5,0,0,0,16,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_usa_abortion.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_usa_abortion.html","wvs_usa_abortion R Documentation   Attitudes on the Justifiability of Abortion in the United States (World Values Survey, 1982-2011)   Description  
A data set on attitudes about the justifiability of abortion in the United States based on World Values Survey responses recorded across six waves (from 1982 to 2011). I assembled this data frame probably around 2014 and routinely use it for in-class illustration about regression, post-estimation simulation, quantities of interest, and how to think about modeling a dependent variable that is on a 1-10 scale, but has curious heaping patterns.    Usage    wvs_usa_abortion    Format  
A data frame with 10387 observations on the following 16 variables.    wvsccode
the country code for the United States (a numeric constant)   wave
the survey wave   year
the survey year corresponding to the survey wave   aj
the justifiability of abortion on a 1-10 scale (1 = never justifiable; 10 = always justifiable)   age
the age of the respondent in years   collegeed
a dummy variable that equals 1 if the respondent graduated from college   female
a dummy variable that equals 1 if the respondent is a woman   unemployed
a dummy variable that equals 1 if the respondent is unemployed   ideology
the ideological self-placement of the respondent on a 1-10 scale (1 = furthest to the left; 10 = furthest to the right)   satisfinancial
the respondent's financial satisfaction with his/her life (1 = most dissatisfied; 10 = most satisfied)   postma4
the post-materialist index for the respondent (-1 = materialist; 0 = mixed, 1 = post-materialist)   cai
the child autonomy index, which ranges from -2 to 2   trustmostpeople
can most people be trusted (1) or ""(you) never can be too careful"" (0)   godimportant
the importance of God to the respondent on a 1-10 scale (1 = God is not at all important; 10 = God is most important)   respectauthority
would more respect for authority be a welcome change to the United States?   nationalpride
a dummy that equals 1 if the respondent is very proud to be an American.     Details  
Data come from the World Values Survey. Note that the college education variable is curiously NA until the third survey wave. The child autonomy index ranges from -2 to 2 where increasing values indicate that children should learn determination and independence over obedience and religious faith. The respectauthority variable is coded where -1 means the respondent believes greater respect for authority in the United States as a future change to the country would be a bad thing. 0 means the respondent doesn't mind such a change. 1 = the respondent believes it would be a good thing."
"stevedata-wvs_usa_educat","stevedata","wvs_usa_educat","Education Categories for the United States in the World Values Survey",42,6,0,3,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_usa_educat.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_usa_educat.html","Toggle navigation             Rdatasets   1.0.0      
 
  Available datasets    
                 
 
 
  Page not found (404)    Content not found. Please use links in the navbar.   
    Contents          
 
Developed by Vincent Arel-Bundock.    
 
Site built with pkgdown 1.6.1."
"stevedata-wvs_usa_regions","stevedata","wvs_usa_regions","Region Categories for the United States in the World Values Survey",63,6,0,5,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/wvs_usa_regions.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/wvs_usa_regions.html","Toggle navigation             Rdatasets   1.0.0      
 
  Available datasets    
                 
 
 
  Page not found (404)    Content not found. Please use links in the navbar.   
    Contents          
 
Developed by Vincent Arel-Bundock.    
 
Site built with pkgdown 1.6.1."
"stevedata-yugo_sales","stevedata","yugo_sales","Yugo Sales in the United States, 1985-1992",24,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/stevedata/yugo_sales.csv","https://vincentarelbundock.github.io/Rdatasets/doc/stevedata/yugo_sales.html","yugo_sales R Documentation   Yugo Sales in the United States, 1985-1992   Description  
A data set on Yugo sales against two competing models in the United States from 1985 to 1992.    Usage    yugo_sales    Format  
A data frame with 24 observations on the following 3 variables.    year
the year   car
the car type, either the Hyundai Excel, Yugo, or Toyota Tercel   sales
the number of units sold in the United States     Details  
Data come from https://carsalesbase.com . I'm aware the inclusion of the Tercel is questionable since the third generation of Tercels were quite different from the first and second generations. However, I use these data to illustrate how poorly the Yugo fared against competing models, including the first and second generation Tercels. I think the inclusion is fair for that purpose."
"survival-cancer","survival","cancer","NCCTG Lung Cancer Data",228,10,2,0,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/cancer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/cancer.html","lung R Documentation   NCCTG Lung Cancer Data   Description  
Survival in patients with advanced lung cancer from the North Central Cancer Treatment Group. Performance scores rate how well the patient can perform usual daily activities.    Usage   lung data(cancer, package=""survival"")    Format  
 inst: Institution code
 time: Survival time in days
 status: censoring status 1=censored, 2=dead
 age: Age in years
 sex: Male=1 Female=2
 ph.ecog: ECOG performance score as rated by the physician. 0=asymptomatic, 1= symptomatic but completely ambulatory, 2= in bed <50% of the day, 3= in bed > 50% of the day but not bedbound, 4 = bedbound
 ph.karno: Karnofsky performance score (bad=0-good=100) rated by physician
 pat.karno: Karnofsky performance score as rated by patient
 meal.cal: Calories consumed at meals
 wt.loss: Weight loss in last six months
    Note  
The use of 1/2 for alive/dead instead of the usual 0/1 is a historical footnote. For data contained on punch cards, IBM 360 Fortran treated blank as a zero, which led to a policy within the section of Biostatistics to never use ""0"" as a data value since one could not distinguish it from a missing value. The policy became a habit, as is often the case; and the 1/2 coding endured long beyond the demise of punch cards and Fortran.    Source  
Terry Therneau   References  
Loprinzi CL. Laurie JA. Wieand HS. Krook JE. Novotny PJ. Kugler JW. Bartel J. Law M. Bateman M. Klatt NE. et al. Prospective evaluation of prognostic variables from patient-completed questionnaires. North Central Cancer Treatment Group. Journal of Clinical Oncology. 12(3):601-7, 1994."
"survival-cgd","survival","cgd","Chronic Granulotamous Disease data",203,16,6,0,5,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/cgd.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/cgd.html","cgd R Documentation   Chronic Granulotamous Disease data   Description  
Data are from a placebo controlled trial of gamma interferon in chronic granulotomous disease (CGD). Contains the data on time to serious infections observed through end of study for each patient.   Usage   cgd data(cgd)    Format   id
subject identification number   center
enrolling center   random
date of randomization   treatment
placebo or gamma interferon   sex
sex   age
age in years, at study entry   height
height in cm at study entry   weight
weight in kg at study entry   inherit
pattern of inheritance   steroids
use of steroids at study entry,1=yes   propylac
use of prophylactic antibiotics at study entry   hos.cat
a categorization of the centers into 4 groups   tstart, tstop
start and end of each time interval   status
1=the interval ends with an infection   enum
observation number within subject     Details  
The cgd0 data set is in the form found in the references, with one line per patient and no recoding of the variables. The cgd data set (this one) has been cast into (start, stop] format with one line per event, and covariates such as center recoded as factors to include meaningful labels.   Source  
Fleming and Harrington, Counting Processes and Survival Analysis, appendix D.2.   See Also  
link{cgd0}"
"survival-diabetic","survival","diabetic","Ddiabetic retinopathy",394,8,4,0,2,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/diabetic.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/diabetic.html","diabetic R Documentation   Ddiabetic retinopathy   Description  
Partial results from a trial of laser coagulation for the treatment of diabetic retinopathy.    Usage   diabetic data(diabetic, package=""survival"")    Format  
A data frame with 394 observations on the following 8 variables.    id
subject id   laser
laser type: xenon or argon   age
age at diagnosis   eye
a factor with levels of left right   trt
treatment: 0 = no treatment, 1= laser   risk
risk group of 6-12   time
time to event or last follow-up   status
status of 0= censored or 1 = visual loss     Details  
The 197 patients in this dataset were a 50% random sample of the patients with ""high-risk"" diabetic retinopathy as defined by the Diabetic Retinopathy Study (DRS). Each patient had one eye randomized to laser treatment and the other eye received no treatment. For each eye, the event of interest was the time from initiation of treatment to the time when visual acuity dropped below 5/200 two visits in a row. Thus there is a built-in lag time of approximately 6 months (visits were every 3 months). Survival times in this dataset are therefore the actual time to blindness in months, minus the minimum possible time to event (6.5 months). Censoring was caused by death, dropout, or end of the study.    References  
Huster, Brookmeyer and Self, Biometrics, 1989.   
American Journal of Ophthalmology, 1976, 81:4, pp 383-396    Examples    # juvenile diabetes is defined as and age less than 20 juvenile <- 1*(diabetic$age < 20) coxph(Surv(time, status) ~ trt + juvenile, cluster= id, data= diabetic)"
"survival-flchain","survival","flchain","Assay of serum free light chain for 7874 subjects.",7874,11,3,0,2,0,9,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/flchain.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/flchain.html","flchain R Documentation   Assay of serum free light chain for 7874 subjects.   Description  
This is a stratified random sample containing 1/2 of the subjects from a study of the relationship between serum free light chain (FLC) and mortality. The original sample contains samples on approximately 2/3 of the residents of Olmsted County aged 50 or greater.    Usage   flchain data(flchain, package=""survival"")    Format  
A data frame with 7874 persons containing the following variables.    age
age in years   sex
F=female, M=male   sample.yr
the calendar year in which a blood sample was obtained   kappa
serum free light chain, kappa portion   lambda
serum free light chain, lambda portion   flc.grp
the FLC group for the subject, as used in the original analysis   creatinine
serum creatinine   mgus
1 if the subject had been diagnosed with monoclonal gammapothy (MGUS)   futime
days from enrollment until death. Note that there are 3 subjects whose sample was obtained on their death date.   death
0=alive at last contact date, 1=dead   chapter
for those who died, a grouping of their primary cause of death by chapter headings of the International Code of Diseases ICD-9     Details  
In 1995 Dr. Robert Kyle embarked on a study to determine the prevalence of monoclonal gammopathy of undetermined significance (MGUS) in Olmsted County, Minnesota, a condition which is normally only found by chance from a test (serum electrophoresis) which is ordered for other causes. Later work suggested that one component of immunoglobulin production, the serum free light chain, might be a possible marker for immune disregulation. In 2010 Dr. Angela Dispenzieri and colleagues assayed FLC levels on those samples from the original study for which they had patient permission and from which sufficient material remained for further testing. They found that elevated FLC levels were indeed associated with higher death rates.   
Patients were recruited when they came to the clinic for other appointments, with a final random sample of those who had not yet had a visit since the study began. An interesting side question is whether there are differences between early, mid, and late recruits.   
This data set contains an age and sex stratified random sample that includes 7874 of the original 15759 subjects. The original subject identifiers and dates have been removed to protect patient identity. Subsampling was done to further protect this information.    Source  
The primary investigator (A Dispenzieri) and statistician (T Therneau) for the study.   References  
A Dispenzieri, J Katzmann, R Kyle, D Larson, T Therneau, C Colby, R Clark, G Mead, S Kumar, LJ Melton III and SV Rajkumar (2012). Use of monclonal serum immunoglobulin free light chains to predict overall survival in the general population, Mayo Clinic Proceedings 87:512-523.   
R Kyle, T Therneau, SV Rajkumar, D Larson, M Plevak, J Offord, A Dispenzieri, J Katzmann, and LJ Melton, III, 2006, Prevalence of monoclonal gammopathy of undetermined significance, New England J Medicine 354:1362-1369.    Examples    data(flchain) age.grp <- cut(flchain$age, c(49,54, 59,64, 69,74,79, 89, 110), labels= paste(c(50,55,60,65,70,75,80,90), c(54,59,64,69,74,79,89,109), sep='-')) table(flchain$sex, age.grp)"
"survival-heart","survival","heart","Stanford Heart Transplant data",172,8,3,0,1,0,7,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/heart.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/heart.html","heart R Documentation   Stanford Heart Transplant data   Description  
Survival of patients on the waiting list for the Stanford heart transplant program.   Usage   heart data(heart, package=""survival"")   Format  
jasa: original data   
 birth.dt: birth date
 accept.dt: acceptance into program
 tx.date: transplant date
 fu.date: end of followup
 fustat: dead or alive
 surgery: prior bypass surgery
 age: age (in years)
 futime: followup time
 wait.time: time before transplant
 transplant: transplant indicator
 mismatch: mismatch score
 hla.a2: particular type of mismatch
 mscore: another mismatch score
 reject: rejection occurred
   
jasa1, heart: processed data   
 start, stop, event: Entry and exit time and status for this interval of time
 age: age-48 years
 year: year of acceptance (in years after 1 Nov 1967)
 surgery: prior bypass surgery 1=yes
 transplant: received transplant 1=yes
 id: patient id
    Source  
J Crowley and M Hu (1977), Covariance analysis of heart transplant survival data.  Journal of the American Statistical Association ,  72 , 27–36.    See Also  
stanford2"
"survival-logan","survival","logan","Data from the 1972-78 GSS data used by Logan",838,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/logan.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/logan.html","logan R Documentation   Data from the 1972-78 GSS data used by Logan   Description  
Intergenerational occupational mobility data with covariates.    Usage   logan data(logan, package=""survival"")    Format  
A data frame with 838 observations on the following 4 variables.    occupation
subject's occupation, a factor with levels  farm , operatives , craftsmen , sales , and professional   focc
father's occupation   education
total years of schooling, 0 to 20   race
levels of non-black and black     Source  
General Social Survey data, see the web site for detailed information on the variables.  https://gss.norc.org/ .    References  
Logan, John A. (1983). A Multivariate Model for Mobility Tables.  American Journal of Sociology 89: 324-349."
"survival-nwtco","survival","nwtco","Data from the National Wilm's Tumor Study",4028,9,5,0,0,1,8,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/nwtco.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/nwtco.html","nwtco R Documentation   Data from the National Wilm's Tumor Study   Description  
Measurement error example. Tumor histology predicts survival, but prediction is stronger with central lab histology than with the local institution determination.    Usage   nwtco data(nwtco, package=""survival"")    Format  
A data frame with 4028 observations on the following 9 variables.    seqno
id number   instit
Histology from local institution   histol
Histology from central lab   stage
Disease stage   study
study   rel
indicator for relapse   edrel
time to relapse   age
age in months   in.subcohort
Included in the subcohort for the example in the paper     References  
NE Breslow and N Chatterjee (1999), Design and analysis of two-phase studies with binary outcome applied to Wilms tumour prognosis.  Applied Statistics 48 , 457–68.    Examples    with(nwtco, table(instit,histol)) anova(coxph(Surv(edrel,rel)~histol+instit,data=nwtco)) anova(coxph(Surv(edrel,rel)~instit+histol,data=nwtco))"
"survival-pbc","survival","pbc","Mayo Clinic Primary Biliary Cholangitis Data",418,20,5,0,1,0,19,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/pbc.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/pbc.html","pbc R Documentation   Mayo Clinic Primary Biliary Cholangitis Data   Description  
Primary sclerosing cholangitis is an autoimmune disease leading to destruction of the small bile ducts in the liver. Progression is slow but inexhortable, eventually leading to cirrhosis and liver decompensation. The condition has been recognised since at least 1851 and was named ""primary biliary cirrhosis"" in 1949. Because cirrhosis is a feature only of advanced disease, a change of its name to ""primary biliary cholangitis"" was proposed by patient advocacy groups in 2014.   
This data is from the Mayo Clinic trial in PBC conducted between 1974 and 1984. A total of 424 PBC patients, referred to Mayo Clinic during that ten-year interval, met eligibility criteria for the randomized placebo controlled trial of the drug D-penicillamine. The first 312 cases in the data set participated in the randomized trial and contain largely complete data. The additional 112 cases did not participate in the clinical trial, but consented to have basic measurements recorded and to be followed for survival. Six of those cases were lost to follow-up shortly after diagnosis, so the data here are on an additional 106 cases as well as the 312 randomized participants.   
A nearly identical data set found in appendix D of Fleming and Harrington; this version has fewer missing values.    Usage   pbc data(pbc, package=""survival"")    Format  
 age: in years
 albumin: serum albumin (g/dl)
 alk.phos: alkaline phosphotase (U/liter)
 ascites: presence of ascites
 ast: aspartate aminotransferase, once called SGOT (U/ml)
 bili: serum bilirunbin (mg/dl)
 chol: serum cholesterol (mg/dl)
 copper: urine copper (ug/day)
 edema: 0 no edema, 0.5 untreated or successfully treated
  1 edema despite diuretic therapy
 hepato: presence of hepatomegaly or enlarged liver
 id: case number
 platelet: platelet count
 protime: standardised blood clotting time
 sex: m/f
 spiders: blood vessel malformations in the skin
 stage: histologic stage of disease (needs biopsy)
 status: status at endpoint, 0/1/2 for censored, transplant, dead
 time: number of days between registration and the earlier of death,
  transplantion, or study analysis in July, 1986
 trt: 1/2/NA for D-penicillmain, placebo, not randomised
 trig: triglycerides (mg/dl)
    Source  
T Therneau and P Grambsch (2000),  Modeling Survival Data: Extending the Cox Model , Springer-Verlag, New York. ISBN: 0-387-98784-3.    See Also  
pbcseq"
"survival-retinopathy","survival","retinopathy","Diabetic Retinopathy",394,9,5,0,3,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/retinopathy.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/retinopathy.html","retinopathy R Documentation   Diabetic Retinopathy   Description  
A trial of laser coagulation as a treatment to delay diabetic retinopathy.    Usage   retinopathy data(retinopathy, package=""survival"")    Format  
A data frame with 394 observations on the following 9 variables.    id
numeric subject id   laser
type of laser used: xenon argon   eye
which eye was treated: right left   age
age at diagnosis of diabetes   type
type of diabetes: juvenile adult , (diagnosis before age 20)   trt
0 = control eye, 1 = treated eye   futime
time to loss of vision or last follow-up   status
0 = censored, 1 = loss of vision in this eye   risk
a risk score for the eye. This high risk subset is defined as a score of 6 or greater in at least one eye.     Details  
The 197 patients in this dataset were a 50% random sample of the patients with ""high-risk"" diabetic retinopathy as defined by the Diabetic Retinopathy Study (DRS). Each patient had one eye randomized to laser treatment and the other eye received no treatment, and has two observations in the data set. For each eye, the event of interest was the time from initiation of treatment to the time when visual acuity dropped below 5/200 two visits in a row. Thus there is a built-in lag time of approximately 6 months (visits were every 3 months). Survival times in this dataset are the actual time to vision loss in months, minus the minimum possible time to event (6.5 months). Censoring was caused by death, dropout, or end of the study.    References  
W. J. Huster, R. Brookmeyer and S. G. Self (1989). Modelling paired survival data with covariates, Biometrics 45:145-156.   
A. L. Blair, D. R. Hadden, J. A. Weaver, D. B. Archer, P. B. Johnston and C. J. Maguire (1976). The 5-year prognosis for vision in diabetes, American Journal of Ophthalmology, 81:383-396.    Examples    coxph(Surv(futime, status) ~ type + trt, cluster= id, retinopathy)"
"survival-rhDNase","survival","rhDNase","rhDNASE data set",767,8,1,0,0,0,6,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/rhDNase.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/rhDNase.html","rhDNase R Documentation   rhDNASE data set   Description  
Results of a randomized trial of rhDNase for the treatment of cystic fibrosis.    Usage   rhDNase data(rhDNase, package=""survival"")    Format  
A data frame with 767 observations on the following 8 variables.    id
subject id   inst
enrolling institution   trt
treatment arm: 0=placebo, 1= rhDNase   entry.dt
date of entry into the study   end.dt
date of last follow-up   fev
forced expriatory volume at enrollment, a measure of lung capacity   ivstart
days from enrollment to the start of IV antibiotics   ivstop
days from enrollment to the cessation of IV antibiotics     Details  
In patients with cystic fibrosis, extracellular DNA is released by leukocytes that accumulate in the airways in response to chronic bacterial infection. This excess DNA thickens the mucus, which then cannot be cleared from the lung by the cilia. The accumulation leads to exacerbations of respiratory symptoms and progressive deterioration of lung function. At the time of this study more than 90% of cystic fibrosis patients eventually died of lung disease.   
Deoxyribonuclease I (DNase I) is a human enzyme normally present in the mucus of human lungs that digests extracellular DNA. Genentech, Inc. cloned a highly purified recombinant DNase I (rhDNase or Pulmozyme) which when delivered to the lungs in an aerosolized form cuts extracellular DNA, reducing the viscoelasticity of airway secretions and improving clearance. In 1992 the company conducted a randomized double-blind trial comparing rhDNase to placebo. Patients were then monitored for pulmonary exacerbations, along with measures of lung volume and flow. The primary endpoint was the time until first pulmonary exacerbation; however, data on all exacerbations were collected for 169 days.   
The definition of an exacerbation was an infection that required the use of intravenous (IV) antibiotics. Subjects had 0–5 such episodes during the trial, those with more than one have multiple rows in the data set, those with none have NA for the IV start and end times. A few subjects were infected at the time of enrollment, subject 173 for instance has a first infection interval of -21 to 7. We do not count this first infection as an ""event"", and the subject first enters the risk set at day 7. Subjects who have an event are not considered to be at risk for another event during the course of antibiotics, nor for an additional 6 days after they end. (If the symptoms reappear immediately after cessation then from a medical standpoint this would not be a new infection.)   
This data set reproduces the data in Therneau and Grambsch, is does not exactly reproduce those in Therneau and Hamilton due to data set updates.    References  
T. M. Therneau and P. M. Grambsch, Modeling Survival Data: Extending the Cox Model, Springer, 2000.   
T. M. Therneau and S.A. Hamilton, rhDNase as an example of recurrent event analysis, Statistics in Medicine, 16:2029-2047, 1997.    Examples    # Build the start-stop data set for analysis, and # replicate line 2 of table 8.13 first <- subset(rhDNase, !duplicated(id)) #first row for each subject dnase <- tmerge(first, first, id=id, tstop=as.numeric(end.dt -entry.dt)) # Subjects whose fu ended during the 6 day window are the reason for # this next line temp.end <- with(rhDNase, pmin(ivstop+6, end.dt-entry.dt)) dnase <- tmerge(dnase, rhDNase, id=id, infect=event(ivstart), end= event(temp.end)) # toss out the non-at-risk intervals, and extra variables # 3 subjects had an event on their last day of fu, infect=1 and end=1 dnase <- subset(dnase, (infect==1 | end==0), c(id:trt, fev:infect)) agfit <- coxph(Surv(tstart, tstop, infect) ~ trt + fev, cluster=id, data=dnase)"
"survival-solder","survival","solder","Data from a soldering experiment",900,6,1,0,5,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/solder.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/solder.html","solder R Documentation   Data from a soldering experiment   Description  
In 1988 an experiment was designed and implemented at one of AT&T's factories to investigate alternatives in the ""wave soldering"" procedure for mounting electronic componentes to printed circuit boards. The experiment varied a number of factors relevant to the process. The response, measured by eye, is the number of visible solder skips.    Usage   solder data(solder, package=""survival"")    Format  
A data frame with 900 observations on the following 6 variables.    Opening
the amount of clearance around the mounting pad (3 levels)   Solder
the amount of solder (Thick or Thin)   Mask
type and thickness of the material used for the solder mask (A1.5, A3, A6, B3, B6)   PadType
the geometry and size of the mounting pad (10 levels)   Panel
each board was divided into 3 panels   skips
the number of skips     Details  
This data set is used as a detailed example in chapter 1 of Chambers and Hastie. Observations 1-360 and 541-900 form a balanced design of 3*2*10*3= 180 observations for four of the pad types (A1.5, A3, B3, B6), while rows 361-540 match 3 of the 6 Solder*Opening combinations with pad type A6 and the other 3 with pad type A3.    References  
J Chambers and T Hastie, Statistical models in S. Chapman and Hall, 1993.    Examples    # The balanced subset used by Chambers and Hastie # contains the first 180 of each mask and deletes mask A6. index <- 1 + (1:nrow(solder)) - match(solder$Mask, solder$Mask) solder.balance <- droplevels(subset(solder, Mask != ""A6"" & index <= 180))"
"survival-tobin","survival","tobin","Tobin's Tobit data",20,3,0,0,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/tobin.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/tobin.html","tobin R Documentation   Tobin's Tobit data   Description  
Economists fit a parametric censored data model called the ‘tobit’. These data are from Tobin's original paper.   Usage   tobin data(tobin, package=""survival"")    Format  
A data frame with 20 observations on the following 3 variables.    durable
Durable goods purchase   age
Age in years   quant
Liquidity ratio (x 1000)     Source  
J Tobin (1958), Estimation of relationships for limited dependent variables.  Econometrica 26 , 24–36.    Examples    tfit <- survreg(Surv(durable, durable>0, type='left') ~age + quant, data=tobin, dist='gaussian') predict(tfit,type=""response"")"
"survival-transplant","survival","transplant","Liver transplant waiting list",815,6,1,0,3,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/transplant.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/transplant.html","transplant R Documentation   Liver transplant waiting list   Description  
Subjects on a liver transplant waiting list from 1990-1999, and their disposition: received a transplant, died while waiting, withdrew from the list, or censored.    Usage   transplant data(transplant, package=""survival"")    Format  
A data frame with 815 (transplant) observations on the following 6 variables.    age
age at addition to the waiting list   sex
m or f   abo
blood type: A , B , AB or O   year
year in which they entered the waiting list   futime
time from entry to final disposition   event
final disposition: censored ,  death ,  ltx or withdraw     Details  
This represents the transplant experience in a particular region, over a time period in which liver transplant became much more widely recognized as a viable treatment modality. The number of liver transplants rises over the period, but the number of subjects added to the liver transplant waiting list grew much faster. Important questions addressed by the data are the change in waiting time, who waits, and whether there was an consequent increase in deaths while on the list.   
Blood type is an important consideration. Donor livers from subjects with blood type O can be used by patients with A, B, AB or 0 blood types, whereas an AB liver can only be used by an AB recipient. Thus type O subjects on the waiting list are at a disadvantage, since the pool of competitors is larger for type O donor livers.   
This data is of historical interest and provides a useful example of competing risks, but it has little relevance to current practice. Liver allocation policies have evolved and now depend directly on each individual patient's risk and need, assessments of which are regularly updated while a patient is on the waiting list. The overall organ shortage remains acute, however.   
The transplant data set was a version used early in the analysis,  transplant2 has several additions and corrections, and was the final data set and matches the paper.    References  
Kim WR, Therneau TM, Benson JT, Kremers WK, Rosen CB, Gores GJ, Dickson ER. Deaths on the liver transplant waiting list: An analysis of competing risks. Hepatology 2006 Feb; 43(2):345-51.    Examples    #since event is a factor, survfit creates competing risk curves pfit <- survfit(Surv(futime, event) ~ abo, transplant) pfit[,2] #time to liver transplant, by blood type plot(pfit[,2], mark.time=FALSE, col=1:4, lwd=2, xmax=735, xscale=30.5, xlab=""Months"", ylab=""Fraction transplanted"", xaxt = 'n') temp <- c(0, 6, 12, 18, 24) axis(1, temp*30.5, temp) legend(450, .35, levels(transplant$abo), lty=1, col=1:4, lwd=2) # competing risks for type O plot(pfit[4,], xscale=30.5, xmax=735, col=1:3, lwd=2) legend(450, .4, c(""Death"", ""Transpant"", ""Withdrawal""), col=1:3, lwd=2)"
"survival-udca","survival","udca","Data from a trial of usrodeoxycholic acid",170,15,2,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/survival/udca.csv","https://vincentarelbundock.github.io/Rdatasets/doc/survival/udca.html","udca R Documentation   Data from a trial of usrodeoxycholic acid    Description  
Data from a trial of ursodeoxycholic acid (UDCA) in patients with primary biliary cirrohosis (PBC).   Usage   udca udca2 data(udca, package=""survival"")    Format  
A data frame with 170 observations on the following 15 variables.    id
subject identifier   trt
treatment of 0=placebo, 1=UDCA   entry.dt
date of entry into the study   last.dt
date of last on-study visit   stage
stage of disease   bili
bilirubin value at entry   riskscore
the Mayo PBC risk score at entry   death.dt
date of death   tx.dt
date of liver transplant   hprogress.dt
date of histologic progression   varices.dt
appearance of esphogeal varices   ascites.dt
appearance of ascites   enceph.dt
appearance of encephalopathy   double.dt
doubling of initial bilirubin   worsen.dt
worsening of symptoms by two stages     Details  
This data set is used in the Therneau and Grambsh. The udca1  data set contains the baseline variables along with the time until the first endpoint (any of death, transplant, ..., worsening). The udca2 data set treats all of the endpoints as parallel events and has a stratum for each.    References  
T. M. Therneau and P. M. Grambsch, Modeling survival data: extending the Cox model. Springer, 2000.   
K. D. Lindor, E. R. Dickson, W. P Baldus, R.A. Jorgensen, J. Ludwig, P. A. Murtaugh, J. M. Harrison, R. H. Weisner, M. L. Anderson, S. M. Lange, G. LeSage, S. S. Rossi and A. F. Hofman. Ursodeoxycholic acid in the treatment of primary biliary cirrhosis. Gastroenterology, 106:1284-1290, 1994.    Examples    # values found in table 8.3 of the book fit1 <- coxph(Surv(futime, status) ~ trt + log(bili) + stage, cluster =id , data=udca1) fit2 <- coxph(Surv(futime, status) ~ trt + log(bili) + stage + strata(endpoint), cluster=id, data=udca2)"
"texmex-liver","texmex","liver","Liver related laboratory data",606,9,0,0,1,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/liver.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/liver.html","liver R Documentation   Liver related laboratory data   Description  
Liver related laboratory data from a randomized, blind, parallel group clinical trial with 4 doses of a drug.    Usage    data(liver)    Format  
A data frame with 606 observations on the following 9 variables.    ALP.B
Alkaline phosphatase at baseline. A numeric vector.   ALT.B
Alanine aminotransferase at baseline. A numeric vector.   AST.B
Aspartate aminotransferase at baseline. A numeric vector.   TBL.B
Total bilirubin at baseline. A numeric vector.   ALP.M
Alkaline phosphatase after treatment. A numeric vector.   ALT.M
Alanine aminotransferase after treatment. A numeric vector.   AST.M
Aspartate aminotransferase after treatment. A numeric vector.   TBL.M
Total bilirubin after treatment. A numeric vector.   dose
The treatment group (i.e. dose group). A factor with levels A B C D     Details  
Dose A is the lowest dose, dose, B the next, C the next, and D the highest dose. The baseline values were taken prior to any treatment being received, and the clinical trial had a single post-baseline visit.    Source  
AstraZeneca data on file."
"texmex-nidd","texmex","nidd","Rain, wavesurge, portpirie and nidd datasets.",154,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/nidd.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/nidd.html","rain, wavesurge and portpirie R Documentation   Rain, wavesurge, portpirie and nidd datasets.   Description  
Rainfall, wave-surge, Port Pirie and River Nidd data sets.    Format  
The format of the rain data is: num [1:17531] 0 2.3 1.3 6.9 4.6 0 1 1.5 1.8 1.8 ...   
The wave-surge data is bivariate and is used for testing functions in  texmex .   
The Port Pirie data has two columns: 'Year' and 'SeaLevel'.   
The River Nidd data represents 154 measurements of the level of the River Nidd at Hunsingore Weir (Yorkshire, UK) between 1934 and 1969. Each measurement breaches the threshold of $65 m^3/2$. Various authors have analysed this dataset, as described by Papastathopoulos and Tawn~ egp , there being some apparent difficulty in identifying a threshold above which GPD models are suitable.    Details  
The rain, wave-surge and Port Pirie datasets are used by Coles and appear in the ismev package. The River Nidd data appear in the evir  package.    Source  
Copied from the ismev package and the evir package    References  
S. Coles, An Introduction to Statistical Modeling of Extreme Values, Springer, 2001   
I. Papastathopoulos and J. A. Tawn, Extended Generalised Pareto Models for Tail Estimation, Journal of Statistical Planning and Inference, 143, 134 – 143, 2011"
"texmex-portpirie","texmex","portpirie","Rain, wavesurge, portpirie and nidd datasets.",65,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/portpirie.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/portpirie.html","rain, wavesurge and portpirie R Documentation   Rain, wavesurge, portpirie and nidd datasets.   Description  
Rainfall, wave-surge, Port Pirie and River Nidd data sets.    Format  
The format of the rain data is: num [1:17531] 0 2.3 1.3 6.9 4.6 0 1 1.5 1.8 1.8 ...   
The wave-surge data is bivariate and is used for testing functions in  texmex .   
The Port Pirie data has two columns: 'Year' and 'SeaLevel'.   
The River Nidd data represents 154 measurements of the level of the River Nidd at Hunsingore Weir (Yorkshire, UK) between 1934 and 1969. Each measurement breaches the threshold of $65 m^3/2$. Various authors have analysed this dataset, as described by Papastathopoulos and Tawn~ egp , there being some apparent difficulty in identifying a threshold above which GPD models are suitable.    Details  
The rain, wave-surge and Port Pirie datasets are used by Coles and appear in the ismev package. The River Nidd data appear in the evir  package.    Source  
Copied from the ismev package and the evir package    References  
S. Coles, An Introduction to Statistical Modeling of Extreme Values, Springer, 2001   
I. Papastathopoulos and J. A. Tawn, Extended Generalised Pareto Models for Tail Estimation, Journal of Statistical Planning and Inference, 143, 134 – 143, 2011"
"texmex-rain","texmex","rain","Rain, wavesurge, portpirie and nidd datasets.",17531,1,0,0,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/rain.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/rain.html","rain, wavesurge and portpirie R Documentation   Rain, wavesurge, portpirie and nidd datasets.   Description  
Rainfall, wave-surge, Port Pirie and River Nidd data sets.    Format  
The format of the rain data is: num [1:17531] 0 2.3 1.3 6.9 4.6 0 1 1.5 1.8 1.8 ...   
The wave-surge data is bivariate and is used for testing functions in  texmex .   
The Port Pirie data has two columns: 'Year' and 'SeaLevel'.   
The River Nidd data represents 154 measurements of the level of the River Nidd at Hunsingore Weir (Yorkshire, UK) between 1934 and 1969. Each measurement breaches the threshold of $65 m^3/2$. Various authors have analysed this dataset, as described by Papastathopoulos and Tawn~ egp , there being some apparent difficulty in identifying a threshold above which GPD models are suitable.    Details  
The rain, wave-surge and Port Pirie datasets are used by Coles and appear in the ismev package. The River Nidd data appear in the evir  package.    Source  
Copied from the ismev package and the evir package    References  
S. Coles, An Introduction to Statistical Modeling of Extreme Values, Springer, 2001   
I. Papastathopoulos and J. A. Tawn, Extended Generalised Pareto Models for Tail Estimation, Journal of Statistical Planning and Inference, 143, 134 – 143, 2011"
"texmex-summer","texmex","summer","Air pollution data, separately for summer and winter months",578,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/summer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/summer.html","summer and winter data R Documentation   Air pollution data, separately for summer and winter months   Description  
Air pollution data from Leeds (U.K.) city centre, collected from 1994 to 1998. The summer data set corresponds to the months of April to July inclusive. The winter data set corresponds to the months of November to February inclusive. Some outliers have been removed, as discussed by Heffernan and Tawn, 2004.    Format  
Data frames with 578 (summer) and 532 (winter) observations on the following 5 variables.    O3
Daily maximum ozone in parts per billion.   NO2
Daily maximum NO2 in parts per billion.   NO
Daily maximum NO in parts per billion.   SO2
Daily maximum SO2 in parts per billion.   PM10
Daily maximum PM10 in micrograms/metre^3     Source  
Provided as online supplementary material to Heffernan and Tawn, 2004:   
http://www.blackwellpublishing.com/rss/Readmefiles/heffernan.htm    References  
J. E. Heffernan and J. A. Tawn, A conditional approach for multivariate extreme values, Journal of the Royal Statistical society B, 66, 497 – 546, 2004    Examples    data(summer) data(winter)"
"texmex-wavesurge","texmex","wavesurge","Rain, wavesurge, portpirie and nidd datasets.",2894,2,0,0,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/wavesurge.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/wavesurge.html","rain, wavesurge and portpirie R Documentation   Rain, wavesurge, portpirie and nidd datasets.   Description  
Rainfall, wave-surge, Port Pirie and River Nidd data sets.    Format  
The format of the rain data is: num [1:17531] 0 2.3 1.3 6.9 4.6 0 1 1.5 1.8 1.8 ...   
The wave-surge data is bivariate and is used for testing functions in  texmex .   
The Port Pirie data has two columns: 'Year' and 'SeaLevel'.   
The River Nidd data represents 154 measurements of the level of the River Nidd at Hunsingore Weir (Yorkshire, UK) between 1934 and 1969. Each measurement breaches the threshold of $65 m^3/2$. Various authors have analysed this dataset, as described by Papastathopoulos and Tawn~ egp , there being some apparent difficulty in identifying a threshold above which GPD models are suitable.    Details  
The rain, wave-surge and Port Pirie datasets are used by Coles and appear in the ismev package. The River Nidd data appear in the evir  package.    Source  
Copied from the ismev package and the evir package    References  
S. Coles, An Introduction to Statistical Modeling of Extreme Values, Springer, 2001   
I. Papastathopoulos and J. A. Tawn, Extended Generalised Pareto Models for Tail Estimation, Journal of Statistical Planning and Inference, 143, 134 – 143, 2011"
"texmex-winter","texmex","winter","Air pollution data, separately for summer and winter months",532,5,0,0,0,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/texmex/winter.csv","https://vincentarelbundock.github.io/Rdatasets/doc/texmex/winter.html","summer and winter data R Documentation   Air pollution data, separately for summer and winter months   Description  
Air pollution data from Leeds (U.K.) city centre, collected from 1994 to 1998. The summer data set corresponds to the months of April to July inclusive. The winter data set corresponds to the months of November to February inclusive. Some outliers have been removed, as discussed by Heffernan and Tawn, 2004.    Format  
Data frames with 578 (summer) and 532 (winter) observations on the following 5 variables.    O3
Daily maximum ozone in parts per billion.   NO2
Daily maximum NO2 in parts per billion.   NO
Daily maximum NO in parts per billion.   SO2
Daily maximum SO2 in parts per billion.   PM10
Daily maximum PM10 in micrograms/metre^3     Source  
Provided as online supplementary material to Heffernan and Tawn, 2004:   
http://www.blackwellpublishing.com/rss/Readmefiles/heffernan.htm    References  
J. E. Heffernan and J. A. Tawn, A conditional approach for multivariate extreme values, Journal of the Royal Statistical society B, 66, 497 – 546, 2004    Examples    data(summer) data(winter)"
"tidyr-billboard","tidyr","billboard","Song rankings for Billboard top 100 in the year 2000",317,79,10,2,0,11,65,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/billboard.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/billboard.html","billboard R Documentation   Song rankings for Billboard top 100 in the year 2000   Description  
Song rankings for Billboard top 100 in the year 2000    Usage    billboard    Format  
A dataset with variables:    artist
Artist name   track
Song name   date.enter
Date the song entered the top 100   wk1 – wk76
Rank of the song in each week after it entered     Source  
The ""Whitburn"" project, https://waxy.org/2008/05/the_whitburn_project/ , (downloaded April 2008)"
"tidyr-construction","tidyr","construction","Completed construction in the US in 2018",9,9,0,1,0,1,7,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/construction.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/construction.html","construction R Documentation   Completed construction in the US in 2018   Description  
Completed construction in the US in 2018    Usage    construction    Format  
A dataset with variables:    Year,Month
Record date   1 unit , 2 to 4 units , 5 units or mote
Number of completed units of each size   Northeast,Midwest,South,West
Number of completed units in each region     Source  
Completions of ""New Residential Construction"" found in Table 5 at  https://www.census.gov/construction/nrc/xls/newresconst.xls  (downloaded March 2019)"
"tidyr-fish_encounters","tidyr","fish_encounters","Fish encounters",114,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/fish_encounters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/fish_encounters.html","fish_encounters R Documentation   Fish encounters   Description  
Information about fish swimming down a river: each station represents an autonomous monitor that records if a tagged fish was seen at that location. Fish travel in one direction (migrating downstream). Information about misses is just as important as hits, but is not directly recorded in this form of the data.    Usage    fish_encounters    Format  
A dataset with variables:    fish
Fish identifier   station
Measurement station   seen
Was the fish seen? (1 if yes, and true for all rows)     Source  
Dataset provided by Myfanwy Johnston; more details at  https://fishsciences.github.io/post/visualizing-fish-encounter-histories/"
"tidyr-population","tidyr","population","World Health Organization TB data",4060,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/population.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/population.html","who R Documentation   World Health Organization TB data   Description  
A subset of data from the World Health Organization Global Tuberculosis Report, and accompanying global populations.    Usage    who population    Format  
who : a data frame with 7,240 rows and the columns:    country
Country name   iso2, iso3
2 & 3 letter ISO country codes   year
Year   new_sp_m014 - new_rel_f65
Counts of new TB cases recorded by group. Column names encode three variables that describe the group (see details).    
population : a data frame with 4,060 rows and three columns:    country
Country name   year
Year   population
Population     Details  
The data uses the original codes given by the World Health Organization. The column names for columns five through 60 are made by combining new_ to a code for method of diagnosis ( rel = relapse, sn = negative pulmonary smear, sp = positive pulmonary smear, ep = extrapulmonary) to a code for gender ( f = female, m = male) to a code for age group ( 014 = 0-14 yrs of age, 1524 = 15-24 years of age, 2534 = 25 to 34 years of age, 3544 = 35 to 44 years of age, 4554 = 45 to 54 years of age, 5564 = 55 to 64 years of age, 65 = 65 years of age or older).    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-relig_income","tidyr","relig_income","Pew religion and income survey",18,11,0,1,0,0,10,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/relig_income.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/relig_income.html","relig_income R Documentation   Pew religion and income survey   Description  
Pew religion and income survey    Usage    relig_income    Format  
A dataset with variables:    religion
Name of religion   <$10k - Don\'t know/refused
Number of respondees with income range in column name     Source  
Downloaded from https://www.pewforum.org/religious-landscape-study/  (downloaded November 2009)"
"tidyr-smiths","tidyr","smiths","Some data about the Smith family",2,5,2,1,0,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/smiths.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/smiths.html","smiths R Documentation   Some data about the Smith family   Description  
A small demo dataset describing John and Mary Smith.    Usage    smiths    Format  
A data frame with 2 rows and 5 columns."
"tidyr-table1","tidyr","table1","Example tabular representations",6,4,1,1,0,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table1.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table1.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-table2","tidyr","table2","Example tabular representations",12,4,2,2,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table2.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table2.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-table3","tidyr","table3","Example tabular representations",6,3,1,2,0,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table3.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table3.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-table4a","tidyr","table4a","Example tabular representations",3,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table4a.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table4a.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-table4b","tidyr","table4b","Example tabular representations",3,3,0,1,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table4b.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table4b.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-table5","tidyr","table5","Example tabular representations",6,4,2,4,0,0,0,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/table5.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/table5.html","table1 R Documentation   Example tabular representations   Description  
Data sets that demonstrate multiple ways to layout the same tabular data.    Usage    table1 table2 table3 table4a table4b table5    Details  
table1 , table2 , table3 , table4a , table4b , and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The data contains values associated with four variables (country, year, cases, and population), but each table organizes the values in a different layout.   
The data is a subset of the data contained in the World Health Organization Global Tuberculosis Report    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-us_rent_income","tidyr","us_rent_income","US rent and income data",104,5,1,3,0,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/us_rent_income.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/us_rent_income.html","us_rent_income R Documentation   US rent and income data   Description  
Captured from the 2017 American Community Survey using the tidycensus package.    Usage    us_rent_income    Format  
A dataset with variables:    GEOID
FIP state identifier   NAME
Name of state   variable
Variable name: income = median yearly income, rent = median monthly rent   estimate
Estimated value   moe
90% margin of error"
"tidyr-who","tidyr","who","World Health Organization TB data",7240,60,0,3,0,0,57,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/who.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/who.html","who R Documentation   World Health Organization TB data   Description  
A subset of data from the World Health Organization Global Tuberculosis Report, and accompanying global populations.    Usage    who population    Format  
who : a data frame with 7,240 rows and the columns:    country
Country name   iso2, iso3
2 & 3 letter ISO country codes   year
Year   new_sp_m014 - new_rel_f65
Counts of new TB cases recorded by group. Column names encode three variables that describe the group (see details).    
population : a data frame with 4,060 rows and three columns:    country
Country name   year
Year   population
Population     Details  
The data uses the original codes given by the World Health Organization. The column names for columns five through 60 are made by combining new_ to a code for method of diagnosis ( rel = relapse, sn = negative pulmonary smear, sp = positive pulmonary smear, ep = extrapulmonary) to a code for gender ( f = female, m = male) to a code for age group ( 014 = 0-14 yrs of age, 1524 = 15-24 years of age, 2534 = 25 to 34 years of age, 3544 = 35 to 44 years of age, 4554 = 45 to 54 years of age, 5564 = 55 to 64 years of age, 65 = 65 years of age or older).    Source  
https://www.who.int/teams/global-tuberculosis-programme/data"
"tidyr-world_bank_pop","tidyr","world_bank_pop","Population data from the world bank",1056,20,0,2,0,0,18,"https://vincentarelbundock.github.io/Rdatasets/csv/tidyr/world_bank_pop.csv","https://vincentarelbundock.github.io/Rdatasets/doc/tidyr/world_bank_pop.html","world_bank_pop R Documentation   Population data from the world bank   Description  
Data about population from the World Bank.    Usage    world_bank_pop    Format  
A dataset with variables:    country
Three letter country code   indicator
Indicator name: SP.POP.GROW = population growth,  SP.POP.TOTL = total population, SP.URB.GROW = urban population growth, SP.URB.TOTL = total urban population   2000-2018
Value for each year     Source  
Dataset from the World Bank data bank: https://data.worldbank.org"
"vcd-Arthritis","vcd","Arthritis","Arthritis Treatment Data",84,5,2,0,3,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Arthritis.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Arthritis.html","Arthritis R Documentation   Arthritis Treatment Data   Description  
Data from Koch \& Edwards (1988) from a double-blind clinical trial investigating a new treatment for rheumatoid arthritis.    Usage   data(""Arthritis"")   Format  
A data frame with 84 observations and 5 variables.    ID
patient ID.   Treatment
factor indicating treatment (Placebo, Treated).   Sex
factor indicating sex (Female, Male).   Age
age of patient.   Improved
ordered factor indicating treatment outcome (None, Some, Marked).     Source  
Michael Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/arthrit.sas     References  
G. Koch \& S. Edwards (1988), Clinical efficiency trials with categorical data. In K. E. Peace (ed.), Biopharmaceutical Statistics for Drug Development , 403–451. Marcel Dekker, New York.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Arthritis"") art <- xtabs(~ Treatment + Improved, data = Arthritis, subset = Sex == ""Female"") art mosaic(art, gp = shading_Friendly) mosaic(art, gp = shading_max)"
"vcd-Baseball","vcd","Baseball","Baseball Data",322,25,3,2,6,0,17,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Baseball.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Baseball.html","Baseball R Documentation   Baseball Data   Description  
Baseball data.    Usage    data(""Baseball"")    Format  
A data frame with 322 observations and 25 variables.    name1
player's first name.   name2
player's last name.   atbat86
times at Bat: number of official plate appearances by a hitter. It counts as an official at-bat as long as the batter does not walk, sacrifice, get hit by a pitch or reach base due to catcher's interference.   hits86
hits.   homer86
home runs.   runs86
the number of runs scored by a player. A run is scored by an offensive player who advances from batter to runner and touches first, second, third and home base in that order without being put out.   rbi86
Runs Batted In: A hitter earns a run batted in when he drives in a run via a hit, walk, sacrifice (bunt or fly) fielder's choice, hit-batsman or on an error (when the official scorer rules that the run would have scored anyway).   walks86
A “walk” (or “base on balls”) is an award of first base granted to a batter who receives four pitches outside the strike zone.   years
Years in the Major Leagues. Seems to count all years a player has actually played in the Major Leagues, not necessarily consecutive.   atbat
career times at bat.   hits
career hits.   homeruns
career home runs.   runs
career runs.   rbi
career runs batted in.   walks
career walks.   league86
player's league.   div86
player's division.   team86
player's team.   posit86
player's position (see Hitters ).   outs86
number of putouts (see Hitters )   assist86
number of assists (see Hitters )   error86
number of assists (see Hitters )   sal87
annual salary on opening day (in USD 1000).   league87
league in 1987.   team87
team in 1987.     Source  
SAS System for Statistical Graphics, First Edition, page A2.3    References  
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    See Also  
Hitters   Examples    data(""Baseball"")"
"vcd-BrokenMarriage","vcd","BrokenMarriage","Broken Marriage Data",20,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/BrokenMarriage.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/BrokenMarriage.html","BrokenMarriage R Documentation   Broken Marriage Data   Description  
Data from the Danish Welfare Study about broken marriages or permanent relationships depending on gender and social rank.    Usage    data(""BrokenMarriage"")    Format  
A data frame with 20 observations and 4 variables.    Freq
frequency.   gender
factor indicating gender (male, female).   rank
factor indicating social rank (I, II, III, IV, V).   broken
factor indicating whether the marriage or permanent relationship was broken (yes, no).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, page 177.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    data(""BrokenMarriage"") structable(~ ., data = BrokenMarriage)"
"vcd-Bundesliga","vcd","Bundesliga","Ergebnisse der Fussball-Bundesliga",14018,7,0,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Bundesliga.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Bundesliga.html","Bundesliga R Documentation   Ergebnisse der Fussball-Bundesliga   Description  
Results from the first German soccer league (1963-2008).    Usage    data(""Bundesliga"")    Format  
A data frame with 14018 observations and 7 variables.    HomeTeam
factor. Name of the home team.   AwayTeam
factor. Name of the away team.   HomeGoals
number of goals scored by the home team.   AwayGoals
number of goals scored by the away team.   Round
round of the game.   Year
year in which the season started.   Date
starting time of the game (in ""POSIXct"" format).     Details  
The data comprises all games in the first German soccer league since its foundation in 1963. The data have been queried online from the official Web page of the DFB and prepared as a data frame in R by Daniel Dekic, Torsten Hothorn, and Achim Zeileis (replacing earlier versions of the data in the package containing only subsets of years).   
Each year/season comprises 34 rounds (except 1963, 1964, 1991) so that all 18 teams play twice against each other (switching home court advantage). In 1963/64, there were only 16 teams, hence only 30 rounds. In 1991, after the German unification, there was one season with 20 teams and 38 rounds.    Source  
Homepage of the Deutscher Fussball-Bund (DFB, German Football Association):  https://www.dfb.de/index/     References  
Leonhard Knorr-Held (1999), Dynamic rating of sports teams. SFB 386 “Statistical Analysis of Discrete Structures”, Discussion paper 98 .    See Also  
UKSoccer     Examples    data(""Bundesliga"") ## number of goals per game poisson distributed? ngoals1 <- xtabs(~ HomeGoals, data = Bundesliga, subset = Year == 1995) ngoals2 <- xtabs(~ AwayGoals, data = Bundesliga, subset = Year == 1995) ngoals3 <- table(apply(subset(Bundesliga, Year == 1995)[,3:4], 1, sum)) gf1 <- goodfit(ngoals1) gf2 <- goodfit(ngoals2) gf3 <- goodfit(ngoals3) summary(gf1) summary(gf2) summary(gf3) plot(gf1) plot(gf2) plot(gf3) Ord_plot(ngoals1) distplot(ngoals1)"
"vcd-Bundestag2005","vcd","Bundestag2005","Votes in German Bundestag Election 2005",80,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Bundestag2005.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Bundestag2005.html","Bundestag2005 R Documentation   Votes in German Bundestag Election 2005   Description  
Number of votes by province in the German Bundestag election 2005 (for the parties that eventually entered the parliament).    Usage    data(""Bundestag2005"")    Format  
A 2-way ""table"" giving the number of votes for each party ( Fraktion ) in each of the 16 German provinces ( Bundesland ):   
 No Name Levels
 1 Bundesland Schleswig-Holstein, Mecklenburg-Vorpommern, ...
 2 Fraktion SPD, CDU/CSU, Gruene, FDP, Linke    Details  
In the election for the German parliament “Bundestag”, five parties obtained enough votes to enter the parliament: the social democrats SPD, the conservative CDU/CSU, the liberal FDP, the green party “Die Gruenen” and the leftist party “Die Linke”. The table Bundestag2005 gives the number of votes for each party ( Fraktion ) in each of the 16 German provinces ( Bundesland ). The provinces are ordered from North to South.   
The data have been obtained from the German statistical office (Statistisches Bundesamt) from the Web page given below.   
Note that the number of seats in the parliament cannot be computed from the number of votes alone. The examples below show the distribution of seats that resulted from the election.    Source  
Der Bundeswahlleiter, Statistisches Bundesamt. https://www.bundeswahlleiter.de/bundestagswahlen/2005.html     Examples    library(colorspace) ## The outcome of the election in terms of seats in the ## parliament was: seats <- structure(c(226, 61, 54, 51, 222), .Names = c(""CDU/CSU"", ""FDP"", ""Linke"", ""Gruene"", ""SPD"")) ## Hues are chosen as metaphors for the political parties ## CDU/CSU: blue, FDP: yellow, Linke: purple, Gruene: green, SPD: red ## using the respective hues from a color wheel with ## chroma = 60 and luminance = 75 parties <- rainbow_hcl(6, c = 60, l = 75)[c(5, 2, 6, 3, 1)] names(parties) <- names(seats) parties ## The pie chart shows that neither the SPD+Gruene coalition nor ## the opposition of CDU/CSU+FDP could assemble a majority. ## No party would enter a coalition with the leftists, leading to a ## big coalition. pie(seats, clockwise = TRUE, col = parties) ## The regional distribution of the votes, stratified by province, ## is shown in a mosaic display: first for the 10 Western then the ## 6 Eastern provinces. data(""Bundestag2005"") votes <- Bundestag2005[c(1, 3:5, 9, 11, 13:16, 2, 6:8, 10, 12), c(""CDU/CSU"", ""FDP"", ""SPD"", ""Gruene"", ""Linke"")] mosaic(votes, gp = gpar(fill = parties[colnames(votes)]), spacing = spacing_highlighting, labeling = labeling_left, labeling_args = list(rot_labels = c(0, 90, 0, 0), pos_labels = ""center"", just_labels = c(""center"",""center"",""center"",""right""), varnames = FALSE), margins = unit(c(2.5, 1, 1, 12), ""lines""), keep_aspect_ratio = FALSE)"
"vcd-Butterfly","vcd","Butterfly","Butterfly Species in Malaya",24,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Butterfly.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Butterfly.html","Butterfly R Documentation   Butterfly Species in Malaya   Description  
Data from Fisher et al. (1943) giving the number of tokens found for each of 501 species of butterflies collected in Malaya.    Usage    data(""Butterfly"")    Format  
A 1-way table giving the number of tokens for 501 species of butterflies. The variable and its levels are   
 No Name Levels
 1 nTokens 0, 1, ..., 24
    Source  
Michael Friendly (2000), Visualizing Categorical Data, pages 21–22.    References  
R. A. Fisher, A. S. Corbet, C. B. Williams (1943), The relation between the number of species and the number of individuals,  Journal of Animal Ecology , 12 , 42–58.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Butterfly"") Ord_plot(Butterfly)"
"vcd-CoalMiners","vcd","CoalMiners","Breathlessness and Wheeze in Coal Miners",36,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/CoalMiners.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/CoalMiners.html","CoalMiners R Documentation   Breathlessness and Wheeze in Coal Miners   Description  
Data from Ashford & Sowden (1970) given by Agresti (1990) on the association between two pulmonary conditions, breathlessness and wheeze, in a large sample of coal miners who were smokers with no radiological evidence of pneumoconlosis, aged between 20–64 when examined. This data is frequently used as an example of fitting models for bivariate, binary responses.    Usage    data(""CoalMiners"")    Format  
A 3-dimensional table of size 2 x 2 x 9 resulting from cross-tabulating variables for 18,282 coal miners. The variables and their levels are as follows:   
 No Name Levels
 1 Breathlessness B, NoB
 2 Wheeze W, NoW
 3 Age 20-24, 25-29, 30-34, ..., 60-64    Details  
In an earlier version of this data set, the first group, aged 20-24, was inadvertently omitted from this data table and the breathlessness variable was called wheeze and vice versa.    Source  
Michael Friendly (2000), Visualizing Categorical Data, pages 82–83, 319–322.    References  
A. Agresti (1990),  Categorical Data Analysis . Wiley-Interscience, New York, Table 7.11, p. 237   
J. R. Ashford and R. D. Sowdon (1970), Multivariate probit analysis,  Biometrics , 26 , 535–546.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""CoalMiners"") ftable(CoalMiners, row.vars = 3) ## Fourfold display, both margins equated fourfold(CoalMiners[,,2:9], mfcol = c(2,4)) ## Fourfold display, strata equated fourfold(CoalMiners[,,2:9], std = ""ind.max"", mfcol = c(2,4)) ## Log Odds Ratio Plot lor_CM <- loddsratio(CoalMiners) summary(lor_CM) plot(lor_CM) lor_CM_df <- as.data.frame(lor_CM) # fit linear models using WLS age <- seq(20, 60, by = 5) lmod <- lm(LOR ~ age, weights = 1 / ASE^2, data = lor_CM_df) grid.lines(age, fitted(lmod), gp = gpar(col = ""blue"")) qmod <- lm(LOR ~ poly(age, 2), weights = 1 / ASE^2, data = lor_CM_df) grid.lines(age, fitted(qmod), gp = gpar(col = ""red""))"
"vcd-DanishWelfare","vcd","DanishWelfare","Danish Welfare Study Data",180,5,0,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/DanishWelfare.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/DanishWelfare.html","DanishWelfare R Documentation   Danish Welfare Study Data   Description  
Data from the Danish Welfare Study.    Usage   data(""DanishWelfare"")   Format  
A data frame with 180 observations and 5 variables.    Freq
frequency.   Alcohol
factor indicating daily alcohol consumption: less than 1 unit (<1), 1-2 units (1-2) or more than 2 units (>2). 1 unit is approximately 1 bottle of beer or 4cl 40% alcohol.   Income
factor indicating income group in 1000 DKK (0-50, 50-100, 100-150, >150).   Status
factor indicating marriage status (Widow, Married, Unmarried).   Urban
factor indicating urbanization: Copenhagen (Copenhagen), Suburbian Copenhagen (SubCopenhagen), three largest cities (LargeCity), other cities (City), countryside (Country).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, page 205.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    data(""DanishWelfare"") ftable(xtabs(Freq ~ ., data = DanishWelfare))"
"vcd-Employment","vcd","Employment","Employment Status",24,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Employment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Employment.html","Employment R Documentation   Employment Status   Description  
Data from a 1974 Danish study given by Andersen (1991) on the employees who had been laid off. The workers are classified by their employment status on 1975-01-01, the cause of their layoff and the length of employment before they were laid off.    Usage    data(""Employment"")    Format  
A 3-dimensional array resulting from cross-tabulating variables for 1314 employees. The variables and their levels are as follows:   
 No Name Levels
 1 EmploymentStatus NewJob, Unemployed
 2 EmploymentLength <1Mo, 1-3Mo, 3-12Mo, 1-2Yr, 2-5Yr, >5Yr
 3 LayoffCause Closure, Replaced    Source  
Michael Friendly (2000), Visualizing Categorical Data, pages 126–129.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . Springer-Verlag, Berlin.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Employment"") ## Employment Status mosaic(Employment, expected = ~ LayoffCause * EmploymentLength + EmploymentStatus, main = ""Layoff*EmployLength + EmployStatus"") mosaic(Employment, expected = ~ LayoffCause * EmploymentLength + LayoffCause * EmploymentStatus, main = ""Layoff*EmployLength + Layoff*EmployStatus"") ## Stratified view grid.newpage() pushViewport(viewport(layout = grid.layout(ncol = 2))) pushViewport(viewport(layout.pos.col = 1)) ## Closure mosaic(Employment[,,1], main = ""Layoff: Closure"", newpage = FALSE) popViewport(1) pushViewport(viewport(layout.pos.col = 2)) ## Replaced mosaic(Employment[,,2], main = ""Layoff: Replaced"", newpage = FALSE) popViewport(2)"
"vcd-Federalist","vcd","Federalist","'May' in Federalist Papers",7,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Federalist.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Federalist.html","Federalist R Documentation   ‘May’ in Federalist Papers   Description  
Data from Mosteller & Wallace (1984) investigating the use of certain keywords (‘may’ in this data set) to identify the author of 12 disputed ‘Federalist Papers’ by Alexander Hamilton, John Jay and James Madison.    Usage    data(""Federalist"")    Format  
A 1-way table giving the number of occurrences of ‘may’ in 262 blocks of text. The variable and its levels are   
 No Name Levels
 1 nMay 0, 1, ..., 6
    Source  
Michael Friendly (2000), Visualizing Categorical Data, page 19.    References  
F. Mosteller & D. L. Wallace (1984),  Applied Bayesian and Classical Inference: The Case of the Federalist Papers . Springer-Verlag, New York, NY.  
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Federalist"") gf <- goodfit(Federalist, type = ""nbinomial"") summary(gf) plot(gf)"
"vcd-Hitters","vcd","Hitters","Hitters Data",154,4,0,0,1,0,3,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Hitters.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Hitters.html","Hitters R Documentation   Hitters Data   Description  
This data set is deduced from the Baseball fielding data set: fielding performance basically includes the numbers of Errors, Putouts and Assists made by each player. In order to reduce the number of observations, the was compressed by calculating the mean number of errors, putouts and assists for each team and for only 6 positions (1B, 2B, 3B, C, OF, SS and UT). In addition, each of these three variables was scaled to a common range by dividing each variable by the maximum of the variable.    Usage   data(""Hitters"")   Format  
A data frame with 154 observations and 4 variables.    Positions
factor indicating the field position (1B=first baseman, 2B=second baseman, 3B=third baseman, C=catcher, OF=outfielder, SS=Short Stop, UT=Utility Players).   Putouts
occur when a fielder causes an opposing player to be tagged or forced out.   Assists
are credited to other fielders involved in making that putout.   Errors
count the errors made by a player.     Source  
SAS System for Statistical Graphics, First Edition, Page A2.3    References  
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Hitters"") attach(Hitters) colors <- c(""black"",""red"",""green"",""blue"",""red"",""black"",""blue"") pch <- substr(levels(Positions), 1, 1) ternaryplot(Hitters[,2:4], pch = as.character(Positions), col = colors[as.numeric(Positions)], main = ""Baseball Hitters Data"") grid_legend(0.8, 0.9, pch, colors, levels(Positions), title = ""POSITION(S)"") detach(Hitters)"
"vcd-HorseKicks","vcd","HorseKicks","Death by Horse Kicks",5,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/HorseKicks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/HorseKicks.html","HorseKicks R Documentation   Death by Horse Kicks   Description  
Data from von Bortkiewicz (1898), given by Andrews \& Herzberg (1985), on number of deaths by horse or mule kicks in 10 (of 14 reported) corps of the Prussian army. 4 corps were not considered by Fisher (1925) as they had a different organization. This data set is a popular subset of the VonBort data.    Usage    data(""HorseKicks"")    Format  
A 1-way table giving the number of deaths in 200 corps-years. The variable and its levels are   
 No Name Levels
 1 nDeaths 0, 1, ..., 4
    Source  
Michael Friendly (2000), Visualizing Categorical Data, page 18.    References  
D. F. Andrews & A. M. Herzberg (1985),  Data: A Collection of Problems from Many Fields for the Student and Research Worker . Springer-Verlag, New York, NY.   
R. A. Fisher (1925),  Statistical Methods for Research Workers . Oliver \& Boyd, London.   
L. von Bortkiewicz (1898),  Das Gesetz der kleinen Zahlen . Teubner, Leipzig.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    See Also  
VonBort     Examples    data(""HorseKicks"") gf <- goodfit(HorseKicks) summary(gf) plot(gf)"
"vcd-Hospital","vcd","Hospital","Hospital data",9,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Hospital.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Hospital.html","Hospital R Documentation   Hospital data   Description  
The table relates the length of stay (in years) of 132 long-term schizophrenic patients in two London mental hospitals with the frequency of visits.    Usage    data(""Hospital"")    Format  
A 2-dimensional array resulting from cross-tabulating 132 patients. The variables and their levels are as follows:   
 No Name Levels
 1 Visit Frequency Regular, Less than monthly, Never
 2 Length of Stay 2--9 years, 10--19 years, 20+ years    Details  
Wing (1962) who collected this data concludes that the longer the length of stay in hospital, the less frequent the visits.   
Haberman (1974) notes that this pattern does not increase from the ""Less than monthly"" to the ""Never"" group, which are homogeneous.    Source  
S.J Haberman (1974): Log-linear models for frequency tables with ordered classifications. Biometrics, 30:689–700.    References  
J.K. Wing (1962): Institutionalism in mental hospitals. British Journal of Social Clinical Psychology, 1:38–51.    Examples    data(""Hospital"") mosaic(t(Hospital), shade = TRUE) mosaic(Hospital, shade = TRUE) sieve(Hospital, shade = TRUE) assoc(Hospital, shade = TRUE)"
"vcd-JobSatisfaction","vcd","JobSatisfaction","Job Satisfaction Data",8,4,3,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/JobSatisfaction.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/JobSatisfaction.html","JobSatisfaction R Documentation   Job Satisfaction Data   Description  
Data from Petersen (1968) about the job satisfaction of 715 blue collar workers, selected from Danish Industry in 1968.    Usage    data(""JobSatisfaction"")    Format  
A data frame with 8 observations and 4 variables.    Freq
frequency.   management
factor indicating quality of management (bad, good).   supervisor
factor indicating supervisor's job satisfaction (low, high).   own
factor indicating worker's own job satisfaction (low, high).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, Table 5.4.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.   
E. Petersen (1968),  Job Satisfaction in Denmark . (In Danish). Mentalhygiejnisk Forlag, Copenhagen.    Examples    data(""JobSatisfaction"") structable(~ ., data = JobSatisfaction) mantelhaen.test(xtabs(Freq ~ own + supervisor + management, data = JobSatisfaction))"
"vcd-JointSports","vcd","JointSports","Opinions About Joint Sports",40,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/JointSports.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/JointSports.html","JointSports R Documentation   Opinions About Joint Sports   Description  
Data from a Danish study in 1983 and 1985 about sports activities and the opinion about joint sports with the other gender among 16–19 year old high school students.    Usage    data(""JointSports"")    Format  
A data frame with 40 observations and 5 variables.    Freq
frequency.   opinion
factor indicating opinion about sports joint with the other gender (very good, good, indifferent, bad, very bad).   year
factor indicating year of study (1983, 1985).   grade
factor indicating school grade (1st, 3rd).   gender
factor indicating gender (Boy, Girl).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, page 210.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    library(MASS) data(""JointSports"") tab <- xtabs(Freq ~ gender + opinion + grade + year, data = JointSports) doubledecker(opinion ~ gender + year + grade, data = tab) loglm(~ opinion* (gender + grade+ year) + gender*year*grade, data = tab)"
"vcd-Lifeboats","vcd","Lifeboats","Lifeboats on the Titanic",18,8,1,0,2,0,5,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Lifeboats.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Lifeboats.html","Lifeboats R Documentation   Lifeboats on the Titanic   Description  
Data from Mersey (1912) about the 18 (out of 20) lifeboats launched before the sinking of the S. S. Titanic.    Usage   data(""Lifeboats"")   Format  
A data frame with 18 observations and 8 variables.    launch
launch time in ""POSIXt"" format.   side
factor. Side of the boat.   boat
factor indicating the boat.   crew
number of male crew members on board.   men
number of men on board.   women
number of women (including female crew) on board.   total
total number of passengers.   cap
capacity of the boat.     Source  
M. Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/lifeboat.sas     References  
L. Mersey (1912), Report on the loss of the “Titanic” (S. S.). Parliamentary command paper 6452.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Lifeboats"") attach(Lifeboats) ternaryplot( Lifeboats[,4:6], pch = ifelse(side == ""Port"", 1, 19), col = ifelse(side == ""Port"", ""red"", ""blue""), id = ifelse(men / total > 0.1, as.character(boat), NA), prop_size = 2, dimnames_position = ""edge"", main = ""Lifeboats on the Titanic"" ) grid_legend(0.8, 0.9, c(1, 19), c(""red"", ""blue""), c(""Port"", ""Starboard""), title = ""SIDE"") detach(Lifeboats)"
"vcd-MSPatients","vcd","MSPatients","Diagnosis of Multiple Sclerosis",4,8,0,0,0,0,8,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/MSPatients.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/MSPatients.html","MSPatients R Documentation   Diagnosis of Multiple Sclerosis   Description  
Data from Westlund \& Kurland (1953) on the diagnosis of multiple sclerosis (MS): two samples of patients, one from Winnipeg and one from New Orleans, were each rated by two neurologists (one from each city) in four diagnostic categories.    Usage    data(""MSPatients"")    Format  
A 3-dimensional array resulting from cross-tabulating 218 observations on 3 variables. The variables and their levels are as follows:   
 No Name Levels
 1 New Orleans Neurologist Certain, Probable, Possible, Doubtful
 2 Winnipeg Neurologist Certain, Probable, Possible, Doubtful
 3 Patients Winnipeg, New Orleans    Source  
M. Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/msdiag.sas     References  
K. B. Westlund \& L. T. Kurland (1953), Studies on multiple sclerosis in Winnipeg, Manitoba and New Orleans, Louisiana,  American Journal of Hygiene , 57 , 380–396.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""MSPatients"") ## Not run: ## best visualized using a resized device, e.g. using: ## get(getOption(""device""))(width = 12) pushViewport(viewport(layout = grid.layout(ncol = 2))) pushViewport(viewport(layout.pos.col = 1)) popViewport() pushViewport(viewport(layout.pos.col = 2)) popViewport(2) dev.off() ## End(Not run) ## alternative, more convenient way mplot( agreementplot(t(MSPatients[,,1]), return_grob = TRUE, main = ""Winnipeg Patients""), agreementplot(t(MSPatients[,,2]), return_grob = TRUE, main = ""New Orleans Patients"") ) ## alternatively, use cotabplot: cotabplot(MSPatients, panel = cotab_agreementplot)"
"vcd-NonResponse","vcd","NonResponse","Non-Response Survey Data",12,4,2,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/NonResponse.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/NonResponse.html","NonResponse R Documentation   Non-Response Survey Data   Description  
Data about non-response for a Danish survey in 1965.    Usage    data(""NonResponse"")    Format  
A data frame with 12 observations and 4 variables.    Freq
frequency.   residence
factor indicating whether residence was in Copenhagen, in a city outside Copenhagen or at the countryside (Copenhagen, City, Country).   response
factor indicating whether a response was given (yes, no).   gender
factor indicating gender (male, female).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, Table 5.17.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    data(""NonResponse"") structable(~ ., data = NonResponse)"
"vcd-OvaryCancer","vcd","OvaryCancer","Ovary Cancer Data",16,5,4,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/OvaryCancer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/OvaryCancer.html","OvaryCancer R Documentation   Ovary Cancer Data   Description  
Data from Obel (1975) about a retrospective study of ovary cancer carried out in 1973. Information was obtained from 299 women, who were operated for ovary cancer 10 years before.    Usage    data(""OvaryCancer"")    Format  
A data frame with 16 observations and 5 variables.    Freq
frequency.   stage
factor indicating the stage of the cancer at the time of operation (early, advanced).   operation
factor indicating type of operation (radical, limited).   survival
factor indicating survival status after 10 years (yes, no).   xray
factor indicating whether X-ray treatment was received (yes, no).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, Table 6.4.    References  
E. B. Obel (1975), A Comparative Study of Patients with Cancer of the Ovary Who Have Survived More or Less Than 10 Years.  Acta Obstetricia et Gynecologica Scandinavica , 55 , 429-439.   
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    data(""OvaryCancer"") tab <- xtabs(Freq ~ xray + survival + stage + operation, data = OvaryCancer) ftable(tab, col.vars = ""survival"", row.vars = c(""stage"", ""operation"", ""xray"")) ## model: ~ xray * operation * stage + survival * stage ## interpretation: treat xray, operation, stage as fixed margins, ## the survival depends on stage, but not xray and operation. doubledecker(survival ~ stage + operation + xray, data = tab) mosaic(~ stage + operation + xray + survival, split = c(FALSE, TRUE, TRUE, FALSE), data = tab, keep = FALSE, gp = gpar(fill = rev(grey.colors(2)))) mosaic(~ stage + operation + xray + survival, split = c(FALSE, TRUE, TRUE, FALSE), data = tab, keep = FALSE, expected = ~ xray * operation * stage + survival*stage)"
"vcd-PreSex","vcd","PreSex","Pre-marital Sex and Divorce",16,5,4,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/PreSex.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/PreSex.html","PreSex R Documentation   Pre-marital Sex and Divorce   Description  
Data from Thornes \& Collard (1979), reported in Gilbert (1981), on pre- and extra-marital sex and divorce.    Usage    data(""PreSex"")    Format  
A 4-dimensional array resulting from cross-tabulating 1036 observations on 4 variables. The variables and their levels are as follows:   
 No Name Levels
 1 MaritalStatus Divorced, Married
 2 ExtramaritalSex Yes, No
 3 PremaritalSex Yes, No
 4 Gender Women, Men    Source  
Michael Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/marital.sas     References  
G. N. Gilbert (1981),  Modelling Society: An Introduction to Loglinear Analysis for Social Researchers . Allen and Unwin, London.   
B. Thornes \& J. Collard (1979),  Who Divorces? . Routledge \& Kegan, London.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""PreSex"") ## Mosaic display for Gender and Premarital Sexual Experience ## (Gender Pre) mosaic(margin.table(PreSex, c(3,4)), main = ""Gender and Premarital Sex"") ## (Gender Pre)(Extra) mosaic(margin.table(PreSex, c(2,3,4)), expected = ~Gender * PremaritalSex + ExtramaritalSex , main = ""PreMaritalSex*Gender +Sex"") ## (Gender Pre Extra)(Marital) mosaic(PreSex, expected = ~Gender*PremaritalSex*ExtramaritalSex + MaritalStatus, main = ""PreMarital*ExtraMarital + MaritalStatus"") ## (GPE)(PEM) mosaic(PreSex, expected = ~ Gender * PremaritalSex * ExtramaritalSex + MaritalStatus * PremaritalSex * ExtramaritalSex, main = ""G*P*E + P*E*M"")"
"vcd-Punishment","vcd","Punishment","Corporal Punishment Data",36,5,2,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Punishment.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Punishment.html","Punishment R Documentation   Corporal Punishment Data   Description  
Data from a study of the Gallup Institute in Denmark in 1979 about the attitude of a random sample of 1,456 persons towards corporal punishment of children.    Usage    data(""Punishment"")    Format  
A data frame with 36 observations and 5 variables.    Freq
frequency.   attitude
factor indicating attitude: (no, moderate) punishment of children.   memory
factor indicating whether the person had memories of corporal punishment as a child (yes, no).   education
factor indicating highest level of education (elementary, secondary, high).   age
factor indicating age group in years (15-24, 25-39, 40-).     Note  
Anderson (1991) erroneously indicates the total sum of respondents to be 783.   Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, pages 207–208.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    data(""Punishment"", package = ""vcd"") pun <- xtabs(Freq ~ memory + attitude + age + education, data = Punishment) ## model: ~ (memory + attitude) * age * education ## use maximum sum-of-squares test/shading cotabplot(~ memory + attitude | age + education, data = pun, panel = cotab_coindep, n = 5000, type = ""assoc"", test = ""maxchisq"", interpolate = 1:2)"
"vcd-RepVict","vcd","RepVict","Repeat Victimization Data",64,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/RepVict.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/RepVict.html","RepVict R Documentation   Repeat Victimization Data   Description  
Data from Reiss (1980) given by Fienberg (1980) about instances of repeat victimization for households in the U.S. National Crime Survey.    Usage    data(""RepVict"")    Format  
A 2-dimensional array resulting from cross-tabulating victimization. The variables and their levels are as follows:   
 No Name Levels
 1 First Victimization Rape, Assault, Robbery, Pickpocket, Personal Larceny,
  Burglary, Household Larceny, Auto Theft
 2 Second Victimization Rape, Assault, Robbery, Pickpocket, Personal Larceny,
  Burglary, Household Larceny, Auto Theft    Source  
Michael Friendly (2000), Visualizing Categorical Data, page 113.    References  
S. E. Fienberg (1980),  The Analysis of Cross-Classified Categorical Data , MIT Press, Cambridge, 2nd edition.   
A. J. J. Reiss (1980), Victim proneness by type of crime in repeat victimization. In S. E. Fienberg & A. J. J. Reiss (eds.),  Indicators of Crime and Criminal Justice . U.S. Government Printing Office, Washington, DC.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""RepVict"") mosaic(RepVict[-c(4,7),-c(4,7)], gp = shading_max, main = ""Repeat Victimization Data"")"
"vcd-Rochdale","vcd","Rochdale","Rochdale Data",256,9,8,0,8,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Rochdale.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Rochdale.html","Rochdale R Documentation   Rochdale Data   Description  
Information on 665 households of Rochdale, Lancashire, UK. The study was conducted to identify influence factors on economical activity of wives.   Usage    data(""Rochdale"")    Format  
A 8-dimensional array resulting from cross-tabulating 665 observations on 8 variables. The variables and their levels are as follows:   
 No Name Levels
 1 EconActive yes, no
 2 Age <38, >38
 3 HusbandEmployed yes, no
 4 Child yes, no
 5 Education yes, no
 6 HusbandEducation yes, no
 7 Asian yes, no
 8 HouseholdWorking yes, no
    Note  
Many observations are missing: only 91 out of all 256 combinations contain information.    Source  
Whittaker (1990).    References  
H. Hofmann (2003). Constructing and reading mosaicplots.  Computational Statistics & Data Analysis ,  43 , 4, 565–580.   
J. Whittaker (1990),  Graphical Models on Applied Multivariate Statistics , Wiley, New York.    Examples    data(""Rochdale"") mosaic(Rochdale)"
"vcd-Saxony","vcd","Saxony","Families in Saxony",13,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Saxony.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Saxony.html","Saxony R Documentation   Families in Saxony   Description  
Data from Geissler, cited in Sokal & Rohlf (1969) and Lindsey (1995) on gender distributions in families in Saxony in the 19th century.    Usage    data(""Saxony"")    Format  
A 1-way table giving the number of male children in 6115 families of size 12. The variable and its levels are   
 No Name Levels
 1 nMales 0, 1, ..., 12
    Source  
M. Friendly (2000), Visualizing Categorical Data, pages 40–42.    References  
J. K. Lindsey (1995),  Analysis of Frequency and Count Data . Oxford University Press, Oxford, UK.   
R. R. Sokal & F. J. Rohlf (1969),  Biometry. The Principles and Practice of Statistics . W. H. Freeman, San Francisco, CA.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Saxony"") gf <- goodfit(Saxony, type = ""binomial"") summary(gf) plot(gf)"
"vcd-SexualFun","vcd","SexualFun","Sex is Fun",16,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/SexualFun.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/SexualFun.html","SexualFun R Documentation   Sex is Fun   Description  
Data from Hout et al. (1987) given by Agresti (1990) summarizing the responses of married couples to the questionnaire item: Sex is fun for me and my partner: (a) never or occasionally, (b) fairly often, (c) very often, (d) almost always.    Usage    data(""SexualFun"")    Format  
A 2-dimensional array resulting from cross-tabulating the ratings of 91 married couples. The variables and their levels are as follows:   
 No Name Levels
 1 Husband Never Fun, Fairly Often, Very Often, Always Fun
 2 Wife Never Fun, Fairly Often, Very Often, Always Fun    Source  
M. Friendly (2000), Visualizing Categorical Data, page 91.    References  
A. Agresti (1990),  Categorical Data Analysis . Wiley-Interscience, New York.   
M. Hout, O. D. Duncan, M. E. Sobel (1987), Association and heterogeneity: Structural models of similarities and differences,  Sociological Methodology , 17 , 145-184.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""SexualFun"") ## Kappa statistics Kappa(SexualFun) ## Agreement Chart agreementplot(t(SexualFun), weights = 1) ## Partial Agreement Chart and B-Statistics agreementplot(t(SexualFun), xlab = ""Husband's Rating"", ylab = ""Wife's Rating"", main = ""Husband's and Wife's Sexual Fun"")"
"vcd-SpaceShuttle","vcd","SpaceShuttle","Space Shuttle O-ring Failures",24,6,1,0,2,0,4,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/SpaceShuttle.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/SpaceShuttle.html","SpaceShuttle R Documentation   Space Shuttle O-ring Failures   Description  
Data from Dalal et al. (1989) about O-ring failures in the NASA space shuttle program. The damage index comes from a discussion of the data by Tufte (1997).    Usage    data(""SpaceShuttle"")    Format  
A data frame with 24 observations and 6 variables.    FlightNumber
Number of space shuttle flight.   Temperature
temperature during start (in degrees F).   Pressure
pressure.   Fail
did any O-ring failures occur? (no, yes).   nFailures
how many (of six) 0-rings failed?.   Damage
damage index.     Source  
Michael Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/orings.sas     References  
S. Dalal, E. B. Fowlkes, B. Hoadly (1989), Risk analysis of the space shuttle: Pre-Challenger prediction of failure,  Journal of the American Statistical Association ,  84 , 945–957.   
E. R. Tufte (1997),  Visual Explanations: Images and Quantities, Evidence and Narrative . Graphics Press, Cheshire, CT.  
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""SpaceShuttle"") plot(nFailures/6 ~ Temperature, data = SpaceShuttle, xlim = c(30, 81), ylim = c(0,1), main = ""NASA Space Shuttle O-Ring Failures"", ylab = ""Estimated failure probability"", pch = 19, col = 4) fm <- glm(cbind(nFailures, 6 - nFailures) ~ Temperature, data = SpaceShuttle, family = binomial) lines(30 : 81, predict(fm, data.frame(Temperature = 30 : 81), type = ""re""), lwd = 2) abline(v = 31, lty = 3)"
"vcd-Suicide","vcd","Suicide","Suicide Rates in Germany",306,6,1,0,4,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Suicide.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Suicide.html","Suicide R Documentation   Suicide Rates in Germany   Description  
Data from Heuer (1979) on suicide rates in West Germany classified by age, sex, and method of suicide.    Usage    data(""Suicide"")    Format  
A data frame with 306 observations and 6 variables.    Freq
frequency of suicides.   sex
factor indicating sex (male, female).   method
factor indicating method used.   age
age (rounded).   age.group
factor. Age classified into 5 groups.   method2
factor indicating method used (same as method  but some levels are merged).     Source  
Michael Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/suicide.sas     References  
J. Heuer (1979),  Selbstmord bei Kindern und Jugendlichen . Ernst Klett Verlag, Stuttgart.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""Suicide"") structable(~ sex + method2 + age.group, data = Suicide)"
"vcd-Trucks","vcd","Trucks","Truck Accidents Data",24,5,3,0,4,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/Trucks.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/Trucks.html","Trucks R Documentation   Truck Accidents Data   Description  
Data from a study in England in two periods from November 1969 to October 1971 and November 1971 to October 1973. A new compulsory safety measure for trucks was introduced in October 1971. Therefore, the question is whether the safety measure had an effect on the number of accidents and on the point of collision on the truck.    Usage    data(""Trucks"")    Format  
A data frame with 24 observations on 5 variables.    Freq
frequency of accidents involving trucks.   period
factor indicating time period (before, after) 1971-11-01.   collision
factor indicating whether the collision was in the back or forward (including the front and the sides) of the truck (back, forward).   parked
factor indicating whether the truck was parked (yes, no).   light
factor indicating light conditions: day light (daylight), night on an illuminated road (night, illuminate), night on a dark road (night, dark).     Source  
E. B. Andersen (1991), The Statistical Analysis of Categorical Data, Table 6.8.    References  
E. B. Andersen (1991),  The Statistical Analysis of Categorical Data . 2nd edition. Springer-Verlag, Berlin.    Examples    library(MASS) data(""Trucks"") tab <- xtabs(Freq ~ period + collision + light + parked, data = Trucks) loglm(~ (collision + period) * parked * light, data = tab) doubledecker(collision ~ parked + light + period, data = tab) cotabplot(tab, panel = cotab_coindep)"
"vcd-UKSoccer","vcd","UKSoccer","UK Soccer Scores",25,3,0,0,2,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/UKSoccer.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/UKSoccer.html","UKSoccer R Documentation   UK Soccer Scores   Description  
Data from Lee (1997), on the goals scored by Home and Away teams in the Premier Football League, 1995/6 season.    Usage    data(""UKSoccer"")    Format  
A 2-dimensional array resulting from cross-tabulating the number of goals scored in 380 games. The variables and their levels are as follows:   
 No Name Levels
 1 Home 0, 1, ..., 4
 2 Away 0, 1, ..., 4    Source  
M. Friendly (2000), Visualizing Categorical Data, page 27.    References  
A. J. Lee (1997), Modelling scores in the Premier League: Is Manchester United really the best?,  Chance , 10 (1), 15–19.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    See Also  
Bundesliga     Examples    data(""UKSoccer"") mosaic(UKSoccer, gp = shading_max, main = ""UK Soccer Scores"")"
"vcd-VisualAcuity","vcd","VisualAcuity","Visual Acuity in Left and Right Eyes",32,4,1,0,3,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/VisualAcuity.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/VisualAcuity.html","VisualAcuity R Documentation   Visual Acuity in Left and Right Eyes   Description  
Data from Kendall & Stuart (1961) on unaided vision among 3,242 men and 7,477 women, all aged 30-39 and employed in the U.K. Royal Ordnance factories 1943-1946.    Usage    data(""VisualAcuity"")    Format  
A data frame with 32 observations and 4 variables.    Freq
frequency of visual acuity measurements.   right
visual acuity on right eye.   left
visual acuity on left eye.   gender
factor indicating gender of patient.     Source  
M. Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/vision.sas     References  
M. G. Kendall & A. Stuart (1961),  The Advanced Theory of Statistics , Vol. 2. Griffin, London.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""VisualAcuity"") structable(~ gender + left + right, data = VisualAcuity) sieve(Freq ~ left + right | gender, data = VisualAcuity, shade = TRUE) cotabplot(Freq ~ left + right | gender, data = VisualAcuity, panel = cotab_agreementplot)"
"vcd-VonBort","vcd","VonBort","Von Bortkiewicz Horse Kicks Data",280,4,1,0,2,0,2,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/VonBort.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/VonBort.html","VonBort R Documentation   Von Bortkiewicz Horse Kicks Data   Description  
Data from von Bortkiewicz (1898), given by Andrews \& Herzberg (1985), on number of deaths by horse or mule kicks in 14 corps of the Prussian army.    Usage    data(""VonBort"")    Format  
A data frame with 280 observations and 4 variables.    deaths
number of deaths.   year
year of the deaths.   corps
factor indicating the corps.   fisher
factor indicating whether the corresponding corps was considered by Fisher (1925) or not.     Source  
Michael Friendly (2000), Visualizing Categorical Data:  http://euclid.psych.yorku.ca/ftp/sas/vcd/catdata/vonbort.sas     References  
D. F. Andrews \& A. M. Herzberg (1985),  Data: A Collection of Problems from Many Fields for the Student and Research Worker . Springer-Verlag, New York, NY.   
R. A. Fisher (1925),  Statistical Methods for Research Workers . Oliver & Boyd, London.   
L. von Bortkiewicz (1898),  Das Gesetz der kleinen Zahlen . Teubner, Leipzig.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    See Also  
HorseKicks for a popular subsample.    Examples    data(""VonBort"") ## HorseKicks data xtabs(~ deaths, data = VonBort, subset = fisher == ""yes"")"
"vcd-WeldonDice","vcd","WeldonDice","Weldon's Dice Data",11,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/WeldonDice.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/WeldonDice.html","WeldonDice R Documentation   Weldon's Dice Data   Description  
Data from Pearson (1900) about the frequency of 5s and 6s in throws of 12 dice. Weldon tossed the dice 26,306 times and reported his results in a letter to Francis Galton on 1894-02-02.    Usage    data(""WeldonDice"")    Format  
A 1-way table giving the frequency of a 5 or a 6 in 26,306 throws of 12 dice where 10 indicates ‘10 or more’ 5s or 6s. The variable and its levels are   
 No Name Levels
 1 n56 0, 1, ..., 10
    Source  
M. Friendly (2000), Visualizing Categorical Data, pages 20–21.    References  
K. Pearson (1900), On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen by random sampling,  Philosophical Magazine , 50 (5th series), 157–175.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""WeldonDice"") gf <- goodfit(WeldonDice, type = ""binomial"") summary(gf) plot(gf)"
"vcd-WomenQueue","vcd","WomenQueue","Women in Queues",11,2,0,0,1,0,1,"https://vincentarelbundock.github.io/Rdatasets/csv/vcd/WomenQueue.csv","https://vincentarelbundock.github.io/Rdatasets/doc/vcd/WomenQueue.html","WomenQueue R Documentation   Women in Queues   Description  
Data from Jinkinson \& Slater (1981) and Hoaglin \& Tukey (1985) reporting the frequency distribution of females in 100 queues of length 10 in a London Underground station.    Usage    data(""WomenQueue"")    Format  
A 1-way table giving the number of women in 100 queues of length 10. The variable and its levels are  
 No Name Levels
 1 nWomen 0, 1, ..., 10
    Source  
M. Friendly (2000), Visualizing Categorical Data, pages 19–20.    References  
D. C. Hoaglin \& J. W. Tukey (1985), Checking the shape of discrete distributions. In D. C. Hoaglin, F. Mosteller, J. W. Tukey (eds.),  Exploring Data Tables, Trends and Shapes , chapter 9. John Wiley \& Sons, New York.   
R. A. Jinkinson \& M. Slater (1981), Critical discussion of a graphical method for identifying discrete distributions,  The Statistician , 30 , 239–248.   
M. Friendly (2000),  Visualizing Categorical Data . SAS Institute, Cary, NC.    Examples    data(""WomenQueue"") gf <- goodfit(WomenQueue, type = ""binomial"") summary(gf) plot(gf)"
"Statistics-AirlinePassengerMiles","Statistics","AirlinePassengerMiles","Airline Passenger Miles",24,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Revenue passenger miles flown by commercial airlines."
"Statistics-AirplaneGlass","Statistics","AirplaneGlass","Airplane Glass",31,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Time to failure for airplane glass."
"Statistics-AnimalWeights","Statistics","AnimalWeights","Animal Weights",28,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Brain and body weights for 28 animal species."
"Statistics-AnorexiaTreatment","Statistics","AnorexiaTreatment","Anorexia Treatment",72,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Anorexia data on weight change."
"Statistics-AnscombeRegressionLines","Statistics","AnscombeRegressionLines","Anscombe Regression Lines",11,8,0,0,0,0,8,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Anscombe's 4 regression line data."
"Statistics-AustraliaAIDS","Statistics","AustraliaAIDS","Australia AIDS",2843,7,0,4,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Australian AIDS survival data."
"Statistics-AustraliaRainfall","Statistics","AustraliaRainfall","Australia Rainfall",47,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Maximum one-day rainfall for 47 year period in Turramura."
"Statistics-Baboon","Statistics","Baboon","Baboon",152,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Time to descent for sleeping baboons"
"Statistics-BatchChemicalProcessYields","Statistics","BatchChemicalProcessYields","BatchChemicalProcessYields",70,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Yields from a batch chemical process also known as Box-Jenkins Series F"
"Statistics-BeaverBodyTemperatures","Statistics","BeaverBodyTemperatures","Beaver Body Temperatures",114,4,0,0,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Body temperature series of a female beaver."
"Statistics-BelgianCalls","Statistics","BelgianCalls","Belgian Calls",24,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Belgium phone calls 1950-1973."
"Statistics-BiochemicalOxygenDemand","Statistics","BiochemicalOxygenDemand","Biochemical Oxygen Demand",6,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Biochemical experiment of oxygen demand data."
"Statistics-BirthWeightRisk","Statistics","BirthWeightRisk","Birth Weight Risk",189,11,0,0,0,0,11,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Risk factors associated with low infant birth weight."
"Statistics-BlackCherryTrees","Statistics","BlackCherryTrees","Black Cherry Trees",31,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Girth, height and volume of black cherry trees."
"Statistics-BoforsSteel","Statistics","BoforsSteel","Bofors Steel",389,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Yield strength of Bofors steel."
"Statistics-BoilingAlps","Statistics","BoilingAlps","Boiling Alps",17,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Data on boiling points of water in the Alps."
"Statistics-BoneMarrowLeukemia","Statistics","BoneMarrowLeukemia","Bone Marrow Leukemia",137,22,0,0,0,0,22,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Bone marrow transplantation for Leukemia"
"Statistics-BoneMarrowTransplants","Statistics","BoneMarrowTransplants","Bone Marrow Transplants",101,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Autologous and allogeneic bone marrow transplants"
"Statistics-BostonHomes","Statistics","BostonHomes","Boston Homes",506,14,0,0,0,0,14,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Housing values in suburbs of Boston."
"Statistics-BuffaloSnow","Statistics","BuffaloSnow","Buffalo Snow",63,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Snowfall records for Buffalo, New York from 1910 to 1972."
"Statistics-Cabbages","Statistics","Cabbages","Cabbages",60,4,0,2,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Data from a cabbage field trial."
"Statistics-CarStoppingDistances","Statistics","CarStoppingDistances","Car Stopping Distances",50,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Car stopping distances as a function of speed."
"Statistics-CementHeat","Statistics","CementHeat","Cement Heat",13,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Heat evolved by setting cements."
"Statistics-CeramicStrength","Statistics","CeramicStrength","Ceramic Strength",480,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Ceramic break points."
"Statistics-ChanningHouse","Statistics","ChanningHouse","Channing House",462,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Channing House retirement center data"
"Statistics-ChemicalProcessConcentrations","Statistics","ChemicalProcessConcentrations","ChemicalProcessConcentrations",197,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Chemical process concentration readings also known as Box-Jenkins Series A"
"Statistics-ChemicalProcessTemperatures","Statistics","ChemicalProcessTemperatures","ChemicalProcessTemperatures",226,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Every minute readings of a chemical process temperature also known as Box-Jenkins Series C"
"Statistics-ChemicalProcessViscosityReadings","Statistics","ChemicalProcessViscosityReadings","ChemicalProcessViscosityReadings",310,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Chemical process viscosity hourly readings also known as Box-Jenkins Series D"
"Statistics-ChickenWeight","Statistics","ChickenWeight","Chicken Weight",71,2,0,1,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Chickens growth weight."
"Statistics-CopperLevels","Statistics","CopperLevels","Copper Levels",24,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Copper in wholemeal flour."
"Statistics-CosmeticDeterioration","Statistics","CosmeticDeterioration","Cosmetic Deterioration",95,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Time to cosmetic deterioration of breast cancer patients"
"Statistics-CPUPerformance","Statistics","CPUPerformance","CPU Performance",209,10,0,2,0,0,8,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Performance of computer CPUs."
"Statistics-CrabMeasures","Statistics","CrabMeasures","Crab Measures",200,8,0,2,0,0,6,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Morphological measurements on Leptograpsus crabs."
"Statistics-Cushings","Statistics","Cushings","Cushings",27,4,0,2,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Diagnostic tests on patients with Cushing's syndrome."
"Statistics-CyrtoideaeLength","Statistics","CyrtoideaeLength","Cyrtoideae Length",100,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Length of Cyrtoideae."
"Statistics-DenmarkMelanoma","Statistics","DenmarkMelanoma","Denmark Melanoma",205,7,0,0,0,0,7,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Survival from malignant melanoma."
"Statistics-DNaseAssay","Statistics","DNaseAssay","DNase Assay",176,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Elisa assay of DNase data."
"Statistics-EarthquakeWaitingTimes","Statistics","EarthquakeWaitingTimes","Earthquake Waiting Times",62,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Earthquake waiting times."
"Statistics-EconomicFluctuation","Statistics","EconomicFluctuation","Economic Fluctuation",16,7,0,0,0,0,7,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Longley's economic fluctuation data."
"Statistics-EmployeeAttitude","Statistics","EmployeeAttitude","Employee Attitude",30,7,0,0,0,0,7,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Chatterjee-Price attitude data."
"Statistics-EsophagealCancer","Statistics","EsophagealCancer","Esophageal Cancer",88,5,0,3,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Case-control study of esophageal cancer."
"Statistics-FatigueLifeFailures","Statistics","FatigueLifeFailures","Fatigue Life Failures",22,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Fatigue-life of deep-groove ball-bearings."
"Statistics-FemaleHeightsAndWeights","Statistics","FemaleHeightsAndWeights","Female Heights And Weights",15,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Female heights and weights data."
"Statistics-FiberStrength","Statistics","FiberStrength","Fiber Strength",3000,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Fiber strength of Indian cotton."
"Statistics-FisherCats","Statistics","FisherCats","Fisher's Cats",144,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Anatomical data from domestic cats."
"Statistics-FisherIris","Statistics","FisherIris","Fisher Iris",150,5,0,1,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Fisher's iris data."
"Statistics-FlyAsh","Statistics","FlyAsh","Fly Ash",211,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Fly ash particle diameters."
"Statistics-Formaldehyde","Statistics","Formaldehyde","Formaldehyde",6,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Formaldehyde concentration analysis."
"Statistics-GAGUrineLevels","Statistics","GAGUrineLevels","GAG Urine Levels",314,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Level of GAG in urine of children."
"Statistics-GalaxyVelocity","Statistics","GalaxyVelocity","Galaxy Velocity",82,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Velocities for 82 galaxies."
"Statistics-GasFurnaceData","Statistics","GasFurnaceData","GasFurnaceData",296,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Gas furnace data also known as Box-Jenkins Series J"
"Statistics-GilgaiSoil","Statistics","GilgaiSoil","Gilgai Soil",365,9,0,0,0,0,9,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Line transect of soil in Gilgai territory."
"Statistics-GreatBritanAutoDeaths","Statistics","GreatBritanAutoDeaths","Great Britan Auto Deaths",192,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Deaths of car drivers in Great Britain 1969-84."
"Statistics-GuineaPigToothGrowth","Statistics","GuineaPigToothGrowth","Guinea Pig Tooth Growth",60,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Guinea pigs' tooth growth."
"Statistics-Hodgkins","Statistics","Hodgkins","Hodgkins",43,6,0,0,0,0,6,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Bone marrow transplants for Hodgkin's and non-Hodgkin's lymphoma"
"Statistics-IBMStockClosingPrices","Statistics","IBMStockClosingPrices","IBMStockClosingPrices",369,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","IBM Common Stock Daily Closing Prices also known as Box-Jenkins Series B"
"Statistics-IndomethicinPharmacokinetics","Statistics","IndomethicinPharmacokinetics","Indomethicin Pharmacokinetics",66,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Indomethicin pharmacokinetics experiment."
"Statistics-InternationalAirlinePassengers","Statistics","InternationalAirlinePassengers","InternationalAirlinePassengers",12,13,0,0,0,0,13,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Monthly totals of international airline passegers also known as Box-Jenkins Series G"
"Statistics-KaleDDT","Statistics","KaleDDT","Kale DDT",15,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","DDT in Kale."
"Statistics-KidneyInfection","Statistics","KidneyInfection","Kidney Infection",119,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Times to infection for kidney dialysis patients"
"Statistics-KidneyTransplant","Statistics","KidneyTransplant","Kidney Transplant",863,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Death times of Kidney transplant patients"
"Statistics-LakeMeadLevels","Statistics","LakeMeadLevels","Lake Mead Levels",75,13,0,0,0,0,13,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Lake Mead levels."
"Statistics-LarynxCancer","Statistics","LarynxCancer","Larynx Cancer",90,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Death times of male laryngeal cancer patients"
"Statistics-LifeCycleSavings","Statistics","LifeCycleSavings","Life Cycle Savings",50,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Life-cycle savings hypothesis study."
"Statistics-LoblollyTreeGrowth","Statistics","LoblollyTreeGrowth","Loblolly Tree Growth",83,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Loblolly pine tree growth measurement."
"Statistics-LosAngelesOzoneReadings","Statistics","LosAngelesOzoneReadings","LosAngelesOzoneReadings",18,13,0,0,0,0,13,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Monthly averages of hourly readings of ozone in downtown Los Angeles, also known as Box-Jenkins Series R"
"Statistics-MahanadiRiverFlow","Statistics","MahanadiRiverFlow","Mahanadi River Flow",22,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Mahanadi river flow data."
"Statistics-MarkTwainAuthorship","Statistics","MarkTwainAuthorship","Mark Twain Authorship",13,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Distribution of word lengths for Mark Twain and Quintus Curtius Snodgrass."
"Statistics-MercuryVaporPressure","Statistics","MercuryVaporPressure","Mercury Vapor Pressure",19,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Relation of mercury vapor pressure vs temperature."
"Statistics-MinkFurSales","Statistics","MinkFurSales","MinkFurSales",62,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Annual mink fur sales of Hudson's Bay Company, also known as Box-Jenkins Series L"
"Statistics-MotorFailures","Statistics","MotorFailures","Motor Failures",40,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Accelerated life testing of motorettes."
"Statistics-NewcombLightSpeed","Statistics","NewcombLightSpeed","Newcomb Light Speed",66,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Newcomb's measurements of the passage time of light."
"Statistics-NickelContent","Statistics","NickelContent","Nickel Content",31,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Determinations of nickel content."
"Statistics-OldFaithful","Statistics","OldFaithful","Old Faithful",272,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Old faithful geyser data."
"Statistics-OrangeTreeGrowth","Statistics","OrangeTreeGrowth","Orange Tree Growth",35,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Orange tree growth data."
"Statistics-OtitisMedia","Statistics","OtitisMedia","Otitis Media",220,5,0,4,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Presence of bacteria after drug treatments for ear infections."
"Statistics-OzoneConcentrations","Statistics","OzoneConcentrations","Ozone Concentrations",284,3,0,2,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Ozone concentrations by city and date."
"Statistics-PlantGrowth","Statistics","PlantGrowth","Plant Growth",30,2,0,1,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Comparison of growth of plants by yield weight."
"Statistics-Psychiatric","Statistics","Psychiatric","Psychiatric",26,4,0,0,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Death times of psychiatric patients"
"Statistics-PuromycinReactionVelocity","Statistics","PuromycinReactionVelocity","Puromycin Reaction Velocity",23,3,0,1,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Velocities of enzymatic reactions with or without Puromycin."
"Statistics-QuarterlyRevenue","Statistics","QuarterlyRevenue","Quarterly Revenue",39,5,0,0,0,0,5,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Regression study of revenue data."
"Statistics-RainfallSeeding","Statistics","RainfallSeeding","Rainfall Seeding",52,2,0,1,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Rainfall seeding data."
"Statistics-RiverLengths","Statistics","RiverLengths","River Lengths",141,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Lengths of 141 major rivers in North America."
"Statistics-ScientificDiscoveries","Statistics","ScientificDiscoveries","Scientific Discoveries",100,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Number of great scientific discoveries of each year."
"Statistics-ScottishHillRaces","Statistics","ScottishHillRaces","Scottish Hill Races",35,4,0,1,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Record times in Scottish hill races."
"Statistics-SingerHeights","Statistics","SingerHeights","Singer Heights",235,2,0,1,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Heights of singers."
"Statistics-SoporificDrugs","Statistics","SoporificDrugs","Soporific Drugs",20,3,0,2,0,0,0,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Comparison of the effect of two soporific drugs on sleep."
"Statistics-SP500","Statistics","SP500","Standard and Poor's 500",2780,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Returns of the Standard and Poors 500."
"Statistics-SpeedOfLight","Statistics","SpeedOfLight","Speed Of Light",100,3,0,2,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Michaelson and Morley's speed of light data."
"Statistics-StacklossPlant","Statistics","StacklossPlant","Stackloss Plant",21,4,0,0,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Brownlee's stack loss plant data."
"Statistics-SwissBankNotes","Statistics","SwissBankNotes","Swiss Bank Notes",200,7,0,0,0,0,7,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Swiss bank note data."
"Statistics-SwissFertility","Statistics","SwissFertility","Swiss Fertility",47,6,0,0,0,0,6,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Swiss fertility and socioeconomic indicators (1888)."
"Statistics-Terrorism","Statistics","Terrorism","Terrorism",9101,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","The severity of terrorist attacks."
"Statistics-TimeToAIDS","Statistics","TimeToAIDS","Time to AIDS",295,3,0,0,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Time to AIDS in years for adults and children"
"Statistics-TopOilFields2001","Statistics","TopOilFields2001","Top Oil Fields 2001",116,3,0,2,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Top producing oil fields in 2001."
"Statistics-UgandaVolcanoes","Statistics","UgandaVolcanoes","Uganda Volcanoes",120,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Volcanic craters in Uganda."
"Statistics-UKLungDiseaseDeaths","Statistics","UKLungDiseaseDeaths","UK Lung-Disease Deaths",72,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Monthly deaths from lung diseases in the UK."
"Statistics-UKUnemployment","Statistics","UKUnemployment","UKUnemployment",60,4,0,0,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Unemploymet and GDP data in UK, also known as Box-Jenkins Series P"
"Statistics-UniversitySalaries","Statistics","UniversitySalaries","University Salaries",25438,4,0,2,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Salaries from three university campuses."
"Statistics-USAccidentalDeaths","Statistics","USAccidentalDeaths","US Accidental Deaths",72,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Accidental deaths in the US Jan 1973 - Dec 1978."
"Statistics-USArrests","Statistics","USArrests","US Arrests",50,5,0,1,0,0,4,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","50 US states arrests data in 1973."
"Statistics-USCars1993","Statistics","USCars1993","US Cars 1993",93,26,0,7,0,0,19,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Data from 93 cars on sale in the USA in 1993."
"Statistics-USCityTemperature","Statistics","USCityTemperature","US City Temperature",360,4,0,3,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","US city temperatures."
"Statistics-USEarthquakes","Statistics","USEarthquakes","US Earthquakes",3567,7,0,0,0,0,7,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Earthquakes in the U.S. from July 28th, 1789 to March 24th, 2010."
"Statistics-USHogPrices","Statistics","USHogPrices","USHogPrices",82,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Logged and codded U.S. hog price data, also known as Box-Jenkins Series Q"
"Statistics-USHurricaneLoss","Statistics","USHurricaneLoss","US Hurricane Loss",30,4,0,1,0,0,3,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","U.S. loss due to hurricanes in millions of U.S. Dollars."
"Statistics-USLifeTable2003","Statistics","USLifeTable2003","US Life Table 2003",101,8,0,0,0,0,8,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","U.S. life table 2003."
"Statistics-USStateIncome","Statistics","USStateIncome","US State Income",50,2,0,1,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","United States per capita income by state."
"Statistics-WarpBreaks","Statistics","WarpBreaks","Warp Breaks",54,3,0,2,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Number of breaks in yarn during weaving."
"Statistics-WesternUgandaBorder","Statistics","WesternUgandaBorder","Western Uganda Border",396,2,0,0,0,0,2,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Bounding coordinates for Western Uganda."
"Statistics-WolfSunspotNumbers","Statistics","WolfSunspotNumbers","WolfSunspotNumbers",100,1,0,0,0,0,1,"Missing[""KeyAbsent"", ""CSVURL""]","Missing[""KeyAbsent"", ""DocURL""]","Yearly averages of Wolf sunspot numbers for years 1770-1869, also known as Box-Jenkins Series E"
